The experimental settings are: 
{'path_to_phase1_x': '/home/chenlihui/KDD/kdd/test_x/0001in.csv', 'path_to_test_x': './data/sdwpf_baidukddcup2022_test_toy/test_x', 'path_to_test_y': './data/sdwpf_baidukddcup2022_test_toy/test_y', 'data_path': '../data', 'path_to_mean': 'mean_folder', 'path_to_std': 'std_folder', 'filename': 'wtbdata_245days.csv', 'actual_filename': 'wtbdata_259days.csv', 'use_new_data': False, 'task': 'MS', 'target': 'Patv', 'checkpoints': 'checkpoints', 'turbine_id': 0, 'input_len': 36, 'step_size': 1, 'output_len': 288, 'columns': ['Day', 'Tmstamp', 'Wspd', 'Wdir', 'Etmp', 'Patv'], 'column_pos': [1, 2, 3, 4, 5, 12], 'start_col': 1, 'scale_cols': ['Wspd', 'Wdir', 'Etmp', 'Patv'], 'in_var': 6, 'out_var': 1, 'day_len': 144, 'train_days': 214, 'actual_train_days': 228, 'val_days': 31, 'actual_val_days': 31, 'total_days': 245, 'actual_total_days': 259, 'gru_hidden_size': 12, 'gru_layers': 4, 'dropout': 0.05, 'num_workers': 0, 'train_epochs': 32, 'batch_size': 64, 'patience': 12, 'lr': 2.5e-05, 'lr_adjust': 'type1', 'device': 0, 'capacity': 134, 'pred_file': 'predict.py', 'framework': 'pytorch', 'is_debug': True}

>>>>>>>>> Training Turbine   0 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.5455291271209717
lalalalalal
260 [[ 1.          0.17150681 -0.14099709  0.41267037  0.04118805]
 [ 0.99904822  0.17150681 -0.14099709  0.41267037  0.04118805]
 [ 0.9961947   0.19848733 -0.09091341  0.40483623  0.06959731]
 [ 0.99144486  0.2389581  -0.05079113  0.40001521  0.13125104]
 [ 0.98480775  0.19309122 -0.00596485  0.39820733  0.06884475]]
hahahahahahah
265 [[ 0.99985184  1.          0.17150681 -0.14099709  0.41267037  0.04118805]
 [ 0.99985184  0.99904822  0.17150681 -0.14099709  0.41267037  0.04118805]
 [ 0.99985184  0.9961947   0.19848733 -0.09091341  0.40483623  0.06959731]
 [ 0.99985184  0.99144486  0.2389581  -0.05079113  0.40001521  0.13125104]
 [ 0.99985184  0.98480775  0.19309122 -0.00596485  0.39820733  0.06884475]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.17150681 -0.14099709  0.41267037  0.04118805]
 [ 0.99985184  0.99904822  0.17150681 -0.14099709  0.41267037  0.04118805]
 [ 0.99985184  0.9961947   0.19848733 -0.09091341  0.40483623  0.06959731]
 [ 0.99985184  0.99144486  0.2389581  -0.05079113  0.40001521  0.13125104]
 [ 0.99985184  0.98480775  0.19309122 -0.00596485  0.39820733  0.06884475]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.5488011837005615
lalalalalal
260 [[ 1.          0.22411882 -0.03349704 -1.28914742  0.08758357]
 [ 0.99904822  0.11484773 -0.11803054 -1.26926074 -0.0932009 ]
 [ 0.9961947   0.4170295  -0.01703307 -1.29276318  0.39099819]
 [ 0.99144486  0.600497   -0.01039214 -1.37291253  0.60839485]
 [ 0.98480775  0.59779895 -0.03889279 -1.31988138  0.60465085]]
hahahahahahah
265 [[-0.84754092  1.          0.22411882 -0.03349704 -1.28914742  0.08758357]
 [-0.84754092  0.99904822  0.11484773 -0.11803054 -1.26926074 -0.0932009 ]
 [-0.84754092  0.9961947   0.4170295  -0.01703307 -1.29276318  0.39099819]
 [-0.84754092  0.99144486  0.600497   -0.01039214 -1.37291253  0.60839485]
 [-0.84754092  0.98480775  0.59779895 -0.03889279 -1.31988138  0.60465085]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.22411882 -0.03349704 -1.28914742  0.08758357]
 [-0.84754092  0.99904822  0.11484773 -0.11803054 -1.26926074 -0.0932009 ]
 [-0.84754092  0.9961947   0.4170295  -0.01703307 -1.29276318  0.39099819]
 [-0.84754092  0.99144486  0.600497   -0.01039214 -1.37291253  0.60839485]
 [-0.84754092  0.98480775  0.59779895 -0.03889279 -1.31988138  0.60465085]]

Epoch: 0, 
Train Loss: 0.9886248974489564, 
Validation Loss: 0.6586602535098791
Elapsed time for epoch-0: 4.369430065155029
common line69: model saved with val loss 0.6586602535098791

Epoch: 1, 
Train Loss: 0.9337563445838559, 
Validation Loss: 0.6422764100134373
Elapsed time for epoch-1: 2.4711263179779053
common line69: model saved with val loss 0.6422764100134373

Epoch: 2, 
Train Loss: 0.9215930050411144, 
Validation Loss: 0.6431969814002514
Elapsed time for epoch-2: 2.4315314292907715

Epoch: 3, 
Train Loss: 0.9151899080817439, 
Validation Loss: 0.6356662511825562
Elapsed time for epoch-3: 2.7793304920196533
common line69: model saved with val loss 0.6356662511825562

Epoch: 4, 
Train Loss: 0.910481511169121, 
Validation Loss: 0.6442986819893122
Elapsed time for epoch-4: 2.619887351989746

Epoch: 5, 
Train Loss: 0.9071003764617342, 
Validation Loss: 0.637438153848052
Elapsed time for epoch-5: 2.6097357273101807

Epoch: 6, 
Train Loss: 0.9044712620372531, 
Validation Loss: 0.6339147975668311
Elapsed time for epoch-6: 2.450544834136963
common line69: model saved with val loss 0.6339147975668311

Epoch: 7, 
Train Loss: 0.9024965620341421, 
Validation Loss: 0.6339113432914019
Elapsed time for epoch-7: 2.7092373371124268
common line69: model saved with val loss 0.6339113432914019

Epoch: 8, 
Train Loss: 0.9006814856489166, 
Validation Loss: 0.6346379164606333
Elapsed time for epoch-8: 2.775672674179077

Epoch: 9, 
Train Loss: 0.8989872923668694, 
Validation Loss: 0.6236841664649546
Elapsed time for epoch-9: 2.4401726722717285
common line69: model saved with val loss 0.6236841664649546

Epoch: 10, 
Train Loss: 0.8975086594078722, 
Validation Loss: 0.6228850320912898
Elapsed time for epoch-10: 2.5881214141845703
common line69: model saved with val loss 0.6228850320912898

Epoch: 11, 
Train Loss: 0.8966322884339244, 
Validation Loss: 0.6219389624893665
Elapsed time for epoch-11: 2.6842236518859863
common line69: model saved with val loss 0.6219389624893665

Epoch: 12, 
Train Loss: 0.8956142143041146, 
Validation Loss: 0.6236204672604799
Elapsed time for epoch-12: 2.432676076889038

Epoch: 13, 
Train Loss: 0.89462991409442, 
Validation Loss: 0.6238984931260347
Elapsed time for epoch-13: 2.6029841899871826

Epoch: 14, 
Train Loss: 0.8939186717782702, 
Validation Loss: 0.6208463162183762
Elapsed time for epoch-14: 2.6679282188415527
common line69: model saved with val loss 0.6208463162183762

Epoch: 15, 
Train Loss: 0.8931368927494818, 
Validation Loss: 0.6163075584918261
Elapsed time for epoch-15: 2.46480131149292
common line69: model saved with val loss 0.6163075584918261

Epoch: 16, 
Train Loss: 0.8926287765512947, 
Validation Loss: 0.6172012044116855
Elapsed time for epoch-16: 2.75317120552063

Epoch: 17, 
Train Loss: 0.8922674489371917, 
Validation Loss: 0.6200823932886124
Elapsed time for epoch-17: 2.516979455947876

Epoch: 18, 
Train Loss: 0.8915694640213702, 
Validation Loss: 0.6199549240991473
Elapsed time for epoch-18: 2.7531213760375977

Epoch: 19, 
Train Loss: 0.8913579379059687, 
Validation Loss: 0.6161945620551705
Elapsed time for epoch-19: 2.499788522720337
common line69: model saved with val loss 0.6161945620551705

Epoch: 20, 
Train Loss: 0.8907469521049692, 
Validation Loss: 0.616820523981005
Elapsed time for epoch-20: 2.5332210063934326

Epoch: 21, 
Train Loss: 0.8901727702938208, 
Validation Loss: 0.6112646544352174
Elapsed time for epoch-21: 2.648073434829712
common line69: model saved with val loss 0.6112646544352174

Epoch: 22, 
Train Loss: 0.8899004155096888, 
Validation Loss: 0.6166189922951162
Elapsed time for epoch-22: 2.882941961288452

Epoch: 23, 
Train Loss: 0.889405862623904, 
Validation Loss: 0.6073841135948896
Elapsed time for epoch-23: 2.6240696907043457
common line69: model saved with val loss 0.6073841135948896

Epoch: 24, 
Train Loss: 0.8888822661227539, 
Validation Loss: 0.6100432015955448
Elapsed time for epoch-24: 2.591775417327881

Epoch: 25, 
Train Loss: 0.8884544992396811, 
Validation Loss: 0.6118370271287858
Elapsed time for epoch-25: 2.590268135070801

Epoch: 26, 
Train Loss: 0.8882525491864741, 
Validation Loss: 0.6082597407512367
Elapsed time for epoch-26: 2.5394787788391113

Epoch: 27, 
Train Loss: 0.8879574393274403, 
Validation Loss: 0.6073825266212225
Elapsed time for epoch-27: 2.6815950870513916
common line69: model saved with val loss 0.6073825266212225

Epoch: 28, 
Train Loss: 0.8876370325559327, 
Validation Loss: 0.6086901370435953
Elapsed time for epoch-28: 2.855147361755371

Epoch: 29, 
Train Loss: 0.8870266317820349, 
Validation Loss: 0.6100182798691094
Elapsed time for epoch-29: 2.7037527561187744

Epoch: 30, 
Train Loss: 0.8868635974260939, 
Validation Loss: 0.6080957781523466
Elapsed time for epoch-30: 2.831329107284546

Epoch: 31, 
Train Loss: 0.8864344635180065, 
Validation Loss: 0.6083082887344062
Elapsed time for epoch-31: 2.547393321990967

train line101: min loss for the epoch 31 is 0.6073825266212225

Training the 0-th turbine in 156.2780797481537 secs

>>>>>>>>> Training Turbine   1 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir  ...  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  ...   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  ...   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  ...   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  ...   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.602262258529663
lalalalalal
260 [[ 1.         -0.0663848  -0.165754   -0.43702372 -0.19265256]
 [ 0.99904822  0.32748227 -0.26174468  0.76880359  0.10173783]
 [ 0.9961947   0.37257143 -0.36431468  0.7574716   0.10139557]
 [ 0.99144486  0.43622672 -0.36363988  0.75232069  0.15446606]
 [ 0.98480775  0.36726683 -0.3180907   0.75232069  0.11900017]]
hahahahahahah
265 [[ 0.99985184  1.         -0.0663848  -0.165754   -0.43702372 -0.19265256]
 [ 0.99985184  0.99904822  0.32748227 -0.26174468  0.76880359  0.10173783]
 [ 0.99985184  0.9961947   0.37257143 -0.36431468  0.7574716   0.10139557]
 [ 0.99985184  0.99144486  0.43622672 -0.36363988  0.75232069  0.15446606]
 [ 0.99985184  0.98480775  0.36726683 -0.3180907   0.75232069  0.11900017]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.0663848  -0.165754   -0.43702372 -0.19265256]
 [ 0.99985184  0.99904822  0.32748227 -0.26174468  0.76880359  0.10173783]
 [ 0.99985184  0.9961947   0.37257143 -0.36431468  0.7574716   0.10139557]
 [ 0.99985184  0.99144486  0.43622672 -0.36363988  0.75232069  0.15446606]
 [ 0.99985184  0.98480775  0.36726683 -0.3180907   0.75232069  0.11900017]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir  ...  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  ...   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  ...   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  ...   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  ...   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.60101580619812
lalalalalal
260 [[ 1.          0.07153498  0.00244057 -2.28568423  0.14343912]
 [ 0.99904822 -0.10749551 -0.00295785 -2.29598604 -0.12318606]
 [ 0.9961947   0.31156845 -0.0154417  -2.29598604  0.43964772]
 [ 0.99144486  0.58210341 -0.04175901 -2.30113695  0.90282193]
 [ 0.98480775  0.64310639 -0.10012944 -2.31761985  0.92472608]]
hahahahahahah
265 [[-0.84754092  1.          0.07153498  0.00244057 -2.28568423  0.14343912]
 [-0.84754092  0.99904822 -0.10749551 -0.00295785 -2.29598604 -0.12318606]
 [-0.84754092  0.9961947   0.31156845 -0.0154417  -2.29598604  0.43964772]
 [-0.84754092  0.99144486  0.58210341 -0.04175901 -2.30113695  0.90282193]
 [-0.84754092  0.98480775  0.64310639 -0.10012944 -2.31761985  0.92472608]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.07153498  0.00244057 -2.28568423  0.14343912]
 [-0.84754092  0.99904822 -0.10749551 -0.00295785 -2.29598604 -0.12318606]
 [-0.84754092  0.9961947   0.31156845 -0.0154417  -2.29598604  0.43964772]
 [-0.84754092  0.99144486  0.58210341 -0.04175901 -2.30113695  0.90282193]
 [-0.84754092  0.98480775  0.64310639 -0.10012944 -2.31761985  0.92472608]]

Epoch: 0, 
Train Loss: 0.992484147683913, 
Validation Loss: 0.862525830976665
Elapsed time for epoch-0: 2.4239892959594727
common line69: model saved with val loss 0.862525830976665

Epoch: 1, 
Train Loss: 0.9521435127288354, 
Validation Loss: 0.8636123156175017
Elapsed time for epoch-1: 2.908417224884033

Epoch: 2, 
Train Loss: 0.9409235559341287, 
Validation Loss: 0.8508020164445043
Elapsed time for epoch-2: 2.738741159439087
common line69: model saved with val loss 0.8508020164445043

Epoch: 3, 
Train Loss: 0.9342081198672286, 
Validation Loss: 0.8538226159289479
Elapsed time for epoch-3: 2.506510019302368

Epoch: 4, 
Train Loss: 0.9302915211986093, 
Validation Loss: 0.8519688481464982
Elapsed time for epoch-4: 2.6860694885253906

Epoch: 5, 
Train Loss: 0.9273514638678366, 
Validation Loss: 0.8474936578422785
Elapsed time for epoch-5: 2.6350743770599365
common line69: model saved with val loss 0.8474936578422785

Epoch: 6, 
Train Loss: 0.9252829628080881, 
Validation Loss: 0.8544412776827812
Elapsed time for epoch-6: 2.670408010482788

Epoch: 7, 
Train Loss: 0.9233059092980473, 
Validation Loss: 0.8574235066771507
Elapsed time for epoch-7: 2.8020997047424316

Epoch: 8, 
Train Loss: 0.921569704633801, 
Validation Loss: 0.8546694600954652
Elapsed time for epoch-8: 2.3077023029327393

Epoch: 9, 
Train Loss: 0.9203839432291624, 
Validation Loss: 0.8552124900743365
Elapsed time for epoch-9: 2.3470187187194824

Epoch: 10, 
Train Loss: 0.9186729796293402, 
Validation Loss: 0.8633188428357244
Elapsed time for epoch-10: 2.7629685401916504

Epoch: 11, 
Train Loss: 0.9173617941491744, 
Validation Loss: 0.8537904135882854
Elapsed time for epoch-11: 2.6252007484436035

Epoch: 12, 
Train Loss: 0.9160321497616648, 
Validation Loss: 0.8607024643570185
Elapsed time for epoch-12: 2.371994972229004

Epoch: 13, 
Train Loss: 0.9143677758319038, 
Validation Loss: 0.8667624667286873
Elapsed time for epoch-13: 2.479396343231201

Epoch: 14, 
Train Loss: 0.9133673897560906, 
Validation Loss: 0.8622398627921939
Elapsed time for epoch-14: 2.672281265258789

Epoch: 15, 
Train Loss: 0.9121973239073232, 
Validation Loss: 0.8544008331373334
Elapsed time for epoch-15: 2.876046895980835

Epoch: 16, 
Train Loss: 0.9112949549150067, 
Validation Loss: 0.863492482341826
Elapsed time for epoch-16: 2.4817073345184326

Epoch: 17, 
Train Loss: 0.9105618895352388, 
Validation Loss: 0.8631532154977322
Elapsed time for epoch-17: 3.051518678665161
Early stopped! 

train line101: min loss for the epoch 17 is 0.8474936578422785

Training the 1-th turbine in 118.52080774307251 secs

>>>>>>>>> Training Turbine   2 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  ...  Pab3  Prtv    Patv
0       1    1   00:00  ...   NaN   NaN     NaN
1       1    1   00:10  ...   1.0 -0.25  494.66
2       1    1   00:20  ...   1.0 -0.24  509.76
3       1    1   00:30  ...   1.0 -0.26  542.53
4       1    1   00:40  ...   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.698338508605957
lalalalalal
260 [[ 1.         -0.09854567 -0.28591457 -0.66807522 -0.1849105 ]
 [ 0.99904822  0.24871884 -0.42497614  0.41758736  0.1303128 ]
 [ 0.9961947   0.22927202 -0.36379566  0.41238312  0.18621146]
 [ 0.99144486  0.22371579 -0.3661106   0.41238312  0.10283791]
 [ 0.98480775  0.2070471  -0.38363798  0.41064837  0.16312243]]
hahahahahahah
265 [[ 0.99985184  1.         -0.09854567 -0.28591457 -0.66807522 -0.1849105 ]
 [ 0.99985184  0.99904822  0.24871884 -0.42497614  0.41758736  0.1303128 ]
 [ 0.99985184  0.9961947   0.22927202 -0.36379566  0.41238312  0.18621146]
 [ 0.99985184  0.99144486  0.22371579 -0.3661106   0.41238312  0.10283791]
 [ 0.99985184  0.98480775  0.2070471  -0.38363798  0.41064837  0.16312243]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.09854567 -0.28591457 -0.66807522 -0.1849105 ]
 [ 0.99985184  0.99904822  0.24871884 -0.42497614  0.41758736  0.1303128 ]
 [ 0.99985184  0.9961947   0.22927202 -0.36379566  0.41238312  0.18621146]
 [ 0.99985184  0.99144486  0.22371579 -0.3661106   0.41238312  0.10283791]
 [ 0.99985184  0.98480775  0.2070471  -0.38363798  0.41064837  0.16312243]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  ...  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN  ...   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17  ...   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27  ...   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42  ...   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  ...   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.6768929958343506
lalalalalal
260 [[ 1.          0.09592246 -0.12320756 -1.37440643  0.15597431]
 [ 0.99904822  0.30428116 -0.16702601 -1.37382818  0.58591533]
 [ 0.9961947   0.5543116  -0.25565503 -1.37382818  0.94321551]
 [ 0.99144486  0.46541189 -0.19050609 -1.38654966  0.86416456]
 [ 0.98480775  0.46541189 -0.19976584 -1.40331888  0.87776495]]
hahahahahahah
265 [[-0.84754092  1.          0.09592246 -0.12320756 -1.37440643  0.15597431]
 [-0.84754092  0.99904822  0.30428116 -0.16702601 -1.37382818  0.58591533]
 [-0.84754092  0.9961947   0.5543116  -0.25565503 -1.37382818  0.94321551]
 [-0.84754092  0.99144486  0.46541189 -0.19050609 -1.38654966  0.86416456]
 [-0.84754092  0.98480775  0.46541189 -0.19976584 -1.40331888  0.87776495]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.09592246 -0.12320756 -1.37440643  0.15597431]
 [-0.84754092  0.99904822  0.30428116 -0.16702601 -1.37382818  0.58591533]
 [-0.84754092  0.9961947   0.5543116  -0.25565503 -1.37382818  0.94321551]
 [-0.84754092  0.99144486  0.46541189 -0.19050609 -1.38654966  0.86416456]
 [-0.84754092  0.98480775  0.46541189 -0.19976584 -1.40331888  0.87776495]]

Epoch: 0, 
Train Loss: 1.0008872977825773, 
Validation Loss: 0.9197810580953956
Elapsed time for epoch-0: 2.6303675174713135
common line69: model saved with val loss 0.9197810580953956

Epoch: 1, 
Train Loss: 0.9550285646144081, 
Validation Loss: 0.8366307392716408
Elapsed time for epoch-1: 2.6609323024749756
common line69: model saved with val loss 0.8366307392716408

Epoch: 2, 
Train Loss: 0.9334919691837135, 
Validation Loss: 0.818256800994277
Elapsed time for epoch-2: 2.7711985111236572
common line69: model saved with val loss 0.818256800994277

Epoch: 3, 
Train Loss: 0.9264376594238922, 
Validation Loss: 0.8210359802469611
Elapsed time for epoch-3: 2.853731870651245

Epoch: 4, 
Train Loss: 0.9224590535173897, 
Validation Loss: 0.8261853205040097
Elapsed time for epoch-4: 2.4606995582580566

Epoch: 5, 
Train Loss: 0.9201927052325561, 
Validation Loss: 0.8212981214746833
Elapsed time for epoch-5: 2.6994242668151855

Epoch: 6, 
Train Loss: 0.9183587682347337, 
Validation Loss: 0.8118616119027138
Elapsed time for epoch-6: 2.466554641723633
common line69: model saved with val loss 0.8118616119027138

Epoch: 7, 
Train Loss: 0.9167868903204173, 
Validation Loss: 0.8193135028705001
Elapsed time for epoch-7: 2.788938283920288

Epoch: 8, 
Train Loss: 0.9157032046247932, 
Validation Loss: 0.8147320076823235
Elapsed time for epoch-8: 2.6389577388763428

Epoch: 9, 
Train Loss: 0.9142849913665226, 
Validation Loss: 0.8165264697745442
Elapsed time for epoch-9: 2.4159038066864014

Epoch: 10, 
Train Loss: 0.9129591206041705, 
Validation Loss: 0.8214156711474061
Elapsed time for epoch-10: 2.4139866828918457

Epoch: 11, 
Train Loss: 0.9116786546817347, 
Validation Loss: 0.8094076924026012
Elapsed time for epoch-11: 2.3930766582489014
common line69: model saved with val loss 0.8094076924026012

Epoch: 12, 
Train Loss: 0.9103173349334412, 
Validation Loss: 0.8046126523986459
Elapsed time for epoch-12: 2.546787977218628
common line69: model saved with val loss 0.8046126523986459

Epoch: 13, 
Train Loss: 0.9089921180691037, 
Validation Loss: 0.8154179556295276
Elapsed time for epoch-13: 2.5332865715026855

Epoch: 14, 
Train Loss: 0.9074567404865217, 
Validation Loss: 0.8165793642401695
Elapsed time for epoch-14: 2.450608253479004

Epoch: 15, 
Train Loss: 0.9060384405761206, 
Validation Loss: 0.8153716372326016
Elapsed time for epoch-15: 2.555786609649658

Epoch: 16, 
Train Loss: 0.9047929411675749, 
Validation Loss: 0.8102257149294019
Elapsed time for epoch-16: 2.7642722129821777

Epoch: 17, 
Train Loss: 0.9037468865388582, 
Validation Loss: 0.8110412899404764
Elapsed time for epoch-17: 2.374312162399292

Epoch: 18, 
Train Loss: 0.9028452552166306, 
Validation Loss: 0.8098514778539538
Elapsed time for epoch-18: 2.800203323364258

Epoch: 19, 
Train Loss: 0.9018867941213256, 
Validation Loss: 0.805109042674303
Elapsed time for epoch-19: 2.9899673461914062

Epoch: 20, 
Train Loss: 0.9014712979062265, 
Validation Loss: 0.8079860704019666
Elapsed time for epoch-20: 3.2459053993225098

Epoch: 21, 
Train Loss: 0.9008366364140471, 
Validation Loss: 0.8021452808752656
Elapsed time for epoch-21: 3.149799346923828
common line69: model saved with val loss 0.8021452808752656

Epoch: 22, 
Train Loss: 0.9004309466656517, 
Validation Loss: 0.8120481548830867
Elapsed time for epoch-22: 3.1127328872680664

Epoch: 23, 
Train Loss: 0.8998611345261085, 
Validation Loss: 0.8090789588168263
Elapsed time for epoch-23: 3.158928394317627

Epoch: 24, 
Train Loss: 0.8993362065623788, 
Validation Loss: 0.8061980940401554
Elapsed time for epoch-24: 3.12007212638855

Epoch: 25, 
Train Loss: 0.8989877288832384, 
Validation Loss: 0.8082511033862829
Elapsed time for epoch-25: 2.9294159412384033

Epoch: 26, 
Train Loss: 0.8987531322641533, 
Validation Loss: 0.8112654415890574
Elapsed time for epoch-26: 3.1023168563842773

Epoch: 27, 
Train Loss: 0.8983684735638755, 
Validation Loss: 0.8092891788110137
Elapsed time for epoch-27: 3.05090069770813

Epoch: 28, 
Train Loss: 0.8982687918077997, 
Validation Loss: 0.8100696476176381
Elapsed time for epoch-28: 3.22562837600708

Epoch: 29, 
Train Loss: 0.8978936451823771, 
Validation Loss: 0.8072667922824621
Elapsed time for epoch-29: 3.1319589614868164

Epoch: 30, 
Train Loss: 0.8975167676430791, 
Validation Loss: 0.8098111525177956
Elapsed time for epoch-30: 3.0188424587249756

Epoch: 31, 
Train Loss: 0.8975806758433831, 
Validation Loss: 0.811499061062932
Elapsed time for epoch-31: 3.054629325866699

train line101: min loss for the epoch 31 is 0.8021452808752656

Training the 2-th turbine in 163.64302277565002 secs

>>>>>>>>> Training Turbine   3 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir  ...  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  ...   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  ...   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  ...   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  ...   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.7507641315460205
lalalalalal
260 [[ 1.         -0.26245316  0.04254105 -0.72653044 -0.22348375]
 [ 0.99904822  0.10108834 -0.13996394  0.36445792  0.14927624]
 [ 0.9961947   0.13772431 -0.30843008  0.35817343  0.15211156]
 [ 0.99144486  0.21099624 -0.26083497  0.35126048  0.22295206]
 [ 0.98480775  0.13772431 -0.23686621  0.35000358  0.15492557]]
hahahahahahah
265 [[ 0.99985184  1.         -0.26245316  0.04254105 -0.72653044 -0.22348375]
 [ 0.99985184  0.99904822  0.10108834 -0.13996394  0.36445792  0.14927624]
 [ 0.99985184  0.9961947   0.13772431 -0.30843008  0.35817343  0.15211156]
 [ 0.99985184  0.99144486  0.21099624 -0.26083497  0.35126048  0.22295206]
 [ 0.99985184  0.98480775  0.13772431 -0.23686621  0.35000358  0.15492557]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.26245316  0.04254105 -0.72653044 -0.22348375]
 [ 0.99985184  0.99904822  0.10108834 -0.13996394  0.36445792  0.14927624]
 [ 0.99985184  0.9961947   0.13772431 -0.30843008  0.35817343  0.15211156]
 [ 0.99985184  0.99144486  0.21099624 -0.26083497  0.35126048  0.22295206]
 [ 0.99985184  0.98480775  0.13772431 -0.23686621  0.35000358  0.15492557]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.119712829589844
lalalalalal
260 [[ 1.         -0.07222795 -0.0598398  -1.26825392 -0.05312974]
 [ 0.99904822 -0.07645518 -0.1040108  -1.27705222 -0.11481405]
 [ 0.9961947   0.15181506  0.10999598 -1.26951082  0.30875795]
 [ 0.99144486  0.35472195  0.1325951  -1.26448323  0.73348113]
 [ 0.98480775  0.49562951 -0.0314197  -1.26511167  0.98625144]]
hahahahahahah
265 [[-0.84754092  1.         -0.07222795 -0.0598398  -1.26825392 -0.05312974]
 [-0.84754092  0.99904822 -0.07645518 -0.1040108  -1.27705222 -0.11481405]
 [-0.84754092  0.9961947   0.15181506  0.10999598 -1.26951082  0.30875795]
 [-0.84754092  0.99144486  0.35472195  0.1325951  -1.26448323  0.73348113]
 [-0.84754092  0.98480775  0.49562951 -0.0314197  -1.26511167  0.98625144]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.07222795 -0.0598398  -1.26825392 -0.05312974]
 [-0.84754092  0.99904822 -0.07645518 -0.1040108  -1.27705222 -0.11481405]
 [-0.84754092  0.9961947   0.15181506  0.10999598 -1.26951082  0.30875795]
 [-0.84754092  0.99144486  0.35472195  0.1325951  -1.26448323  0.73348113]
 [-0.84754092  0.98480775  0.49562951 -0.0314197  -1.26511167  0.98625144]]

Epoch: 0, 
Train Loss: 1.0016120912648048, 
Validation Loss: 0.8317803917452693
Elapsed time for epoch-0: 3.595421314239502
common line69: model saved with val loss 0.8317803917452693

Epoch: 1, 
Train Loss: 0.9492895316426494, 
Validation Loss: 0.7922312514856458
Elapsed time for epoch-1: 4.239179849624634
common line69: model saved with val loss 0.7922312514856458

Epoch: 2, 
Train Loss: 0.939076536593317, 
Validation Loss: 0.7893277406692505
Elapsed time for epoch-2: 4.263169050216675
common line69: model saved with val loss 0.7893277406692505

Epoch: 3, 
Train Loss: 0.9344022763626916, 
Validation Loss: 0.7843526965007186
Elapsed time for epoch-3: 4.4405837059021
common line69: model saved with val loss 0.7843526965007186

Epoch: 4, 
Train Loss: 0.9314487508865965, 
Validation Loss: 0.7820025216788054
Elapsed time for epoch-4: 4.511476039886475
common line69: model saved with val loss 0.7820025216788054

Epoch: 5, 
Train Loss: 0.9294786090109529, 
Validation Loss: 0.7821050370112062
Elapsed time for epoch-5: 4.797746419906616

Epoch: 6, 
Train Loss: 0.9279621073177883, 
Validation Loss: 0.7811538381502032
Elapsed time for epoch-6: 4.128232479095459
common line69: model saved with val loss 0.7811538381502032

Epoch: 7, 
Train Loss: 0.9264203542921724, 
Validation Loss: 0.7857848284766078
Elapsed time for epoch-7: 3.4796721935272217

Epoch: 8, 
Train Loss: 0.9252292963386584, 
Validation Loss: 0.7823447659611702
Elapsed time for epoch-8: 3.6065566539764404

Epoch: 9, 
Train Loss: 0.9240641045470198, 
Validation Loss: 0.7775054797530174
Elapsed time for epoch-9: 3.472703695297241
common line69: model saved with val loss 0.7775054797530174

Epoch: 10, 
Train Loss: 0.9225875171793609, 
Validation Loss: 0.7749703461304307
Elapsed time for epoch-10: 3.21869158744812
common line69: model saved with val loss 0.7749703461304307

Epoch: 11, 
Train Loss: 0.921446174007504, 
Validation Loss: 0.7764463014900684
Elapsed time for epoch-11: 4.437852382659912

Epoch: 12, 
Train Loss: 0.919793257442843, 
Validation Loss: 0.7791540808975697
Elapsed time for epoch-12: 3.645402193069458

Epoch: 13, 
Train Loss: 0.9185359056005958, 
Validation Loss: 0.7781383125111461
Elapsed time for epoch-13: 4.479112148284912

Epoch: 14, 
Train Loss: 0.917150450228643, 
Validation Loss: 0.7785540204495192
Elapsed time for epoch-14: 4.813806533813477

Epoch: 15, 
Train Loss: 0.9159029879990745, 
Validation Loss: 0.7803147956728935
Elapsed time for epoch-15: 4.59856104850769

Epoch: 16, 
Train Loss: 0.9148592387928682, 
Validation Loss: 0.7792519116774201
Elapsed time for epoch-16: 4.462865591049194

Epoch: 17, 
Train Loss: 0.9141035530747486, 
Validation Loss: 0.7764274841174483
Elapsed time for epoch-17: 3.9109108448028564

Epoch: 18, 
Train Loss: 0.9134960419991437, 
Validation Loss: 0.7763542113825679
Elapsed time for epoch-18: 4.924038410186768

Epoch: 19, 
Train Loss: 0.9126568763446408, 
Validation Loss: 0.7733200155198574
Elapsed time for epoch-19: 4.171304941177368
common line69: model saved with val loss 0.7733200155198574

Epoch: 20, 
Train Loss: 0.9123479608728104, 
Validation Loss: 0.7732541784644127
Elapsed time for epoch-20: 4.535564184188843
common line69: model saved with val loss 0.7732541784644127

Epoch: 21, 
Train Loss: 0.9116423799961555, 
Validation Loss: 0.7698003500699997
Elapsed time for epoch-21: 4.683448076248169
common line69: model saved with val loss 0.7698003500699997

Epoch: 22, 
Train Loss: 0.911299703251414, 
Validation Loss: 0.7762100286781788
Elapsed time for epoch-22: 4.469658613204956

Epoch: 23, 
Train Loss: 0.9108846821203953, 
Validation Loss: 0.7744174832478166
Elapsed time for epoch-23: 4.432227849960327

Epoch: 24, 
Train Loss: 0.9103324439595727, 
Validation Loss: 0.7741290088742971
Elapsed time for epoch-24: 3.7970685958862305

Epoch: 25, 
Train Loss: 0.9101305344775945, 
Validation Loss: 0.7758020861074328
Elapsed time for epoch-25: 3.538440704345703

Epoch: 26, 
Train Loss: 0.9097624443659261, 
Validation Loss: 0.7740016523748636
Elapsed time for epoch-26: 3.5178604125976562

Epoch: 27, 
Train Loss: 0.9094504577522519, 
Validation Loss: 0.7720776880159974
Elapsed time for epoch-27: 3.8874456882476807

Epoch: 28, 
Train Loss: 0.909253338555328, 
Validation Loss: 0.7762420494109392
Elapsed time for epoch-28: 4.225244522094727

Epoch: 29, 
Train Loss: 0.9088859022164545, 
Validation Loss: 0.7754748091101646
Elapsed time for epoch-29: 4.029205322265625

Epoch: 30, 
Train Loss: 0.9087139575922188, 
Validation Loss: 0.7714766785502434
Elapsed time for epoch-30: 3.03490948677063

Epoch: 31, 
Train Loss: 0.908311526439771, 
Validation Loss: 0.7742377780377865
Elapsed time for epoch-31: 3.4528656005859375

train line101: min loss for the epoch 31 is 0.7698003500699997

Training the 3-th turbine in 222.4232738018036 secs

>>>>>>>>> Training Turbine   4 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.074855327606201
lalalalalal
260 [[ 1.         -0.09949523 -0.09663991 -0.44750494 -0.1026008 ]
 [ 0.99904822  0.1404268  -0.066263    0.52144972  0.14082638]
 [ 0.9961947   0.19252415 -0.20927339  0.51904835  0.14055169]
 [ 0.99144486  0.21171792 -0.19801004  0.51264468  0.22162717]
 [ 0.98480775  0.16510449 -0.18981851  0.51264468  0.13634684]]
hahahahahahah
265 [[ 0.99985184  1.         -0.09949523 -0.09663991 -0.44750494 -0.1026008 ]
 [ 0.99985184  0.99904822  0.1404268  -0.066263    0.52144972  0.14082638]
 [ 0.99985184  0.9961947   0.19252415 -0.20927339  0.51904835  0.14055169]
 [ 0.99985184  0.99144486  0.21171792 -0.19801004  0.51264468  0.22162717]
 [ 0.99985184  0.98480775  0.16510449 -0.18981851  0.51264468  0.13634684]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.09949523 -0.09663991 -0.44750494 -0.1026008 ]
 [ 0.99985184  0.99904822  0.1404268  -0.066263    0.52144972  0.14082638]
 [ 0.99985184  0.9961947   0.19252415 -0.20927339  0.51904835  0.14055169]
 [ 0.99985184  0.99144486  0.21171792 -0.19801004  0.51264468  0.22162717]
 [ 0.99985184  0.98480775  0.16510449 -0.18981851  0.51264468  0.13634684]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.621246814727783
lalalalalal
260 [[ 1.         -0.10909211  0.04517589 -1.85671162 -0.09841707]
 [ 0.99904822 -0.04054296  0.06992112 -1.8551107  -0.05612555]
 [ 0.9961947   0.21171792  0.08391498 -1.91594552  0.32486793]
 [ 0.99144486  0.49139845  0.0845976  -1.92715194  0.7909727 ]
 [ 0.98480775  0.62301282 -0.02223355 -1.93835835  1.03857303]]
hahahahahahah
265 [[-0.84754092  1.         -0.10909211  0.04517589 -1.85671162 -0.09841707]
 [-0.84754092  0.99904822 -0.04054296  0.06992112 -1.8551107  -0.05612555]
 [-0.84754092  0.9961947   0.21171792  0.08391498 -1.91594552  0.32486793]
 [-0.84754092  0.99144486  0.49139845  0.0845976  -1.92715194  0.7909727 ]
 [-0.84754092  0.98480775  0.62301282 -0.02223355 -1.93835835  1.03857303]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.10909211  0.04517589 -1.85671162 -0.09841707]
 [-0.84754092  0.99904822 -0.04054296  0.06992112 -1.8551107  -0.05612555]
 [-0.84754092  0.9961947   0.21171792  0.08391498 -1.91594552  0.32486793]
 [-0.84754092  0.99144486  0.49139845  0.0845976  -1.92715194  0.7909727 ]
 [-0.84754092  0.98480775  0.62301282 -0.02223355 -1.93835835  1.03857303]]

Epoch: 0, 
Train Loss: 0.9994001714121393, 
Validation Loss: 0.5792283797636628
Elapsed time for epoch-0: 5.487914085388184
common line69: model saved with val loss 0.5792283797636628

Epoch: 1, 
Train Loss: 0.9583509604470068, 
Validation Loss: 0.558812920935452
Elapsed time for epoch-1: 5.3488969802856445
common line69: model saved with val loss 0.558812920935452

Epoch: 2, 
Train Loss: 0.948443576568315, 
Validation Loss: 0.5590601181611419
Elapsed time for epoch-2: 4.991964101791382

Epoch: 3, 
Train Loss: 0.941933014437932, 
Validation Loss: 0.5575973419472575
Elapsed time for epoch-3: 3.904101610183716
common line69: model saved with val loss 0.5575973419472575

Epoch: 4, 
Train Loss: 0.9377261397718382, 
Validation Loss: 0.555256434250623
Elapsed time for epoch-4: 3.8021445274353027
common line69: model saved with val loss 0.555256434250623

Epoch: 5, 
Train Loss: 0.9346947349420115, 
Validation Loss: 0.5517915394157171
Elapsed time for epoch-5: 5.034428834915161
common line69: model saved with val loss 0.5517915394157171

Epoch: 6, 
Train Loss: 0.9321239561844272, 
Validation Loss: 0.5457484475336969
Elapsed time for epoch-6: 4.25401759147644
common line69: model saved with val loss 0.5457484475336969

Epoch: 7, 
Train Loss: 0.9299431840161315, 
Validation Loss: 0.5489832926541567
Elapsed time for epoch-7: 4.547770023345947

Epoch: 8, 
Train Loss: 0.9279655547452574, 
Validation Loss: 0.5458808094263077
Elapsed time for epoch-8: 3.8497979640960693

Epoch: 9, 
Train Loss: 0.9258887862958828, 
Validation Loss: 0.5501474030315876
Elapsed time for epoch-9: 3.68912672996521

Epoch: 10, 
Train Loss: 0.9245246407114157, 
Validation Loss: 0.5416234196163714
Elapsed time for epoch-10: 4.1346752643585205
common line69: model saved with val loss 0.5416234196163714

Epoch: 11, 
Train Loss: 0.9225425974411123, 
Validation Loss: 0.5413939212448895
Elapsed time for epoch-11: 4.396945953369141
common line69: model saved with val loss 0.5413939212448895

Epoch: 12, 
Train Loss: 0.9212878717093909, 
Validation Loss: 0.5299153300002217
Elapsed time for epoch-12: 4.152406930923462
common line69: model saved with val loss 0.5299153300002217

Epoch: 13, 
Train Loss: 0.9200172644703328, 
Validation Loss: 0.530511595774442
Elapsed time for epoch-13: 3.852951765060425

Epoch: 14, 
Train Loss: 0.9187534350056609, 
Validation Loss: 0.5282659223303199
Elapsed time for epoch-14: 3.5047249794006348
common line69: model saved with val loss 0.5282659223303199

Epoch: 15, 
Train Loss: 0.9174715787673197, 
Validation Loss: 0.5234607239253819
Elapsed time for epoch-15: 3.3245604038238525
common line69: model saved with val loss 0.5234607239253819

Epoch: 16, 
Train Loss: 0.91667850177829, 
Validation Loss: 0.516391696408391
Elapsed time for epoch-16: 3.118316173553467
common line69: model saved with val loss 0.516391696408391

Epoch: 17, 
Train Loss: 0.9157251391340705, 
Validation Loss: 0.516007112339139
Elapsed time for epoch-17: 3.19553804397583
common line69: model saved with val loss 0.516007112339139

Epoch: 18, 
Train Loss: 0.9152044994490487, 
Validation Loss: 0.5152810593135655
Elapsed time for epoch-18: 3.2099761962890625
common line69: model saved with val loss 0.5152810593135655

Epoch: 19, 
Train Loss: 0.9144738153750155, 
Validation Loss: 0.5133422031067312
Elapsed time for epoch-19: 2.703781843185425
common line69: model saved with val loss 0.5133422031067312

Epoch: 20, 
Train Loss: 0.9136981340516516, 
Validation Loss: 0.5178170865401626
Elapsed time for epoch-20: 3.1026837825775146

Epoch: 21, 
Train Loss: 0.9132937116532767, 
Validation Loss: 0.5119218495674431
Elapsed time for epoch-21: 2.97741961479187
common line69: model saved with val loss 0.5119218495674431

Epoch: 22, 
Train Loss: 0.9125985136302579, 
Validation Loss: 0.5159814795479178
Elapsed time for epoch-22: 3.2872068881988525

Epoch: 23, 
Train Loss: 0.9125499938215528, 
Validation Loss: 0.50685512740165
Elapsed time for epoch-23: 3.895538806915283
common line69: model saved with val loss 0.50685512740165

Epoch: 24, 
Train Loss: 0.9119429245215505, 
Validation Loss: 0.5115678664296865
Elapsed time for epoch-24: 3.551769733428955

Epoch: 25, 
Train Loss: 0.9114210565550989, 
Validation Loss: 0.5089089688844979
Elapsed time for epoch-25: 3.258007526397705

Epoch: 26, 
Train Loss: 0.9109506811164007, 
Validation Loss: 0.5102894180454314
Elapsed time for epoch-26: 3.4539120197296143

Epoch: 27, 
Train Loss: 0.9106137085111201, 
Validation Loss: 0.5066839065402746
Elapsed time for epoch-27: 3.328918218612671
common line69: model saved with val loss 0.5066839065402746

Epoch: 28, 
Train Loss: 0.910152471240829, 
Validation Loss: 0.5104115060530603
Elapsed time for epoch-28: 3.236788749694824

Epoch: 29, 
Train Loss: 0.9100632945529553, 
Validation Loss: 0.505150543525815
Elapsed time for epoch-29: 3.6982786655426025
common line69: model saved with val loss 0.505150543525815

Epoch: 30, 
Train Loss: 0.9097929484203082, 
Validation Loss: 0.5059062973596156
Elapsed time for epoch-30: 3.371027708053589

Epoch: 31, 
Train Loss: 0.9094243441559687, 
Validation Loss: 0.5076409387402236
Elapsed time for epoch-31: 3.6254096031188965

train line101: min loss for the epoch 31 is 0.505150543525815

Training the 4-th turbine in 234.70598101615906 secs

>>>>>>>>> Training Turbine   5 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir  ...  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  ...   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  ...   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  ...   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  ...   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 5.713346004486084
lalalalalal
260 [[ 1.          0.0159154  -0.17921165 -0.68562296 -0.12192132]
 [ 0.99904822  0.31578345 -0.33010558  0.44995245  0.08189975]
 [ 0.9961947   0.23400125 -0.06900072  0.44995245  0.16479557]
 [ 0.99144486  0.27489235 -0.05732936  0.44995245  0.22763763]
 [ 0.98480775  0.19583623 -0.06233137  0.44660366  0.10517458]]
hahahahahahah
265 [[ 0.99985184  1.          0.0159154  -0.17921165 -0.68562296 -0.12192132]
 [ 0.99985184  0.99904822  0.31578345 -0.33010558  0.44995245  0.08189975]
 [ 0.99985184  0.9961947   0.23400125 -0.06900072  0.44995245  0.16479557]
 [ 0.99985184  0.99144486  0.27489235 -0.05732936  0.44995245  0.22763763]
 [ 0.99985184  0.98480775  0.19583623 -0.06233137  0.44660366  0.10517458]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.0159154  -0.17921165 -0.68562296 -0.12192132]
 [ 0.99985184  0.99904822  0.31578345 -0.33010558  0.44995245  0.08189975]
 [ 0.99985184  0.9961947   0.23400125 -0.06900072  0.44995245  0.16479557]
 [ 0.99985184  0.99144486  0.27489235 -0.05732936  0.44995245  0.22763763]
 [ 0.99985184  0.98480775  0.19583623 -0.06233137  0.44660366  0.10517458]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  ...  Pab3  Prtv    Patv
0       1    1   00:00  ...   NaN   NaN     NaN
1       1    1   00:10  ...   1.0 -0.25  494.66
2       1    1   00:20  ...   1.0 -0.24  509.76
3       1    1   00:30  ...   1.0 -0.26  542.53
4       1    1   00:40  ...   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 3.3485913276672363
lalalalalal
260 [[ 1.00000000e+00 -2.77017697e-02 -1.71465589e-02 -1.58745268e+00
  -1.31262427e-01]
 [ 9.99048222e-01  5.68064983e-02 -7.53365961e-02 -1.59281075e+00
  -7.46858719e-02]
 [ 9.96194698e-01  1.71301571e-01  1.13739341e-01 -1.58879220e+00
   2.22899536e-01]
 [ 9.91444861e-01  4.19374229e-01  1.09737734e-01 -1.58678292e+00
   6.52985263e-01]
 [ 9.84807753e-01  5.31143229e-01 -3.06462188e-04 -1.58946195e+00
   8.89287195e-01]]
hahahahahahah
265 [[-8.47540923e-01  1.00000000e+00 -2.77017697e-02 -1.71465589e-02
  -1.58745268e+00 -1.31262427e-01]
 [-8.47540923e-01  9.99048222e-01  5.68064983e-02 -7.53365961e-02
  -1.59281075e+00 -7.46858719e-02]
 [-8.47540923e-01  9.96194698e-01  1.71301571e-01  1.13739341e-01
  -1.58879220e+00  2.22899536e-01]
 [-8.47540923e-01  9.91444861e-01  4.19374229e-01  1.09737734e-01
  -1.58678292e+00  6.52985263e-01]
 [-8.47540923e-01  9.84807753e-01  5.31143229e-01 -3.06462188e-04
  -1.58946195e+00  8.89287195e-01]]

 wind turbine line248 data after normalization: 
 [[-8.47540923e-01  1.00000000e+00 -2.77017697e-02 -1.71465589e-02
  -1.58745268e+00 -1.31262427e-01]
 [-8.47540923e-01  9.99048222e-01  5.68064983e-02 -7.53365961e-02
  -1.59281075e+00 -7.46858719e-02]
 [-8.47540923e-01  9.96194698e-01  1.71301571e-01  1.13739341e-01
  -1.58879220e+00  2.22899536e-01]
 [-8.47540923e-01  9.91444861e-01  4.19374229e-01  1.09737734e-01
  -1.58678292e+00  6.52985263e-01]
 [-8.47540923e-01  9.84807753e-01  5.31143229e-01 -3.06462188e-04
  -1.58946195e+00  8.89287195e-01]]

Epoch: 0, 
Train Loss: 0.995192584119925, 
Validation Loss: 0.8601651759818196
Elapsed time for epoch-0: 4.49614143371582
common line69: model saved with val loss 0.8601651759818196

Epoch: 1, 
Train Loss: 0.9476418943465257, 
Validation Loss: 0.8038190975785255
Elapsed time for epoch-1: 4.090287446975708
common line69: model saved with val loss 0.8038190975785255

Epoch: 2, 
Train Loss: 0.9351388234801653, 
Validation Loss: 0.80101762060076
Elapsed time for epoch-2: 5.197640419006348
common line69: model saved with val loss 0.80101762060076

Epoch: 3, 
Train Loss: 0.9295529716906428, 
Validation Loss: 0.8048746762797236
Elapsed time for epoch-3: 4.156817674636841

Epoch: 4, 
Train Loss: 0.925380604858158, 
Validation Loss: 0.7988075185567141
Elapsed time for epoch-4: 4.3765857219696045
common line69: model saved with val loss 0.7988075185567141

Epoch: 5, 
Train Loss: 0.9226539003498414, 
Validation Loss: 0.8026287788525224
Elapsed time for epoch-5: 4.1985156536102295

Epoch: 6, 
Train Loss: 0.9204932972162712, 
Validation Loss: 0.7995008425787091
Elapsed time for epoch-6: 5.0767738819122314

Epoch: 7, 
Train Loss: 0.9188296165035552, 
Validation Loss: 0.801475927233696
Elapsed time for epoch-7: 4.09015417098999

Epoch: 8, 
Train Loss: 0.917570600740048, 
Validation Loss: 0.8054640106856823
Elapsed time for epoch-8: 4.553021192550659

Epoch: 9, 
Train Loss: 0.9164748120458186, 
Validation Loss: 0.8030959405004978
Elapsed time for epoch-9: 4.367956638336182

Epoch: 10, 
Train Loss: 0.9154794820967842, 
Validation Loss: 0.8027340425178409
Elapsed time for epoch-10: 4.649212121963501

Epoch: 11, 
Train Loss: 0.9147274917414209, 
Validation Loss: 0.7996863313019276
Elapsed time for epoch-11: 4.42576003074646

Epoch: 12, 
Train Loss: 0.9139098901959026, 
Validation Loss: 0.8028075406327844
Elapsed time for epoch-12: 3.818598985671997

Epoch: 13, 
Train Loss: 0.9131815134226775, 
Validation Loss: 0.8009647177532315
Elapsed time for epoch-13: 3.868501901626587

Epoch: 14, 
Train Loss: 0.9124622172167322, 
Validation Loss: 0.7999411104246974
Elapsed time for epoch-14: 3.5254580974578857

Epoch: 15, 
Train Loss: 0.9115560943839931, 
Validation Loss: 0.8094081403687596
Elapsed time for epoch-15: 3.5519795417785645

Epoch: 16, 
Train Loss: 0.9108030878696121, 
Validation Loss: 0.8108779732137918
Elapsed time for epoch-16: 3.210643768310547
Early stopped! 

train line101: min loss for the epoch 16 is 0.7988075185567141

Training the 5-th turbine in 184.4237823486328 secs

>>>>>>>>> Training Turbine   6 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir  ...  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  ...   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  ...   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  ...   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  ...   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 3.3346948623657227
lalalalalal
260 [[ 1.         -0.04050696 -0.16613847 -0.33387538 -0.04861001]
 [ 0.99904822  0.20983216 -0.29424617  0.33307885  0.04324553]
 [ 0.9961947   0.22668191 -0.31863173  0.33268408  0.07939485]
 [ 0.99144486  0.27241694 -0.3664007   0.33268408  0.08805363]
 [ 0.98480775  0.16650424 -0.37274763  0.33110502 -0.03321189]]
hahahahahahah
265 [[ 0.99985184  1.         -0.04050696 -0.16613847 -0.33387538 -0.04861001]
 [ 0.99985184  0.99904822  0.20983216 -0.29424617  0.33307885  0.04324553]
 [ 0.99985184  0.9961947   0.22668191 -0.31863173  0.33268408  0.07939485]
 [ 0.99985184  0.99144486  0.27241694 -0.3664007   0.33268408  0.08805363]
 [ 0.99985184  0.98480775  0.16650424 -0.37274763  0.33110502 -0.03321189]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.04050696 -0.16613847 -0.33387538 -0.04861001]
 [ 0.99985184  0.99904822  0.20983216 -0.29424617  0.33307885  0.04324553]
 [ 0.99985184  0.9961947   0.22668191 -0.31863173  0.33268408  0.07939485]
 [ 0.99985184  0.99144486  0.27241694 -0.3664007   0.33268408  0.08805363]
 [ 0.99985184  0.98480775  0.16650424 -0.37274763  0.33110502 -0.03321189]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir  ...  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  ...   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  ...   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  ...   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  ...   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 4.371503591537476
lalalalalal
260 [[ 1.          0.01244939 -0.01531545 -0.8816108  -0.1301006 ]
 [ 0.99904822  0.10151235 -0.03268599 -0.88318986 -0.03515265]
 [ 0.9961947   0.24112455  0.14903654 -0.88911132  0.26677417]
 [ 0.99144486  0.37351544  0.10026542 -0.89108514  0.53986684]
 [ 0.98480775  0.45294997  0.09391849 -0.89108514  0.71327695]]
hahahahahahah
265 [[-0.84754092  1.          0.01244939 -0.01531545 -0.8816108  -0.1301006 ]
 [-0.84754092  0.99904822  0.10151235 -0.03268599 -0.88318986 -0.03515265]
 [-0.84754092  0.9961947   0.24112455  0.14903654 -0.88911132  0.26677417]
 [-0.84754092  0.99144486  0.37351544  0.10026542 -0.89108514  0.53986684]
 [-0.84754092  0.98480775  0.45294997  0.09391849 -0.89108514  0.71327695]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.01244939 -0.01531545 -0.8816108  -0.1301006 ]
 [-0.84754092  0.99904822  0.10151235 -0.03268599 -0.88318986 -0.03515265]
 [-0.84754092  0.9961947   0.24112455  0.14903654 -0.88911132  0.26677417]
 [-0.84754092  0.99144486  0.37351544  0.10026542 -0.89108514  0.53986684]
 [-0.84754092  0.98480775  0.45294997  0.09391849 -0.89108514  0.71327695]]

Epoch: 0, 
Train Loss: 0.9852054290661291, 
Validation Loss: 0.8210897203534842
Elapsed time for epoch-0: 3.943206787109375
common line69: model saved with val loss 0.8210897203534842

Epoch: 1, 
Train Loss: 0.9470651286239383, 
Validation Loss: 0.7964080842211843
Elapsed time for epoch-1: 4.667675495147705
common line69: model saved with val loss 0.7964080842211843

Epoch: 2, 
Train Loss: 0.9376632253161999, 
Validation Loss: 0.7818647576496005
Elapsed time for epoch-2: 4.799680948257446
common line69: model saved with val loss 0.7818647576496005

Epoch: 3, 
Train Loss: 0.9311937938968674, 
Validation Loss: 0.7745023602619767
Elapsed time for epoch-3: 4.867044448852539
common line69: model saved with val loss 0.7745023602619767

Epoch: 4, 
Train Loss: 0.9261306871135696, 
Validation Loss: 0.7702795602381229
Elapsed time for epoch-4: 5.359339714050293
common line69: model saved with val loss 0.7702795602381229

Epoch: 5, 
Train Loss: 0.9224293662720368, 
Validation Loss: 0.7685600956901908
Elapsed time for epoch-5: 5.9076828956604
common line69: model saved with val loss 0.7685600956901908

Epoch: 6, 
Train Loss: 0.9197767477075592, 
Validation Loss: 0.7668325705453753
Elapsed time for epoch-6: 6.118109703063965
common line69: model saved with val loss 0.7668325705453753

Epoch: 7, 
Train Loss: 0.9174988048166788, 
Validation Loss: 0.7704291576519608
Elapsed time for epoch-7: 4.95171046257019

Epoch: 8, 
Train Loss: 0.9158718634803756, 
Validation Loss: 0.7755461949855089
Elapsed time for epoch-8: 4.533586263656616

Epoch: 9, 
Train Loss: 0.9142259855230316, 
Validation Loss: 0.7761055119335651
Elapsed time for epoch-9: 4.221602201461792

Epoch: 10, 
Train Loss: 0.9129508013735298, 
Validation Loss: 0.7744703106582165
Elapsed time for epoch-10: 3.6908631324768066

Epoch: 11, 
Train Loss: 0.9115098545781705, 
Validation Loss: 0.7735650902613997
Elapsed time for epoch-11: 3.5410280227661133

Epoch: 12, 
Train Loss: 0.9106506234457513, 
Validation Loss: 0.7827611798420548
Elapsed time for epoch-12: 3.7969701290130615

Epoch: 13, 
Train Loss: 0.9096963393087146, 
Validation Loss: 0.7753084450960159
Elapsed time for epoch-13: 4.425657272338867

Epoch: 14, 
Train Loss: 0.9087025902601851, 
Validation Loss: 0.7705648932605982
Elapsed time for epoch-14: 4.220661878585815

Epoch: 15, 
Train Loss: 0.9079067293836289, 
Validation Loss: 0.7776339957490563
Elapsed time for epoch-15: 4.070379734039307

Epoch: 16, 
Train Loss: 0.9072227678379091, 
Validation Loss: 0.7752457708120346
Elapsed time for epoch-16: 4.159335136413574

Epoch: 17, 
Train Loss: 0.9066833990211246, 
Validation Loss: 0.782107693143189
Elapsed time for epoch-17: 3.6099610328674316

Epoch: 18, 
Train Loss: 0.9057531545893485, 
Validation Loss: 0.7805782435461879
Elapsed time for epoch-18: 4.315865993499756
Early stopped! 

train line101: min loss for the epoch 18 is 0.7668325705453753

Training the 6-th turbine in 193.50661277770996 secs

>>>>>>>>> Training Turbine   7 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir  ...  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  ...   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  ...   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  ...   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  ...   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 4.947437047958374
lalalalalal
260 [[ 1.          0.03492366 -0.1203716  -0.23620639 -0.01608888]
 [ 0.99904822  0.30312968 -0.22837076  0.32706138  0.16054293]
 [ 0.9961947   0.31860311 -0.26131966  0.32706138  0.1583295 ]
 [ 0.99144486  0.3779179  -0.32755027  0.32706138  0.21927264]
 [ 0.98480775  0.30828749 -0.3282159   0.32636275  0.10952861]]
hahahahahahah
265 [[ 0.99985184  1.          0.03492366 -0.1203716  -0.23620639 -0.01608888]
 [ 0.99985184  0.99904822  0.30312968 -0.22837076  0.32706138  0.16054293]
 [ 0.99985184  0.9961947   0.31860311 -0.26131966  0.32706138  0.1583295 ]
 [ 0.99985184  0.99144486  0.3779179  -0.32755027  0.32706138  0.21927264]
 [ 0.99985184  0.98480775  0.30828749 -0.3282159   0.32636275  0.10952861]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.03492366 -0.1203716  -0.23620639 -0.01608888]
 [ 0.99985184  0.99904822  0.30312968 -0.22837076  0.32706138  0.16054293]
 [ 0.99985184  0.9961947   0.31860311 -0.26131966  0.32706138  0.1583295 ]
 [ 0.99985184  0.99144486  0.3779179  -0.32755027  0.32706138  0.21927264]
 [ 0.99985184  0.98480775  0.30828749 -0.3282159   0.32636275  0.10952861]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir  ...  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  ...   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  ...   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  ...   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  ...   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 4.137197732925415
lalalalalal
260 [[ 1.         -0.09917935 -0.00837864 -0.71581362 -0.0487001 ]
 [ 0.99904822 -0.001181   -0.04166035 -0.71633759  0.06178174]
 [ 0.9961947   0.11229078  0.13539837 -0.72087866  0.2892803 ]
 [ 0.99144486  0.26186722 -0.10522842 -0.7296115   0.57945059]
 [ 0.98480775  0.22576256 -0.11088631 -0.73939227  0.64831992]]
hahahahahahah
265 [[-0.84754092  1.         -0.09917935 -0.00837864 -0.71581362 -0.0487001 ]
 [-0.84754092  0.99904822 -0.001181   -0.04166035 -0.71633759  0.06178174]
 [-0.84754092  0.9961947   0.11229078  0.13539837 -0.72087866  0.2892803 ]
 [-0.84754092  0.99144486  0.26186722 -0.10522842 -0.7296115   0.57945059]
 [-0.84754092  0.98480775  0.22576256 -0.11088631 -0.73939227  0.64831992]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.09917935 -0.00837864 -0.71581362 -0.0487001 ]
 [-0.84754092  0.99904822 -0.001181   -0.04166035 -0.71633759  0.06178174]
 [-0.84754092  0.9961947   0.11229078  0.13539837 -0.72087866  0.2892803 ]
 [-0.84754092  0.99144486  0.26186722 -0.10522842 -0.7296115   0.57945059]
 [-0.84754092  0.98480775  0.22576256 -0.11088631 -0.73939227  0.64831992]]

Epoch: 0, 
Train Loss: 0.9944577898297992, 
Validation Loss: 0.7886137841269374
Elapsed time for epoch-0: 4.619685888290405
common line69: model saved with val loss 0.7886137841269374

Epoch: 1, 
Train Loss: 0.9442241128001895, 
Validation Loss: 0.7640736540779471
Elapsed time for epoch-1: 4.688978433609009
common line69: model saved with val loss 0.7640736540779471

Epoch: 2, 
Train Loss: 0.9349449797838676, 
Validation Loss: 0.7574256621301174
Elapsed time for epoch-2: 4.5558083057403564
common line69: model saved with val loss 0.7574256621301174

Epoch: 3, 
Train Loss: 0.9295954044376101, 
Validation Loss: 0.7601699084043503
Elapsed time for epoch-3: 4.334824085235596

Epoch: 4, 
Train Loss: 0.9258950462862223, 
Validation Loss: 0.7567309318110347
Elapsed time for epoch-4: 4.1918487548828125
common line69: model saved with val loss 0.7567309318110347

Epoch: 5, 
Train Loss: 0.9229274327013673, 
Validation Loss: 0.7570349322631955
Elapsed time for epoch-5: 4.511574983596802

Epoch: 6, 
Train Loss: 0.9202899747535962, 
Validation Loss: 0.7507431702688336
Elapsed time for epoch-6: 5.304749250411987
common line69: model saved with val loss 0.7507431702688336

Epoch: 7, 
Train Loss: 0.916739146373853, 
Validation Loss: 0.7464464288204908
Elapsed time for epoch-7: 3.9439799785614014
common line69: model saved with val loss 0.7464464288204908

Epoch: 8, 
Train Loss: 0.9142788965411547, 
Validation Loss: 0.7447439087554812
Elapsed time for epoch-8: 4.578579425811768
common line69: model saved with val loss 0.7447439087554812

Epoch: 9, 
Train Loss: 0.9118040045018957, 
Validation Loss: 0.7489043036475778
Elapsed time for epoch-9: 4.063614845275879

Epoch: 10, 
Train Loss: 0.9102709041673596, 
Validation Loss: 0.7503469455987215
Elapsed time for epoch-10: 4.678991079330444

Epoch: 11, 
Train Loss: 0.9090323448181152, 
Validation Loss: 0.7471124986186624
Elapsed time for epoch-11: 4.496398210525513

Epoch: 12, 
Train Loss: 0.9080912296761986, 
Validation Loss: 0.7476536575704813
Elapsed time for epoch-12: 4.649932146072388

Epoch: 13, 
Train Loss: 0.9072584816638161, 
Validation Loss: 0.7433688389137387
Elapsed time for epoch-13: 5.017153978347778
common line69: model saved with val loss 0.7433688389137387

Epoch: 14, 
Train Loss: 0.9067697429857334, 
Validation Loss: 0.7463925266638398
Elapsed time for epoch-14: 3.7220048904418945

Epoch: 15, 
Train Loss: 0.9063262710300815, 
Validation Loss: 0.7469746265560389
Elapsed time for epoch-15: 4.229151487350464

Epoch: 16, 
Train Loss: 0.9057222291701982, 
Validation Loss: 0.7455579657107592
Elapsed time for epoch-16: 4.23937201499939

Epoch: 17, 
Train Loss: 0.9053691077132185, 
Validation Loss: 0.7451312970370054
Elapsed time for epoch-17: 4.091455936431885

Epoch: 18, 
Train Loss: 0.9050231202810752, 
Validation Loss: 0.74164336360991
Elapsed time for epoch-18: 5.693319320678711
common line69: model saved with val loss 0.74164336360991

Epoch: 19, 
Train Loss: 0.904701550843335, 
Validation Loss: 0.741034833714366
Elapsed time for epoch-19: 6.488873481750488
common line69: model saved with val loss 0.741034833714366

Epoch: 20, 
Train Loss: 0.9040821288563624, 
Validation Loss: 0.7412134204059839
Elapsed time for epoch-20: 3.751413583755493

Epoch: 21, 
Train Loss: 0.9039508943297282, 
Validation Loss: 0.7378822416067123
Elapsed time for epoch-21: 5.536214590072632
common line69: model saved with val loss 0.7378822416067123

Epoch: 22, 
Train Loss: 0.9036395124026707, 
Validation Loss: 0.7400699611753225
Elapsed time for epoch-22: 4.622119903564453

Epoch: 23, 
Train Loss: 0.9033845159686914, 
Validation Loss: 0.7364644603803754
Elapsed time for epoch-23: 4.05007004737854
common line69: model saved with val loss 0.7364644603803754

Epoch: 24, 
Train Loss: 0.9031905139945134, 
Validation Loss: 0.7357105119153857
Elapsed time for epoch-24: 5.339425325393677
common line69: model saved with val loss 0.7357105119153857

Epoch: 25, 
Train Loss: 0.9028999025330824, 
Validation Loss: 0.7401721319183707
Elapsed time for epoch-25: 4.715997219085693

Epoch: 26, 
Train Loss: 0.9027642020407844, 
Validation Loss: 0.7393153198063374
Elapsed time for epoch-26: 4.891865015029907

Epoch: 27, 
Train Loss: 0.9025513940498608, 
Validation Loss: 0.7356952773407102
Elapsed time for epoch-27: 4.748855352401733
common line69: model saved with val loss 0.7356952773407102

Epoch: 28, 
Train Loss: 0.9022284165149977, 
Validation Loss: 0.7370499949902296
Elapsed time for epoch-28: 4.424030780792236

Epoch: 29, 
Train Loss: 0.9022742834161309, 
Validation Loss: 0.7359643261879683
Elapsed time for epoch-29: 4.657940626144409

Epoch: 30, 
Train Loss: 0.9020367287287191, 
Validation Loss: 0.735479149967432
Elapsed time for epoch-30: 4.578497409820557
common line69: model saved with val loss 0.735479149967432

Epoch: 31, 
Train Loss: 0.9019708231467158, 
Validation Loss: 0.732930245809257
Elapsed time for epoch-31: 4.56659460067749
common line69: model saved with val loss 0.732930245809257

train line101: min loss for the epoch 31 is 0.732930245809257

Training the 7-th turbine in 258.8903121948242 secs

>>>>>>>>> Training Turbine   8 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  ...  Pab3  Prtv    Patv
0       1    1   00:00  ...   NaN   NaN     NaN
1       1    1   00:10  ...   1.0 -0.25  494.66
2       1    1   00:20  ...   1.0 -0.24  509.76
3       1    1   00:30  ...   1.0 -0.26  542.53
4       1    1   00:40  ...   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 5.619039058685303
lalalalalal
260 [[ 1.          0.06698398 -0.29804557 -0.9597703  -0.00524038]
 [ 0.99904822  0.22799285 -0.35178337 -0.04627658  0.16702647]
 [ 0.9961947   0.21119193  0.04972924 -0.04675447  0.23347776]
 [ 0.99144486  0.2559944   0.08893418 -0.05105552  0.22768308]
 [ 0.98480775  0.17198977  0.06595197 -0.05392288  0.10897539]]
hahahahahahah
265 [[ 0.99985184  1.          0.06698398 -0.29804557 -0.9597703  -0.00524038]
 [ 0.99985184  0.99904822  0.22799285 -0.35178337 -0.04627658  0.16702647]
 [ 0.99985184  0.9961947   0.21119193  0.04972924 -0.04675447  0.23347776]
 [ 0.99985184  0.99144486  0.2559944   0.08893418 -0.05105552  0.22768308]
 [ 0.99985184  0.98480775  0.17198977  0.06595197 -0.05392288  0.10897539]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.06698398 -0.29804557 -0.9597703  -0.00524038]
 [ 0.99985184  0.99904822  0.22799285 -0.35178337 -0.04627658  0.16702647]
 [ 0.99985184  0.9961947   0.21119193  0.04972924 -0.04675447  0.23347776]
 [ 0.99985184  0.99144486  0.2559944   0.08893418 -0.05105552  0.22768308]
 [ 0.99985184  0.98480775  0.17198977  0.06595197 -0.05392288  0.10897539]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 6.226620674133301
lalalalalal
260 [[ 1.00000000e+00 -2.40210291e-02  2.87748807e-02 -6.42687860e-01
  -6.26557163e-02]
 [ 9.99048222e-01  1.07586220e-01 -1.51616843e-02 -6.46511009e-01
   7.24771998e-02]
 [ 9.96194698e-01  1.74789922e-01  7.91329436e-02 -6.43165754e-01
   2.86505394e-01]
 [ 9.91444861e-01  3.48399485e-01 -1.57786534e-01 -6.51289946e-01
   5.66609686e-01]
 [ 9.84807753e-01  3.34398714e-01  4.71266528e-05 -6.49856265e-01
   5.75739443e-01]]
hahahahahahah
265 [[-8.47540923e-01  1.00000000e+00 -2.40210291e-02  2.87748807e-02
  -6.42687860e-01 -6.26557163e-02]
 [-8.47540923e-01  9.99048222e-01  1.07586220e-01 -1.51616843e-02
  -6.46511009e-01  7.24771998e-02]
 [-8.47540923e-01  9.96194698e-01  1.74789922e-01  7.91329436e-02
  -6.43165754e-01  2.86505394e-01]
 [-8.47540923e-01  9.91444861e-01  3.48399485e-01 -1.57786534e-01
  -6.51289946e-01  5.66609686e-01]
 [-8.47540923e-01  9.84807753e-01  3.34398714e-01  4.71266528e-05
  -6.49856265e-01  5.75739443e-01]]

 wind turbine line248 data after normalization: 
 [[-8.47540923e-01  1.00000000e+00 -2.40210291e-02  2.87748807e-02
  -6.42687860e-01 -6.26557163e-02]
 [-8.47540923e-01  9.99048222e-01  1.07586220e-01 -1.51616843e-02
  -6.46511009e-01  7.24771998e-02]
 [-8.47540923e-01  9.96194698e-01  1.74789922e-01  7.91329436e-02
  -6.43165754e-01  2.86505394e-01]
 [-8.47540923e-01  9.91444861e-01  3.48399485e-01 -1.57786534e-01
  -6.51289946e-01  5.66609686e-01]
 [-8.47540923e-01  9.84807753e-01  3.34398714e-01  4.71266528e-05
  -6.49856265e-01  5.75739443e-01]]

Epoch: 0, 
Train Loss: 0.9891872086695263, 
Validation Loss: 0.7831016266718507
Elapsed time for epoch-0: 4.3653342723846436
common line69: model saved with val loss 0.7831016266718507

Epoch: 1, 
Train Loss: 0.9502591247819051, 
Validation Loss: 0.7702112952247262
Elapsed time for epoch-1: 4.179117202758789
common line69: model saved with val loss 0.7702112952247262

Epoch: 2, 
Train Loss: 0.9393991871791727, 
Validation Loss: 0.7687923898920417
Elapsed time for epoch-2: 4.8324294090271
common line69: model saved with val loss 0.7687923898920417

Epoch: 3, 
Train Loss: 0.9322553066646352, 
Validation Loss: 0.7735780635848641
Elapsed time for epoch-3: 5.793749094009399

Epoch: 4, 
Train Loss: 0.9276885992589117, 
Validation Loss: 0.7778631569817662
Elapsed time for epoch-4: 5.866425514221191

Epoch: 5, 
Train Loss: 0.9241330309324906, 
Validation Loss: 0.7701991554349661
Elapsed time for epoch-5: 4.999755144119263

Epoch: 6, 
Train Loss: 0.9213293848418388, 
Validation Loss: 0.7719291029497981
Elapsed time for epoch-6: 4.4491190910339355

Epoch: 7, 
Train Loss: 0.919221308176257, 
Validation Loss: 0.780423091724515
Elapsed time for epoch-7: 4.204385995864868

Epoch: 8, 
Train Loss: 0.9169465774247626, 
Validation Loss: 0.7899596700444818
Elapsed time for epoch-8: 4.77695631980896

Epoch: 9, 
Train Loss: 0.9151019584231016, 
Validation Loss: 0.7867307094857097
Elapsed time for epoch-9: 5.353808879852295

Epoch: 10, 
Train Loss: 0.9134566816462188, 
Validation Loss: 0.7865780610591173
Elapsed time for epoch-10: 4.376200199127197

Epoch: 11, 
Train Loss: 0.9114587663852868, 
Validation Loss: 0.7895465204492211
Elapsed time for epoch-11: 4.071928262710571

Epoch: 12, 
Train Loss: 0.9101967567405781, 
Validation Loss: 0.7945229858160019
Elapsed time for epoch-12: 4.520298719406128

Epoch: 13, 
Train Loss: 0.9088398297043407, 
Validation Loss: 0.7917889403179288
Elapsed time for epoch-13: 4.304947853088379

Epoch: 14, 
Train Loss: 0.907733881673893, 
Validation Loss: 0.7927242862060666
Elapsed time for epoch-14: 4.859694480895996
Early stopped! 

train line101: min loss for the epoch 14 is 0.7687923898920417

Training the 8-th turbine in 197.83692741394043 secs

>>>>>>>>> Training Turbine   9 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir  ...  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  ...   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  ...   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  ...   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  ...   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 3.7804651260375977
lalalalalal
260 [[ 1.          0.04590307 -0.21715807  0.21027429  0.04352498]
 [ 0.99904822  0.23169353 -0.35642176  0.46397623  0.14668763]
 [ 0.9961947   0.25054184 -0.37824788  0.45812157  0.16288268]
 [ 0.99144486  0.28823845 -0.24631386  0.45291743  0.22003431]
 [ 0.98480775  0.15091507  0.0527366   0.45291743  0.09566385]]
hahahahahahah
265 [[ 0.99985184  1.          0.04590307 -0.21715807  0.21027429  0.04352498]
 [ 0.99985184  0.99904822  0.23169353 -0.35642176  0.46397623  0.14668763]
 [ 0.99985184  0.9961947   0.25054184 -0.37824788  0.45812157  0.16288268]
 [ 0.99985184  0.99144486  0.28823845 -0.24631386  0.45291743  0.22003431]
 [ 0.99985184  0.98480775  0.15091507  0.0527366   0.45291743  0.09566385]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.04590307 -0.21715807  0.21027429  0.04352498]
 [ 0.99985184  0.99904822  0.23169353 -0.35642176  0.46397623  0.14668763]
 [ 0.99985184  0.9961947   0.25054184 -0.37824788  0.45812157  0.16288268]
 [ 0.99985184  0.99144486  0.28823845 -0.24631386  0.45291743  0.22003431]
 [ 0.99985184  0.98480775  0.15091507  0.0527366   0.45291743  0.09566385]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day  ...  Prtv    Patv
0       1    1  ...   NaN     NaN
1       1    1  ... -0.25  494.66
2       1    1  ... -0.24  509.76
3       1    1  ... -0.26  542.53
4       1    1  ... -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 3.4441254138946533
lalalalalal
260 [[ 1.         -0.02141232 -0.09988338 -1.5701929  -0.05389542]
 [ 0.99904822  0.15091507  0.0289559  -1.56889186  0.12861671]
 [ 0.9961947   0.22900091 -0.03163602 -1.56889186  0.34705183]
 [ 0.99144486  0.28285322 -0.01632516 -1.5630372   0.45349726]
 [ 0.98480775  0.33670553 -0.12513001 -1.56563927  0.5353479 ]]
hahahahahahah
265 [[-0.84754092  1.         -0.02141232 -0.09988338 -1.5701929  -0.05389542]
 [-0.84754092  0.99904822  0.15091507  0.0289559  -1.56889186  0.12861671]
 [-0.84754092  0.9961947   0.22900091 -0.03163602 -1.56889186  0.34705183]
 [-0.84754092  0.99144486  0.28285322 -0.01632516 -1.5630372   0.45349726]
 [-0.84754092  0.98480775  0.33670553 -0.12513001 -1.56563927  0.5353479 ]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.02141232 -0.09988338 -1.5701929  -0.05389542]
 [-0.84754092  0.99904822  0.15091507  0.0289559  -1.56889186  0.12861671]
 [-0.84754092  0.9961947   0.22900091 -0.03163602 -1.56889186  0.34705183]
 [-0.84754092  0.99144486  0.28285322 -0.01632516 -1.5630372   0.45349726]
 [-0.84754092  0.98480775  0.33670553 -0.12513001 -1.56563927  0.5353479 ]]

Epoch: 0, 
Train Loss: 1.0019212034570069, 
Validation Loss: 0.7971573816612363
Elapsed time for epoch-0: 3.7561941146850586
common line69: model saved with val loss 0.7971573816612363

Epoch: 1, 
Train Loss: 0.9525882522849476, 
Validation Loss: 0.7513803821057081
Elapsed time for epoch-1: 4.479680299758911
common line69: model saved with val loss 0.7513803821057081

Epoch: 2, 
Train Loss: 0.9389006181173966, 
Validation Loss: 0.746206970885396
Elapsed time for epoch-2: 4.472853660583496
common line69: model saved with val loss 0.746206970885396

Epoch: 3, 
Train Loss: 0.9313842989817387, 
Validation Loss: 0.7417679037898779
Elapsed time for epoch-3: 4.545731782913208
common line69: model saved with val loss 0.7417679037898779

Epoch: 4, 
Train Loss: 0.9265586562266871, 
Validation Loss: 0.7450106116011739
Elapsed time for epoch-4: 4.966090679168701

Epoch: 5, 
Train Loss: 0.9231783980581941, 
Validation Loss: 0.7413189942017198
Elapsed time for epoch-5: 4.704303026199341
common line69: model saved with val loss 0.7413189942017198

Epoch: 6, 
Train Loss: 0.9200911038563031, 
Validation Loss: 0.7433092389255762
Elapsed time for epoch-6: 4.856860399246216

Epoch: 7, 
Train Loss: 0.9178557941893569, 
Validation Loss: 0.7405690550804138
Elapsed time for epoch-7: 4.728906154632568
common line69: model saved with val loss 0.7405690550804138

Epoch: 8, 
Train Loss: 0.9159028174496499, 
Validation Loss: 0.7426397325471044
Elapsed time for epoch-8: 4.456262826919556

Epoch: 9, 
Train Loss: 0.9140902762653447, 
Validation Loss: 0.7426432836800814
Elapsed time for epoch-9: 5.127488374710083

Epoch: 10, 
Train Loss: 0.9124282851439565, 
Validation Loss: 0.7361554754897952
Elapsed time for epoch-10: 4.190515995025635
common line69: model saved with val loss 0.7361554754897952

Epoch: 11, 
Train Loss: 0.911478923774567, 
Validation Loss: 0.7352707972750068
Elapsed time for epoch-11: 4.343344688415527
common line69: model saved with val loss 0.7352707972750068

Epoch: 12, 
Train Loss: 0.9101642335162443, 
Validation Loss: 0.7346930587664247
Elapsed time for epoch-12: 4.326862096786499
common line69: model saved with val loss 0.7346930587664247

Epoch: 13, 
Train Loss: 0.9094969724156275, 
Validation Loss: 0.7317537041381001
Elapsed time for epoch-13: 5.583347320556641
common line69: model saved with val loss 0.7317537041381001

Epoch: 14, 
Train Loss: 0.9084939401941139, 
Validation Loss: 0.7363891340792179
Elapsed time for epoch-14: 4.978545665740967

Epoch: 15, 
Train Loss: 0.9079245425322476, 
Validation Loss: 0.7338415095582604
Elapsed time for epoch-15: 4.793948650360107

Epoch: 16, 
Train Loss: 0.9075248695972586, 
Validation Loss: 0.7261258531361818
Elapsed time for epoch-16: 5.587487697601318
common line69: model saved with val loss 0.7261258531361818

Epoch: 17, 
Train Loss: 0.9070860953891978, 
Validation Loss: 0.7362691164016724
Elapsed time for epoch-17: 6.149641275405884

Epoch: 18, 
Train Loss: 0.906451721026116, 
Validation Loss: 0.7266626609489322
Elapsed time for epoch-18: 5.543400049209595

Epoch: 19, 
Train Loss: 0.9061172588282272, 
Validation Loss: 0.7315138857811689
Elapsed time for epoch-19: 5.228884696960449

Epoch: 20, 
Train Loss: 0.9058702459104923, 
Validation Loss: 0.7358860950917006
Elapsed time for epoch-20: 6.5400710105896

Epoch: 21, 
Train Loss: 0.905557931220832, 
Validation Loss: 0.731500705704093
Elapsed time for epoch-21: 5.966848850250244

Epoch: 22, 
Train Loss: 0.9052503063899129, 
Validation Loss: 0.7309736898168921
Elapsed time for epoch-22: 6.111342430114746

Epoch: 23, 
Train Loss: 0.904783760048762, 
Validation Loss: 0.7337879538536072
Elapsed time for epoch-23: 5.670761346817017

Epoch: 24, 
Train Loss: 0.904639100577651, 
Validation Loss: 0.7333733942359686
Elapsed time for epoch-24: 4.861278295516968

Epoch: 25, 
Train Loss: 0.9043178575880387, 
Validation Loss: 0.7393368491902947
Elapsed time for epoch-25: 4.944255113601685

Epoch: 26, 
Train Loss: 0.9041716112058704, 
Validation Loss: 0.7283311411738396
Elapsed time for epoch-26: 5.485977411270142

Epoch: 27, 
Train Loss: 0.903964898541194, 
Validation Loss: 0.7365999156609178
Elapsed time for epoch-27: 4.601945638656616

Epoch: 28, 
Train Loss: 0.9037712241421226, 
Validation Loss: 0.7347835227847099
Elapsed time for epoch-28: 3.6786532402038574
Early stopped! 

train line101: min loss for the epoch 28 is 0.7261258531361818

Training the 9-th turbine in 246.5022885799408 secs

>>>>>>>>> Training Turbine  10 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir  ...  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  ...   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  ...   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  ...   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  ...   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.7951619625091553
lalalalalal
260 [[ 1.          0.10332727 -0.08921509 -0.56559654  0.06981039]
 [ 0.99904822  0.17675744 -0.12360412  0.4460417   0.15156974]
 [ 0.9961947   0.22476947 -0.13328144  0.4460417   0.20540847]
 [ 0.99144486  0.25301184 -0.21277368  0.44225397  0.20449065]
 [ 0.98480775  0.16263625 -0.22487032  0.43341595  0.06181072]]
hahahahahahah
265 [[ 0.99985184  1.          0.10332727 -0.08921509 -0.56559654  0.06981039]
 [ 0.99985184  0.99904822  0.17675744 -0.12360412  0.4460417   0.15156974]
 [ 0.99985184  0.9961947   0.22476947 -0.13328144  0.4460417   0.20540847]
 [ 0.99985184  0.99144486  0.25301184 -0.21277368  0.44225397  0.20449065]
 [ 0.99985184  0.98480775  0.16263625 -0.22487032  0.43341595  0.06181072]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.10332727 -0.08921509 -0.56559654  0.06981039]
 [ 0.99985184  0.99904822  0.17675744 -0.12360412  0.4460417   0.15156974]
 [ 0.99985184  0.9961947   0.22476947 -0.13328144  0.4460417   0.20540847]
 [ 0.99985184  0.99144486  0.25301184 -0.21277368  0.44225397  0.20449065]
 [ 0.99985184  0.98480775  0.16263625 -0.22487032  0.43341595  0.06181072]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir  ...  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  ...   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  ...   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  ...   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  ...   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 5.403752326965332
lalalalalal
260 [[ 1.         -0.0082301  -0.03754513 -1.51631552 -0.0363756 ]
 [ 0.99904822  0.15981202 -0.04791368 -1.51726245  0.17478652]
 [ 0.9961947   0.26148455  0.14425017 -1.51726245  0.40668313]
 [ 0.99144486  0.26148455  0.10243034 -1.52041889  0.39295749]
 [ 0.98480775  0.3405632   0.02985047 -1.52168147  0.56767782]]
hahahahahahah
265 [[-0.84754092  1.         -0.0082301  -0.03754513 -1.51631552 -0.0363756 ]
 [-0.84754092  0.99904822  0.15981202 -0.04791368 -1.51726245  0.17478652]
 [-0.84754092  0.9961947   0.26148455  0.14425017 -1.51726245  0.40668313]
 [-0.84754092  0.99144486  0.26148455  0.10243034 -1.52041889  0.39295749]
 [-0.84754092  0.98480775  0.3405632   0.02985047 -1.52168147  0.56767782]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.0082301  -0.03754513 -1.51631552 -0.0363756 ]
 [-0.84754092  0.99904822  0.15981202 -0.04791368 -1.51726245  0.17478652]
 [-0.84754092  0.9961947   0.26148455  0.14425017 -1.51726245  0.40668313]
 [-0.84754092  0.99144486  0.26148455  0.10243034 -1.52041889  0.39295749]
 [-0.84754092  0.98480775  0.3405632   0.02985047 -1.52168147  0.56767782]]

Epoch: 0, 
Train Loss: 1.0034231528514574, 
Validation Loss: 0.5968819614499807
Elapsed time for epoch-0: 4.811295032501221
common line69: model saved with val loss 0.5968819614499807

Epoch: 1, 
Train Loss: 0.9519890817273565, 
Validation Loss: 0.5702882278710604
Elapsed time for epoch-1: 4.8791468143463135
common line69: model saved with val loss 0.5702882278710604

Epoch: 2, 
Train Loss: 0.9412623034054491, 
Validation Loss: 0.5705931531265378
Elapsed time for epoch-2: 4.517258644104004

Epoch: 3, 
Train Loss: 0.9357352601129467, 
Validation Loss: 0.5756621770560741
Elapsed time for epoch-3: 4.3732194900512695

Epoch: 4, 
Train Loss: 0.9318963227903142, 
Validation Loss: 0.5790986390784383
Elapsed time for epoch-4: 4.169107913970947

Epoch: 5, 
Train Loss: 0.928958097801489, 
Validation Loss: 0.5850045960396528
Elapsed time for epoch-5: 4.734374046325684

Epoch: 6, 
Train Loss: 0.9267750839475825, 
Validation Loss: 0.5803533894941211
Elapsed time for epoch-6: 4.3684961795806885

Epoch: 7, 
Train Loss: 0.9249009686608275, 
Validation Loss: 0.5841081142425537
Elapsed time for epoch-7: 4.04335618019104

Epoch: 8, 
Train Loss: 0.9232090398544023, 
Validation Loss: 0.5747438222169876
Elapsed time for epoch-8: 4.084153175354004

Epoch: 9, 
Train Loss: 0.9218322647218945, 
Validation Loss: 0.5772831430658698
Elapsed time for epoch-9: 4.367047071456909

Epoch: 10, 
Train Loss: 0.9204232146759995, 
Validation Loss: 0.5735565768554807
Elapsed time for epoch-10: 4.74742317199707

Epoch: 11, 
Train Loss: 0.9193882561531388, 
Validation Loss: 0.5859036948531866
Elapsed time for epoch-11: 4.59699821472168

Epoch: 12, 
Train Loss: 0.9184718561523101, 
Validation Loss: 0.5767027083784342
Elapsed time for epoch-12: 4.05390477180481

Epoch: 13, 
Train Loss: 0.9175073519474318, 
Validation Loss: 0.5787865556776524
Elapsed time for epoch-13: 4.444261074066162
Early stopped! 

train line101: min loss for the epoch 13 is 0.5702882278710604

Training the 10-th turbine in 159.71277260780334 secs

>>>>>>>>> Training Turbine  11 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir  ...  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  ...   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  ...   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  ...   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  ...   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 5.871089935302734
lalalalalal
260 [[ 1.          0.03192315 -0.05459987 -0.72531159  0.02242241]
 [ 0.99904822  0.18375301 -0.06675796  0.49558779  0.16192082]
 [ 0.9961947   0.17507702 -0.08377928  0.49411638  0.12303785]
 [ 0.99144486  0.17218502 -0.15290669  0.48896646  0.11410358]
 [ 0.98480775  0.13458905 -0.20640227  0.48675935  0.08967065]]
hahahahahahah
265 [[ 0.99985184  1.          0.03192315 -0.05459987 -0.72531159  0.02242241]
 [ 0.99985184  0.99904822  0.18375301 -0.06675796  0.49558779  0.16192082]
 [ 0.99985184  0.9961947   0.17507702 -0.08377928  0.49411638  0.12303785]
 [ 0.99985184  0.99144486  0.17218502 -0.15290669  0.48896646  0.11410358]
 [ 0.99985184  0.98480775  0.13458905 -0.20640227  0.48675935  0.08967065]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.03192315 -0.05459987 -0.72531159  0.02242241]
 [ 0.99985184  0.99904822  0.18375301 -0.06675796  0.49558779  0.16192082]
 [ 0.99985184  0.9961947   0.17507702 -0.08377928  0.49411638  0.12303785]
 [ 0.99985184  0.99144486  0.17218502 -0.15290669  0.48896646  0.11410358]
 [ 0.99985184  0.98480775  0.13458905 -0.20640227  0.48675935  0.08967065]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir  ...  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  ...   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  ...   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  ...   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  ...   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.9151742458343506
lalalalalal
260 [[ 1.         -0.04471478 -0.09645843 -1.82996988 -0.03201164]
 [ 0.99904822  0.13169706 -0.09767424 -1.8358555   0.17561584]
 [ 0.9961947   0.20688899  0.09893939 -1.82408425  0.39966477]
 [ 0.99144486  0.24159296  0.08469706 -1.82261284  0.44926467]
 [ 0.98480775  0.33413687 -0.01152551 -1.82261284  0.62012741]]
hahahahahahah
265 [[-0.84754092  1.         -0.04471478 -0.09645843 -1.82996988 -0.03201164]
 [-0.84754092  0.99904822  0.13169706 -0.09767424 -1.8358555   0.17561584]
 [-0.84754092  0.9961947   0.20688899  0.09893939 -1.82408425  0.39966477]
 [-0.84754092  0.99144486  0.24159296  0.08469706 -1.82261284  0.44926467]
 [-0.84754092  0.98480775  0.33413687 -0.01152551 -1.82261284  0.62012741]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.04471478 -0.09645843 -1.82996988 -0.03201164]
 [-0.84754092  0.99904822  0.13169706 -0.09767424 -1.8358555   0.17561584]
 [-0.84754092  0.9961947   0.20688899  0.09893939 -1.82408425  0.39966477]
 [-0.84754092  0.99144486  0.24159296  0.08469706 -1.82261284  0.44926467]
 [-0.84754092  0.98480775  0.33413687 -0.01152551 -1.82261284  0.62012741]]

Epoch: 0, 
Train Loss: 0.9927234228919534, 
Validation Loss: 0.7675637630745769
Elapsed time for epoch-0: 3.184417486190796
common line69: model saved with val loss 0.7675637630745769

Epoch: 1, 
Train Loss: 0.9493250042951408, 
Validation Loss: 0.7476810710504651
Elapsed time for epoch-1: 2.6924123764038086
common line69: model saved with val loss 0.7476810710504651

Epoch: 2, 
Train Loss: 0.9377484175087023, 
Validation Loss: 0.7446403857320547
Elapsed time for epoch-2: 2.9672470092773438
common line69: model saved with val loss 0.7446403857320547

Epoch: 3, 
Train Loss: 0.9315095507547635, 
Validation Loss: 0.7448259545490146
Elapsed time for epoch-3: 2.7546708583831787

Epoch: 4, 
Train Loss: 0.9271424325073466, 
Validation Loss: 0.7412713197991252
Elapsed time for epoch-4: 2.9143407344818115
common line69: model saved with val loss 0.7412713197991252

Epoch: 5, 
Train Loss: 0.9245870030727708, 
Validation Loss: 0.7400150252506137
Elapsed time for epoch-5: 4.038921594619751
common line69: model saved with val loss 0.7400150252506137

Epoch: 6, 
Train Loss: 0.9223779061762225, 
Validation Loss: 0.7343901181593537
Elapsed time for epoch-6: 4.929128408432007
common line69: model saved with val loss 0.7343901181593537

Epoch: 7, 
Train Loss: 0.9206376559093219, 
Validation Loss: 0.7378657581284642
Elapsed time for epoch-7: 4.2900800704956055

Epoch: 8, 
Train Loss: 0.9195387334633274, 
Validation Loss: 0.7326883412897587
Elapsed time for epoch-8: 3.913839340209961
common line69: model saved with val loss 0.7326883412897587

Epoch: 9, 
Train Loss: 0.9184224630604271, 
Validation Loss: 0.7340902658179402
Elapsed time for epoch-9: 3.8630146980285645

Epoch: 10, 
Train Loss: 0.917066781460738, 
Validation Loss: 0.7284791581332684
Elapsed time for epoch-10: 3.343493700027466
common line69: model saved with val loss 0.7284791581332684

Epoch: 11, 
Train Loss: 0.9163366433452157, 
Validation Loss: 0.7336620111018419
Elapsed time for epoch-11: 2.7312967777252197

Epoch: 12, 
Train Loss: 0.9152368752896285, 
Validation Loss: 0.7299396395683289
Elapsed time for epoch-12: 2.921712636947632

Epoch: 13, 
Train Loss: 0.914320828533974, 
Validation Loss: 0.7305475240573287
Elapsed time for epoch-13: 2.8149945735931396

Epoch: 14, 
Train Loss: 0.9131518707555883, 
Validation Loss: 0.7366283787414432
Elapsed time for epoch-14: 2.7340710163116455

Epoch: 15, 
Train Loss: 0.9124157004246191, 
Validation Loss: 0.7314193788915873
Elapsed time for epoch-15: 2.7730157375335693

Epoch: 16, 
Train Loss: 0.9112397975781384, 
Validation Loss: 0.7299758931621909
Elapsed time for epoch-16: 2.7197515964508057

Epoch: 17, 
Train Loss: 0.9104213477934108, 
Validation Loss: 0.727018759585917
Elapsed time for epoch-17: 2.891521453857422
common line69: model saved with val loss 0.727018759585917

Epoch: 18, 
Train Loss: 0.9097436206931827, 
Validation Loss: 0.7295834152027965
Elapsed time for epoch-18: 3.305509328842163

Epoch: 19, 
Train Loss: 0.9089720822682902, 
Validation Loss: 0.7283589281141758
Elapsed time for epoch-19: 4.140218257904053

Epoch: 20, 
Train Loss: 0.9087795498741775, 
Validation Loss: 0.73097441252321
Elapsed time for epoch-20: 5.0650835037231445

Epoch: 21, 
Train Loss: 0.9082468835746541, 
Validation Loss: 0.7264740820974112
Elapsed time for epoch-21: 4.639686822891235
common line69: model saved with val loss 0.7264740820974112

Epoch: 22, 
Train Loss: 0.9076993608174204, 
Validation Loss: 0.7232307316735387
Elapsed time for epoch-22: 5.2373480796813965
common line69: model saved with val loss 0.7232307316735387

Epoch: 23, 
Train Loss: 0.907537133503361, 
Validation Loss: 0.7242565415799618
Elapsed time for epoch-23: 6.394329309463501

Epoch: 24, 
Train Loss: 0.9069444801376647, 
Validation Loss: 0.7383442362770438
Elapsed time for epoch-24: 6.924294710159302

Epoch: 25, 
Train Loss: 0.9066889652935397, 
Validation Loss: 0.7269938960671425
Elapsed time for epoch-25: 5.583384037017822

Epoch: 26, 
Train Loss: 0.90618634211416, 
Validation Loss: 0.7305115787312388
Elapsed time for epoch-26: 5.857099294662476

Epoch: 27, 
Train Loss: 0.9061863691616459, 
Validation Loss: 0.7328094709664583
Elapsed time for epoch-27: 5.79903507232666

Epoch: 28, 
Train Loss: 0.9060635947379745, 
Validation Loss: 0.7284122621640563
Elapsed time for epoch-28: 6.989078521728516

Epoch: 29, 
Train Loss: 0.90581350717224, 
Validation Loss: 0.733977060765028
Elapsed time for epoch-29: 6.547561883926392

Epoch: 30, 
Train Loss: 0.9054871406875739, 
Validation Loss: 0.7276312168687582
Elapsed time for epoch-30: 5.908205032348633

Epoch: 31, 
Train Loss: 0.9054353602794039, 
Validation Loss: 0.7415685951709747
Elapsed time for epoch-31: 4.62158203125

train line101: min loss for the epoch 31 is 0.7232307316735387

Training the 11-th turbine in 251.72581243515015 secs

>>>>>>>>> Training Turbine  12 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir  ...  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  ...   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  ...   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  ...   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  ...   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 3.3136484622955322
lalalalalal
260 [[ 1.          0.01657995 -0.17258709 -0.2781311   0.0995379 ]
 [ 0.99904822  0.21337137 -0.20639778  0.39705411  0.17772694]
 [ 0.9961947   0.2189541  -0.19059839  0.39780327  0.17909411]
 [ 0.99144486  0.24965915 -0.23926051  0.39705411  0.1529877 ]
 [ 0.98480775  0.18406201 -0.24842416  0.39368286  0.09246335]]
hahahahahahah
265 [[ 0.99985184  1.          0.01657995 -0.17258709 -0.2781311   0.0995379 ]
 [ 0.99985184  0.99904822  0.21337137 -0.20639778  0.39705411  0.17772694]
 [ 0.99985184  0.9961947   0.2189541  -0.19059839  0.39780327  0.17909411]
 [ 0.99985184  0.99144486  0.24965915 -0.23926051  0.39705411  0.1529877 ]
 [ 0.99985184  0.98480775  0.18406201 -0.24842416  0.39368286  0.09246335]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.01657995 -0.17258709 -0.2781311   0.0995379 ]
 [ 0.99985184  0.99904822  0.21337137 -0.20639778  0.39705411  0.17772694]
 [ 0.99985184  0.9961947   0.2189541  -0.19059839  0.39780327  0.17909411]
 [ 0.99985184  0.99144486  0.24965915 -0.23926051  0.39705411  0.1529877 ]
 [ 0.99985184  0.98480775  0.18406201 -0.24842416  0.39368286  0.09246335]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir  ...  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  ...   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  ...   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  ...   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  ...   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 5.726490020751953
lalalalalal
260 [[ 1.          0.00401879  0.07103949 -0.81603177 -0.03267601]
 [ 0.99904822  0.16033538  0.06471973 -0.81621906  0.12544901]
 [ 0.9961947   0.22174547  0.07451535 -0.82258697  0.38881348]
 [ 0.99144486  0.36131385 -0.09264218 -0.82371072  0.50612959]
 [ 0.98480775  0.47855129 -0.21176958 -0.82445988  0.59920558]]
hahahahahahah
265 [[-0.84754092  1.          0.00401879  0.07103949 -0.81603177 -0.03267601]
 [-0.84754092  0.99904822  0.16033538  0.06471973 -0.81621906  0.12544901]
 [-0.84754092  0.9961947   0.22174547  0.07451535 -0.82258697  0.38881348]
 [-0.84754092  0.99144486  0.36131385 -0.09264218 -0.82371072  0.50612959]
 [-0.84754092  0.98480775  0.47855129 -0.21176958 -0.82445988  0.59920558]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.00401879  0.07103949 -0.81603177 -0.03267601]
 [-0.84754092  0.99904822  0.16033538  0.06471973 -0.81621906  0.12544901]
 [-0.84754092  0.9961947   0.22174547  0.07451535 -0.82258697  0.38881348]
 [-0.84754092  0.99144486  0.36131385 -0.09264218 -0.82371072  0.50612959]
 [-0.84754092  0.98480775  0.47855129 -0.21176958 -0.82445988  0.59920558]]

Epoch: 0, 
Train Loss: 0.9978872788052598, 
Validation Loss: 0.8061411958187819
Elapsed time for epoch-0: 4.136828184127808
common line69: model saved with val loss 0.8061411958187819

Epoch: 1, 
Train Loss: 0.9488013415526944, 
Validation Loss: 0.7465580329298973
Elapsed time for epoch-1: 3.071531057357788
common line69: model saved with val loss 0.7465580329298973

Epoch: 2, 
Train Loss: 0.9350537562570652, 
Validation Loss: 0.7374852001667023
Elapsed time for epoch-2: 3.3014578819274902
common line69: model saved with val loss 0.7374852001667023

Epoch: 3, 
Train Loss: 0.9289583685267874, 
Validation Loss: 0.739313755184412
Elapsed time for epoch-3: 3.114272356033325

Epoch: 4, 
Train Loss: 0.9249545938077093, 
Validation Loss: 0.7407546853646636
Elapsed time for epoch-4: 3.021589517593384

Epoch: 5, 
Train Loss: 0.9221685406039742, 
Validation Loss: 0.7426781170070171
Elapsed time for epoch-5: 3.3333635330200195

Epoch: 6, 
Train Loss: 0.9199495478337553, 
Validation Loss: 0.7387985866516829
Elapsed time for epoch-6: 4.6749351024627686

Epoch: 7, 
Train Loss: 0.9184737432153285, 
Validation Loss: 0.7362930066883564
Elapsed time for epoch-7: 4.659289598464966
common line69: model saved with val loss 0.7362930066883564

Epoch: 8, 
Train Loss: 0.9169287061741372, 
Validation Loss: 0.741617419756949
Elapsed time for epoch-8: 4.28471565246582

Epoch: 9, 
Train Loss: 0.9157867106069036, 
Validation Loss: 0.7330462969839573
Elapsed time for epoch-9: 4.002470254898071
common line69: model saved with val loss 0.7330462969839573

Epoch: 10, 
Train Loss: 0.9145383683322859, 
Validation Loss: 0.7378535140305758
Elapsed time for epoch-10: 4.186059236526489

Epoch: 11, 
Train Loss: 0.913414509231303, 
Validation Loss: 0.7408030284568667
Elapsed time for epoch-11: 4.169247627258301

Epoch: 12, 
Train Loss: 0.9127594000902497, 
Validation Loss: 0.7323851780965924
Elapsed time for epoch-12: 3.788907766342163
common line69: model saved with val loss 0.7323851780965924

Epoch: 13, 
Train Loss: 0.911891289368397, 
Validation Loss: 0.7357761422172189
Elapsed time for epoch-13: 3.3564417362213135

Epoch: 14, 
Train Loss: 0.9110668186380082, 
Validation Loss: 0.7342743193730712
Elapsed time for epoch-14: 4.043789386749268

Epoch: 15, 
Train Loss: 0.9103434212317988, 
Validation Loss: 0.7350341463461518
Elapsed time for epoch-15: 3.674114227294922

Epoch: 16, 
Train Loss: 0.9098275126028461, 
Validation Loss: 0.738112417049706
Elapsed time for epoch-16: 4.590492486953735

Epoch: 17, 
Train Loss: 0.9092540998919671, 
Validation Loss: 0.7402567537501454
Elapsed time for epoch-17: 4.168617010116577

Epoch: 18, 
Train Loss: 0.9084682817719564, 
Validation Loss: 0.7341615678742528
Elapsed time for epoch-18: 3.9077765941619873

Epoch: 19, 
Train Loss: 0.908011683145491, 
Validation Loss: 0.7381760152056813
Elapsed time for epoch-19: 4.190812110900879

Epoch: 20, 
Train Loss: 0.9071559253610483, 
Validation Loss: 0.7362352451309562
Elapsed time for epoch-20: 4.291593313217163

Epoch: 21, 
Train Loss: 0.9068473829191273, 
Validation Loss: 0.7368175964802504
Elapsed time for epoch-21: 3.6538033485412598

Epoch: 22, 
Train Loss: 0.905956613666871, 
Validation Loss: 0.7373446775600314
Elapsed time for epoch-22: 4.166351556777954

Epoch: 23, 
Train Loss: 0.9054155110561547, 
Validation Loss: 0.7345676431432366
Elapsed time for epoch-23: 4.048257827758789

Epoch: 24, 
Train Loss: 0.9043119489645758, 
Validation Loss: 0.7375116366893053
Elapsed time for epoch-24: 3.572767734527588
Early stopped! 

train line101: min loss for the epoch 24 is 0.7323851780965924

Training the 12-th turbine in 195.1743700504303 secs

>>>>>>>>> Training Turbine  13 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.878209114074707
lalalalalal
260 [[ 1.          0.1500001  -0.17575656 -0.71887517  0.05277758]
 [ 0.99904822  0.33417555 -0.2374276   0.48103798  0.10782665]
 [ 0.9961947   0.32326145 -0.20820606  0.47811848  0.1525208 ]
 [ 0.99144486  0.35873228 -0.25815451  0.47519899  0.0840975 ]
 [ 0.98480775  0.26596242 -0.2931524   0.47227949 -0.01069152]]
hahahahahahah
265 [[ 0.99985184  1.          0.1500001  -0.17575656 -0.71887517  0.05277758]
 [ 0.99985184  0.99904822  0.33417555 -0.2374276   0.48103798  0.10782665]
 [ 0.99985184  0.9961947   0.32326145 -0.20820606  0.47811848  0.1525208 ]
 [ 0.99985184  0.99144486  0.35873228 -0.25815451  0.47519899  0.0840975 ]
 [ 0.99985184  0.98480775  0.26596242 -0.2931524   0.47227949 -0.01069152]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.1500001  -0.17575656 -0.71887517  0.05277758]
 [ 0.99985184  0.99904822  0.33417555 -0.2374276   0.48103798  0.10782665]
 [ 0.99985184  0.9961947   0.32326145 -0.20820606  0.47811848  0.1525208 ]
 [ 0.99985184  0.99144486  0.35873228 -0.25815451  0.47519899  0.0840975 ]
 [ 0.99985184  0.98480775  0.26596242 -0.2931524   0.47227949 -0.01069152]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.9768476486206055
lalalalalal
260 [[ 1.          0.05450171 -0.01231982 -1.79179021 -0.02509698]
 [ 0.99904822  0.18137814  0.17914922 -1.79543958  0.162089  ]
 [ 0.9961947   0.27960505  0.06090393 -1.79397983  0.37733109]
 [ 0.99144486  0.37783196 -0.02030477 -1.79543958  0.45917114]
 [ 0.98480775  0.45423066 -0.13617157 -1.79543958  0.58579038]]
hahahahahahah
265 [[-0.84754092  1.          0.05450171 -0.01231982 -1.79179021 -0.02509698]
 [-0.84754092  0.99904822  0.18137814  0.17914922 -1.79543958  0.162089  ]
 [-0.84754092  0.9961947   0.27960505  0.06090393 -1.79397983  0.37733109]
 [-0.84754092  0.99144486  0.37783196 -0.02030477 -1.79543958  0.45917114]
 [-0.84754092  0.98480775  0.45423066 -0.13617157 -1.79543958  0.58579038]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.05450171 -0.01231982 -1.79179021 -0.02509698]
 [-0.84754092  0.99904822  0.18137814  0.17914922 -1.79543958  0.162089  ]
 [-0.84754092  0.9961947   0.27960505  0.06090393 -1.79397983  0.37733109]
 [-0.84754092  0.99144486  0.37783196 -0.02030477 -1.79543958  0.45917114]
 [-0.84754092  0.98480775  0.45423066 -0.13617157 -1.79543958  0.58579038]]

Epoch: 0, 
Train Loss: 0.9802297778239771, 
Validation Loss: 0.6245354288257658
Elapsed time for epoch-0: 3.359117269515991
common line69: model saved with val loss 0.6245354288257658

Epoch: 1, 
Train Loss: 0.9464358187773648, 
Validation Loss: 0.626113111153245
Elapsed time for epoch-1: 3.1645002365112305

Epoch: 2, 
Train Loss: 0.9361008713726237, 
Validation Loss: 0.6316740065813065
Elapsed time for epoch-2: 3.2572152614593506

Epoch: 3, 
Train Loss: 0.9302661698155043, 
Validation Loss: 0.6179087683558464
Elapsed time for epoch-3: 3.0195536613464355
common line69: model saved with val loss 0.6179087683558464

Epoch: 4, 
Train Loss: 0.926045712177493, 
Validation Loss: 0.634257442317903
Elapsed time for epoch-4: 3.3061938285827637

Epoch: 5, 
Train Loss: 0.9228482509360594, 
Validation Loss: 0.6263723019510508
Elapsed time for epoch-5: 2.977842092514038

Epoch: 6, 
Train Loss: 0.9203379370835649, 
Validation Loss: 0.6435054177418351
Elapsed time for epoch-6: 3.0974555015563965

Epoch: 7, 
Train Loss: 0.9185152453284303, 
Validation Loss: 0.6340495627373457
Elapsed time for epoch-7: 3.9425570964813232

Epoch: 8, 
Train Loss: 0.9165723679446373, 
Validation Loss: 0.6465497026219964
Elapsed time for epoch-8: 4.105123281478882

Epoch: 9, 
Train Loss: 0.9151556902572888, 
Validation Loss: 0.6307839332148433
Elapsed time for epoch-9: 4.3037800788879395

Epoch: 10, 
Train Loss: 0.913787432954091, 
Validation Loss: 0.6348519623279572
Elapsed time for epoch-10: 4.08795428276062

Epoch: 11, 
Train Loss: 0.9124705303116005, 
Validation Loss: 0.6456541754305363
Elapsed time for epoch-11: 3.685734987258911

Epoch: 12, 
Train Loss: 0.9112321550355238, 
Validation Loss: 0.6352318739518523
Elapsed time for epoch-12: 2.8961875438690186

Epoch: 13, 
Train Loss: 0.9101561255314771, 
Validation Loss: 0.6369156828150153
Elapsed time for epoch-13: 3.288062572479248

Epoch: 14, 
Train Loss: 0.9084896338837487, 
Validation Loss: 0.6541391294449568
Elapsed time for epoch-14: 4.429406404495239

Epoch: 15, 
Train Loss: 0.9073260033330998, 
Validation Loss: 0.6550489319488406
Elapsed time for epoch-15: 4.387782096862793
Early stopped! 

train line101: min loss for the epoch 15 is 0.6179087683558464

Training the 13-th turbine in 150.98963141441345 secs

>>>>>>>>> Training Turbine  14 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.9350931644439697
lalalalalal
260 [[ 1.          0.16778227 -0.18323799 -0.51882241  0.09972244]
 [ 0.99904822  0.24326706 -0.29511479  0.38773912  0.07258634]
 [ 0.9961947   0.2204792  -0.25657037  0.38773912  0.11639022]
 [ 0.99144486  0.24041857 -0.31928672  0.38560101  0.02713071]
 [ 0.98480775  0.16635803 -0.35783113  0.38025571 -0.01165352]]
hahahahahahah
265 [[ 0.99985184  1.          0.16778227 -0.18323799 -0.51882241  0.09972244]
 [ 0.99985184  0.99904822  0.24326706 -0.29511479  0.38773912  0.07258634]
 [ 0.99985184  0.9961947   0.2204792  -0.25657037  0.38773912  0.11639022]
 [ 0.99985184  0.99144486  0.24041857 -0.31928672  0.38560101  0.02713071]
 [ 0.99985184  0.98480775  0.16635803 -0.35783113  0.38025571 -0.01165352]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.16778227 -0.18323799 -0.51882241  0.09972244]
 [ 0.99985184  0.99904822  0.24326706 -0.29511479  0.38773912  0.07258634]
 [ 0.99985184  0.9961947   0.2204792  -0.25657037  0.38773912  0.11639022]
 [ 0.99985184  0.99144486  0.24041857 -0.31928672  0.38560101  0.02713071]
 [ 0.99985184  0.98480775  0.16635803 -0.35783113  0.38025571 -0.01165352]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.8291356563568115
lalalalalal
260 [[ 1.          0.07093387 -0.01550444 -1.27464671  0.04377704]
 [ 0.99904822  0.26605491 -0.00929813 -1.27411218  0.25421582]
 [ 0.9961947   0.29453974  0.08967609 -1.26930141  0.49252005]
 [ 0.99144486  0.27175188 -0.13930388 -1.27250859  0.40750793]
 [ 0.98480775  0.414176   -0.2526506  -1.27197406  0.59909088]]
hahahahahahah
265 [[-0.84754092  1.          0.07093387 -0.01550444 -1.27464671  0.04377704]
 [-0.84754092  0.99904822  0.26605491 -0.00929813 -1.27411218  0.25421582]
 [-0.84754092  0.9961947   0.29453974  0.08967609 -1.26930141  0.49252005]
 [-0.84754092  0.99144486  0.27175188 -0.13930388 -1.27250859  0.40750793]
 [-0.84754092  0.98480775  0.414176   -0.2526506  -1.27197406  0.59909088]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.07093387 -0.01550444 -1.27464671  0.04377704]
 [-0.84754092  0.99904822  0.26605491 -0.00929813 -1.27411218  0.25421582]
 [-0.84754092  0.9961947   0.29453974  0.08967609 -1.26930141  0.49252005]
 [-0.84754092  0.99144486  0.27175188 -0.13930388 -1.27250859  0.40750793]
 [-0.84754092  0.98480775  0.414176   -0.2526506  -1.27197406  0.59909088]]

Epoch: 0, 
Train Loss: 1.010625965580219, 
Validation Loss: 0.801544539630413
Elapsed time for epoch-0: 3.5074996948242188
common line69: model saved with val loss 0.801544539630413

Epoch: 1, 
Train Loss: 0.9664873339298392, 
Validation Loss: 0.748971613124013
Elapsed time for epoch-1: 3.1518735885620117
common line69: model saved with val loss 0.748971613124013

Epoch: 2, 
Train Loss: 0.9431756615889173, 
Validation Loss: 0.7284754170104861
Elapsed time for epoch-2: 3.2382307052612305
common line69: model saved with val loss 0.7284754170104861

Epoch: 3, 
Train Loss: 0.9361552045124919, 
Validation Loss: 0.7183755692094564
Elapsed time for epoch-3: 3.1271982192993164
common line69: model saved with val loss 0.7183755692094564

Epoch: 4, 
Train Loss: 0.9316996383566817, 
Validation Loss: 0.7171399919316173
Elapsed time for epoch-4: 3.07240891456604
common line69: model saved with val loss 0.7171399919316173

Epoch: 5, 
Train Loss: 0.9287665656634739, 
Validation Loss: 0.7161880945786834
Elapsed time for epoch-5: 3.285926342010498
common line69: model saved with val loss 0.7161880945786834

Epoch: 6, 
Train Loss: 0.92712023603816, 
Validation Loss: 0.7130274036899209
Elapsed time for epoch-6: 2.464048147201538
common line69: model saved with val loss 0.7130274036899209

Epoch: 7, 
Train Loss: 0.9255459035645012, 
Validation Loss: 0.7130684424191713
Elapsed time for epoch-7: 3.0460305213928223

Epoch: 8, 
Train Loss: 0.9243104239972699, 
Validation Loss: 0.7064874013885856
Elapsed time for epoch-8: 3.430595874786377
common line69: model saved with val loss 0.7064874013885856

Epoch: 9, 
Train Loss: 0.9233432372077173, 
Validation Loss: 0.7049734843894839
Elapsed time for epoch-9: 3.4012064933776855
common line69: model saved with val loss 0.7049734843894839

Epoch: 10, 
Train Loss: 0.9226625140975503, 
Validation Loss: 0.701494412496686
Elapsed time for epoch-10: 3.6327569484710693
common line69: model saved with val loss 0.701494412496686

Epoch: 11, 
Train Loss: 0.9217325516608583, 
Validation Loss: 0.7057891264557838
Elapsed time for epoch-11: 2.622452735900879

Epoch: 12, 
Train Loss: 0.9210022601510296, 
Validation Loss: 0.7029732670634985
Elapsed time for epoch-12: 3.3272385597229004

Epoch: 13, 
Train Loss: 0.9203797929427203, 
Validation Loss: 0.7006465187296271
Elapsed time for epoch-13: 4.346758127212524
common line69: model saved with val loss 0.7006465187296271

Epoch: 14, 
Train Loss: 0.9196614556703246, 
Validation Loss: 0.7045270716771483
Elapsed time for epoch-14: 4.309613466262817

Epoch: 15, 
Train Loss: 0.9190086281600118, 
Validation Loss: 0.7001293515786529
Elapsed time for epoch-15: 3.9440274238586426
common line69: model saved with val loss 0.7001293515786529

Epoch: 16, 
Train Loss: 0.9182593643414874, 
Validation Loss: 0.7051778780296445
Elapsed time for epoch-16: 3.9928038120269775

Epoch: 17, 
Train Loss: 0.9176244596723749, 
Validation Loss: 0.6944941487163305
Elapsed time for epoch-17: 3.803154230117798
common line69: model saved with val loss 0.6944941487163305

Epoch: 18, 
Train Loss: 0.9171017404614377, 
Validation Loss: 0.697372242808342
Elapsed time for epoch-18: 3.8825411796569824

Epoch: 19, 
Train Loss: 0.916245617285496, 
Validation Loss: 0.7044913405552506
Elapsed time for epoch-19: 4.405925512313843

Epoch: 20, 
Train Loss: 0.9153384508705941, 
Validation Loss: 0.6996200978755951
Elapsed time for epoch-20: 4.087521553039551

Epoch: 21, 
Train Loss: 0.9146029474605032, 
Validation Loss: 0.6968584349378943
Elapsed time for epoch-21: 3.737908124923706

Epoch: 22, 
Train Loss: 0.9131805857940882, 
Validation Loss: 0.6969557339325547
Elapsed time for epoch-22: 4.252229452133179

Epoch: 23, 
Train Loss: 0.9122345184578615, 
Validation Loss: 0.7024916540831327
Elapsed time for epoch-23: 4.12972092628479

Epoch: 24, 
Train Loss: 0.911546552882475, 
Validation Loss: 0.6979026002809405
Elapsed time for epoch-24: 4.02109694480896

Epoch: 25, 
Train Loss: 0.9105709173849651, 
Validation Loss: 0.7002814393490553
Elapsed time for epoch-25: 3.814791679382324

Epoch: 26, 
Train Loss: 0.9099166256790402, 
Validation Loss: 0.7017537513747811
Elapsed time for epoch-26: 4.314793825149536

Epoch: 27, 
Train Loss: 0.9095046945980617, 
Validation Loss: 0.6973717166110873
Elapsed time for epoch-27: 4.744540452957153

Epoch: 28, 
Train Loss: 0.9090349041864652, 
Validation Loss: 0.6939862295985222
Elapsed time for epoch-28: 4.6351158618927
common line69: model saved with val loss 0.6939862295985222

Epoch: 29, 
Train Loss: 0.9087666320700606, 
Validation Loss: 0.6973067056387663
Elapsed time for epoch-29: 4.164332151412964

Epoch: 30, 
Train Loss: 0.9080355157371328, 
Validation Loss: 0.6964407870545983
Elapsed time for epoch-30: 4.8612589836120605

Epoch: 31, 
Train Loss: 0.9078715116787357, 
Validation Loss: 0.7022083830088377
Elapsed time for epoch-31: 6.1209611892700195

train line101: min loss for the epoch 31 is 0.6939862295985222

Training the 14-th turbine in 227.27468967437744 secs

>>>>>>>>> Training Turbine  15 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.8004109859466553
lalalalalal
260 [[ 1.00000000e+00  4.92865820e-02 -1.10289380e-01 -7.75394809e-01
   1.56670022e-02]
 [ 9.99048222e-01  1.59901255e-01 -1.78350850e-01  5.80525322e-01
   5.90735119e-02]
 [ 9.96194698e-01  1.27454285e-01 -1.08961351e-01  5.74872289e-01
   1.61621335e-02]
 [ 9.91444861e-01  1.59901255e-01 -1.99599310e-01  5.71641985e-01
  -5.18289530e-04]
 [ 9.84807753e-01  1.06806212e-01 -2.37116120e-01  5.65988953e-01
  -6.62717248e-02]]
hahahahahahah
265 [[ 9.99851839e-01  1.00000000e+00  4.92865820e-02 -1.10289380e-01
  -7.75394809e-01  1.56670022e-02]
 [ 9.99851839e-01  9.99048222e-01  1.59901255e-01 -1.78350850e-01
   5.80525322e-01  5.90735119e-02]
 [ 9.99851839e-01  9.96194698e-01  1.27454285e-01 -1.08961351e-01
   5.74872289e-01  1.61621335e-02]
 [ 9.99851839e-01  9.91444861e-01  1.59901255e-01 -1.99599310e-01
   5.71641985e-01 -5.18289530e-04]
 [ 9.99851839e-01  9.84807753e-01  1.06806212e-01 -2.37116120e-01
   5.65988953e-01 -6.62717248e-02]]

 wind turbine line248 data after normalization: 
 [[ 9.99851839e-01  1.00000000e+00  4.92865820e-02 -1.10289380e-01
  -7.75394809e-01  1.56670022e-02]
 [ 9.99851839e-01  9.99048222e-01  1.59901255e-01 -1.78350850e-01
   5.80525322e-01  5.90735119e-02]
 [ 9.99851839e-01  9.96194698e-01  1.27454285e-01 -1.08961351e-01
   5.74872289e-01  1.61621335e-02]
 [ 9.99851839e-01  9.91444861e-01  1.59901255e-01 -1.99599310e-01
   5.71641985e-01 -5.18289530e-04]
 [ 9.99851839e-01  9.84807753e-01  1.06806212e-01 -2.37116120e-01
   5.65988953e-01 -6.62717248e-02]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.657529830932617
lalalalalal
260 [[ 1.          0.044862   -0.12207563 -2.00452551 -0.06536949]
 [ 0.99904822  0.15400181 -0.04720802 -2.00937096  0.06037186]
 [ 0.9961947   0.27494052  0.01222127 -2.00937096  0.38946912]
 [ 0.99144486  0.26609134 -0.02197547 -2.00937096  0.35945316]
 [ 0.98480775  0.27494052 -0.09966515 -2.01583157  0.41666833]]
hahahahahahah
265 [[-0.84754092  1.          0.044862   -0.12207563 -2.00452551 -0.06536949]
 [-0.84754092  0.99904822  0.15400181 -0.04720802 -2.00937096  0.06037186]
 [-0.84754092  0.9961947   0.27494052  0.01222127 -2.00937096  0.38946912]
 [-0.84754092  0.99144486  0.26609134 -0.02197547 -2.00937096  0.35945316]
 [-0.84754092  0.98480775  0.27494052 -0.09966515 -2.01583157  0.41666833]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.044862   -0.12207563 -2.00452551 -0.06536949]
 [-0.84754092  0.99904822  0.15400181 -0.04720802 -2.00937096  0.06037186]
 [-0.84754092  0.9961947   0.27494052  0.01222127 -2.00937096  0.38946912]
 [-0.84754092  0.99144486  0.26609134 -0.02197547 -2.00937096  0.35945316]
 [-0.84754092  0.98480775  0.27494052 -0.09966515 -2.01583157  0.41666833]]

Epoch: 0, 
Train Loss: 1.0127894899674825, 
Validation Loss: 0.74352802708745
Elapsed time for epoch-0: 5.2044477462768555
common line69: model saved with val loss 0.74352802708745

Epoch: 1, 
Train Loss: 0.9804119440186926, 
Validation Loss: 0.6697444105520844
Elapsed time for epoch-1: 4.462889194488525
common line69: model saved with val loss 0.6697444105520844

Epoch: 2, 
Train Loss: 0.9426763537300735, 
Validation Loss: 0.6539069684222341
Elapsed time for epoch-2: 3.711399555206299
common line69: model saved with val loss 0.6539069684222341

Epoch: 3, 
Train Loss: 0.9341344884714159, 
Validation Loss: 0.6564873810857534
Elapsed time for epoch-3: 3.594747543334961

Epoch: 4, 
Train Loss: 0.9290333112247852, 
Validation Loss: 0.6451831292361021
Elapsed time for epoch-4: 4.1743175983428955
common line69: model saved with val loss 0.6451831292361021

Epoch: 5, 
Train Loss: 0.92627164683923, 
Validation Loss: 0.6544426055625081
Elapsed time for epoch-5: 4.388373613357544

Epoch: 6, 
Train Loss: 0.9241540987952417, 
Validation Loss: 0.6513888537883759
Elapsed time for epoch-6: 4.378449440002441

Epoch: 7, 
Train Loss: 0.9222617472420219, 
Validation Loss: 0.6508304225280881
Elapsed time for epoch-7: 4.355477571487427

Epoch: 8, 
Train Loss: 0.9211718357410752, 
Validation Loss: 0.648905374109745
Elapsed time for epoch-8: 3.9818592071533203

Epoch: 9, 
Train Loss: 0.9199554064945012, 
Validation Loss: 0.6502977330237627
Elapsed time for epoch-9: 3.3294060230255127

Epoch: 10, 
Train Loss: 0.9189765940443808, 
Validation Loss: 0.6417677905410528
Elapsed time for epoch-10: 3.789454936981201
common line69: model saved with val loss 0.6417677905410528

Epoch: 11, 
Train Loss: 0.9178568941204488, 
Validation Loss: 0.6358421398326755
Elapsed time for epoch-11: 4.095834493637085
common line69: model saved with val loss 0.6358421398326755

Epoch: 12, 
Train Loss: 0.9169895736610189, 
Validation Loss: 0.6349455071613193
Elapsed time for epoch-12: 4.281778812408447
common line69: model saved with val loss 0.6349455071613193

Epoch: 13, 
Train Loss: 0.9164724770714255, 
Validation Loss: 0.6473935125395656
Elapsed time for epoch-13: 3.3948235511779785

Epoch: 14, 
Train Loss: 0.915634023291724, 
Validation Loss: 0.6458712862804532
Elapsed time for epoch-14: 4.093002796173096

Epoch: 15, 
Train Loss: 0.9151455440691539, 
Validation Loss: 0.6444701887667179
Elapsed time for epoch-15: 3.5655741691589355

Epoch: 16, 
Train Loss: 0.9146019255413729, 
Validation Loss: 0.6435156408697367
Elapsed time for epoch-16: 4.054777145385742

Epoch: 17, 
Train Loss: 0.913715870565727, 
Validation Loss: 0.6479422925040126
Elapsed time for epoch-17: 4.27400279045105

Epoch: 18, 
Train Loss: 0.9132375124873233, 
Validation Loss: 0.6353454133495688
Elapsed time for epoch-18: 3.443957567214966

Epoch: 19, 
Train Loss: 0.9128087700164619, 
Validation Loss: 0.6417811382561922
Elapsed time for epoch-19: 3.3715264797210693

Epoch: 20, 
Train Loss: 0.9119910988487115, 
Validation Loss: 0.6366352010518312
Elapsed time for epoch-20: 3.3027193546295166

Epoch: 21, 
Train Loss: 0.9111669967655375, 
Validation Loss: 0.6316220005974174
Elapsed time for epoch-21: 4.245088577270508
common line69: model saved with val loss 0.6316220005974174

Epoch: 22, 
Train Loss: 0.9105789398445803, 
Validation Loss: 0.6400205297395587
Elapsed time for epoch-22: 4.113457202911377

Epoch: 23, 
Train Loss: 0.9099172941025566, 
Validation Loss: 0.6359951253980398
Elapsed time for epoch-23: 3.5620007514953613

Epoch: 24, 
Train Loss: 0.9093590885901651, 
Validation Loss: 0.6387997111305594
Elapsed time for epoch-24: 3.277451753616333

Epoch: 25, 
Train Loss: 0.9086877911531624, 
Validation Loss: 0.6406175503507257
Elapsed time for epoch-25: 3.6533024311065674

Epoch: 26, 
Train Loss: 0.9081881902798885, 
Validation Loss: 0.6347036398947239
Elapsed time for epoch-26: 3.12631893157959

Epoch: 27, 
Train Loss: 0.9076926312526735, 
Validation Loss: 0.6349377874284983
Elapsed time for epoch-27: 3.306318998336792

Epoch: 28, 
Train Loss: 0.9071441654648099, 
Validation Loss: 0.6320122880861163
Elapsed time for epoch-28: 3.1914234161376953

Epoch: 29, 
Train Loss: 0.9066583717069706, 
Validation Loss: 0.6403732253238559
Elapsed time for epoch-29: 3.0612945556640625

Epoch: 30, 
Train Loss: 0.9062761291235435, 
Validation Loss: 0.6300512487068772
Elapsed time for epoch-30: 3.245962381362915
common line69: model saved with val loss 0.6300512487068772

Epoch: 31, 
Train Loss: 0.9059852006054726, 
Validation Loss: 0.6359923472627997
Elapsed time for epoch-31: 4.042932033538818

train line101: min loss for the epoch 31 is 0.6300512487068772

Training the 15-th turbine in 203.68330478668213 secs

>>>>>>>>> Training Turbine  16 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.866727352142334
lalalalalal
260 [[ 1.          0.28111842 -0.02527259 -0.48810863  0.54885444]
 [ 0.99904822  0.03482245 -0.08354677  0.37560863  0.05144023]
 [ 0.9961947  -0.00527224 -0.0612561   0.37300157  0.0141314 ]
 [ 0.99144486 -0.01672786 -0.12016715  0.36987311 -0.04773373]
 [ 0.98480775 -0.04823084 -0.14245782  0.36778746 -0.04616725]]
hahahahahahah
265 [[ 0.99985184  1.          0.28111842 -0.02527259 -0.48810863  0.54885444]
 [ 0.99985184  0.99904822  0.03482245 -0.08354677  0.37560863  0.05144023]
 [ 0.99985184  0.9961947  -0.00527224 -0.0612561   0.37300157  0.0141314 ]
 [ 0.99985184  0.99144486 -0.01672786 -0.12016715  0.36987311 -0.04773373]
 [ 0.99985184  0.98480775 -0.04823084 -0.14245782  0.36778746 -0.04616725]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.28111842 -0.02527259 -0.48810863  0.54885444]
 [ 0.99985184  0.99904822  0.03482245 -0.08354677  0.37560863  0.05144023]
 [ 0.99985184  0.9961947  -0.00527224 -0.0612561   0.37300157  0.0141314 ]
 [ 0.99985184  0.99144486 -0.01672786 -0.12016715  0.36987311 -0.04773373]
 [ 0.99985184  0.98480775 -0.04823084 -0.14245782  0.36778746 -0.04616725]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.5048134326934814
lalalalalal
260 [[ 1.         -0.01529591 -0.09230382 -1.27778552  0.0793722 ]
 [ 0.99904822  0.13219528 -0.06571423 -1.27830693  0.25982688]
 [ 0.9961947   0.08923668 -0.00966912 -1.27987117  0.39919994]
 [ 0.99144486  0.05200589 -0.06316673 -1.2814354   0.30229849]
 [ 0.98480775  0.15797044 -0.08959709 -1.28769233  0.40279624]]
hahahahahahah
265 [[-0.84754092  1.         -0.01529591 -0.09230382 -1.27778552  0.0793722 ]
 [-0.84754092  0.99904822  0.13219528 -0.06571423 -1.27830693  0.25982688]
 [-0.84754092  0.9961947   0.08923668 -0.00966912 -1.27987117  0.39919994]
 [-0.84754092  0.99144486  0.05200589 -0.06316673 -1.2814354   0.30229849]
 [-0.84754092  0.98480775  0.15797044 -0.08959709 -1.28769233  0.40279624]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.01529591 -0.09230382 -1.27778552  0.0793722 ]
 [-0.84754092  0.99904822  0.13219528 -0.06571423 -1.27830693  0.25982688]
 [-0.84754092  0.9961947   0.08923668 -0.00966912 -1.27987117  0.39919994]
 [-0.84754092  0.99144486  0.05200589 -0.06316673 -1.2814354   0.30229849]
 [-0.84754092  0.98480775  0.15797044 -0.08959709 -1.28769233  0.40279624]]

Epoch: 0, 
Train Loss: 0.9963269251234391, 
Validation Loss: 0.670883615501225
Elapsed time for epoch-0: 4.081693887710571
common line69: model saved with val loss 0.670883615501225

Epoch: 1, 
Train Loss: 0.9484649479639631, 
Validation Loss: 0.6479830062016845
Elapsed time for epoch-1: 4.020461559295654
common line69: model saved with val loss 0.6479830062016845

Epoch: 2, 
Train Loss: 0.939265896918393, 
Validation Loss: 0.646195700392127
Elapsed time for epoch-2: 3.949317693710327
common line69: model saved with val loss 0.646195700392127

Epoch: 3, 
Train Loss: 0.9341980422995672, 
Validation Loss: 0.6431863894686103
Elapsed time for epoch-3: 5.794369220733643
common line69: model saved with val loss 0.6431863894686103

Epoch: 4, 
Train Loss: 0.9308310822278512, 
Validation Loss: 0.6374425636604428
Elapsed time for epoch-4: 4.481707334518433
common line69: model saved with val loss 0.6374425636604428

Epoch: 5, 
Train Loss: 0.9281081433306221, 
Validation Loss: 0.6374048069119453
Elapsed time for epoch-5: 5.003451824188232
common line69: model saved with val loss 0.6374048069119453

Epoch: 6, 
Train Loss: 0.926153924910962, 
Validation Loss: 0.6349173430353403
Elapsed time for epoch-6: 4.930870294570923
common line69: model saved with val loss 0.6349173430353403

Epoch: 7, 
Train Loss: 0.92425971321699, 
Validation Loss: 0.6398083353415132
Elapsed time for epoch-7: 4.051802635192871

Epoch: 8, 
Train Loss: 0.9223941441844491, 
Validation Loss: 0.634574705734849
Elapsed time for epoch-8: 4.331260919570923
common line69: model saved with val loss 0.634574705734849

Epoch: 9, 
Train Loss: 0.921265849671444, 
Validation Loss: 0.6322173299267888
Elapsed time for epoch-9: 3.61619234085083
common line69: model saved with val loss 0.6322173299267888

Epoch: 10, 
Train Loss: 0.9199715100166177, 
Validation Loss: 0.6328794667497277
Elapsed time for epoch-10: 4.375339508056641

Epoch: 11, 
Train Loss: 0.9188269858851152, 
Validation Loss: 0.6339521193876863
Elapsed time for epoch-11: 3.505218505859375

Epoch: 12, 
Train Loss: 0.9177447593763095, 
Validation Loss: 0.6298797358758748
Elapsed time for epoch-12: 4.1991868019104
common line69: model saved with val loss 0.6298797358758748

Epoch: 13, 
Train Loss: 0.916616770149279, 
Validation Loss: 0.6292568459175527
Elapsed time for epoch-13: 4.257265090942383
common line69: model saved with val loss 0.6292568459175527

Epoch: 14, 
Train Loss: 0.9159235543563586, 
Validation Loss: 0.6317843804135919
Elapsed time for epoch-14: 4.213258743286133

Epoch: 15, 
Train Loss: 0.9150176029495832, 
Validation Loss: 0.6313206059858203
Elapsed time for epoch-15: 4.080782175064087

Epoch: 16, 
Train Loss: 0.9143886761505062, 
Validation Loss: 0.6285824687220156
Elapsed time for epoch-16: 3.866644859313965
common line69: model saved with val loss 0.6285824687220156

Epoch: 17, 
Train Loss: 0.9137113441188797, 
Validation Loss: 0.6273743542842567
Elapsed time for epoch-17: 3.9278273582458496
common line69: model saved with val loss 0.6273743542842567

Epoch: 18, 
Train Loss: 0.9131017591522521, 
Validation Loss: 0.625203737989068
Elapsed time for epoch-18: 3.6005048751831055
common line69: model saved with val loss 0.625203737989068

Epoch: 19, 
Train Loss: 0.9127691008714067, 
Validation Loss: 0.6231963797472417
Elapsed time for epoch-19: 4.308279752731323
common line69: model saved with val loss 0.6231963797472417

Epoch: 20, 
Train Loss: 0.9120649322241294, 
Validation Loss: 0.624692770652473
Elapsed time for epoch-20: 4.268815040588379

Epoch: 21, 
Train Loss: 0.9118902836026264, 
Validation Loss: 0.6241904823109508
Elapsed time for epoch-21: 3.4046642780303955

Epoch: 22, 
Train Loss: 0.911186864646543, 
Validation Loss: 0.625460630748421
Elapsed time for epoch-22: 3.609182834625244

Epoch: 23, 
Train Loss: 0.910978844311057, 
Validation Loss: 0.6260580732487142
Elapsed time for epoch-23: 3.604043960571289

Epoch: 24, 
Train Loss: 0.9106774510455733, 
Validation Loss: 0.6221799738705158
Elapsed time for epoch-24: 3.7063145637512207
common line69: model saved with val loss 0.6221799738705158

Epoch: 25, 
Train Loss: 0.9102605203119647, 
Validation Loss: 0.6231556376442313
Elapsed time for epoch-25: 3.4630393981933594

Epoch: 26, 
Train Loss: 0.9100418942315238, 
Validation Loss: 0.6229112106375396
Elapsed time for epoch-26: 3.4550914764404297

Epoch: 27, 
Train Loss: 0.909493614770785, 
Validation Loss: 0.6201968840323389
Elapsed time for epoch-27: 4.06733250617981
common line69: model saved with val loss 0.6201968840323389

Epoch: 28, 
Train Loss: 0.9095931739366355, 
Validation Loss: 0.6217161477543414
Elapsed time for epoch-28: 4.623208522796631

Epoch: 29, 
Train Loss: 0.9094316310742322, 
Validation Loss: 0.6180640361271799
Elapsed time for epoch-29: 3.562490463256836
common line69: model saved with val loss 0.6180640361271799

Epoch: 30, 
Train Loss: 0.9090663771919844, 
Validation Loss: 0.6212571151554585
Elapsed time for epoch-30: 3.1799492835998535

Epoch: 31, 
Train Loss: 0.9087406802578133, 
Validation Loss: 0.6197147481143475
Elapsed time for epoch-31: 3.0347299575805664

train line101: min loss for the epoch 31 is 0.6180640361271799

Training the 16-th turbine in 221.23988699913025 secs

>>>>>>>>> Training Turbine  17 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.074451446533203
lalalalalal
260 [[ 1.          0.3443876  -0.06242779 -0.41927695  0.30893368]
 [ 0.99904822  0.34585598 -0.19975463 -0.2323251  -0.00352596]
 [ 0.9961947   0.2988678  -0.15703814 -0.2323251  -0.01666854]
 [ 0.99144486  0.2166385  -0.22978966 -0.2336864  -0.15799096]
 [ 0.98480775  0.23719582 -0.25515257 -0.23459393 -0.11965277]]
hahahahahahah
265 [[ 0.99985184  1.          0.3443876  -0.06242779 -0.41927695  0.30893368]
 [ 0.99985184  0.99904822  0.34585598 -0.19975463 -0.2323251  -0.00352596]
 [ 0.99985184  0.9961947   0.2988678  -0.15703814 -0.2323251  -0.01666854]
 [ 0.99985184  0.99144486  0.2166385  -0.22978966 -0.2336864  -0.15799096]
 [ 0.99985184  0.98480775  0.23719582 -0.25515257 -0.23459393 -0.11965277]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.3443876  -0.06242779 -0.41927695  0.30893368]
 [ 0.99985184  0.99904822  0.34585598 -0.19975463 -0.2323251  -0.00352596]
 [ 0.99985184  0.9961947   0.2988678  -0.15703814 -0.2323251  -0.01666854]
 [ 0.99985184  0.99144486  0.2166385  -0.22978966 -0.2336864  -0.15799096]
 [ 0.99985184  0.98480775  0.23719582 -0.25515257 -0.23459393 -0.11965277]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.141777038574219
lalalalalal
260 [[ 1.         -0.08731626 -0.11365421 -0.455635    0.14942956]
 [ 0.99904822  0.00812847 -0.03055729 -0.4539901   0.37508919]
 [ 0.9961947  -0.03592294  0.02751044 -0.44049054  0.39992162]
 [ 0.99144486 -0.00655533 -0.01954444 -0.43209586  0.35565906]
 [ 0.98480775  0.0815475  -0.08028195 -0.43050768  0.40430248]]
hahahahahahah
265 [[-0.84754092  1.         -0.08731626 -0.11365421 -0.455635    0.14942956]
 [-0.84754092  0.99904822  0.00812847 -0.03055729 -0.4539901   0.37508919]
 [-0.84754092  0.9961947  -0.03592294  0.02751044 -0.44049054  0.39992162]
 [-0.84754092  0.99144486 -0.00655533 -0.01954444 -0.43209586  0.35565906]
 [-0.84754092  0.98480775  0.0815475  -0.08028195 -0.43050768  0.40430248]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.08731626 -0.11365421 -0.455635    0.14942956]
 [-0.84754092  0.99904822  0.00812847 -0.03055729 -0.4539901   0.37508919]
 [-0.84754092  0.9961947  -0.03592294  0.02751044 -0.44049054  0.39992162]
 [-0.84754092  0.99144486 -0.00655533 -0.01954444 -0.43209586  0.35565906]
 [-0.84754092  0.98480775  0.0815475  -0.08028195 -0.43050768  0.40430248]]

Epoch: 0, 
Train Loss: 0.9936742497091534, 
Validation Loss: 0.7139544375240803
Elapsed time for epoch-0: 4.478821754455566
common line69: model saved with val loss 0.7139544375240803

Epoch: 1, 
Train Loss: 0.9476495415222745, 
Validation Loss: 0.6649974277243018
Elapsed time for epoch-1: 3.7624409198760986
common line69: model saved with val loss 0.6649974277243018

Epoch: 2, 
Train Loss: 0.9360686528081653, 
Validation Loss: 0.6678912718780339
Elapsed time for epoch-2: 3.4512670040130615

Epoch: 3, 
Train Loss: 0.9306362853581164, 
Validation Loss: 0.6640662243589759
Elapsed time for epoch-3: 3.32991361618042
common line69: model saved with val loss 0.6640662243589759

Epoch: 4, 
Train Loss: 0.926695893917765, 
Validation Loss: 0.6546429325826466
Elapsed time for epoch-4: 3.246344804763794
common line69: model saved with val loss 0.6546429325826466

Epoch: 5, 
Train Loss: 0.9235931572293034, 
Validation Loss: 0.6539826742373407
Elapsed time for epoch-5: 4.303438901901245
common line69: model saved with val loss 0.6539826742373407

Epoch: 6, 
Train Loss: 0.9206699710182783, 
Validation Loss: 0.653757450170815
Elapsed time for epoch-6: 3.902379035949707
common line69: model saved with val loss 0.653757450170815

Epoch: 7, 
Train Loss: 0.9184803633379335, 
Validation Loss: 0.6463898476213217
Elapsed time for epoch-7: 3.785656690597534
common line69: model saved with val loss 0.6463898476213217

Epoch: 8, 
Train Loss: 0.9168958138017094, 
Validation Loss: 0.6548805125057697
Elapsed time for epoch-8: 5.0832531452178955

Epoch: 9, 
Train Loss: 0.9155060135516799, 
Validation Loss: 0.6442116452381015
Elapsed time for epoch-9: 4.811478614807129
common line69: model saved with val loss 0.6442116452381015

Epoch: 10, 
Train Loss: 0.9140286048670777, 
Validation Loss: 0.6456529651768506
Elapsed time for epoch-10: 4.9106199741363525

Epoch: 11, 
Train Loss: 0.912921377966384, 
Validation Loss: 0.6478832829743624
Elapsed time for epoch-11: 4.34082818031311

Epoch: 12, 
Train Loss: 0.9120745651361322, 
Validation Loss: 0.6491324375383556
Elapsed time for epoch-12: 5.402331590652466

Epoch: 13, 
Train Loss: 0.9112679855663235, 
Validation Loss: 0.6444458267651498
Elapsed time for epoch-13: 4.348949193954468

Epoch: 14, 
Train Loss: 0.9105976046133442, 
Validation Loss: 0.6484853327274323
Elapsed time for epoch-14: 4.3648521900177

Epoch: 15, 
Train Loss: 0.9097459025743628, 
Validation Loss: 0.6534947212785482
Elapsed time for epoch-15: 3.935819149017334

Epoch: 16, 
Train Loss: 0.9093979942698439, 
Validation Loss: 0.649396744556725
Elapsed time for epoch-16: 3.8322982788085938

Epoch: 17, 
Train Loss: 0.9088300531651793, 
Validation Loss: 0.6442954326048493
Elapsed time for epoch-17: 3.944654941558838

Epoch: 18, 
Train Loss: 0.9084095571722303, 
Validation Loss: 0.645334049127996
Elapsed time for epoch-18: 3.6793696880340576

Epoch: 19, 
Train Loss: 0.9080380342838144, 
Validation Loss: 0.6494847424328327
Elapsed time for epoch-19: 3.511881113052368

Epoch: 20, 
Train Loss: 0.9078305771871775, 
Validation Loss: 0.6474963752552867
Elapsed time for epoch-20: 3.5808491706848145

Epoch: 21, 
Train Loss: 0.9073448471662378, 
Validation Loss: 0.6440606638789177
Elapsed time for epoch-21: 3.4963390827178955
common line69: model saved with val loss 0.6440606638789177

Epoch: 22, 
Train Loss: 0.9068136098755508, 
Validation Loss: 0.6441666604951024
Elapsed time for epoch-22: 3.4219138622283936

Epoch: 23, 
Train Loss: 0.9066098609140941, 
Validation Loss: 0.6392966280691326
Elapsed time for epoch-23: 3.102163553237915
common line69: model saved with val loss 0.6392966280691326

Epoch: 24, 
Train Loss: 0.9062756337538487, 
Validation Loss: 0.647764666005969
Elapsed time for epoch-24: 3.1676509380340576

Epoch: 25, 
Train Loss: 0.9062778863335857, 
Validation Loss: 0.6423139814287424
Elapsed time for epoch-25: 3.0040650367736816

Epoch: 26, 
Train Loss: 0.9058286930833545, 
Validation Loss: 0.6401593014597893
Elapsed time for epoch-26: 3.0070228576660156

Epoch: 27, 
Train Loss: 0.905783362749244, 
Validation Loss: 0.6435305471532047
Elapsed time for epoch-27: 3.1209187507629395

Epoch: 28, 
Train Loss: 0.9053455880459618, 
Validation Loss: 0.6399259297177196
Elapsed time for epoch-28: 3.819312334060669

Epoch: 29, 
Train Loss: 0.9052554346433207, 
Validation Loss: 0.6405309396795928
Elapsed time for epoch-29: 3.7628448009490967

Epoch: 30, 
Train Loss: 0.9049603400611076, 
Validation Loss: 0.645128611009568
Elapsed time for epoch-30: 3.328449010848999

Epoch: 31, 
Train Loss: 0.9049206963356804, 
Validation Loss: 0.6427817610092461
Elapsed time for epoch-31: 3.4050469398498535

train line101: min loss for the epoch 31 is 0.6392966280691326

Training the 17-th turbine in 217.40360808372498 secs

>>>>>>>>> Training Turbine  18 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.469733953475952
lalalalalal
260 [[ 1.         -0.03574202 -0.06800869 -0.03392961  0.28011791]
 [ 0.99904822 -0.00177534 -0.15223555  0.48293194  0.0155227 ]
 [ 0.9961947  -0.03857258 -0.11483752  0.47773735 -0.03029375]
 [ 0.99144486 -0.08103093 -0.21662519  0.47189344 -0.08153675]
 [ 0.98480775 -0.09235316 -0.2319096   0.46734818 -0.06772999]]
hahahahahahah
265 [[ 0.99985184  1.         -0.03574202 -0.06800869 -0.03392961  0.28011791]
 [ 0.99985184  0.99904822 -0.00177534 -0.15223555  0.48293194  0.0155227 ]
 [ 0.99985184  0.9961947  -0.03857258 -0.11483752  0.47773735 -0.03029375]
 [ 0.99985184  0.99144486 -0.08103093 -0.21662519  0.47189344 -0.08153675]
 [ 0.99985184  0.98480775 -0.09235316 -0.2319096   0.46734818 -0.06772999]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.03574202 -0.06800869 -0.03392961  0.28011791]
 [ 0.99985184  0.99904822 -0.00177534 -0.15223555  0.48293194  0.0155227 ]
 [ 0.99985184  0.9961947  -0.03857258 -0.11483752  0.47773735 -0.03029375]
 [ 0.99985184  0.99144486 -0.08103093 -0.21662519  0.47189344 -0.08153675]
 [ 0.99985184  0.98480775 -0.09235316 -0.2319096   0.46734818 -0.06772999]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.3484256267547607
lalalalalal
260 [[ 1.          0.12843028 -0.10085391 -1.57022916  0.16215369]
 [ 0.99904822  0.21617755 -0.17890196 -1.57347578  0.28043846]
 [ 0.9961947   0.16522752 -0.13402433 -1.57347578  0.37211717]
 [ 0.99144486  0.1142775  -0.17272316 -1.57347578  0.25820569]
 [ 0.98480775  0.22749977 -0.20426758 -1.57347578  0.39176261]]
hahahahahahah
265 [[-0.84754092  1.          0.12843028 -0.10085391 -1.57022916  0.16215369]
 [-0.84754092  0.99904822  0.21617755 -0.17890196 -1.57347578  0.28043846]
 [-0.84754092  0.9961947   0.16522752 -0.13402433 -1.57347578  0.37211717]
 [-0.84754092  0.99144486  0.1142775  -0.17272316 -1.57347578  0.25820569]
 [-0.84754092  0.98480775  0.22749977 -0.20426758 -1.57347578  0.39176261]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.12843028 -0.10085391 -1.57022916  0.16215369]
 [-0.84754092  0.99904822  0.21617755 -0.17890196 -1.57347578  0.28043846]
 [-0.84754092  0.9961947   0.16522752 -0.13402433 -1.57347578  0.37211717]
 [-0.84754092  0.99144486  0.1142775  -0.17272316 -1.57347578  0.25820569]
 [-0.84754092  0.98480775  0.22749977 -0.20426758 -1.57347578  0.39176261]]

Epoch: 0, 
Train Loss: 0.9947158745607408, 
Validation Loss: 0.629647240974009
Elapsed time for epoch-0: 3.8736491203308105
common line69: model saved with val loss 0.629647240974009

Epoch: 1, 
Train Loss: 0.9519524847259041, 
Validation Loss: 0.5888711460866034
Elapsed time for epoch-1: 3.794806718826294
common line69: model saved with val loss 0.5888711460866034

Epoch: 2, 
Train Loss: 0.9415580381114944, 
Validation Loss: 0.5883393813855946
Elapsed time for epoch-2: 4.571777820587158
common line69: model saved with val loss 0.5883393813855946

Epoch: 3, 
Train Loss: 0.9356413777886319, 
Validation Loss: 0.5836610747501254
Elapsed time for epoch-3: 4.088637828826904
common line69: model saved with val loss 0.5836610747501254

Epoch: 4, 
Train Loss: 0.9319532382137635, 
Validation Loss: 0.5820593521930277
Elapsed time for epoch-4: 4.1822686195373535
common line69: model saved with val loss 0.5820593521930277

Epoch: 5, 
Train Loss: 0.9293907285988832, 
Validation Loss: 0.5789291388355196
Elapsed time for epoch-5: 4.244649410247803
common line69: model saved with val loss 0.5789291388355196

Epoch: 6, 
Train Loss: 0.9276127066431927, 
Validation Loss: 0.5756062916480005
Elapsed time for epoch-6: 3.6481282711029053
common line69: model saved with val loss 0.5756062916480005

Epoch: 7, 
Train Loss: 0.9262986168140123, 
Validation Loss: 0.5751819014549255
Elapsed time for epoch-7: 4.162879467010498
common line69: model saved with val loss 0.5751819014549255

Epoch: 8, 
Train Loss: 0.924924482943631, 
Validation Loss: 0.5707727349363267
Elapsed time for epoch-8: 3.2759499549865723
common line69: model saved with val loss 0.5707727349363267

Epoch: 9, 
Train Loss: 0.924074603855109, 
Validation Loss: 0.5724401064217091
Elapsed time for epoch-9: 4.2178919315338135

Epoch: 10, 
Train Loss: 0.9228057448102647, 
Validation Loss: 0.5673869946040213
Elapsed time for epoch-10: 3.9119670391082764
common line69: model saved with val loss 0.5673869946040213

Epoch: 11, 
Train Loss: 0.9221357308766421, 
Validation Loss: 0.563289234880358
Elapsed time for epoch-11: 3.918727159500122
common line69: model saved with val loss 0.563289234880358

Epoch: 12, 
Train Loss: 0.9213845759880643, 
Validation Loss: 0.5637424476444721
Elapsed time for epoch-12: 3.851763963699341

Epoch: 13, 
Train Loss: 0.9207156096436396, 
Validation Loss: 0.5653932294808328
Elapsed time for epoch-13: 4.371038913726807

Epoch: 14, 
Train Loss: 0.919783047142149, 
Validation Loss: 0.5648518288508058
Elapsed time for epoch-14: 4.6193695068359375

Epoch: 15, 
Train Loss: 0.9193218951465703, 
Validation Loss: 0.5613485304638743
Elapsed time for epoch-15: 3.871697187423706
common line69: model saved with val loss 0.5613485304638743

Epoch: 16, 
Train Loss: 0.9186223428539869, 
Validation Loss: 0.5645226486958563
Elapsed time for epoch-16: 4.1627678871154785

Epoch: 17, 
Train Loss: 0.9181584173641285, 
Validation Loss: 0.5613178042694926
Elapsed time for epoch-17: 4.580822944641113
common line69: model saved with val loss 0.5613178042694926

Epoch: 18, 
Train Loss: 0.9174217228629008, 
Validation Loss: 0.5564181334339082
Elapsed time for epoch-18: 4.641483783721924
common line69: model saved with val loss 0.5564181334339082

Epoch: 19, 
Train Loss: 0.9169433998460529, 
Validation Loss: 0.5554085439071059
Elapsed time for epoch-19: 4.616023063659668
common line69: model saved with val loss 0.5554085439071059

Epoch: 20, 
Train Loss: 0.916292627819446, 
Validation Loss: 0.5590309496037662
Elapsed time for epoch-20: 4.220838308334351

Epoch: 21, 
Train Loss: 0.9154995785040014, 
Validation Loss: 0.5561030134558678
Elapsed time for epoch-21: 5.77669358253479

Epoch: 22, 
Train Loss: 0.9149491019359156, 
Validation Loss: 0.5561330709606409
Elapsed time for epoch-22: 3.372133731842041

Epoch: 23, 
Train Loss: 0.9142999485009858, 
Validation Loss: 0.5577840753830969
Elapsed time for epoch-23: 3.77363657951355

Epoch: 24, 
Train Loss: 0.9138503532950618, 
Validation Loss: 0.5561253153719008
Elapsed time for epoch-24: 3.279144287109375

Epoch: 25, 
Train Loss: 0.9130199367509169, 
Validation Loss: 0.5567802349105477
Elapsed time for epoch-25: 3.320808172225952

Epoch: 26, 
Train Loss: 0.912474264242068, 
Validation Loss: 0.5513360304757953
Elapsed time for epoch-26: 3.368119239807129
common line69: model saved with val loss 0.5513360304757953

Epoch: 27, 
Train Loss: 0.9122577948229653, 
Validation Loss: 0.5560457520186901
Elapsed time for epoch-27: 3.496553421020508

Epoch: 28, 
Train Loss: 0.9116722758577651, 
Validation Loss: 0.5531871411949396
Elapsed time for epoch-28: 3.0777382850646973

Epoch: 29, 
Train Loss: 0.9113103837526145, 
Validation Loss: 0.5613658758811653
Elapsed time for epoch-29: 3.182562828063965

Epoch: 30, 
Train Loss: 0.9109947591268716, 
Validation Loss: 0.5557811409235001
Elapsed time for epoch-30: 3.2292041778564453

Epoch: 31, 
Train Loss: 0.9104436327930258, 
Validation Loss: 0.5557918227277696
Elapsed time for epoch-31: 3.060711145401001

train line101: min loss for the epoch 31 is 0.5513360304757953

Training the 18-th turbine in 218.24865865707397 secs

>>>>>>>>> Training Turbine  19 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.8917973041534424
lalalalalal
260 [[ 1.          0.30721452 -0.04294184 -0.72442287  0.3278308 ]
 [ 0.99904822  0.10432174 -0.1595276   0.49315509 -0.03047828]
 [ 0.9961947   0.05550543 -0.19194892  0.49108613 -0.09789788]
 [ 0.99144486 -0.011617   -0.16836978  0.48694823 -0.19043008]
 [ 0.98480775 -0.01771904 -0.25187923  0.47936208 -0.2417141 ]]
hahahahahahah
265 [[ 0.99985184  1.          0.30721452 -0.04294184 -0.72442287  0.3278308 ]
 [ 0.99985184  0.99904822  0.10432174 -0.1595276   0.49315509 -0.03047828]
 [ 0.99985184  0.9961947   0.05550543 -0.19194892  0.49108613 -0.09789788]
 [ 0.99985184  0.99144486 -0.011617   -0.16836978  0.48694823 -0.19043008]
 [ 0.99985184  0.98480775 -0.01771904 -0.25187923  0.47936208 -0.2417141 ]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.30721452 -0.04294184 -0.72442287  0.3278308 ]
 [ 0.99985184  0.99904822  0.10432174 -0.1595276   0.49315509 -0.03047828]
 [ 0.99985184  0.9961947   0.05550543 -0.19194892  0.49108613 -0.09789788]
 [ 0.99985184  0.99144486 -0.011617   -0.16836978  0.48694823 -0.19043008]
 [ 0.99985184  0.98480775 -0.01771904 -0.25187923  0.47936208 -0.2417141 ]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.7839322090148926
lalalalalal
260 [[ 1.         -0.03297413 -0.0989423  -1.67579574 -0.07914975]
 [ 0.99904822  0.14703601 -0.0442518  -1.67855434  0.05659867]
 [ 0.9961947   0.33009717 -0.04195938 -1.68062329  0.59022404]
 [ 0.99144486  0.23246455 -0.05047407 -1.68062329  0.41450493]
 [ 0.98480775  0.12567887 -0.05767881 -1.68545084  0.26870917]]
hahahahahahah
265 [[-0.84754092  1.         -0.03297413 -0.0989423  -1.67579574 -0.07914975]
 [-0.84754092  0.99904822  0.14703601 -0.0442518  -1.67855434  0.05659867]
 [-0.84754092  0.9961947   0.33009717 -0.04195938 -1.68062329  0.59022404]
 [-0.84754092  0.99144486  0.23246455 -0.05047407 -1.68062329  0.41450493]
 [-0.84754092  0.98480775  0.12567887 -0.05767881 -1.68545084  0.26870917]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.03297413 -0.0989423  -1.67579574 -0.07914975]
 [-0.84754092  0.99904822  0.14703601 -0.0442518  -1.67855434  0.05659867]
 [-0.84754092  0.9961947   0.33009717 -0.04195938 -1.68062329  0.59022404]
 [-0.84754092  0.99144486  0.23246455 -0.05047407 -1.68062329  0.41450493]
 [-0.84754092  0.98480775  0.12567887 -0.05767881 -1.68545084  0.26870917]]

Epoch: 0, 
Train Loss: 0.9914894438340884, 
Validation Loss: 0.6366182481870055
Elapsed time for epoch-0: 3.9455320835113525
common line69: model saved with val loss 0.6366182481870055

Epoch: 1, 
Train Loss: 0.9515789750994754, 
Validation Loss: 0.6071296855807304
Elapsed time for epoch-1: 4.013986825942993
common line69: model saved with val loss 0.6071296855807304

Epoch: 2, 
Train Loss: 0.9422081943069186, 
Validation Loss: 0.5929826945066452
Elapsed time for epoch-2: 4.457951784133911
common line69: model saved with val loss 0.5929826945066452

Epoch: 3, 
Train Loss: 0.9371505353380652, 
Validation Loss: 0.5959133417345583
Elapsed time for epoch-3: 3.9457895755767822

Epoch: 4, 
Train Loss: 0.933379390910894, 
Validation Loss: 0.6015287237241864
Elapsed time for epoch-4: 4.1069016456604

Epoch: 5, 
Train Loss: 0.9309513320942887, 
Validation Loss: 0.5911499229259789
Elapsed time for epoch-5: 3.9223127365112305
common line69: model saved with val loss 0.5911499229259789

Epoch: 6, 
Train Loss: 0.9285329960975326, 
Validation Loss: 0.5955471694469452
Elapsed time for epoch-6: 3.981027841567993

Epoch: 7, 
Train Loss: 0.9268435233530878, 
Validation Loss: 0.5924920309334993
Elapsed time for epoch-7: 4.146562576293945

Epoch: 8, 
Train Loss: 0.9255069202485204, 
Validation Loss: 0.5975290415808558
Elapsed time for epoch-8: 4.242498874664307

Epoch: 9, 
Train Loss: 0.9240655509614143, 
Validation Loss: 0.5904212594032288
Elapsed time for epoch-9: 3.7344815731048584
common line69: model saved with val loss 0.5904212594032288

Epoch: 10, 
Train Loss: 0.9228900354199049, 
Validation Loss: 0.5980610568076372
Elapsed time for epoch-10: 4.382885932922363

Epoch: 11, 
Train Loss: 0.921751242725789, 
Validation Loss: 0.5901834201067686
Elapsed time for epoch-11: 4.166771173477173
common line69: model saved with val loss 0.5901834201067686

Epoch: 12, 
Train Loss: 0.9204715507871964, 
Validation Loss: 0.5917706685140729
Elapsed time for epoch-12: 4.336974143981934

Epoch: 13, 
Train Loss: 0.9191695622035435, 
Validation Loss: 0.5930142630822957
Elapsed time for epoch-13: 4.317120552062988

Epoch: 14, 
Train Loss: 0.9181002149311435, 
Validation Loss: 0.5906329499557614
Elapsed time for epoch-14: 4.287878513336182

Epoch: 15, 
Train Loss: 0.9169869657073703, 
Validation Loss: 0.5918906121514738
Elapsed time for epoch-15: 4.165795564651489

Epoch: 16, 
Train Loss: 0.91613878873216, 
Validation Loss: 0.5875037903897464
Elapsed time for epoch-16: 4.127950668334961
common line69: model saved with val loss 0.5875037903897464

Epoch: 17, 
Train Loss: 0.9152774397565537, 
Validation Loss: 0.5862024128437042
Elapsed time for epoch-17: 4.529901742935181
common line69: model saved with val loss 0.5862024128437042

Epoch: 18, 
Train Loss: 0.9147148586872245, 
Validation Loss: 0.5868897158652544
Elapsed time for epoch-18: 3.894132137298584

Epoch: 19, 
Train Loss: 0.9139141907461551, 
Validation Loss: 0.5858704643324018
Elapsed time for epoch-19: 3.93701171875
common line69: model saved with val loss 0.5858704643324018

Epoch: 20, 
Train Loss: 0.9133893576990656, 
Validation Loss: 0.5878411359153688
Elapsed time for epoch-20: 3.3254244327545166

Epoch: 21, 
Train Loss: 0.9130710797900913, 
Validation Loss: 0.585461507551372
Elapsed time for epoch-21: 3.42368483543396
common line69: model saved with val loss 0.585461507551372

Epoch: 22, 
Train Loss: 0.9122332265647519, 
Validation Loss: 0.5888030035421252
Elapsed time for epoch-22: 3.659594774246216

Epoch: 23, 
Train Loss: 0.9120171707467872, 
Validation Loss: 0.5853533307090402
Elapsed time for epoch-23: 3.416625738143921
common line69: model saved with val loss 0.5853533307090402

Epoch: 24, 
Train Loss: 0.9116404638821337, 
Validation Loss: 0.5866534989327192
Elapsed time for epoch-24: 3.6518778800964355

Epoch: 25, 
Train Loss: 0.9111027474663839, 
Validation Loss: 0.5874489098787308
Elapsed time for epoch-25: 3.155341625213623

Epoch: 26, 
Train Loss: 0.9108526639076842, 
Validation Loss: 0.5834637982770801
Elapsed time for epoch-26: 3.7165887355804443
common line69: model saved with val loss 0.5834637982770801

Epoch: 27, 
Train Loss: 0.9105871307248828, 
Validation Loss: 0.5834864345379174
Elapsed time for epoch-27: 3.6565747261047363

Epoch: 28, 
Train Loss: 0.9102085471904579, 
Validation Loss: 0.5849181460216641
Elapsed time for epoch-28: 3.4062554836273193

Epoch: 29, 
Train Loss: 0.9097745704049823, 
Validation Loss: 0.5850268565118313
Elapsed time for epoch-29: 3.3513662815093994

Epoch: 30, 
Train Loss: 0.9096854957712799, 
Validation Loss: 0.5833954522386193
Elapsed time for epoch-30: 3.4243061542510986
common line69: model saved with val loss 0.5833954522386193

Epoch: 31, 
Train Loss: 0.9092056262893837, 
Validation Loss: 0.5811551832593977
Elapsed time for epoch-31: 3.277726173400879
common line69: model saved with val loss 0.5811551832593977

train line101: min loss for the epoch 31 is 0.5811551832593977

Training the 19-th turbine in 225.86006116867065 secs

>>>>>>>>> Training Turbine  20 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.3086447715759277
lalalalalal
260 [[ 1.          0.12123174 -0.22543446 -0.51294786  0.29540453]
 [ 0.99904822  0.08657231 -0.39141372  0.38421181 -0.14420158]
 [ 0.9961947  -0.01451768 -0.39076154  0.38207762 -0.20156456]
 [ 0.99144486 -0.10405454 -0.14326006  0.3762086  -0.23769309]
 [ 0.98480775 -0.12138425 -0.01478103  0.36767184 -0.23702447]]
hahahahahahah
265 [[ 0.99985184  1.          0.12123174 -0.22543446 -0.51294786  0.29540453]
 [ 0.99985184  0.99904822  0.08657231 -0.39141372  0.38421181 -0.14420158]
 [ 0.99985184  0.9961947  -0.01451768 -0.39076154  0.38207762 -0.20156456]
 [ 0.99985184  0.99144486 -0.10405454 -0.14326006  0.3762086  -0.23769309]
 [ 0.99985184  0.98480775 -0.12138425 -0.01478103  0.36767184 -0.23702447]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.12123174 -0.22543446 -0.51294786  0.29540453]
 [ 0.99985184  0.99904822  0.08657231 -0.39141372  0.38421181 -0.14420158]
 [ 0.99985184  0.9961947  -0.01451768 -0.39076154  0.38207762 -0.20156456]
 [ 0.99985184  0.99144486 -0.10405454 -0.14326006  0.3762086  -0.23769309]
 [ 0.99985184  0.98480775 -0.12138425 -0.01478103  0.36767184 -0.23702447]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.9447994232177734
lalalalalal
260 [[ 1.          0.16744431 -0.0436399  -1.18895221  0.24410524]
 [ 0.99904822  0.32052345 -0.10412939 -1.18281641  0.41870728]
 [ 0.9961947   0.34362974 -0.07184659 -1.18334996  0.54618314]
 [ 0.99144486  0.24542802 -0.10184677 -1.18441706  0.42444819]
 [ 0.98480775  0.32341174 -0.17097762 -1.18708479  0.44478346]]
hahahahahahah
265 [[-0.84754092  1.          0.16744431 -0.0436399  -1.18895221  0.24410524]
 [-0.84754092  0.99904822  0.32052345 -0.10412939 -1.18281641  0.41870728]
 [-0.84754092  0.9961947   0.34362974 -0.07184659 -1.18334996  0.54618314]
 [-0.84754092  0.99144486  0.24542802 -0.10184677 -1.18441706  0.42444819]
 [-0.84754092  0.98480775  0.32341174 -0.17097762 -1.18708479  0.44478346]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.16744431 -0.0436399  -1.18895221  0.24410524]
 [-0.84754092  0.99904822  0.32052345 -0.10412939 -1.18281641  0.41870728]
 [-0.84754092  0.9961947   0.34362974 -0.07184659 -1.18334996  0.54618314]
 [-0.84754092  0.99144486  0.24542802 -0.10184677 -1.18441706  0.42444819]
 [-0.84754092  0.98480775  0.32341174 -0.17097762 -1.18708479  0.44478346]]

Epoch: 0, 
Train Loss: 1.0078172592305337, 
Validation Loss: 0.7077567018568516
Elapsed time for epoch-0: 3.987311840057373
common line69: model saved with val loss 0.7077567018568516

Epoch: 1, 
Train Loss: 0.9688616811978716, 
Validation Loss: 0.6451514018699527
Elapsed time for epoch-1: 3.626875400543213
common line69: model saved with val loss 0.6451514018699527

Epoch: 2, 
Train Loss: 0.9401893476728632, 
Validation Loss: 0.6195212658494711
Elapsed time for epoch-2: 4.0281805992126465
common line69: model saved with val loss 0.6195212658494711

Epoch: 3, 
Train Loss: 0.9327055783081455, 
Validation Loss: 0.6134000797756016
Elapsed time for epoch-3: 3.732218027114868
common line69: model saved with val loss 0.6134000797756016

Epoch: 4, 
Train Loss: 0.928128767664693, 
Validation Loss: 0.617531115654856
Elapsed time for epoch-4: 3.5711395740509033

Epoch: 5, 
Train Loss: 0.9243596821021633, 
Validation Loss: 0.6142121101729572
Elapsed time for epoch-5: 3.5530667304992676

Epoch: 6, 
Train Loss: 0.9214254318415618, 
Validation Loss: 0.6168345101177692
Elapsed time for epoch-6: 4.881555557250977

Epoch: 7, 
Train Loss: 0.9191163352557591, 
Validation Loss: 0.6125370231457055
Elapsed time for epoch-7: 4.213789463043213
common line69: model saved with val loss 0.6125370231457055

Epoch: 8, 
Train Loss: 0.9175783763913548, 
Validation Loss: 0.6155856433324516
Elapsed time for epoch-8: 4.128189563751221

Epoch: 9, 
Train Loss: 0.9156210914629848, 
Validation Loss: 0.6081915074028075
Elapsed time for epoch-9: 3.5668420791625977
common line69: model saved with val loss 0.6081915074028075

Epoch: 10, 
Train Loss: 0.914614519151319, 
Validation Loss: 0.6118232803419232
Elapsed time for epoch-10: 3.9954216480255127

Epoch: 11, 
Train Loss: 0.9136430606120775, 
Validation Loss: 0.6119180312380195
Elapsed time for epoch-11: 3.3686025142669678

Epoch: 12, 
Train Loss: 0.9127164799876574, 
Validation Loss: 0.6122190817259252
Elapsed time for epoch-12: 4.12592339515686

Epoch: 13, 
Train Loss: 0.9117558793861325, 
Validation Loss: 0.607908261474222
Elapsed time for epoch-13: 3.8542397022247314
common line69: model saved with val loss 0.607908261474222

Epoch: 14, 
Train Loss: 0.9112609971721634, 
Validation Loss: 0.611063483171165
Elapsed time for epoch-14: 4.201804876327515

Epoch: 15, 
Train Loss: 0.9104891966621415, 
Validation Loss: 0.6073440811596811
Elapsed time for epoch-15: 3.970163345336914
common line69: model saved with val loss 0.6073440811596811

Epoch: 16, 
Train Loss: 0.9100299367383748, 
Validation Loss: 0.6086641792207956
Elapsed time for epoch-16: 4.156217813491821

Epoch: 17, 
Train Loss: 0.9093839571255595, 
Validation Loss: 0.6098227552138269
Elapsed time for epoch-17: 4.372764587402344

Epoch: 18, 
Train Loss: 0.9091700634786061, 
Validation Loss: 0.6082101999782026
Elapsed time for epoch-18: 4.260663986206055

Epoch: 19, 
Train Loss: 0.908489572651246, 
Validation Loss: 0.6139107323251665
Elapsed time for epoch-19: 3.4599602222442627

Epoch: 20, 
Train Loss: 0.908401322464983, 
Validation Loss: 0.6087183919735253
Elapsed time for epoch-20: 4.349628210067749

Epoch: 21, 
Train Loss: 0.9079073286857926, 
Validation Loss: 0.6105426689609885
Elapsed time for epoch-21: 4.068572998046875

Epoch: 22, 
Train Loss: 0.9075180684067622, 
Validation Loss: 0.6141450074501336
Elapsed time for epoch-22: 4.002251625061035

Epoch: 23, 
Train Loss: 0.9070430950206869, 
Validation Loss: 0.6103376294486225
Elapsed time for epoch-23: 4.494947195053101

Epoch: 24, 
Train Loss: 0.9066182292309128, 
Validation Loss: 0.6119217658415437
Elapsed time for epoch-24: 3.707120180130005

Epoch: 25, 
Train Loss: 0.9068104522067959, 
Validation Loss: 0.6092403274960816
Elapsed time for epoch-25: 3.10019850730896

Epoch: 26, 
Train Loss: 0.9064523585203315, 
Validation Loss: 0.6086046239361167
Elapsed time for epoch-26: 2.959047317504883

Epoch: 27, 
Train Loss: 0.9061491877591911, 
Validation Loss: 0.6106608780100942
Elapsed time for epoch-27: 2.9941465854644775
Early stopped! 

train line101: min loss for the epoch 27 is 0.6073440811596811

Training the 20-th turbine in 204.51309418678284 secs

>>>>>>>>> Training Turbine  21 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.904269218444824
lalalalalal
260 [[ 1.          0.19826408 -0.08864778 -0.64206163  0.32552002]
 [ 0.99904822  0.13289581 -0.13896558  0.27150789  0.03085462]
 [ 0.9961947   0.18121149 -0.28390618  0.26145413  0.04241857]
 [ 0.99144486  0.25794815 -0.27346287  0.25457524  0.11806877]
 [ 0.98480775  0.18973778 -0.2440317   0.25034208  0.09664209]]
hahahahahahah
265 [[ 0.99985184  1.          0.19826408 -0.08864778 -0.64206163  0.32552002]
 [ 0.99985184  0.99904822  0.13289581 -0.13896558  0.27150789  0.03085462]
 [ 0.99985184  0.9961947   0.18121149 -0.28390618  0.26145413  0.04241857]
 [ 0.99985184  0.99144486  0.25794815 -0.27346287  0.25457524  0.11806877]
 [ 0.99985184  0.98480775  0.18973778 -0.2440317   0.25034208  0.09664209]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.19826408 -0.08864778 -0.64206163  0.32552002]
 [ 0.99985184  0.99904822  0.13289581 -0.13896558  0.27150789  0.03085462]
 [ 0.99985184  0.9961947   0.18121149 -0.28390618  0.26145413  0.04241857]
 [ 0.99985184  0.99144486  0.25794815 -0.27346287  0.25457524  0.11806877]
 [ 0.99985184  0.98480775  0.18973778 -0.2440317   0.25034208  0.09664209]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.345970392227173
lalalalalal
260 [[ 1.         -0.22662966  0.09094565 -1.13654801 -0.13419547]
 [ 0.99904822 -0.18257713 -0.02282322 -1.12702339 -0.18261547]
 [ 0.9961947  -0.50941847  0.10977527 -1.13813544 -0.33059959]
 [ 0.99144486 -0.60320772  0.20977796 -1.06617167 -0.3252806 ]
 [ 0.98480775 -0.27636639  0.05059647 -1.12331937 -0.07709712]]
hahahahahahah
265 [[-0.84754092  1.         -0.22662966  0.09094565 -1.13654801 -0.13419547]
 [-0.84754092  0.99904822 -0.18257713 -0.02282322 -1.12702339 -0.18261547]
 [-0.84754092  0.9961947  -0.50941847  0.10977527 -1.13813544 -0.33059959]
 [-0.84754092  0.99144486 -0.60320772  0.20977796 -1.06617167 -0.3252806 ]
 [-0.84754092  0.98480775 -0.27636639  0.05059647 -1.12331937 -0.07709712]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.22662966  0.09094565 -1.13654801 -0.13419547]
 [-0.84754092  0.99904822 -0.18257713 -0.02282322 -1.12702339 -0.18261547]
 [-0.84754092  0.9961947  -0.50941847  0.10977527 -1.13813544 -0.33059959]
 [-0.84754092  0.99144486 -0.60320772  0.20977796 -1.06617167 -0.3252806 ]
 [-0.84754092  0.98480775 -0.27636639  0.05059647 -1.12331937 -0.07709712]]

Epoch: 0, 
Train Loss: 0.9938516923609901, 
Validation Loss: 0.8317701192572713
Elapsed time for epoch-0: 4.366250038146973
common line69: model saved with val loss 0.8317701192572713

Epoch: 1, 
Train Loss: 0.9384065227849143, 
Validation Loss: 0.7884059129282832
Elapsed time for epoch-1: 4.485648155212402
common line69: model saved with val loss 0.7884059129282832

Epoch: 2, 
Train Loss: 0.9247393859785145, 
Validation Loss: 0.7866039294749498
Elapsed time for epoch-2: 3.654407024383545
common line69: model saved with val loss 0.7866039294749498

Epoch: 3, 
Train Loss: 0.9186097035387984, 
Validation Loss: 0.7859639143571258
Elapsed time for epoch-3: 4.2632482051849365
common line69: model saved with val loss 0.7859639143571258

Epoch: 4, 
Train Loss: 0.9149844732855549, 
Validation Loss: 0.7874549701809883
Elapsed time for epoch-4: 4.241839170455933

Epoch: 5, 
Train Loss: 0.9127518514625165, 
Validation Loss: 0.7865399550646544
Elapsed time for epoch-5: 3.878627300262451

Epoch: 6, 
Train Loss: 0.9109781440817007, 
Validation Loss: 0.7858995851129293
Elapsed time for epoch-6: 4.112776041030884
common line69: model saved with val loss 0.7858995851129293

Epoch: 7, 
Train Loss: 0.9095845593123877, 
Validation Loss: 0.7891777167096734
Elapsed time for epoch-7: 4.81888484954834

Epoch: 8, 
Train Loss: 0.9080833066411379, 
Validation Loss: 0.788176347501576
Elapsed time for epoch-8: 4.744201421737671

Epoch: 9, 
Train Loss: 0.9070770528887501, 
Validation Loss: 0.7874454511329532
Elapsed time for epoch-9: 4.591630220413208

Epoch: 10, 
Train Loss: 0.906055157425023, 
Validation Loss: 0.7884740037843585
Elapsed time for epoch-10: 5.9542248249053955

Epoch: 11, 
Train Loss: 0.9049845374181491, 
Validation Loss: 0.7882645782083273
Elapsed time for epoch-11: 5.057927131652832

Epoch: 12, 
Train Loss: 0.9040593238187438, 
Validation Loss: 0.794682027772069
Elapsed time for epoch-12: 4.777441024780273

Epoch: 13, 
Train Loss: 0.9028811131705757, 
Validation Loss: 0.794965460896492
Elapsed time for epoch-13: 5.017354488372803

Epoch: 14, 
Train Loss: 0.9024564700216806, 
Validation Loss: 0.7968022301793098
Elapsed time for epoch-14: 5.617028474807739

Epoch: 15, 
Train Loss: 0.9017139933690304, 
Validation Loss: 0.8025729153305292
Elapsed time for epoch-15: 4.7716662883758545

Epoch: 16, 
Train Loss: 0.9008919607941844, 
Validation Loss: 0.8094561360776424
Elapsed time for epoch-16: 4.457851886749268

Epoch: 17, 
Train Loss: 0.9002147920492316, 
Validation Loss: 0.8119139764457941
Elapsed time for epoch-17: 3.7987427711486816

Epoch: 18, 
Train Loss: 0.8997017440675688, 
Validation Loss: 0.8194324020296335
Elapsed time for epoch-18: 4.39823317527771
Early stopped! 

train line101: min loss for the epoch 18 is 0.7858995851129293

Training the 21-th turbine in 182.9639549255371 secs

>>>>>>>>> Training Turbine  22 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.179469347000122
lalalalalal
260 [[ 1.00000000e+00 -1.19802294e-01 -2.86191320e-02 -2.13628706e-01
  -2.05743729e-01]
 [ 9.99048222e-01  1.95229330e-01  4.15754225e-04  4.01228712e-01
   4.36359889e-02]
 [ 9.96194698e-01  1.22217709e-01 -1.71756027e-01  3.92863305e-01
   1.75735217e-02]
 [ 9.91444861e-01  2.54720280e-01 -1.09611183e-01  3.90074836e-01
   1.24814871e-01]
 [ 9.84807753e-01  2.03341732e-01 -6.44458044e-02  3.90074836e-01
   1.17389973e-01]]
hahahahahahah
265 [[ 9.99851839e-01  1.00000000e+00 -1.19802294e-01 -2.86191320e-02
  -2.13628706e-01 -2.05743729e-01]
 [ 9.99851839e-01  9.99048222e-01  1.95229330e-01  4.15754225e-04
   4.01228712e-01  4.36359889e-02]
 [ 9.99851839e-01  9.96194698e-01  1.22217709e-01 -1.71756027e-01
   3.92863305e-01  1.75735217e-02]
 [ 9.99851839e-01  9.91444861e-01  2.54720280e-01 -1.09611183e-01
   3.90074836e-01  1.24814871e-01]
 [ 9.99851839e-01  9.84807753e-01  2.03341732e-01 -6.44458044e-02
   3.90074836e-01  1.17389973e-01]]

 wind turbine line248 data after normalization: 
 [[ 9.99851839e-01  1.00000000e+00 -1.19802294e-01 -2.86191320e-02
  -2.13628706e-01 -2.05743729e-01]
 [ 9.99851839e-01  9.99048222e-01  1.95229330e-01  4.15754225e-04
   4.01228712e-01  4.36359889e-02]
 [ 9.99851839e-01  9.96194698e-01  1.22217709e-01 -1.71756027e-01
   3.92863305e-01  1.75735217e-02]
 [ 9.99851839e-01  9.91444861e-01  2.54720280e-01 -1.09611183e-01
   3.90074836e-01  1.24814871e-01]
 [ 9.99851839e-01  9.84807753e-01  2.03341732e-01 -6.44458044e-02
   3.90074836e-01  1.17389973e-01]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.889479398727417
lalalalalal
260 [[ 1.         -0.30503548  0.05271251 -1.32343937 -0.20875673]
 [ 0.99904822 -0.32666855  0.13727025 -1.32706438 -0.30307445]
 [ 0.9961947  -0.52947861  0.16613534 -1.33375671 -0.34374998]
 [ 0.99144486 -0.35100576  0.14711834 -1.34044904 -0.16718806]
 [ 0.98480775 -0.23743213  0.12164914 -1.35048752 -0.04604386]]
hahahahahahah
265 [[-0.84754092  1.         -0.30503548  0.05271251 -1.32343937 -0.20875673]
 [-0.84754092  0.99904822 -0.32666855  0.13727025 -1.32706438 -0.30307445]
 [-0.84754092  0.9961947  -0.52947861  0.16613534 -1.33375671 -0.34374998]
 [-0.84754092  0.99144486 -0.35100576  0.14711834 -1.34044904 -0.16718806]
 [-0.84754092  0.98480775 -0.23743213  0.12164914 -1.35048752 -0.04604386]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.30503548  0.05271251 -1.32343937 -0.20875673]
 [-0.84754092  0.99904822 -0.32666855  0.13727025 -1.32706438 -0.30307445]
 [-0.84754092  0.9961947  -0.52947861  0.16613534 -1.33375671 -0.34374998]
 [-0.84754092  0.99144486 -0.35100576  0.14711834 -1.34044904 -0.16718806]
 [-0.84754092  0.98480775 -0.23743213  0.12164914 -1.35048752 -0.04604386]]

Epoch: 0, 
Train Loss: 0.967586480394131, 
Validation Loss: 0.8315399046987295
Elapsed time for epoch-0: 4.186943769454956
common line69: model saved with val loss 0.8315399046987295

Epoch: 1, 
Train Loss: 0.9314762685729676, 
Validation Loss: 0.8153347773477435
Elapsed time for epoch-1: 4.096161127090454
common line69: model saved with val loss 0.8153347773477435

Epoch: 2, 
Train Loss: 0.92436717250267, 
Validation Loss: 0.8034006450325251
Elapsed time for epoch-2: 3.1801483631134033
common line69: model saved with val loss 0.8034006450325251

Epoch: 3, 
Train Loss: 0.9201250557138139, 
Validation Loss: 0.8046289784833789
Elapsed time for epoch-3: 3.433579921722412

Epoch: 4, 
Train Loss: 0.9172895754836187, 
Validation Loss: 0.8044930584728718
Elapsed time for epoch-4: 3.281010866165161

Epoch: 5, 
Train Loss: 0.9156764931037646, 
Validation Loss: 0.7979553230106831
Elapsed time for epoch-5: 3.1347222328186035
common line69: model saved with val loss 0.7979553230106831

Epoch: 6, 
Train Loss: 0.9140915507528963, 
Validation Loss: 0.7979660658165812
Elapsed time for epoch-6: 2.8264000415802

Epoch: 7, 
Train Loss: 0.9126723920848189, 
Validation Loss: 0.7980585284531116
Elapsed time for epoch-7: 3.398487091064453

Epoch: 8, 
Train Loss: 0.9118951254782557, 
Validation Loss: 0.7924021892249584
Elapsed time for epoch-8: 3.8982882499694824
common line69: model saved with val loss 0.7924021892249584

Epoch: 9, 
Train Loss: 0.9106787702366084, 
Validation Loss: 0.7916140528395772
Elapsed time for epoch-9: 4.3289453983306885
common line69: model saved with val loss 0.7916140528395772

Epoch: 10, 
Train Loss: 0.9098923723487293, 
Validation Loss: 0.7908232696354389
Elapsed time for epoch-10: 4.451958894729614
common line69: model saved with val loss 0.7908232696354389

Epoch: 11, 
Train Loss: 0.9091952160126021, 
Validation Loss: 0.7886976050212979
Elapsed time for epoch-11: 3.9824225902557373
common line69: model saved with val loss 0.7886976050212979

Epoch: 12, 
Train Loss: 0.9083664009050161, 
Validation Loss: 0.7883762242272496
Elapsed time for epoch-12: 4.244999647140503
common line69: model saved with val loss 0.7883762242272496

Epoch: 13, 
Train Loss: 0.9076644983612189, 
Validation Loss: 0.787554182112217
Elapsed time for epoch-13: 4.272186279296875
common line69: model saved with val loss 0.787554182112217

Epoch: 14, 
Train Loss: 0.9070959495646613, 
Validation Loss: 0.7868424346670508
Elapsed time for epoch-14: 4.450558185577393
common line69: model saved with val loss 0.7868424346670508

Epoch: 15, 
Train Loss: 0.9065297806964201, 
Validation Loss: 0.7861657775938511
Elapsed time for epoch-15: 3.2507643699645996
common line69: model saved with val loss 0.7861657775938511

Epoch: 16, 
Train Loss: 0.9059203170678195, 
Validation Loss: 0.7798991715535522
Elapsed time for epoch-16: 4.289822101593018
common line69: model saved with val loss 0.7798991715535522

Epoch: 17, 
Train Loss: 0.9053938713143853, 
Validation Loss: 0.784724548459053
Elapsed time for epoch-17: 4.407243728637695

Epoch: 18, 
Train Loss: 0.9049257436970702, 
Validation Loss: 0.7828163262456656
Elapsed time for epoch-18: 4.239502429962158

Epoch: 19, 
Train Loss: 0.9043160828472185, 
Validation Loss: 0.7753984155133367
Elapsed time for epoch-19: 3.9560437202453613
common line69: model saved with val loss 0.7753984155133367

Epoch: 20, 
Train Loss: 0.9038080693293018, 
Validation Loss: 0.7800080254673958
Elapsed time for epoch-20: 4.130746603012085

Epoch: 21, 
Train Loss: 0.9035165307401609, 
Validation Loss: 0.7777920234948397
Elapsed time for epoch-21: 4.287239074707031

Epoch: 22, 
Train Loss: 0.9030181428714961, 
Validation Loss: 0.7788909720256925
Elapsed time for epoch-22: 3.7557334899902344

Epoch: 23, 
Train Loss: 0.902545676261437, 
Validation Loss: 0.777081067673862
Elapsed time for epoch-23: 3.6446402072906494

Epoch: 24, 
Train Loss: 0.9021105568449036, 
Validation Loss: 0.7808269513770938
Elapsed time for epoch-24: 3.9999163150787354

Epoch: 25, 
Train Loss: 0.9020038970879146, 
Validation Loss: 0.7787930238991976
Elapsed time for epoch-25: 3.6732566356658936

Epoch: 26, 
Train Loss: 0.901447076757415, 
Validation Loss: 0.7786295246332884
Elapsed time for epoch-26: 4.349615097045898

Epoch: 27, 
Train Loss: 0.9009594793329719, 
Validation Loss: 0.7746495939791203
Elapsed time for epoch-27: 3.6226789951324463
common line69: model saved with val loss 0.7746495939791203

Epoch: 28, 
Train Loss: 0.9007354163322128, 
Validation Loss: 0.7745950371026993
Elapsed time for epoch-28: 3.744621753692627
common line69: model saved with val loss 0.7745950371026993

Epoch: 29, 
Train Loss: 0.900710449874902, 
Validation Loss: 0.776950447820127
Elapsed time for epoch-29: 4.15634822845459

Epoch: 30, 
Train Loss: 0.9004197964648238, 
Validation Loss: 0.7789404336363077
Elapsed time for epoch-30: 4.109711170196533

Epoch: 31, 
Train Loss: 0.900290601143316, 
Validation Loss: 0.7751878201961517
Elapsed time for epoch-31: 5.1239588260650635

train line101: min loss for the epoch 31 is 0.7745950371026993

Training the 22-th turbine in 215.53358268737793 secs

>>>>>>>>> Training Turbine  23 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.284106731414795
lalalalalal
260 [[ 1.         -0.07912597 -0.03397714 -2.83758045 -0.21868033]
 [ 0.99904822  0.18785386 -0.20381289  0.15532797 -0.0981698 ]
 [ 0.9961947   0.22740643 -0.29672215  0.15532797 -0.11949338]
 [ 0.99144486  0.30933674 -0.26027543  0.15532797 -0.02276856]
 [ 0.98480775  0.25283308 -0.24623448  0.15532797 -0.03618214]]
hahahahahahah
265 [[ 0.99985184  1.         -0.07912597 -0.03397714 -2.83758045 -0.21868033]
 [ 0.99985184  0.99904822  0.18785386 -0.20381289  0.15532797 -0.0981698 ]
 [ 0.99985184  0.9961947   0.22740643 -0.29672215  0.15532797 -0.11949338]
 [ 0.99985184  0.99144486  0.30933674 -0.26027543  0.15532797 -0.02276856]
 [ 0.99985184  0.98480775  0.25283308 -0.24623448  0.15532797 -0.03618214]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.07912597 -0.03397714 -2.83758045 -0.21868033]
 [ 0.99985184  0.99904822  0.18785386 -0.20381289  0.15532797 -0.0981698 ]
 [ 0.99985184  0.9961947   0.22740643 -0.29672215  0.15532797 -0.11949338]
 [ 0.99985184  0.99144486  0.30933674 -0.26027543  0.15532797 -0.02276856]
 [ 0.99985184  0.98480775  0.25283308 -0.24623448  0.15532797 -0.03618214]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.114424705505371
lalalalalal
260 [[ 1.         -0.26417549  0.0463849   0.15532797 -0.09454903]
 [ 0.99904822 -0.35458135  0.10538676  0.15532797 -0.23301859]
 [ 0.9961947  -0.42521094 -0.05264861  0.15532797 -0.2297209 ]
 [ 0.99144486 -0.24722439 -0.12673703  0.15532797 -0.04710017]
 [ 0.98480775 -0.22179773  0.12361012  0.15532797  0.1040811 ]]
hahahahahahah
265 [[-0.84754092  1.         -0.26417549  0.0463849   0.15532797 -0.09454903]
 [-0.84754092  0.99904822 -0.35458135  0.10538676  0.15532797 -0.23301859]
 [-0.84754092  0.9961947  -0.42521094 -0.05264861  0.15532797 -0.2297209 ]
 [-0.84754092  0.99144486 -0.24722439 -0.12673703  0.15532797 -0.04710017]
 [-0.84754092  0.98480775 -0.22179773  0.12361012  0.15532797  0.1040811 ]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.26417549  0.0463849   0.15532797 -0.09454903]
 [-0.84754092  0.99904822 -0.35458135  0.10538676  0.15532797 -0.23301859]
 [-0.84754092  0.9961947  -0.42521094 -0.05264861  0.15532797 -0.2297209 ]
 [-0.84754092  0.99144486 -0.24722439 -0.12673703  0.15532797 -0.04710017]
 [-0.84754092  0.98480775 -0.22179773  0.12361012  0.15532797  0.1040811 ]]

Epoch: 0, 
Train Loss: 1.0009203935120286, 
Validation Loss: 0.7643022108823061
Elapsed time for epoch-0: 4.033977270126343
common line69: model saved with val loss 0.7643022108823061

Epoch: 1, 
Train Loss: 0.9526418691673199, 
Validation Loss: 0.7364329099655151
Elapsed time for epoch-1: 4.225060939788818
common line69: model saved with val loss 0.7364329099655151

Epoch: 2, 
Train Loss: 0.9387057749163202, 
Validation Loss: 0.7373882913962007
Elapsed time for epoch-2: 4.356624603271484

Epoch: 3, 
Train Loss: 0.93177252845103, 
Validation Loss: 0.7370454175397754
Elapsed time for epoch-3: 4.001573085784912

Epoch: 4, 
Train Loss: 0.9279663708029675, 
Validation Loss: 0.7344017289578915
Elapsed time for epoch-4: 3.8230061531066895
common line69: model saved with val loss 0.7344017289578915

Epoch: 5, 
Train Loss: 0.9254065823404729, 
Validation Loss: 0.7328330958262086
Elapsed time for epoch-5: 3.3925719261169434
common line69: model saved with val loss 0.7328330958262086

Epoch: 6, 
Train Loss: 0.9230819176725981, 
Validation Loss: 0.7335183806717396
Elapsed time for epoch-6: 3.327072858810425

Epoch: 7, 
Train Loss: 0.9213865004918155, 
Validation Loss: 0.7302951635792851
Elapsed time for epoch-7: 3.844087839126587
common line69: model saved with val loss 0.7302951635792851

Epoch: 8, 
Train Loss: 0.9196791204334307, 
Validation Loss: 0.7343714106827974
Elapsed time for epoch-8: 4.095981121063232

Epoch: 9, 
Train Loss: 0.9185832454627302, 
Validation Loss: 0.7354741403833032
Elapsed time for epoch-9: 4.094170808792114

Epoch: 10, 
Train Loss: 0.9171453999871967, 
Validation Loss: 0.7324866075068712
Elapsed time for epoch-10: 4.931608200073242

Epoch: 11, 
Train Loss: 0.9162770035136648, 
Validation Loss: 0.7362361354753375
Elapsed time for epoch-11: 4.248939752578735

Epoch: 12, 
Train Loss: 0.9151794298105881, 
Validation Loss: 0.7412100620567799
Elapsed time for epoch-12: 3.4648053646087646

Epoch: 13, 
Train Loss: 0.9145477645787872, 
Validation Loss: 0.7344039427116513
Elapsed time for epoch-13: 3.661032199859619

Epoch: 14, 
Train Loss: 0.9136100108383083, 
Validation Loss: 0.7386908270418644
Elapsed time for epoch-14: 3.5943682193756104

Epoch: 15, 
Train Loss: 0.9126468002796173, 
Validation Loss: 0.7383911227807403
Elapsed time for epoch-15: 4.2303361892700195

Epoch: 16, 
Train Loss: 0.9118574707447982, 
Validation Loss: 0.7408920442685485
Elapsed time for epoch-16: 4.416591644287109

Epoch: 17, 
Train Loss: 0.9111291744879314, 
Validation Loss: 0.7445132611319423
Elapsed time for epoch-17: 4.301951885223389

Epoch: 18, 
Train Loss: 0.9103148674764553, 
Validation Loss: 0.7443758994340897
Elapsed time for epoch-18: 3.670694589614868

Epoch: 19, 
Train Loss: 0.9099171966815195, 
Validation Loss: 0.7454934949055314
Elapsed time for epoch-19: 3.4498164653778076
Early stopped! 

train line101: min loss for the epoch 19 is 0.7302951635792851

Training the 23-th turbine in 172.78814339637756 secs

>>>>>>>>> Training Turbine  24 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.726431369781494
lalalalalal
260 [[ 1.         -0.0093249  -0.19016303  0.09292524 -0.10952206]
 [ 0.99904822  0.25806428 -0.35561345  0.10890794  0.05811535]
 [ 0.9961947   0.24698079 -0.37505882  0.10890794  0.02347766]
 [ 0.99144486  0.17770898 -0.04152131  0.10890794  0.21021626]
 [ 0.98480775  0.08627019 -0.01581388  0.10890794  0.07752792]]
hahahahahahah
265 [[ 0.99985184  1.         -0.0093249  -0.19016303  0.09292524 -0.10952206]
 [ 0.99985184  0.99904822  0.25806428 -0.35561345  0.10890794  0.05811535]
 [ 0.99985184  0.9961947   0.24698079 -0.37505882  0.10890794  0.02347766]
 [ 0.99985184  0.99144486  0.17770898 -0.04152131  0.10890794  0.21021626]
 [ 0.99985184  0.98480775  0.08627019 -0.01581388  0.10890794  0.07752792]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.0093249  -0.19016303  0.09292524 -0.10952206]
 [ 0.99985184  0.99904822  0.25806428 -0.35561345  0.10890794  0.05811535]
 [ 0.99985184  0.9961947   0.24698079 -0.37505882  0.10890794  0.02347766]
 [ 0.99985184  0.99144486  0.17770898 -0.04152131  0.10890794  0.21021626]
 [ 0.99985184  0.98480775  0.08627019 -0.01581388  0.10890794  0.07752792]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.6697428226470947
lalalalalal
260 [[ 1.         -0.2739432   0.00511461  0.10890794 -0.21107299]
 [ 0.99904822 -0.38477809  0.10942748  0.10890794 -0.32631365]
 [ 0.9961947  -0.39309071  0.0524097   0.10890794 -0.26796857]
 [ 0.99144486 -0.20744227 -0.15720478  0.10890794 -0.09931114]
 [ 0.98480775 -0.17696267  0.06064927  0.10890794  0.12728336]]
hahahahahahah
265 [[-0.84754092  1.         -0.2739432   0.00511461  0.10890794 -0.21107299]
 [-0.84754092  0.99904822 -0.38477809  0.10942748  0.10890794 -0.32631365]
 [-0.84754092  0.9961947  -0.39309071  0.0524097   0.10890794 -0.26796857]
 [-0.84754092  0.99144486 -0.20744227 -0.15720478  0.10890794 -0.09931114]
 [-0.84754092  0.98480775 -0.17696267  0.06064927  0.10890794  0.12728336]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.2739432   0.00511461  0.10890794 -0.21107299]
 [-0.84754092  0.99904822 -0.38477809  0.10942748  0.10890794 -0.32631365]
 [-0.84754092  0.9961947  -0.39309071  0.0524097   0.10890794 -0.26796857]
 [-0.84754092  0.99144486 -0.20744227 -0.15720478  0.10890794 -0.09931114]
 [-0.84754092  0.98480775 -0.17696267  0.06064927  0.10890794  0.12728336]]

Epoch: 0, 
Train Loss: 1.0014130615887522, 
Validation Loss: 0.869555096141994
Elapsed time for epoch-0: 3.9700324535369873
common line69: model saved with val loss 0.869555096141994

Epoch: 1, 
Train Loss: 0.9556449761911601, 
Validation Loss: 0.7970704073086381
Elapsed time for epoch-1: 3.4052999019622803
common line69: model saved with val loss 0.7970704073086381

Epoch: 2, 
Train Loss: 0.9358213845671726, 
Validation Loss: 0.799291705712676
Elapsed time for epoch-2: 3.085517406463623

Epoch: 3, 
Train Loss: 0.9289202488520566, 
Validation Loss: 0.7975020678713918
Elapsed time for epoch-3: 2.9612886905670166

Epoch: 4, 
Train Loss: 0.9243787312958421, 
Validation Loss: 0.8017920339480042
Elapsed time for epoch-4: 3.294705629348755

Epoch: 5, 
Train Loss: 0.9216891111446028, 
Validation Loss: 0.7927347114309669
Elapsed time for epoch-5: 3.0996124744415283
common line69: model saved with val loss 0.7927347114309669

Epoch: 6, 
Train Loss: 0.9193595180741879, 
Validation Loss: 0.7873998442664742
Elapsed time for epoch-6: 3.612065315246582
common line69: model saved with val loss 0.7873998442664742

Epoch: 7, 
Train Loss: 0.9175631611787972, 
Validation Loss: 0.7904011458158493
Elapsed time for epoch-7: 3.301971912384033

Epoch: 8, 
Train Loss: 0.9160783002857401, 
Validation Loss: 0.7934129443019629
Elapsed time for epoch-8: 3.0874435901641846

Epoch: 9, 
Train Loss: 0.914957104360356, 
Validation Loss: 0.7895856834948063
Elapsed time for epoch-9: 2.8339157104492188

Epoch: 10, 
Train Loss: 0.913784377589947, 
Validation Loss: 0.7820768384262919
Elapsed time for epoch-10: 2.9249138832092285
common line69: model saved with val loss 0.7820768384262919

Epoch: 11, 
Train Loss: 0.9126590122194851, 
Validation Loss: 0.7849854938685894
Elapsed time for epoch-11: 2.868053674697876

Epoch: 12, 
Train Loss: 0.9115155856398975, 
Validation Loss: 0.7805151753127575
Elapsed time for epoch-12: 3.1796011924743652
common line69: model saved with val loss 0.7805151753127575

Epoch: 13, 
Train Loss: 0.9110323989591679, 
Validation Loss: 0.7815867951139808
Elapsed time for epoch-13: 2.9102237224578857

Epoch: 14, 
Train Loss: 0.9100513966644511, 
Validation Loss: 0.7873713439330459
Elapsed time for epoch-14: 3.2753942012786865

Epoch: 15, 
Train Loss: 0.9093895237736341, 
Validation Loss: 0.7801328636705875
Elapsed time for epoch-15: 3.187005043029785
common line69: model saved with val loss 0.7801328636705875

Epoch: 16, 
Train Loss: 0.9086970218590328, 
Validation Loss: 0.7786970529705286
Elapsed time for epoch-16: 3.067875862121582
common line69: model saved with val loss 0.7786970529705286

Epoch: 17, 
Train Loss: 0.9082727593784573, 
Validation Loss: 0.7803763067349792
Elapsed time for epoch-17: 3.826442003250122

Epoch: 18, 
Train Loss: 0.9078413543580961, 
Validation Loss: 0.7805083654820919
Elapsed time for epoch-18: 3.3778436183929443

Epoch: 19, 
Train Loss: 0.9074328991294909, 
Validation Loss: 0.7768921116366982
Elapsed time for epoch-19: 3.771374464035034
common line69: model saved with val loss 0.7768921116366982

Epoch: 20, 
Train Loss: 0.9069705254891339, 
Validation Loss: 0.7735786167904735
Elapsed time for epoch-20: 3.4966588020324707
common line69: model saved with val loss 0.7735786167904735

Epoch: 21, 
Train Loss: 0.9066604564921195, 
Validation Loss: 0.778275947086513
Elapsed time for epoch-21: 4.577759504318237

Epoch: 22, 
Train Loss: 0.9063763613460445, 
Validation Loss: 0.7745938822627068
Elapsed time for epoch-22: 5.040488004684448

Epoch: 23, 
Train Loss: 0.9060039100777201, 
Validation Loss: 0.7811755882576108
Elapsed time for epoch-23: 5.134593963623047

Epoch: 24, 
Train Loss: 0.9060028467108222, 
Validation Loss: 0.7824865272268653
Elapsed time for epoch-24: 4.435829162597656

Epoch: 25, 
Train Loss: 0.9057493552941234, 
Validation Loss: 0.7748583033680916
Elapsed time for epoch-25: 3.7890424728393555

Epoch: 26, 
Train Loss: 0.9055927596172365, 
Validation Loss: 0.7766370587050915
Elapsed time for epoch-26: 4.489206314086914

Epoch: 27, 
Train Loss: 0.9053873417257261, 
Validation Loss: 0.7779570734128356
Elapsed time for epoch-27: 3.4789295196533203

Epoch: 28, 
Train Loss: 0.9050357155188793, 
Validation Loss: 0.7774355411529541
Elapsed time for epoch-28: 3.6177337169647217

Epoch: 29, 
Train Loss: 0.904796536104018, 
Validation Loss: 0.7814935883507133
Elapsed time for epoch-29: 3.4702436923980713

Epoch: 30, 
Train Loss: 0.9048374620806269, 
Validation Loss: 0.7760655777528882
Elapsed time for epoch-30: 3.541616916656494

Epoch: 31, 
Train Loss: 0.9044930239935883, 
Validation Loss: 0.7763258870691061
Elapsed time for epoch-31: 4.0091259479522705

train line101: min loss for the epoch 31 is 0.7735786167904735

Training the 24-th turbine in 217.42601084709167 secs

>>>>>>>>> Training Turbine  25 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.6273515224456787
lalalalalal
260 [[ 1.          0.03830775 -0.13084945  3.82358312 -0.06446068]
 [ 0.99904822  0.32397341 -0.27447225  0.09769324  0.15116582]
 [ 0.9961947   0.20916042 -0.15118682  0.09503342  0.06868737]
 [ 0.99144486  0.33217434  0.0537634   0.09503342  0.27344006]
 [ 0.98480775  0.2528987   0.08024927  0.09339661  0.18927227]]
hahahahahahah
265 [[ 0.99985184  1.          0.03830775 -0.13084945  3.82358312 -0.06446068]
 [ 0.99985184  0.99904822  0.32397341 -0.27447225  0.09769324  0.15116582]
 [ 0.99985184  0.9961947   0.20916042 -0.15118682  0.09503342  0.06868737]
 [ 0.99985184  0.99144486  0.33217434  0.0537634   0.09503342  0.27344006]
 [ 0.99985184  0.98480775  0.2528987   0.08024927  0.09339661  0.18927227]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.03830775 -0.13084945  3.82358312 -0.06446068]
 [ 0.99985184  0.99904822  0.32397341 -0.27447225  0.09769324  0.15116582]
 [ 0.99985184  0.9961947   0.20916042 -0.15118682  0.09503342  0.06868737]
 [ 0.99985184  0.99144486  0.33217434  0.0537634   0.09503342  0.27344006]
 [ 0.99985184  0.98480775  0.2528987   0.08024927  0.09339661  0.18927227]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.9155113697052
lalalalalal
260 [[ 1.         -0.11067578  0.13400929 -0.52654498 -0.16949935]
 [ 0.99904822 -0.1571477   0.13132917 -0.52900019 -0.30709529]
 [ 0.9961947  -0.52345582  0.03326838 -0.5300232  -0.41884856]
 [ 0.99144486 -0.28836255  0.10232083 -0.53145541 -0.17124215]
 [ 0.98480775 -0.20088599 -0.1269081  -0.53247842  0.03868549]]
hahahahahahah
265 [[-0.84754092  1.         -0.11067578  0.13400929 -0.52654498 -0.16949935]
 [-0.84754092  0.99904822 -0.1571477   0.13132917 -0.52900019 -0.30709529]
 [-0.84754092  0.9961947  -0.52345582  0.03326838 -0.5300232  -0.41884856]
 [-0.84754092  0.99144486 -0.28836255  0.10232083 -0.53145541 -0.17124215]
 [-0.84754092  0.98480775 -0.20088599 -0.1269081  -0.53247842  0.03868549]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.11067578  0.13400929 -0.52654498 -0.16949935]
 [-0.84754092  0.99904822 -0.1571477   0.13132917 -0.52900019 -0.30709529]
 [-0.84754092  0.9961947  -0.52345582  0.03326838 -0.5300232  -0.41884856]
 [-0.84754092  0.99144486 -0.28836255  0.10232083 -0.53145541 -0.17124215]
 [-0.84754092  0.98480775 -0.20088599 -0.1269081  -0.53247842  0.03868549]]

Epoch: 0, 
Train Loss: 1.0099080926229973, 
Validation Loss: 0.886462090536952
Elapsed time for epoch-0: 2.480234384536743
common line69: model saved with val loss 0.886462090536952

Epoch: 1, 
Train Loss: 0.9622836944435825, 
Validation Loss: 0.8102351957932115
Elapsed time for epoch-1: 2.665684700012207
common line69: model saved with val loss 0.8102351957932115

Epoch: 2, 
Train Loss: 0.94416924171588, 
Validation Loss: 0.8045718725770712
Elapsed time for epoch-2: 3.3373358249664307
common line69: model saved with val loss 0.8045718725770712

Epoch: 3, 
Train Loss: 0.9356745190981055, 
Validation Loss: 0.8056210270151496
Elapsed time for epoch-3: 3.026491165161133

Epoch: 4, 
Train Loss: 0.9294778630763543, 
Validation Loss: 0.8053225483745337
Elapsed time for epoch-4: 3.1847589015960693

Epoch: 5, 
Train Loss: 0.9249284476542673, 
Validation Loss: 0.8053398476913571
Elapsed time for epoch-5: 3.3850884437561035

Epoch: 6, 
Train Loss: 0.9208278870131789, 
Validation Loss: 0.8043828420341015
Elapsed time for epoch-6: 4.404727935791016
common line69: model saved with val loss 0.8043828420341015

Epoch: 7, 
Train Loss: 0.9173828690242367, 
Validation Loss: 0.8116055699065328
Elapsed time for epoch-7: 4.161779165267944

Epoch: 8, 
Train Loss: 0.9140468204722685, 
Validation Loss: 0.8110494436696172
Elapsed time for epoch-8: 3.634280204772949

Epoch: 9, 
Train Loss: 0.9114386153822186, 
Validation Loss: 0.8090133871883154
Elapsed time for epoch-9: 4.336569547653198

Epoch: 10, 
Train Loss: 0.9090077558986279, 
Validation Loss: 0.8129555266350508
Elapsed time for epoch-10: 3.603830575942993

Epoch: 11, 
Train Loss: 0.90725763079499, 
Validation Loss: 0.8103357423096895
Elapsed time for epoch-11: 3.5613129138946533

Epoch: 12, 
Train Loss: 0.9057203542535045, 
Validation Loss: 0.802910290658474
Elapsed time for epoch-12: 4.174452304840088
common line69: model saved with val loss 0.802910290658474

Epoch: 13, 
Train Loss: 0.9045304143879594, 
Validation Loss: 0.8040586235001683
Elapsed time for epoch-13: 3.8276023864746094

Epoch: 14, 
Train Loss: 0.9037000505613679, 
Validation Loss: 0.8064438039436936
Elapsed time for epoch-14: 3.7532410621643066

Epoch: 15, 
Train Loss: 0.9028197380424547, 
Validation Loss: 0.8066006265580654
Elapsed time for epoch-15: 3.9949982166290283

Epoch: 16, 
Train Loss: 0.9020683982041704, 
Validation Loss: 0.8090485166758299
Elapsed time for epoch-16: 3.76499080657959

Epoch: 17, 
Train Loss: 0.9015686466914266, 
Validation Loss: 0.8023028280586004
Elapsed time for epoch-17: 3.7546792030334473
common line69: model saved with val loss 0.8023028280586004

Epoch: 18, 
Train Loss: 0.9011372200080326, 
Validation Loss: 0.8035920690745115
Elapsed time for epoch-18: 4.022022008895874

Epoch: 19, 
Train Loss: 0.9006646818974439, 
Validation Loss: 0.7980530690401793
Elapsed time for epoch-19: 3.561840534210205
common line69: model saved with val loss 0.7980530690401793

Epoch: 20, 
Train Loss: 0.9004269651755565, 
Validation Loss: 0.8045332375913858
Elapsed time for epoch-20: 4.488826513290405

Epoch: 21, 
Train Loss: 0.8998576753279742, 
Validation Loss: 0.8018411956727505
Elapsed time for epoch-21: 4.1650354862213135

Epoch: 22, 
Train Loss: 0.8996116959748148, 
Validation Loss: 0.7991118263453245
Elapsed time for epoch-22: 3.8927173614501953

Epoch: 23, 
Train Loss: 0.8994485842330115, 
Validation Loss: 0.8011965733021498
Elapsed time for epoch-23: 3.565852403640747

Epoch: 24, 
Train Loss: 0.8991011220867894, 
Validation Loss: 0.7996199252083898
Elapsed time for epoch-24: 3.345430374145508

Epoch: 25, 
Train Loss: 0.898740915190272, 
Validation Loss: 0.8037543445825577
Elapsed time for epoch-25: 3.870610475540161

Epoch: 26, 
Train Loss: 0.8986396644295764, 
Validation Loss: 0.8050427548587322
Elapsed time for epoch-26: 4.096593379974365

Epoch: 27, 
Train Loss: 0.8981778864600077, 
Validation Loss: 0.8053731452673674
Elapsed time for epoch-27: 4.288864850997925

Epoch: 28, 
Train Loss: 0.8979864417254424, 
Validation Loss: 0.7998294234275818
Elapsed time for epoch-28: 5.432070016860962

Epoch: 29, 
Train Loss: 0.8979255648470726, 
Validation Loss: 0.7984708566218615
Elapsed time for epoch-29: 4.070348501205444

Epoch: 30, 
Train Loss: 0.8976142530431267, 
Validation Loss: 0.7914296127855778
Elapsed time for epoch-30: 4.510361194610596
common line69: model saved with val loss 0.7914296127855778

Epoch: 31, 
Train Loss: 0.8973448392974228, 
Validation Loss: 0.8013122575357556
Elapsed time for epoch-31: 3.8639888763427734

train line101: min loss for the epoch 31 is 0.7914296127855778

Training the 25-th turbine in 207.90704560279846 secs

>>>>>>>>> Training Turbine  26 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.302652597427368
lalalalalal
260 [[ 1.         -0.03786202 -0.10394647 -0.91606741 -0.02453236]
 [ 0.99904822  0.13272824 -0.00462267  0.5434034   0.13303574]
 [ 0.9961947   0.15877256 -0.11612607  0.53490823  0.15414289]
 [ 0.99144486  0.23950994 -0.09005143  0.53235967  0.25555528]
 [ 0.98480775  0.0962662  -0.10926432  0.52556353  0.09331775]]
hahahahahahah
265 [[ 0.99985184  1.         -0.03786202 -0.10394647 -0.91606741 -0.02453236]
 [ 0.99985184  0.99904822  0.13272824 -0.00462267  0.5434034   0.13303574]
 [ 0.99985184  0.9961947   0.15877256 -0.11612607  0.53490823  0.15414289]
 [ 0.99985184  0.99144486  0.23950994 -0.09005143  0.53235967  0.25555528]
 [ 0.99985184  0.98480775  0.0962662  -0.10926432  0.52556353  0.09331775]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.03786202 -0.10394647 -0.91606741 -0.02453236]
 [ 0.99985184  0.99904822  0.13272824 -0.00462267  0.5434034   0.13303574]
 [ 0.99985184  0.9961947   0.15877256 -0.11612607  0.53490823  0.15414289]
 [ 0.99985184  0.99144486  0.23950994 -0.09005143  0.53235967  0.25555528]
 [ 0.99985184  0.98480775  0.0962662  -0.10926432  0.52556353  0.09331775]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.934065103530884
lalalalalal
260 [[ 1.         -0.34258052  0.11219858 -2.04550072 -0.34130676]
 [ 0.99904822 -0.2996074   0.2214719  -2.05102259 -0.34440485]
 [ 0.9961947  -0.42462012  0.03654781 -2.05611969 -0.35550449]
 [ 0.99144486 -0.24751877  0.00875773 -2.06206631 -0.16638711]
 [ 0.98480775 -0.26054093 -0.14666084 -2.07820714 -0.07676531]]
hahahahahahah
265 [[-0.84754092  1.         -0.34258052  0.11219858 -2.04550072 -0.34130676]
 [-0.84754092  0.99904822 -0.2996074   0.2214719  -2.05102259 -0.34440485]
 [-0.84754092  0.9961947  -0.42462012  0.03654781 -2.05611969 -0.35550449]
 [-0.84754092  0.99144486 -0.24751877  0.00875773 -2.06206631 -0.16638711]
 [-0.84754092  0.98480775 -0.26054093 -0.14666084 -2.07820714 -0.07676531]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.34258052  0.11219858 -2.04550072 -0.34130676]
 [-0.84754092  0.99904822 -0.2996074   0.2214719  -2.05102259 -0.34440485]
 [-0.84754092  0.9961947  -0.42462012  0.03654781 -2.05611969 -0.35550449]
 [-0.84754092  0.99144486 -0.24751877  0.00875773 -2.06206631 -0.16638711]
 [-0.84754092  0.98480775 -0.26054093 -0.14666084 -2.07820714 -0.07676531]]

Epoch: 0, 
Train Loss: 0.9987495845856786, 
Validation Loss: 0.8401628080755472
Elapsed time for epoch-0: 5.592051267623901
common line69: model saved with val loss 0.8401628080755472

Epoch: 1, 
Train Loss: 0.9520713233647227, 
Validation Loss: 0.7905116258189082
Elapsed time for epoch-1: 4.824904441833496
common line69: model saved with val loss 0.7905116258189082

Epoch: 2, 
Train Loss: 0.9421463673856078, 
Validation Loss: 0.780911274254322
Elapsed time for epoch-2: 4.043743848800659
common line69: model saved with val loss 0.780911274254322

Epoch: 3, 
Train Loss: 0.9372010252305439, 
Validation Loss: 0.7772424081340432
Elapsed time for epoch-3: 4.405513525009155
common line69: model saved with val loss 0.7772424081340432

Epoch: 4, 
Train Loss: 0.9337556077903059, 
Validation Loss: 0.7729400275275111
Elapsed time for epoch-4: 4.777679443359375
common line69: model saved with val loss 0.7729400275275111

Epoch: 5, 
Train Loss: 0.9315037612153703, 
Validation Loss: 0.7662335895001888
Elapsed time for epoch-5: 4.696571588516235
common line69: model saved with val loss 0.7662335895001888

Epoch: 6, 
Train Loss: 0.9297565627498787, 
Validation Loss: 0.7787929438054562
Elapsed time for epoch-6: 4.843751430511475

Epoch: 7, 
Train Loss: 0.9285100473075354, 
Validation Loss: 0.7729292400181293
Elapsed time for epoch-7: 4.022415399551392

Epoch: 8, 
Train Loss: 0.9272978613857462, 
Validation Loss: 0.7717760447412729
Elapsed time for epoch-8: 4.51558256149292

Epoch: 9, 
Train Loss: 0.9266407766512462, 
Validation Loss: 0.7719644997268915
Elapsed time for epoch-9: 4.007955312728882

Epoch: 10, 
Train Loss: 0.9258065184875697, 
Validation Loss: 0.768660799600184
Elapsed time for epoch-10: 3.6163904666900635

Epoch: 11, 
Train Loss: 0.9251630923577717, 
Validation Loss: 0.7669233353808522
Elapsed time for epoch-11: 4.1436097621917725

Epoch: 12, 
Train Loss: 0.9245455050919237, 
Validation Loss: 0.7656366229057312
Elapsed time for epoch-12: 4.272427082061768
common line69: model saved with val loss 0.7656366229057312

Epoch: 13, 
Train Loss: 0.9241473471918026, 
Validation Loss: 0.7715743407607079
Elapsed time for epoch-13: 3.6237802505493164

Epoch: 14, 
Train Loss: 0.9235057408819679, 
Validation Loss: 0.7647443218156695
Elapsed time for epoch-14: 3.403437376022339
common line69: model saved with val loss 0.7647443218156695

Epoch: 15, 
Train Loss: 0.9230786111174512, 
Validation Loss: 0.7646386595442891
Elapsed time for epoch-15: 4.148524045944214
common line69: model saved with val loss 0.7646386595442891

Epoch: 16, 
Train Loss: 0.9228149820275667, 
Validation Loss: 0.7621680591255426
Elapsed time for epoch-16: 4.517951011657715
common line69: model saved with val loss 0.7621680591255426

Epoch: 17, 
Train Loss: 0.9223994883168646, 
Validation Loss: 0.770195484161377
Elapsed time for epoch-17: 3.8149449825286865

Epoch: 18, 
Train Loss: 0.9218908944049803, 
Validation Loss: 0.767297194339335
Elapsed time for epoch-18: 3.1877408027648926

Epoch: 19, 
Train Loss: 0.9217657545784942, 
Validation Loss: 0.760787901468575
Elapsed time for epoch-19: 3.0271925926208496
common line69: model saved with val loss 0.760787901468575

Epoch: 20, 
Train Loss: 0.9213541002333665, 
Validation Loss: 0.7649008631706238
Elapsed time for epoch-20: 3.346446990966797

Epoch: 21, 
Train Loss: 0.9212358803057871, 
Validation Loss: 0.7689874321222305
Elapsed time for epoch-21: 2.989819288253784

Epoch: 22, 
Train Loss: 0.9209251770702731, 
Validation Loss: 0.7649280456826091
Elapsed time for epoch-22: 3.3093717098236084

Epoch: 23, 
Train Loss: 0.920667720191619, 
Validation Loss: 0.766728269867599
Elapsed time for epoch-23: 3.6162729263305664

Epoch: 24, 
Train Loss: 0.9203802666493824, 
Validation Loss: 0.766958812251687
Elapsed time for epoch-24: 3.3979012966156006

Epoch: 25, 
Train Loss: 0.9201978205883202, 
Validation Loss: 0.7603968223556876
Elapsed time for epoch-25: 3.371602773666382
common line69: model saved with val loss 0.7603968223556876

Epoch: 26, 
Train Loss: 0.9197253748899749, 
Validation Loss: 0.767329971306026
Elapsed time for epoch-26: 2.9219813346862793

Epoch: 27, 
Train Loss: 0.9197691626408521, 
Validation Loss: 0.7601879527792335
Elapsed time for epoch-27: 3.283970832824707
common line69: model saved with val loss 0.7601879527792335

Epoch: 28, 
Train Loss: 0.9197928415877479, 
Validation Loss: 0.7655578600242734
Elapsed time for epoch-28: 3.0264406204223633

Epoch: 29, 
Train Loss: 0.9192721971443721, 
Validation Loss: 0.7646181173622608
Elapsed time for epoch-29: 3.198288917541504

Epoch: 30, 
Train Loss: 0.9192537788082572, 
Validation Loss: 0.7628534324467182
Elapsed time for epoch-30: 3.7627007961273193

Epoch: 31, 
Train Loss: 0.9192428448620964, 
Validation Loss: 0.7660878617316484
Elapsed time for epoch-31: 3.0818724632263184

train line101: min loss for the epoch 31 is 0.7601879527792335

Training the 26-th turbine in 206.97468852996826 secs

>>>>>>>>> Training Turbine  27 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.101864337921143
lalalalalal
260 [[ 1.          0.16511953 -0.25658486 -0.751733   -0.06760126]
 [ 0.99904822  0.46975416 -0.36798551  0.5159648   0.12384534]
 [ 0.9961947   0.48940801 -0.3994195   0.50961838  0.14284688]
 [ 0.99144486  0.39956185 -0.13067621  0.50406526  0.29794175]
 [ 0.98480775  0.25356184 -0.06469938  0.50009875  0.14368357]]
hahahahahahah
265 [[ 0.99985184  1.          0.16511953 -0.25658486 -0.751733   -0.06760126]
 [ 0.99985184  0.99904822  0.46975416 -0.36798551  0.5159648   0.12384534]
 [ 0.99985184  0.9961947   0.48940801 -0.3994195   0.50961838  0.14284688]
 [ 0.99985184  0.99144486  0.39956185 -0.13067621  0.50406526  0.29794175]
 [ 0.99985184  0.98480775  0.25356184 -0.06469938  0.50009875  0.14368357]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.16511953 -0.25658486 -0.751733   -0.06760126]
 [ 0.99985184  0.99904822  0.46975416 -0.36798551  0.5159648   0.12384534]
 [ 0.99985184  0.9961947   0.48940801 -0.3994195   0.50961838  0.14284688]
 [ 0.99985184  0.99144486  0.39956185 -0.13067621  0.50406526  0.29794175]
 [ 0.99985184  0.98480775  0.25356184 -0.06469938  0.50009875  0.14368357]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 5.276843309402466
lalalalalal
260 [[ 1.00000000e+00 -3.95015126e-01 -5.24366760e-02 -1.94763690e+00
  -3.84132177e-01]
 [ 9.99048222e-01 -3.61322816e-01  5.58551247e-02 -1.95120677e+00
  -3.28250467e-01]
 [ 9.96194698e-01 -2.43399731e-01 -3.29199719e-02 -1.95517328e+00
  -2.21066793e-01]
 [ 9.91444861e-01 -2.29361269e-01 -1.29985350e-01 -1.96072640e+00
  -1.72935422e-01]
 [ 9.84807753e-01 -1.42322802e-01 -1.84217607e-01 -1.96627952e+00
  -1.30503209e-03]]
hahahahahahah
265 [[-8.47540923e-01  1.00000000e+00 -3.95015126e-01 -5.24366760e-02
  -1.94763690e+00 -3.84132177e-01]
 [-8.47540923e-01  9.99048222e-01 -3.61322816e-01  5.58551247e-02
  -1.95120677e+00 -3.28250467e-01]
 [-8.47540923e-01  9.96194698e-01 -2.43399731e-01 -3.29199719e-02
  -1.95517328e+00 -2.21066793e-01]
 [-8.47540923e-01  9.91444861e-01 -2.29361269e-01 -1.29985350e-01
  -1.96072640e+00 -1.72935422e-01]
 [-8.47540923e-01  9.84807753e-01 -1.42322802e-01 -1.84217607e-01
  -1.96627952e+00 -1.30503209e-03]]

 wind turbine line248 data after normalization: 
 [[-8.47540923e-01  1.00000000e+00 -3.95015126e-01 -5.24366760e-02
  -1.94763690e+00 -3.84132177e-01]
 [-8.47540923e-01  9.99048222e-01 -3.61322816e-01  5.58551247e-02
  -1.95120677e+00 -3.28250467e-01]
 [-8.47540923e-01  9.96194698e-01 -2.43399731e-01 -3.29199719e-02
  -1.95517328e+00 -2.21066793e-01]
 [-8.47540923e-01  9.91444861e-01 -2.29361269e-01 -1.29985350e-01
  -1.96072640e+00 -1.72935422e-01]
 [-8.47540923e-01  9.84807753e-01 -1.42322802e-01 -1.84217607e-01
  -1.96627952e+00 -1.30503209e-03]]

Epoch: 0, 
Train Loss: 1.0027723354952676, 
Validation Loss: 0.8337421482428908
Elapsed time for epoch-0: 4.692005157470703
common line69: model saved with val loss 0.8337421482428908

Epoch: 1, 
Train Loss: 0.956294648411895, 
Validation Loss: 0.7819126304239035
Elapsed time for epoch-1: 4.248473644256592
common line69: model saved with val loss 0.7819126304239035

Epoch: 2, 
Train Loss: 0.9456732137864378, 
Validation Loss: 0.7676285384222865
Elapsed time for epoch-2: 4.325270652770996
common line69: model saved with val loss 0.7676285384222865

Epoch: 3, 
Train Loss: 0.9402773447898256, 
Validation Loss: 0.76618408318609
Elapsed time for epoch-3: 4.0153443813323975
common line69: model saved with val loss 0.76618408318609

Epoch: 4, 
Train Loss: 0.936601281666956, 
Validation Loss: 0.7667307211086154
Elapsed time for epoch-4: 4.429628372192383

Epoch: 5, 
Train Loss: 0.9336452759614512, 
Validation Loss: 0.7693874146789312
Elapsed time for epoch-5: 4.099273443222046

Epoch: 6, 
Train Loss: 0.9310741353185237, 
Validation Loss: 0.7640561293810606
Elapsed time for epoch-6: 4.491978406906128
common line69: model saved with val loss 0.7640561293810606

Epoch: 7, 
Train Loss: 0.929078244236337, 
Validation Loss: 0.760301779024303
Elapsed time for epoch-7: 5.080517292022705
common line69: model saved with val loss 0.760301779024303

Epoch: 8, 
Train Loss: 0.9276581648267618, 
Validation Loss: 0.7614387152716517
Elapsed time for epoch-8: 4.224007844924927

Epoch: 9, 
Train Loss: 0.926136488423628, 
Validation Loss: 0.7582693062722683
Elapsed time for epoch-9: 4.121286153793335
common line69: model saved with val loss 0.7582693062722683

Epoch: 10, 
Train Loss: 0.9251604841536835, 
Validation Loss: 0.7620087647810578
Elapsed time for epoch-10: 4.084611892700195

Epoch: 11, 
Train Loss: 0.9242213398468595, 
Validation Loss: 0.771301968023181
Elapsed time for epoch-11: 4.142717361450195

Epoch: 12, 
Train Loss: 0.9235011848832378, 
Validation Loss: 0.7617223849520087
Elapsed time for epoch-12: 3.046487331390381

Epoch: 13, 
Train Loss: 0.9227098115101582, 
Validation Loss: 0.7680770484730601
Elapsed time for epoch-13: 3.343634605407715

Epoch: 14, 
Train Loss: 0.9220267331399837, 
Validation Loss: 0.7605014722794294
Elapsed time for epoch-14: 3.1764323711395264

Epoch: 15, 
Train Loss: 0.921535730737598, 
Validation Loss: 0.7645793668925762
Elapsed time for epoch-15: 3.0691757202148438

Epoch: 16, 
Train Loss: 0.9210242883247488, 
Validation Loss: 0.7681574383750558
Elapsed time for epoch-16: 3.357316017150879

Epoch: 17, 
Train Loss: 0.9204803241902039, 
Validation Loss: 0.7682205568999052
Elapsed time for epoch-17: 3.114874839782715

Epoch: 18, 
Train Loss: 0.920223371070974, 
Validation Loss: 0.7665856750681996
Elapsed time for epoch-18: 3.1803178787231445

Epoch: 19, 
Train Loss: 0.919951776997382, 
Validation Loss: 0.7670660251751542
Elapsed time for epoch-19: 3.262765884399414

Epoch: 20, 
Train Loss: 0.9194909152613968, 
Validation Loss: 0.7668618140742183
Elapsed time for epoch-20: 3.0916826725006104

Epoch: 21, 
Train Loss: 0.9191333289657321, 
Validation Loss: 0.7728505488485098
Elapsed time for epoch-21: 3.127004623413086
Early stopped! 

train line101: min loss for the epoch 21 is 0.7582693062722683

Training the 27-th turbine in 183.32543301582336 secs

>>>>>>>>> Training Turbine  28 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.6697936058044434
lalalalalal
260 [[ 1.          0.10401523 -0.15140748 -0.28575393 -0.03245336]
 [ 0.99904822  0.36509822 -0.26688637  0.32011893  0.16679286]
 [ 0.9961947   0.39009553 -0.28853866  0.3186673   0.19842833]
 [ 0.99144486  0.50119467 -0.31809575  0.3186673   0.24864441]
 [ 0.98480775  0.37343066 -0.33734224  0.31830439  0.09376931]]
hahahahahahah
265 [[ 0.99985184  1.          0.10401523 -0.15140748 -0.28575393 -0.03245336]
 [ 0.99985184  0.99904822  0.36509822 -0.26688637  0.32011893  0.16679286]
 [ 0.99985184  0.9961947   0.39009553 -0.28853866  0.3186673   0.19842833]
 [ 0.99985184  0.99144486  0.50119467 -0.31809575  0.3186673   0.24864441]
 [ 0.99985184  0.98480775  0.37343066 -0.33734224  0.31830439  0.09376931]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.10401523 -0.15140748 -0.28575393 -0.03245336]
 [ 0.99985184  0.99904822  0.36509822 -0.26688637  0.32011893  0.16679286]
 [ 0.99985184  0.9961947   0.39009553 -0.28853866  0.3186673   0.19842833]
 [ 0.99985184  0.99144486  0.50119467 -0.31809575  0.3186673   0.24864441]
 [ 0.99985184  0.98480775  0.37343066 -0.33734224  0.31830439  0.09376931]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.645573377609253
lalalalalal
260 [[ 1.         -0.40704082 -0.05620614 -0.81577927 -0.40499019]
 [ 0.99904822 -0.29871916  0.00840705 -0.8175938  -0.32880748]
 [ 0.9961947  -0.35704621  0.0152808  -0.82049705 -0.29723806]
 [ 0.99144486 -0.35704621 -0.14075318 -0.82412612 -0.28739738]
 [ 0.98480775 -0.29594168  0.08367454 -0.82775519 -0.15739915]]
hahahahahahah
265 [[-0.84754092  1.         -0.40704082 -0.05620614 -0.81577927 -0.40499019]
 [-0.84754092  0.99904822 -0.29871916  0.00840705 -0.8175938  -0.32880748]
 [-0.84754092  0.9961947  -0.35704621  0.0152808  -0.82049705 -0.29723806]
 [-0.84754092  0.99144486 -0.35704621 -0.14075318 -0.82412612 -0.28739738]
 [-0.84754092  0.98480775 -0.29594168  0.08367454 -0.82775519 -0.15739915]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.40704082 -0.05620614 -0.81577927 -0.40499019]
 [-0.84754092  0.99904822 -0.29871916  0.00840705 -0.8175938  -0.32880748]
 [-0.84754092  0.9961947  -0.35704621  0.0152808  -0.82049705 -0.29723806]
 [-0.84754092  0.99144486 -0.35704621 -0.14075318 -0.82412612 -0.28739738]
 [-0.84754092  0.98480775 -0.29594168  0.08367454 -0.82775519 -0.15739915]]

Epoch: 0, 
Train Loss: 0.9979938997440979, 
Validation Loss: 0.828273412771523
Elapsed time for epoch-0: 5.130779266357422
common line69: model saved with val loss 0.828273412771523

Epoch: 1, 
Train Loss: 0.9483963570424488, 
Validation Loss: 0.7638368755578995
Elapsed time for epoch-1: 4.666738748550415
common line69: model saved with val loss 0.7638368755578995

Epoch: 2, 
Train Loss: 0.9353196366744883, 
Validation Loss: 0.7527594408020377
Elapsed time for epoch-2: 4.087266206741333
common line69: model saved with val loss 0.7527594408020377

Epoch: 3, 
Train Loss: 0.9298125080952123, 
Validation Loss: 0.7537045199424028
Elapsed time for epoch-3: 4.0381433963775635

Epoch: 4, 
Train Loss: 0.9262297750771546, 
Validation Loss: 0.7428999524563551
Elapsed time for epoch-4: 3.643298625946045
common line69: model saved with val loss 0.7428999524563551

Epoch: 5, 
Train Loss: 0.9236095498840348, 
Validation Loss: 0.7429932691156864
Elapsed time for epoch-5: 3.8661351203918457

Epoch: 6, 
Train Loss: 0.9216457015576482, 
Validation Loss: 0.7428056001663208
Elapsed time for epoch-6: 3.9807181358337402
common line69: model saved with val loss 0.7428056001663208

Epoch: 7, 
Train Loss: 0.9201250939058656, 
Validation Loss: 0.7411742424592376
Elapsed time for epoch-7: 3.201948642730713
common line69: model saved with val loss 0.7411742424592376

Epoch: 8, 
Train Loss: 0.9186213582503695, 
Validation Loss: 0.7432001428678632
Elapsed time for epoch-8: 3.727886915206909

Epoch: 9, 
Train Loss: 0.9175297257279148, 
Validation Loss: 0.7500283755362034
Elapsed time for epoch-9: 2.8743231296539307

Epoch: 10, 
Train Loss: 0.9163200656155578, 
Validation Loss: 0.7426043273881078
Elapsed time for epoch-10: 2.916595697402954

Epoch: 11, 
Train Loss: 0.9153453506091062, 
Validation Loss: 0.742640744894743
Elapsed time for epoch-11: 2.9447712898254395

Epoch: 12, 
Train Loss: 0.9145812305833111, 
Validation Loss: 0.7462204089388251
Elapsed time for epoch-12: 2.8173599243164062

Epoch: 13, 
Train Loss: 0.9139566278758169, 
Validation Loss: 0.7386180451139808
Elapsed time for epoch-13: 2.990571975708008
common line69: model saved with val loss 0.7386180451139808

Epoch: 14, 
Train Loss: 0.9133994417781589, 
Validation Loss: 0.7385005885735154
Elapsed time for epoch-14: 2.8966877460479736
common line69: model saved with val loss 0.7385005885735154

Epoch: 15, 
Train Loss: 0.9126262882677447, 
Validation Loss: 0.7393753854557872
Elapsed time for epoch-15: 2.7768845558166504

Epoch: 16, 
Train Loss: 0.9120281369996672, 
Validation Loss: 0.746270795352757
Elapsed time for epoch-16: 3.01413631439209

Epoch: 17, 
Train Loss: 0.9112981838338515, 
Validation Loss: 0.7452154345810413
Elapsed time for epoch-17: 2.7517552375793457

Epoch: 18, 
Train Loss: 0.910871837444666, 
Validation Loss: 0.7428478635847569
Elapsed time for epoch-18: 2.8407132625579834

Epoch: 19, 
Train Loss: 0.9102313529793956, 
Validation Loss: 0.7423618836328387
Elapsed time for epoch-19: 2.9927802085876465

Epoch: 20, 
Train Loss: 0.9097217471659684, 
Validation Loss: 0.7402881374582648
Elapsed time for epoch-20: 2.767427921295166

Epoch: 21, 
Train Loss: 0.9091286650475334, 
Validation Loss: 0.7457496607676148
Elapsed time for epoch-21: 2.9128634929656982

Epoch: 22, 
Train Loss: 0.908812681040844, 
Validation Loss: 0.7389316922053695
Elapsed time for epoch-22: 3.2457776069641113

Epoch: 23, 
Train Loss: 0.9083421761248293, 
Validation Loss: 0.7409568848088384
Elapsed time for epoch-23: 3.4797089099884033

Epoch: 24, 
Train Loss: 0.9079079964832097, 
Validation Loss: 0.7398133249953389
Elapsed time for epoch-24: 3.134147882461548

Epoch: 25, 
Train Loss: 0.9076066792261701, 
Validation Loss: 0.7382156429812312
Elapsed time for epoch-25: 2.7990105152130127
common line69: model saved with val loss 0.7382156429812312

Epoch: 26, 
Train Loss: 0.9070905955398784, 
Validation Loss: 0.7384489383548498
Elapsed time for epoch-26: 3.2559330463409424

Epoch: 27, 
Train Loss: 0.9068850077250424, 
Validation Loss: 0.7431176379323006
Elapsed time for epoch-27: 3.8172502517700195

Epoch: 28, 
Train Loss: 0.9064257623267775, 
Validation Loss: 0.7368144923821092
Elapsed time for epoch-28: 3.6762614250183105
common line69: model saved with val loss 0.7368144923821092

Epoch: 29, 
Train Loss: 0.9062801262661189, 
Validation Loss: 0.7457281099632382
Elapsed time for epoch-29: 3.933734655380249

Epoch: 30, 
Train Loss: 0.9061462800292408, 
Validation Loss: 0.7333317380398512
Elapsed time for epoch-30: 4.032740354537964
common line69: model saved with val loss 0.7333317380398512

Epoch: 31, 
Train Loss: 0.9058757239029187, 
Validation Loss: 0.7394605427980423
Elapsed time for epoch-31: 3.977881908416748

train line101: min loss for the epoch 31 is 0.7333317380398512

Training the 28-th turbine in 202.51025772094727 secs

>>>>>>>>> Training Turbine  29 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.6784801483154297
lalalalalal
260 [[ 1.          0.05894423 -0.31109327 -0.27659225 -0.00114252]
 [ 0.99904822  0.14285192 -0.3860989   0.3592101  -0.01810896]
 [ 0.9961947   0.14844577 -0.24060411  0.35468884  0.05161894]
 [ 0.99144486  0.15683653 -0.19834287  0.35205143  0.10141473]
 [ 0.98480775  0.05614731 -0.26350906  0.35355852 -0.06344474]]
hahahahahahah
265 [[ 0.99985184  1.          0.05894423 -0.31109327 -0.27659225 -0.00114252]
 [ 0.99985184  0.99904822  0.14285192 -0.3860989   0.3592101  -0.01810896]
 [ 0.99985184  0.9961947   0.14844577 -0.24060411  0.35468884  0.05161894]
 [ 0.99985184  0.99144486  0.15683653 -0.19834287  0.35205143  0.10141473]
 [ 0.99985184  0.98480775  0.05614731 -0.26350906  0.35355852 -0.06344474]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.05894423 -0.31109327 -0.27659225 -0.00114252]
 [ 0.99985184  0.99904822  0.14285192 -0.3860989   0.3592101  -0.01810896]
 [ 0.99985184  0.9961947   0.14844577 -0.24060411  0.35468884  0.05161894]
 [ 0.99985184  0.99144486  0.15683653 -0.19834287  0.35205143  0.10141473]
 [ 0.99985184  0.98480775  0.05614731 -0.26350906  0.35355852 -0.06344474]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 6.5442187786102295
lalalalalal
260 [[ 1.         -0.2738896   0.10135704 -0.8121733  -0.28927301]
 [ 0.99904822 -0.22634191  0.09942141 -0.81104299 -0.22060264]
 [ 0.9961947  -0.15082499  0.02909355 -0.81707133 -0.2072456 ]
 [ 0.99144486 -0.16201268 -0.0538159  -0.8215926  -0.2637314 ]
 [ 0.98480775 -0.01377577 -0.06123581 -0.82460677 -0.10137782]]
hahahahahahah
265 [[-0.84754092  1.         -0.2738896   0.10135704 -0.8121733  -0.28927301]
 [-0.84754092  0.99904822 -0.22634191  0.09942141 -0.81104299 -0.22060264]
 [-0.84754092  0.9961947  -0.15082499  0.02909355 -0.81707133 -0.2072456 ]
 [-0.84754092  0.99144486 -0.16201268 -0.0538159  -0.8215926  -0.2637314 ]
 [-0.84754092  0.98480775 -0.01377577 -0.06123581 -0.82460677 -0.10137782]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.2738896   0.10135704 -0.8121733  -0.28927301]
 [-0.84754092  0.99904822 -0.22634191  0.09942141 -0.81104299 -0.22060264]
 [-0.84754092  0.9961947  -0.15082499  0.02909355 -0.81707133 -0.2072456 ]
 [-0.84754092  0.99144486 -0.16201268 -0.0538159  -0.8215926  -0.2637314 ]
 [-0.84754092  0.98480775 -0.01377577 -0.06123581 -0.82460677 -0.10137782]]

Epoch: 0, 
Train Loss: 1.0021323832143254, 
Validation Loss: 0.714230002835393
Elapsed time for epoch-0: 4.388788938522339
common line69: model saved with val loss 0.714230002835393

Epoch: 1, 
Train Loss: 0.9423599352105325, 
Validation Loss: 0.6547834556549788
Elapsed time for epoch-1: 4.852532148361206
common line69: model saved with val loss 0.6547834556549788

Epoch: 2, 
Train Loss: 0.9264042794453997, 
Validation Loss: 0.6454280568286777
Elapsed time for epoch-2: 5.099085569381714
common line69: model saved with val loss 0.6454280568286777

Epoch: 3, 
Train Loss: 0.9205097289395934, 
Validation Loss: 0.6423804587684572
Elapsed time for epoch-3: 4.699702501296997
common line69: model saved with val loss 0.6423804587684572

Epoch: 4, 
Train Loss: 0.916333903159414, 
Validation Loss: 0.6402360545471311
Elapsed time for epoch-4: 4.925142526626587
common line69: model saved with val loss 0.6402360545471311

Epoch: 5, 
Train Loss: 0.9131997804932234, 
Validation Loss: 0.6351388050243258
Elapsed time for epoch-5: 4.184487581253052
common line69: model saved with val loss 0.6351388050243258

Epoch: 6, 
Train Loss: 0.9108481766546473, 
Validation Loss: 0.6368028679862618
Elapsed time for epoch-6: 3.708970785140991

Epoch: 7, 
Train Loss: 0.908386576701613, 
Validation Loss: 0.6358274817466736
Elapsed time for epoch-7: 4.8411078453063965

Epoch: 8, 
Train Loss: 0.9070469426507709, 
Validation Loss: 0.6383929951116443
Elapsed time for epoch-8: 5.933884382247925

Epoch: 9, 
Train Loss: 0.9056661057622493, 
Validation Loss: 0.6335743386298418
Elapsed time for epoch-9: 4.633496999740601
common line69: model saved with val loss 0.6335743386298418

Epoch: 10, 
Train Loss: 0.9043663437126064, 
Validation Loss: 0.6326700574718416
Elapsed time for epoch-10: 3.9048895835876465
common line69: model saved with val loss 0.6326700574718416

Epoch: 11, 
Train Loss: 0.9034135170093104, 
Validation Loss: 0.628740148153156
Elapsed time for epoch-11: 4.137500524520874
common line69: model saved with val loss 0.628740148153156

Epoch: 12, 
Train Loss: 0.9021877528739577, 
Validation Loss: 0.636419128626585
Elapsed time for epoch-12: 4.661775827407837

Epoch: 13, 
Train Loss: 0.9012272102492196, 
Validation Loss: 0.6342204455286264
Elapsed time for epoch-13: 3.893533945083618

Epoch: 14, 
Train Loss: 0.9007000822980865, 
Validation Loss: 0.6342302458360791
Elapsed time for epoch-14: 3.4847261905670166

Epoch: 15, 
Train Loss: 0.899503963960319, 
Validation Loss: 0.6320782462134957
Elapsed time for epoch-15: 3.4225380420684814

Epoch: 16, 
Train Loss: 0.8991497704962722, 
Validation Loss: 0.6307322839275002
Elapsed time for epoch-16: 3.1320993900299072

Epoch: 17, 
Train Loss: 0.8985865193755687, 
Validation Loss: 0.6347491098567843
Elapsed time for epoch-17: 3.2978575229644775

Epoch: 18, 
Train Loss: 0.8978838983203182, 
Validation Loss: 0.6366564072668552
Elapsed time for epoch-18: 3.107565402984619

Epoch: 19, 
Train Loss: 0.8972116737556057, 
Validation Loss: 0.6329106641933322
Elapsed time for epoch-19: 3.273543357849121

Epoch: 20, 
Train Loss: 0.8965904869201804, 
Validation Loss: 0.6304537616670132
Elapsed time for epoch-20: 3.3280344009399414

Epoch: 21, 
Train Loss: 0.8963848318622893, 
Validation Loss: 0.6314576766453683
Elapsed time for epoch-21: 3.2242984771728516

Epoch: 22, 
Train Loss: 0.8956256000434651, 
Validation Loss: 0.63406035117805
Elapsed time for epoch-22: 3.2259154319763184

Epoch: 23, 
Train Loss: 0.8951380578409723, 
Validation Loss: 0.636027748696506
Elapsed time for epoch-23: 3.0623042583465576
Early stopped! 

train line101: min loss for the epoch 23 is 0.628740148153156

Training the 29-th turbine in 194.12722492218018 secs

>>>>>>>>> Training Turbine  30 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.864680051803589
lalalalalal
260 [[ 1.         -0.01830658 -0.82100715 -0.51491003 -0.53858002]
 [ 0.99904822  0.14239515 -1.63025292  0.47092785 -0.85756146]
 [ 0.9961947   0.15770007 -1.6436944   0.45802502 -0.85756146]
 [ 0.99144486  0.31330015 -1.62542778  0.45188081 -0.85756146]
 [ 0.98480775  0.37707068 -1.52237646  0.45188081 -0.85756146]]
hahahahahahah
265 [[ 0.99985184  1.         -0.01830658 -0.82100715 -0.51491003 -0.53858002]
 [ 0.99985184  0.99904822  0.14239515 -1.63025292  0.47092785 -0.85756146]
 [ 0.99985184  0.9961947   0.15770007 -1.6436944   0.45802502 -0.85756146]
 [ 0.99985184  0.99144486  0.31330015 -1.62542778  0.45188081 -0.85756146]
 [ 0.99985184  0.98480775  0.37707068 -1.52237646  0.45188081 -0.85756146]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.01830658 -0.82100715 -0.51491003 -0.53858002]
 [ 0.99985184  0.99904822  0.14239515 -1.63025292  0.47092785 -0.85756146]
 [ 0.99985184  0.9961947   0.15770007 -1.6436944   0.45802502 -0.85756146]
 [ 0.99985184  0.99144486  0.31330015 -1.62542778  0.45188081 -0.85756146]
 [ 0.99985184  0.98480775  0.37707068 -1.52237646  0.45188081 -0.85756146]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.716771364212036
lalalalalal
260 [[ 1.         -0.44046745  0.06888747 -1.48876671 -0.32574053]
 [ 0.99904822 -0.40092973  0.24052477 -1.48907392 -0.2860436 ]
 [ 0.9961947  -0.07442464  0.17297274 -1.49276044  0.00753906]
 [ 0.99144486 -0.23257554  0.03959194 -1.49337486 -0.08455419]
 [ 0.98480775 -0.27338868 -0.01865445 -1.49829023 -0.05482401]]
hahahahahahah
265 [[-0.84754092  1.         -0.44046745  0.06888747 -1.48876671 -0.32574053]
 [-0.84754092  0.99904822 -0.40092973  0.24052477 -1.48907392 -0.2860436 ]
 [-0.84754092  0.9961947  -0.07442464  0.17297274 -1.49276044  0.00753906]
 [-0.84754092  0.99144486 -0.23257554  0.03959194 -1.49337486 -0.08455419]
 [-0.84754092  0.98480775 -0.27338868 -0.01865445 -1.49829023 -0.05482401]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.44046745  0.06888747 -1.48876671 -0.32574053]
 [-0.84754092  0.99904822 -0.40092973  0.24052477 -1.48907392 -0.2860436 ]
 [-0.84754092  0.9961947  -0.07442464  0.17297274 -1.49276044  0.00753906]
 [-0.84754092  0.99144486 -0.23257554  0.03959194 -1.49337486 -0.08455419]
 [-0.84754092  0.98480775 -0.27338868 -0.01865445 -1.49829023 -0.05482401]]

Epoch: 0, 
Train Loss: 0.9945040948751593, 
Validation Loss: 0.8189433105289936
Elapsed time for epoch-0: 5.326682806015015
common line69: model saved with val loss 0.8189433105289936

Epoch: 1, 
Train Loss: 0.957726893930876, 
Validation Loss: 0.7886607414111495
Elapsed time for epoch-1: 4.400381565093994
common line69: model saved with val loss 0.7886607414111495

Epoch: 2, 
Train Loss: 0.9482206902584108, 
Validation Loss: 0.7780709052458405
Elapsed time for epoch-2: 3.4363391399383545
common line69: model saved with val loss 0.7780709052458405

Epoch: 3, 
Train Loss: 0.9429708738036516, 
Validation Loss: 0.7784121287986636
Elapsed time for epoch-3: 3.7324764728546143

Epoch: 4, 
Train Loss: 0.9388051227110774, 
Validation Loss: 0.7721542995423079
Elapsed time for epoch-4: 4.297978401184082
common line69: model saved with val loss 0.7721542995423079

Epoch: 5, 
Train Loss: 0.9361052387902716, 
Validation Loss: 0.7750330893322825
Elapsed time for epoch-5: 3.5316660404205322

Epoch: 6, 
Train Loss: 0.9335498680838016, 
Validation Loss: 0.7719471072778106
Elapsed time for epoch-6: 4.356539011001587
common line69: model saved with val loss 0.7719471072778106

Epoch: 7, 
Train Loss: 0.9317387502734401, 
Validation Loss: 0.774706669151783
Elapsed time for epoch-7: 4.609538316726685

Epoch: 8, 
Train Loss: 0.929975845357951, 
Validation Loss: 0.7716372543945909
Elapsed time for epoch-8: 4.065949201583862
common line69: model saved with val loss 0.7716372543945909

Epoch: 9, 
Train Loss: 0.9283477411049754, 
Validation Loss: 0.7743220971897244
Elapsed time for epoch-9: 4.363066673278809

Epoch: 10, 
Train Loss: 0.9272577946676928, 
Validation Loss: 0.7713031750172377
Elapsed time for epoch-10: 4.168476819992065
common line69: model saved with val loss 0.7713031750172377

Epoch: 11, 
Train Loss: 0.9262150944281025, 
Validation Loss: 0.7781008863821626
Elapsed time for epoch-11: 3.7519805431365967

Epoch: 12, 
Train Loss: 0.9251663173948016, 
Validation Loss: 0.778544900007546
Elapsed time for epoch-12: 4.638811111450195

Epoch: 13, 
Train Loss: 0.9244047398326778, 
Validation Loss: 0.7821706356480718
Elapsed time for epoch-13: 4.0434510707855225

Epoch: 14, 
Train Loss: 0.923526501330007, 
Validation Loss: 0.7727161627262831
Elapsed time for epoch-14: 4.153207778930664

Epoch: 15, 
Train Loss: 0.9232542956827068, 
Validation Loss: 0.782536861486733
Elapsed time for epoch-15: 4.15428900718689

Epoch: 16, 
Train Loss: 0.9227096199238, 
Validation Loss: 0.7764464681968093
Elapsed time for epoch-16: 4.193276643753052

Epoch: 17, 
Train Loss: 0.9222119364167461, 
Validation Loss: 0.7844854462891817
Elapsed time for epoch-17: 3.8323326110839844

Epoch: 18, 
Train Loss: 0.9216245639474452, 
Validation Loss: 0.7906948439776897
Elapsed time for epoch-18: 4.140037536621094

Epoch: 19, 
Train Loss: 0.9210602872762359, 
Validation Loss: 0.7864967435598373
Elapsed time for epoch-19: 4.619220018386841

Epoch: 20, 
Train Loss: 0.920732933433116, 
Validation Loss: 0.7911304906010628
Elapsed time for epoch-20: 3.9263131618499756

Epoch: 21, 
Train Loss: 0.9201500490933907, 
Validation Loss: 0.7949953693896532
Elapsed time for epoch-21: 3.459449291229248

Epoch: 22, 
Train Loss: 0.9197936063053227, 
Validation Loss: 0.798599804751575
Elapsed time for epoch-22: 4.119907855987549
Early stopped! 

train line101: min loss for the epoch 22 is 0.7713031750172377

Training the 30-th turbine in 189.3048493862152 secs

>>>>>>>>> Training Turbine  31 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.694443941116333
lalalalalal
260 [[ 1.          0.24498365 -0.24331299 -0.70136476  0.00492782]
 [ 0.99904822  0.42752674 -0.35836449  0.47600813  0.03496008]
 [ 0.9961947   0.43042425 -0.37270424  0.47332695 -0.02119305]
 [ 0.99144486  0.4130392  -0.26065409  0.46997547  0.07722104]
 [ 0.98480775  0.13487829 -0.05289443  0.46796459 -0.05104548]]
hahahahahahah
265 [[ 0.99985184  1.          0.24498365 -0.24331299 -0.70136476  0.00492782]
 [ 0.99985184  0.99904822  0.42752674 -0.35836449  0.47600813  0.03496008]
 [ 0.99985184  0.9961947   0.43042425 -0.37270424  0.47332695 -0.02119305]
 [ 0.99985184  0.99144486  0.4130392  -0.26065409  0.46997547  0.07722104]
 [ 0.99985184  0.98480775  0.13487829 -0.05289443  0.46796459 -0.05104548]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.24498365 -0.24331299 -0.70136476  0.00492782]
 [ 0.99985184  0.99904822  0.42752674 -0.35836449  0.47600813  0.03496008]
 [ 0.99985184  0.9961947   0.43042425 -0.37270424  0.47332695 -0.02119305]
 [ 0.99985184  0.99144486  0.4130392  -0.26065409  0.46997547  0.07722104]
 [ 0.99985184  0.98480775  0.13487829 -0.05289443  0.46796459 -0.05104548]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.829667329788208
lalalalalal
260 [[ 1.00000000e+00 -1.51975147e-01  8.13288533e-03 -1.63709635e+00
  -1.57383504e-01]
 [ 9.99048222e-01  1.26185761e-01  6.46547234e-03 -1.64145327e+00
   5.53712230e-02]
 [ 9.96194698e-01 -5.46036432e-01  1.68204532e-01 -1.64212357e+00
  -3.64675777e-01]
 [ 9.91444861e-01 -3.80878393e-01 -5.37662197e-04 -1.64949681e+00
  -2.71162156e-01]
 [ 9.84807753e-01 -1.14307524e-01 -2.04179600e-04 -1.65418887e+00
   5.70796449e-02]]
hahahahahahah
265 [[-8.47540923e-01  1.00000000e+00 -1.51975147e-01  8.13288533e-03
  -1.63709635e+00 -1.57383504e-01]
 [-8.47540923e-01  9.99048222e-01  1.26185761e-01  6.46547234e-03
  -1.64145327e+00  5.53712230e-02]
 [-8.47540923e-01  9.96194698e-01 -5.46036432e-01  1.68204532e-01
  -1.64212357e+00 -3.64675777e-01]
 [-8.47540923e-01  9.91444861e-01 -3.80878393e-01 -5.37662197e-04
  -1.64949681e+00 -2.71162156e-01]
 [-8.47540923e-01  9.84807753e-01 -1.14307524e-01 -2.04179600e-04
  -1.65418887e+00  5.70796449e-02]]

 wind turbine line248 data after normalization: 
 [[-8.47540923e-01  1.00000000e+00 -1.51975147e-01  8.13288533e-03
  -1.63709635e+00 -1.57383504e-01]
 [-8.47540923e-01  9.99048222e-01  1.26185761e-01  6.46547234e-03
  -1.64145327e+00  5.53712230e-02]
 [-8.47540923e-01  9.96194698e-01 -5.46036432e-01  1.68204532e-01
  -1.64212357e+00 -3.64675777e-01]
 [-8.47540923e-01  9.91444861e-01 -3.80878393e-01 -5.37662197e-04
  -1.64949681e+00 -2.71162156e-01]
 [-8.47540923e-01  9.84807753e-01 -1.14307524e-01 -2.04179600e-04
  -1.65418887e+00  5.70796449e-02]]

Epoch: 0, 
Train Loss: 1.0108723874602998, 
Validation Loss: 0.8467241758480668
Elapsed time for epoch-0: 4.158971309661865
common line69: model saved with val loss 0.8467241758480668

Epoch: 1, 
Train Loss: 0.9657941027348783, 
Validation Loss: 0.7979253539815545
Elapsed time for epoch-1: 4.074901342391968
common line69: model saved with val loss 0.7979253539815545

Epoch: 2, 
Train Loss: 0.9492509587973106, 
Validation Loss: 0.7836837451905012
Elapsed time for epoch-2: 4.15968132019043
common line69: model saved with val loss 0.7836837451905012

Epoch: 3, 
Train Loss: 0.9424691246587689, 
Validation Loss: 0.7849449394270778
Elapsed time for epoch-3: 3.9672811031341553

Epoch: 4, 
Train Loss: 0.9374659205434703, 
Validation Loss: 0.7756945937871933
Elapsed time for epoch-4: 4.19550085067749
common line69: model saved with val loss 0.7756945937871933

Epoch: 5, 
Train Loss: 0.9340165024545012, 
Validation Loss: 0.7730997297912836
Elapsed time for epoch-5: 5.22320032119751
common line69: model saved with val loss 0.7730997297912836

Epoch: 6, 
Train Loss: 0.9312194762360148, 
Validation Loss: 0.7721529547125101
Elapsed time for epoch-6: 4.318325757980347
common line69: model saved with val loss 0.7721529547125101

Epoch: 7, 
Train Loss: 0.9294838483343605, 
Validation Loss: 0.7621762538328767
Elapsed time for epoch-7: 3.8386716842651367
common line69: model saved with val loss 0.7621762538328767

Epoch: 8, 
Train Loss: 0.9280826314156797, 
Validation Loss: 0.7686252696439624
Elapsed time for epoch-8: 4.375205039978027

Epoch: 9, 
Train Loss: 0.9268075187667077, 
Validation Loss: 0.7674030074849725
Elapsed time for epoch-9: 3.9903502464294434

Epoch: 10, 
Train Loss: 0.9262665835749201, 
Validation Loss: 0.7685272060334682
Elapsed time for epoch-10: 4.367769479751587

Epoch: 11, 
Train Loss: 0.9252710688013991, 
Validation Loss: 0.769746002741158
Elapsed time for epoch-11: 4.94068169593811

Epoch: 12, 
Train Loss: 0.9244538253846288, 
Validation Loss: 0.7734114518389106
Elapsed time for epoch-12: 4.3541834354400635

Epoch: 13, 
Train Loss: 0.9240141961754871, 
Validation Loss: 0.7702998481690884
Elapsed time for epoch-13: 4.545551300048828

Epoch: 14, 
Train Loss: 0.9235057778218213, 
Validation Loss: 0.7673418708145618
Elapsed time for epoch-14: 3.9311306476593018

Epoch: 15, 
Train Loss: 0.9228002005765418, 
Validation Loss: 0.7633299808949232
Elapsed time for epoch-15: 4.075184345245361

Epoch: 16, 
Train Loss: 0.9222448161419701, 
Validation Loss: 0.7642870862036943
Elapsed time for epoch-16: 3.934206247329712

Epoch: 17, 
Train Loss: 0.9216648148638862, 
Validation Loss: 0.7631227681413293
Elapsed time for epoch-17: 4.2643656730651855

Epoch: 18, 
Train Loss: 0.9213813371768519, 
Validation Loss: 0.7697831019759178
Elapsed time for epoch-18: 3.7911338806152344

Epoch: 19, 
Train Loss: 0.9209414023060759, 
Validation Loss: 0.7649259464815259
Elapsed time for epoch-19: 4.255473852157593
Early stopped! 

train line101: min loss for the epoch 19 is 0.7621762538328767

Training the 31-th turbine in 167.8073971271515 secs

>>>>>>>>> Training Turbine  32 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.5680761337280273
lalalalalal
260 [[ 1.          0.11564531 -0.20360819 -0.39488675  0.06797689]
 [ 0.99904822  0.28162971 -0.34234683  0.36546255  0.12694271]
 [ 0.9961947   0.23544275 -0.36160176  0.36405536  0.16873237]
 [ 0.99144486  0.27296966 -0.33650159  0.36264818  0.15576238]
 [ 0.98480775  0.11131528  0.04515862  0.36030287 -0.00436707]]
hahahahahahah
265 [[ 0.99985184  1.          0.11564531 -0.20360819 -0.39488675  0.06797689]
 [ 0.99985184  0.99904822  0.28162971 -0.34234683  0.36546255  0.12694271]
 [ 0.99985184  0.9961947   0.23544275 -0.36160176  0.36405536  0.16873237]
 [ 0.99985184  0.99144486  0.27296966 -0.33650159  0.36264818  0.15576238]
 [ 0.99985184  0.98480775  0.11131528  0.04515862  0.36030287 -0.00436707]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.11564531 -0.20360819 -0.39488675  0.06797689]
 [ 0.99985184  0.99904822  0.28162971 -0.34234683  0.36546255  0.12694271]
 [ 0.99985184  0.9961947   0.23544275 -0.36160176  0.36405536  0.16873237]
 [ 0.99985184  0.99144486  0.27296966 -0.33650159  0.36264818  0.15576238]
 [ 0.99985184  0.98480775  0.11131528  0.04515862  0.36030287 -0.00436707]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.62457013130188
lalalalalal
260 [[ 1.         -0.05899915 -0.02240555 -1.0851113  -0.06699487]
 [ 0.99904822  0.12574871  0.17203485 -1.08393864  0.15791649]
 [ 0.9961947  -0.43715491  0.15140457 -1.08862926 -0.27480943]
 [ 0.99144486 -0.22642689 -0.1810868  -1.09707237 -0.14320488]
 [ 0.98480775  0.22389601 -0.25260511 -1.09331988  0.34820342]]
hahahahahahah
265 [[-0.84754092  1.         -0.05899915 -0.02240555 -1.0851113  -0.06699487]
 [-0.84754092  0.99904822  0.12574871  0.17203485 -1.08393864  0.15791649]
 [-0.84754092  0.9961947  -0.43715491  0.15140457 -1.08862926 -0.27480943]
 [-0.84754092  0.99144486 -0.22642689 -0.1810868  -1.09707237 -0.14320488]
 [-0.84754092  0.98480775  0.22389601 -0.25260511 -1.09331988  0.34820342]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.05899915 -0.02240555 -1.0851113  -0.06699487]
 [-0.84754092  0.99904822  0.12574871  0.17203485 -1.08393864  0.15791649]
 [-0.84754092  0.9961947  -0.43715491  0.15140457 -1.08862926 -0.27480943]
 [-0.84754092  0.99144486 -0.22642689 -0.1810868  -1.09707237 -0.14320488]
 [-0.84754092  0.98480775  0.22389601 -0.25260511 -1.09331988  0.34820342]]

Epoch: 0, 
Train Loss: 0.9979862712261056, 
Validation Loss: 0.5983740026131272
Elapsed time for epoch-0: 3.072489023208618
common line69: model saved with val loss 0.5983740026131272

Epoch: 1, 
Train Loss: 0.9558206418482196, 
Validation Loss: 0.5472480221651495
Elapsed time for epoch-1: 3.204528570175171
common line69: model saved with val loss 0.5472480221651495

Epoch: 2, 
Train Loss: 0.9407800168049436, 
Validation Loss: 0.5486102513968945
Elapsed time for epoch-2: 2.9837543964385986

Epoch: 3, 
Train Loss: 0.9339241908878839, 
Validation Loss: 0.5461645130999386
Elapsed time for epoch-3: 3.281031370162964
common line69: model saved with val loss 0.5461645130999386

Epoch: 4, 
Train Loss: 0.9293481513482182, 
Validation Loss: 0.5460290820337832
Elapsed time for epoch-4: 3.044360399246216
common line69: model saved with val loss 0.5460290820337832

Epoch: 5, 
Train Loss: 0.9260726141579011, 
Validation Loss: 0.545954518020153
Elapsed time for epoch-5: 3.165201187133789
common line69: model saved with val loss 0.545954518020153

Epoch: 6, 
Train Loss: 0.9236113748380116, 
Validation Loss: 0.5483089946210384
Elapsed time for epoch-6: 3.161543607711792

Epoch: 7, 
Train Loss: 0.9216912090778351, 
Validation Loss: 0.5522592002525926
Elapsed time for epoch-7: 3.413907766342163

Epoch: 8, 
Train Loss: 0.9201531578011873, 
Validation Loss: 0.541767206043005
Elapsed time for epoch-8: 4.5831618309021
common line69: model saved with val loss 0.541767206043005

Epoch: 9, 
Train Loss: 0.9187343384788818, 
Validation Loss: 0.5449720439501107
Elapsed time for epoch-9: 4.660004138946533

Epoch: 10, 
Train Loss: 0.9174697675875255, 
Validation Loss: 0.5410247421823442
Elapsed time for epoch-10: 4.401690244674683
common line69: model saved with val loss 0.5410247421823442

Epoch: 11, 
Train Loss: 0.9165009748534996, 
Validation Loss: 0.5511716841720045
Elapsed time for epoch-11: 3.2731754779815674

Epoch: 12, 
Train Loss: 0.9154118052801165, 
Validation Loss: 0.5491794538684189
Elapsed time for epoch-12: 3.9690911769866943

Epoch: 13, 
Train Loss: 0.914722513250944, 
Validation Loss: 0.5519630271010101
Elapsed time for epoch-13: 4.089045524597168

Epoch: 14, 
Train Loss: 0.9137920187551434, 
Validation Loss: 0.5530660785734653
Elapsed time for epoch-14: 4.275236368179321

Epoch: 15, 
Train Loss: 0.9131867289543152, 
Validation Loss: 0.5550064337439835
Elapsed time for epoch-15: 4.25870418548584

Epoch: 16, 
Train Loss: 0.9125891118740835, 
Validation Loss: 0.5513134133070707
Elapsed time for epoch-16: 3.64083194732666

Epoch: 17, 
Train Loss: 0.9123919301924586, 
Validation Loss: 0.5518741444684565
Elapsed time for epoch-17: 3.653700351715088

Epoch: 18, 
Train Loss: 0.9119216705821142, 
Validation Loss: 0.5488078100606799
Elapsed time for epoch-18: 4.261831760406494

Epoch: 19, 
Train Loss: 0.9114497604490328, 
Validation Loss: 0.550362694542855
Elapsed time for epoch-19: 3.575200319290161

Epoch: 20, 
Train Loss: 0.9106346511540293, 
Validation Loss: 0.5521600656211376
Elapsed time for epoch-20: 4.039860486984253

Epoch: 21, 
Train Loss: 0.9106496109181091, 
Validation Loss: 0.5475040348246694
Elapsed time for epoch-21: 3.397921323776245

Epoch: 22, 
Train Loss: 0.9102485457889172, 
Validation Loss: 0.5517003606073558
Elapsed time for epoch-22: 4.227508068084717
Early stopped! 

train line101: min loss for the epoch 22 is 0.5410247421823442

Training the 32-th turbine in 180.46565771102905 secs

>>>>>>>>> Training Turbine  33 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 6.086188077926636
lalalalalal
260 [[ 1.          0.07926312 -0.2100639  -0.55616213  0.10306062]
 [ 0.99904822  0.27669014 -0.29549262  0.47698759  0.21057236]
 [ 0.9961947   0.2707968  -0.2958231   0.48146287  0.20164312]
 [ 0.99144486  0.33267691 -0.29350975  0.47762692  0.25102456]
 [ 0.98480775  0.25901011 -0.34737777  0.47634827  0.10382728]]
hahahahahahah
265 [[ 0.99985184  1.          0.07926312 -0.2100639  -0.55616213  0.10306062]
 [ 0.99985184  0.99904822  0.27669014 -0.29549262  0.47698759  0.21057236]
 [ 0.99985184  0.9961947   0.2707968  -0.2958231   0.48146287  0.20164312]
 [ 0.99985184  0.99144486  0.33267691 -0.29350975  0.47762692  0.25102456]
 [ 0.99985184  0.98480775  0.25901011 -0.34737777  0.47634827  0.10382728]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.07926312 -0.2100639  -0.55616213  0.10306062]
 [ 0.99985184  0.99904822  0.27669014 -0.29549262  0.47698759  0.21057236]
 [ 0.99985184  0.9961947   0.2707968  -0.2958231   0.48146287  0.20164312]
 [ 0.99985184  0.99144486  0.33267691 -0.29350975  0.47762692  0.25102456]
 [ 0.99985184  0.98480775  0.25901011 -0.34737777  0.47634827  0.10382728]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.6643128395080566
lalalalalal
260 [[ 1.         -0.19772404 -0.01590771 -1.54583772 -0.22016233]
 [ 0.99904822  0.00264965  0.13082479 -1.54903435 -0.04573761]
 [ 0.9961947  -0.57489804  0.05117944 -1.55350963 -0.39729288]
 [ 0.99144486 -0.47765787 -0.14248102 -1.55670625 -0.33508129]
 [ 0.98480775  0.0822098   0.06373763 -1.55926356  0.18552087]]
hahahahahahah
265 [[-0.84754092  1.         -0.19772404 -0.01590771 -1.54583772 -0.22016233]
 [-0.84754092  0.99904822  0.00264965  0.13082479 -1.54903435 -0.04573761]
 [-0.84754092  0.9961947  -0.57489804  0.05117944 -1.55350963 -0.39729288]
 [-0.84754092  0.99144486 -0.47765787 -0.14248102 -1.55670625 -0.33508129]
 [-0.84754092  0.98480775  0.0822098   0.06373763 -1.55926356  0.18552087]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.19772404 -0.01590771 -1.54583772 -0.22016233]
 [-0.84754092  0.99904822  0.00264965  0.13082479 -1.54903435 -0.04573761]
 [-0.84754092  0.9961947  -0.57489804  0.05117944 -1.55350963 -0.39729288]
 [-0.84754092  0.99144486 -0.47765787 -0.14248102 -1.55670625 -0.33508129]
 [-0.84754092  0.98480775  0.0822098   0.06373763 -1.55926356  0.18552087]]

Epoch: 0, 
Train Loss: 0.9900085178493452, 
Validation Loss: 0.7394613968208432
Elapsed time for epoch-0: 3.5816292762756348
common line69: model saved with val loss 0.7394613968208432

Epoch: 1, 
Train Loss: 0.9526278426667222, 
Validation Loss: 0.7233308292925358
Elapsed time for epoch-1: 3.360421895980835
common line69: model saved with val loss 0.7233308292925358

Epoch: 2, 
Train Loss: 0.9445398196953685, 
Validation Loss: 0.7165042776614428
Elapsed time for epoch-2: 3.490689754486084
common line69: model saved with val loss 0.7165042776614428

Epoch: 3, 
Train Loss: 0.9392849899390164, 
Validation Loss: 0.7151217609643936
Elapsed time for epoch-3: 3.9746384620666504
common line69: model saved with val loss 0.7151217609643936

Epoch: 4, 
Train Loss: 0.9358016944983426, 
Validation Loss: 0.71308249887079
Elapsed time for epoch-4: 4.545044660568237
common line69: model saved with val loss 0.71308249887079

Epoch: 5, 
Train Loss: 0.9330116616828101, 
Validation Loss: 0.707063527777791
Elapsed time for epoch-5: 4.399727821350098
common line69: model saved with val loss 0.707063527777791

Epoch: 6, 
Train Loss: 0.9306032623813933, 
Validation Loss: 0.7063625492155552
Elapsed time for epoch-6: 4.34128737449646
common line69: model saved with val loss 0.7063625492155552

Epoch: 7, 
Train Loss: 0.9284671277058225, 
Validation Loss: 0.7000321187078953
Elapsed time for epoch-7: 4.221995830535889
common line69: model saved with val loss 0.7000321187078953

Epoch: 8, 
Train Loss: 0.9269381062824185, 
Validation Loss: 0.6995584778487682
Elapsed time for epoch-8: 3.4643008708953857
common line69: model saved with val loss 0.6995584778487682

Epoch: 9, 
Train Loss: 0.9256456650856162, 
Validation Loss: 0.6969840517267585
Elapsed time for epoch-9: 3.3640666007995605
common line69: model saved with val loss 0.6969840517267585

Epoch: 10, 
Train Loss: 0.9242488040643579, 
Validation Loss: 0.694805677048862
Elapsed time for epoch-10: 3.297200918197632
common line69: model saved with val loss 0.694805677048862

Epoch: 11, 
Train Loss: 0.9233483171262661, 
Validation Loss: 0.692882307805121
Elapsed time for epoch-11: 3.045295238494873
common line69: model saved with val loss 0.692882307805121

Epoch: 12, 
Train Loss: 0.9224223320474144, 
Validation Loss: 0.691009116359055
Elapsed time for epoch-12: 3.0330593585968018
common line69: model saved with val loss 0.691009116359055

Epoch: 13, 
Train Loss: 0.9211398297999086, 
Validation Loss: 0.6940997000783682
Elapsed time for epoch-13: 3.419206380844116

Epoch: 14, 
Train Loss: 0.9206958872680905, 
Validation Loss: 0.6929434277117252
Elapsed time for epoch-14: 3.2072277069091797

Epoch: 15, 
Train Loss: 0.9199301729432675, 
Validation Loss: 0.684031399898231
Elapsed time for epoch-15: 2.8429887294769287
common line69: model saved with val loss 0.684031399898231

Epoch: 16, 
Train Loss: 0.9195731481333741, 
Validation Loss: 0.6894604712724686
Elapsed time for epoch-16: 3.7472105026245117

Epoch: 17, 
Train Loss: 0.9190305550308788, 
Validation Loss: 0.6830306770280004
Elapsed time for epoch-17: 4.0792083740234375
common line69: model saved with val loss 0.6830306770280004

Epoch: 18, 
Train Loss: 0.9184053774390902, 
Validation Loss: 0.6812429437413812
Elapsed time for epoch-18: 3.8165745735168457
common line69: model saved with val loss 0.6812429437413812

Epoch: 19, 
Train Loss: 0.9180333921137978, 
Validation Loss: 0.681399998255074
Elapsed time for epoch-19: 3.2942607402801514

Epoch: 20, 
Train Loss: 0.9174912467974574, 
Validation Loss: 0.6815796541050076
Elapsed time for epoch-20: 3.6401329040527344

Epoch: 21, 
Train Loss: 0.9173171953493807, 
Validation Loss: 0.6834041634574533
Elapsed time for epoch-21: 3.4504456520080566

Epoch: 22, 
Train Loss: 0.9170392108063737, 
Validation Loss: 0.6812825258821249
Elapsed time for epoch-22: 4.1496360301971436

Epoch: 23, 
Train Loss: 0.9164300876505235, 
Validation Loss: 0.6821401156485081
Elapsed time for epoch-23: 4.078026056289673

Epoch: 24, 
Train Loss: 0.9164310922893155, 
Validation Loss: 0.684206260368228
Elapsed time for epoch-24: 4.2251856327056885

Epoch: 25, 
Train Loss: 0.9160434238049162, 
Validation Loss: 0.6763581596314907
Elapsed time for epoch-25: 4.17302393913269
common line69: model saved with val loss 0.6763581596314907

Epoch: 26, 
Train Loss: 0.9155200806235065, 
Validation Loss: 0.6787332249805331
Elapsed time for epoch-26: 4.2231385707855225

Epoch: 27, 
Train Loss: 0.9154547630738812, 
Validation Loss: 0.6798203708603978
Elapsed time for epoch-27: 3.9969334602355957

Epoch: 28, 
Train Loss: 0.9152407187874577, 
Validation Loss: 0.6770324632525444
Elapsed time for epoch-28: 4.3580193519592285

Epoch: 29, 
Train Loss: 0.9150666178775435, 
Validation Loss: 0.6801586579531431
Elapsed time for epoch-29: 4.4065260887146

Epoch: 30, 
Train Loss: 0.9148983143958724, 
Validation Loss: 0.6820558616891503
Elapsed time for epoch-30: 3.7351953983306885

Epoch: 31, 
Train Loss: 0.9146363377070227, 
Validation Loss: 0.675021655857563
Elapsed time for epoch-31: 3.759702444076538
common line69: model saved with val loss 0.675021655857563

train line101: min loss for the epoch 31 is 0.675021655857563

Training the 33-th turbine in 221.04416251182556 secs

>>>>>>>>> Training Turbine  34 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.42887020111084
lalalalalal
260 [[ 1.          0.20494386 -0.15587916 -0.49699469  0.13975882]
 [ 0.99904822  0.42290618 -0.28545276  0.3707515   0.22293107]
 [ 0.9961947   0.3967507  -0.28175546  0.36640432  0.23202436]
 [ 0.99144486  0.47812329 -0.30763656  0.36640432  0.23094929]
 [ 0.98480775  0.35315824 -0.33519826  0.36109109  0.09320611]]
hahahahahahah
265 [[ 0.99985184  1.          0.20494386 -0.15587916 -0.49699469  0.13975882]
 [ 0.99985184  0.99904822  0.42290618 -0.28545276  0.3707515   0.22293107]
 [ 0.99985184  0.9961947   0.3967507  -0.28175546  0.36640432  0.23202436]
 [ 0.99985184  0.99144486  0.47812329 -0.30763656  0.36640432  0.23094929]
 [ 0.99985184  0.98480775  0.35315824 -0.33519826  0.36109109  0.09320611]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.20494386 -0.15587916 -0.49699469  0.13975882]
 [ 0.99985184  0.99904822  0.42290618 -0.28545276  0.3707515   0.22293107]
 [ 0.99985184  0.9961947   0.3967507  -0.28175546  0.36640432  0.23202436]
 [ 0.99985184  0.99144486  0.47812329 -0.30763656  0.36640432  0.23094929]
 [ 0.99985184  0.98480775  0.35315824 -0.33519826  0.36109109  0.09320611]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.1899821758270264
lalalalalal
260 [[ 1.         -0.29636946 -0.03000286 -1.03821908 -0.16562788]
 [ 0.99904822 -0.14960817  0.17402095 -1.07541165 -0.01336007]
 [ 0.9961947  -0.58553279  0.10041104 -1.07637769 -0.31865719]
 [ 0.99144486 -0.62040676 -0.03806969 -1.06043802 -0.37886104]
 [ 0.98480775 -0.15251433 -0.20310378 -1.04449835  0.0359363 ]]
hahahahahahah
265 [[-0.84754092  1.         -0.29636946 -0.03000286 -1.03821908 -0.16562788]
 [-0.84754092  0.99904822 -0.14960817  0.17402095 -1.07541165 -0.01336007]
 [-0.84754092  0.9961947  -0.58553279  0.10041104 -1.07637769 -0.31865719]
 [-0.84754092  0.99144486 -0.62040676 -0.03806969 -1.06043802 -0.37886104]
 [-0.84754092  0.98480775 -0.15251433 -0.20310378 -1.04449835  0.0359363 ]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.29636946 -0.03000286 -1.03821908 -0.16562788]
 [-0.84754092  0.99904822 -0.14960817  0.17402095 -1.07541165 -0.01336007]
 [-0.84754092  0.9961947  -0.58553279  0.10041104 -1.07637769 -0.31865719]
 [-0.84754092  0.99144486 -0.62040676 -0.03806969 -1.06043802 -0.37886104]
 [-0.84754092  0.98480775 -0.15251433 -0.20310378 -1.04449835  0.0359363 ]]

Epoch: 0, 
Train Loss: 0.9773200547494808, 
Validation Loss: 0.7001572139561176
Elapsed time for epoch-0: 3.2146944999694824
common line69: model saved with val loss 0.7001572139561176

Epoch: 1, 
Train Loss: 0.9436981644199676, 
Validation Loss: 0.6940360041335225
Elapsed time for epoch-1: 4.12857723236084
common line69: model saved with val loss 0.6940360041335225

Epoch: 2, 
Train Loss: 0.936340170372434, 
Validation Loss: 0.6915918183512986
Elapsed time for epoch-2: 3.6868417263031006
common line69: model saved with val loss 0.6915918183512986

Epoch: 3, 
Train Loss: 0.9321160958845074, 
Validation Loss: 0.6866583609953523
Elapsed time for epoch-3: 3.6399807929992676
common line69: model saved with val loss 0.6866583609953523

Epoch: 4, 
Train Loss: 0.9290861960719613, 
Validation Loss: 0.6841608555987477
Elapsed time for epoch-4: 3.542098045349121
common line69: model saved with val loss 0.6841608555987477

Epoch: 5, 
Train Loss: 0.926650565587172, 
Validation Loss: 0.6861865865066648
Elapsed time for epoch-5: 3.3645129203796387

Epoch: 6, 
Train Loss: 0.9247490809995587, 
Validation Loss: 0.6833895463496447
Elapsed time for epoch-6: 3.5183627605438232
common line69: model saved with val loss 0.6833895463496447

Epoch: 7, 
Train Loss: 0.9228210457984138, 
Validation Loss: 0.67958177998662
Elapsed time for epoch-7: 3.70428466796875
common line69: model saved with val loss 0.67958177998662

Epoch: 8, 
Train Loss: 0.921244681883259, 
Validation Loss: 0.6808471400290728
Elapsed time for epoch-8: 3.5736072063446045

Epoch: 9, 
Train Loss: 0.9199861006326034, 
Validation Loss: 0.679178811609745
Elapsed time for epoch-9: 3.686497688293457
common line69: model saved with val loss 0.679178811609745

Epoch: 10, 
Train Loss: 0.9189089961162135, 
Validation Loss: 0.6790592363104224
Elapsed time for epoch-10: 3.600658416748047
common line69: model saved with val loss 0.6790592363104224

Epoch: 11, 
Train Loss: 0.9179806948459449, 
Validation Loss: 0.6782275792211294
Elapsed time for epoch-11: 4.2200751304626465
common line69: model saved with val loss 0.6782275792211294

Epoch: 12, 
Train Loss: 0.9169165906535477, 
Validation Loss: 0.6755470437929034
Elapsed time for epoch-12: 3.712987184524536
common line69: model saved with val loss 0.6755470437929034

Epoch: 13, 
Train Loss: 0.9157418089003122, 
Validation Loss: 0.6746160527691245
Elapsed time for epoch-13: 3.4707729816436768
common line69: model saved with val loss 0.6746160527691245

Epoch: 14, 
Train Loss: 0.9148101308265654, 
Validation Loss: 0.6716379001736641
Elapsed time for epoch-14: 4.070355415344238
common line69: model saved with val loss 0.6716379001736641

Epoch: 15, 
Train Loss: 0.913874546895508, 
Validation Loss: 0.6708251805976033
Elapsed time for epoch-15: 3.4775309562683105
common line69: model saved with val loss 0.6708251805976033

Epoch: 16, 
Train Loss: 0.9134193984400324, 
Validation Loss: 0.6722010765224695
Elapsed time for epoch-16: 3.1224050521850586

Epoch: 17, 
Train Loss: 0.9123974347314915, 
Validation Loss: 0.6730292718857527
Elapsed time for epoch-17: 3.296846389770508

Epoch: 18, 
Train Loss: 0.9119244101418167, 
Validation Loss: 0.669234890025109
Elapsed time for epoch-18: 4.345996379852295
common line69: model saved with val loss 0.669234890025109

Epoch: 19, 
Train Loss: 0.9113839519124071, 
Validation Loss: 0.6678940271958709
Elapsed time for epoch-19: 4.140215873718262
common line69: model saved with val loss 0.6678940271958709

Epoch: 20, 
Train Loss: 0.9104058525892866, 
Validation Loss: 0.6690007620491087
Elapsed time for epoch-20: 4.08348536491394

Epoch: 21, 
Train Loss: 0.910235113957349, 
Validation Loss: 0.6697271829470992
Elapsed time for epoch-21: 3.978569507598877

Epoch: 22, 
Train Loss: 0.9098187808980461, 
Validation Loss: 0.6668752189725637
Elapsed time for epoch-22: 4.171981573104858
common line69: model saved with val loss 0.6668752189725637

Epoch: 23, 
Train Loss: 0.9092543885237029, 
Validation Loss: 0.6674944777041674
Elapsed time for epoch-23: 4.069557428359985

Epoch: 24, 
Train Loss: 0.9087118816976788, 
Validation Loss: 0.6700407806783915
Elapsed time for epoch-24: 4.272796154022217

Epoch: 25, 
Train Loss: 0.9081586327622918, 
Validation Loss: 0.6662336960434914
Elapsed time for epoch-25: 3.895678758621216
common line69: model saved with val loss 0.6662336960434914

Epoch: 26, 
Train Loss: 0.9077722899803594, 
Validation Loss: 0.6633943654596806
Elapsed time for epoch-26: 4.443341970443726
common line69: model saved with val loss 0.6633943654596806

Epoch: 27, 
Train Loss: 0.9076017135081171, 
Validation Loss: 0.6669824281707406
Elapsed time for epoch-27: 4.107085227966309

Epoch: 28, 
Train Loss: 0.9074048048057476, 
Validation Loss: 0.665763046592474
Elapsed time for epoch-28: 4.2891271114349365

Epoch: 29, 
Train Loss: 0.9070533938518092, 
Validation Loss: 0.6697304388508201
Elapsed time for epoch-29: 4.371089935302734

Epoch: 30, 
Train Loss: 0.9068387096919933, 
Validation Loss: 0.6710921349003911
Elapsed time for epoch-30: 4.29584264755249

Epoch: 31, 
Train Loss: 0.9067398452458262, 
Validation Loss: 0.6666502356529236
Elapsed time for epoch-31: 4.065615653991699

train line101: min loss for the epoch 31 is 0.6633943654596806

Training the 34-th turbine in 219.6609435081482 secs

>>>>>>>>> Training Turbine  35 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.303210735321045
lalalalalal
260 [[ 1.          0.08022938  0.01353942 -0.38895035  0.15057296]
 [ 0.99904822  0.2723264   0.05441169  0.36436569  0.25112716]
 [ 0.9961947   0.26378875  0.11087779  0.36657418  0.27929342]
 [ 0.99144486  0.30078521  0.08100328  0.3634823   0.34247359]
 [ 0.98480775  0.18979583  0.01173382  0.3625989   0.13513803]]
hahahahahahah
265 [[ 0.99985184  1.          0.08022938  0.01353942 -0.38895035  0.15057296]
 [ 0.99985184  0.99904822  0.2723264   0.05441169  0.36436569  0.25112716]
 [ 0.99985184  0.9961947   0.26378875  0.11087779  0.36657418  0.27929342]
 [ 0.99985184  0.99144486  0.30078521  0.08100328  0.3634823   0.34247359]
 [ 0.99985184  0.98480775  0.18979583  0.01173382  0.3625989   0.13513803]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.08022938  0.01353942 -0.38895035  0.15057296]
 [ 0.99985184  0.99904822  0.2723264   0.05441169  0.36436569  0.25112716]
 [ 0.99985184  0.9961947   0.26378875  0.11087779  0.36657418  0.27929342]
 [ 0.99985184  0.99144486  0.30078521  0.08100328  0.3634823   0.34247359]
 [ 0.99985184  0.98480775  0.18979583  0.01173382  0.3625989   0.13513803]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.765026807785034
lalalalalal
260 [[ 1.         -0.19582115 -0.17670537 -1.03051678 -0.10446352]
 [ 0.99904822 -0.06348765 -0.11991098 -1.03360867  0.01928186]
 [ 0.9961947  -0.58712988  0.05572485 -1.03758395 -0.33387114]
 [ 0.99144486 -0.47329461 -0.03192892 -1.03890904 -0.26470758]
 [ 0.98480775 -0.10617587 -0.10973395 -1.04244263  0.08128751]]
hahahahahahah
265 [[-0.84754092  1.         -0.19582115 -0.17670537 -1.03051678 -0.10446352]
 [-0.84754092  0.99904822 -0.06348765 -0.11991098 -1.03360867  0.01928186]
 [-0.84754092  0.9961947  -0.58712988  0.05572485 -1.03758395 -0.33387114]
 [-0.84754092  0.99144486 -0.47329461 -0.03192892 -1.03890904 -0.26470758]
 [-0.84754092  0.98480775 -0.10617587 -0.10973395 -1.04244263  0.08128751]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.19582115 -0.17670537 -1.03051678 -0.10446352]
 [-0.84754092  0.99904822 -0.06348765 -0.11991098 -1.03360867  0.01928186]
 [-0.84754092  0.9961947  -0.58712988  0.05572485 -1.03758395 -0.33387114]
 [-0.84754092  0.99144486 -0.47329461 -0.03192892 -1.03890904 -0.26470758]
 [-0.84754092  0.98480775 -0.10617587 -0.10973395 -1.04244263  0.08128751]]

Epoch: 0, 
Train Loss: 0.9877848205696634, 
Validation Loss: 0.6912925690412521
Elapsed time for epoch-0: 3.232515573501587
common line69: model saved with val loss 0.6912925690412521

Epoch: 1, 
Train Loss: 0.950869421748554, 
Validation Loss: 0.6798600610345602
Elapsed time for epoch-1: 3.202204942703247
common line69: model saved with val loss 0.6798600610345602

Epoch: 2, 
Train Loss: 0.9426249647591295, 
Validation Loss: 0.6803612997755408
Elapsed time for epoch-2: 3.0305252075195312

Epoch: 3, 
Train Loss: 0.9383955865847964, 
Validation Loss: 0.6762416455894709
Elapsed time for epoch-3: 3.13682222366333
common line69: model saved with val loss 0.6762416455894709

Epoch: 4, 
Train Loss: 0.9353132301769337, 
Validation Loss: 0.6757052494212985
Elapsed time for epoch-4: 3.4079644680023193
common line69: model saved with val loss 0.6757052494212985

Epoch: 5, 
Train Loss: 0.933024924968471, 
Validation Loss: 0.6713425293564796
Elapsed time for epoch-5: 3.1879851818084717
common line69: model saved with val loss 0.6713425293564796

Epoch: 6, 
Train Loss: 0.9314854101223105, 
Validation Loss: 0.6731917336583138
Elapsed time for epoch-6: 3.2536447048187256

Epoch: 7, 
Train Loss: 0.9301016280631057, 
Validation Loss: 0.6686589689925313
Elapsed time for epoch-7: 3.0936954021453857
common line69: model saved with val loss 0.6686589689925313

Epoch: 8, 
Train Loss: 0.9285938339073116, 
Validation Loss: 0.658479661680758
Elapsed time for epoch-8: 3.2939231395721436
common line69: model saved with val loss 0.658479661680758

Epoch: 9, 
Train Loss: 0.9278302980320794, 
Validation Loss: 0.6607851246371865
Elapsed time for epoch-9: 3.103755235671997

Epoch: 10, 
Train Loss: 0.9270530221592478, 
Validation Loss: 0.6615212997421622
Elapsed time for epoch-10: 3.098740816116333

Epoch: 11, 
Train Loss: 0.9261206109233263, 
Validation Loss: 0.6630375813692808
Elapsed time for epoch-11: 3.5800740718841553

Epoch: 12, 
Train Loss: 0.9254175762669379, 
Validation Loss: 0.6590288588777184
Elapsed time for epoch-12: 4.1592652797698975

Epoch: 13, 
Train Loss: 0.9247750490903854, 
Validation Loss: 0.6694274824112654
Elapsed time for epoch-13: 4.215811014175415

Epoch: 14, 
Train Loss: 0.9242560262439632, 
Validation Loss: 0.664595166221261
Elapsed time for epoch-14: 3.5591139793395996

Epoch: 15, 
Train Loss: 0.9235763229241892, 
Validation Loss: 0.6584755685180426
Elapsed time for epoch-15: 3.3174779415130615
common line69: model saved with val loss 0.6584755685180426

Epoch: 16, 
Train Loss: 0.9226718697728229, 
Validation Loss: 0.6615106305107474
Elapsed time for epoch-16: 4.132225036621094

Epoch: 17, 
Train Loss: 0.9223807320123961, 
Validation Loss: 0.655861210078001
Elapsed time for epoch-17: 5.208316326141357
common line69: model saved with val loss 0.655861210078001

Epoch: 18, 
Train Loss: 0.9219745917230093, 
Validation Loss: 0.6538939313031733
Elapsed time for epoch-18: 4.029098749160767
common line69: model saved with val loss 0.6538939313031733

Epoch: 19, 
Train Loss: 0.9214922348741724, 
Validation Loss: 0.6523752231150866
Elapsed time for epoch-19: 4.043857574462891
common line69: model saved with val loss 0.6523752231150866

Epoch: 20, 
Train Loss: 0.920852591009701, 
Validation Loss: 0.6480746534653008
Elapsed time for epoch-20: 4.417584419250488
common line69: model saved with val loss 0.6480746534653008

Epoch: 21, 
Train Loss: 0.9207630218828425, 
Validation Loss: 0.6543528297916055
Elapsed time for epoch-21: 4.263553142547607

Epoch: 22, 
Train Loss: 0.9204187768848002, 
Validation Loss: 0.6452190326526761
Elapsed time for epoch-22: 4.222021818161011
common line69: model saved with val loss 0.6452190326526761

Epoch: 23, 
Train Loss: 0.919980705034833, 
Validation Loss: 0.6458628550171852
Elapsed time for epoch-23: 4.4103684425354

Epoch: 24, 
Train Loss: 0.9195889999636081, 
Validation Loss: 0.6431031282991171
Elapsed time for epoch-24: 3.954923152923584
common line69: model saved with val loss 0.6431031282991171

Epoch: 25, 
Train Loss: 0.9188342403714397, 
Validation Loss: 0.6452279672957957
Elapsed time for epoch-25: 3.8903660774230957

Epoch: 26, 
Train Loss: 0.9185965438099468, 
Validation Loss: 0.646660229191184
Elapsed time for epoch-26: 4.10154128074646

Epoch: 27, 
Train Loss: 0.9184158203982505, 
Validation Loss: 0.6410169051960111
Elapsed time for epoch-27: 3.559713125228882
common line69: model saved with val loss 0.6410169051960111

Epoch: 28, 
Train Loss: 0.9181479541193537, 
Validation Loss: 0.6434782231226563
Elapsed time for epoch-28: 3.441969633102417

Epoch: 29, 
Train Loss: 0.917960012660307, 
Validation Loss: 0.6401827824302018
Elapsed time for epoch-29: 3.9354910850524902
common line69: model saved with val loss 0.6401827824302018

Epoch: 30, 
Train Loss: 0.9175665815587805, 
Validation Loss: 0.640509738586843
Elapsed time for epoch-30: 3.568401575088501

Epoch: 31, 
Train Loss: 0.9170864416020257, 
Validation Loss: 0.6435268712230027
Elapsed time for epoch-31: 4.080722332000732

train line101: min loss for the epoch 31 is 0.6401827824302018

Training the 35-th turbine in 217.2822003364563 secs

>>>>>>>>> Training Turbine  36 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.625368356704712
lalalalalal
260 [[ 1.          0.16243355 -0.04184144 -0.58453628  0.14303142]
 [ 0.99904822  0.28452024 -0.08547578  0.4556742   0.21489407]
 [ 0.9961947   0.22773573 -0.1064967   0.4556742   0.16366655]
 [ 0.99144486  0.27884179 -0.14535356  0.4556742   0.19292694]
 [ 0.98480775  0.17095122 -0.19249138  0.45123968  0.06837375]]
hahahahahahah
265 [[ 0.99985184  1.          0.16243355 -0.04184144 -0.58453628  0.14303142]
 [ 0.99985184  0.99904822  0.28452024 -0.08547578  0.4556742   0.21489407]
 [ 0.99985184  0.9961947   0.22773573 -0.1064967   0.4556742   0.16366655]
 [ 0.99985184  0.99144486  0.27884179 -0.14535356  0.4556742   0.19292694]
 [ 0.99985184  0.98480775  0.17095122 -0.19249138  0.45123968  0.06837375]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.16243355 -0.04184144 -0.58453628  0.14303142]
 [ 0.99985184  0.99904822  0.28452024 -0.08547578  0.4556742   0.21489407]
 [ 0.99985184  0.9961947   0.22773573 -0.1064967   0.4556742   0.16366655]
 [ 0.99985184  0.99144486  0.27884179 -0.14535356  0.4556742   0.19292694]
 [ 0.99985184  0.98480775  0.17095122 -0.19249138  0.45123968  0.06837375]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.2140555381774902
lalalalalal
260 [[ 1.00000000e+00 -2.21161067e-02  5.18900616e-04 -1.49171131e+00
   3.90262672e-03]
 [ 9.99048222e-01  1.62433548e-01  2.31323164e-02 -1.49487882e+00
   1.75196013e-01]
 [ 9.96194698e-01  2.56127987e-01  1.32377410e-01 -1.49487882e+00
   5.66368135e-01]
 [ 9.91444861e-01  1.76629675e-01  1.89388697e-01 -1.49487882e+00
   4.46291351e-01]
 [ 9.84807753e-01  2.44771086e-01  7.34551290e-02 -1.49487882e+00
   5.72591427e-01]]
hahahahahahah
265 [[-8.47540923e-01  1.00000000e+00 -2.21161067e-02  5.18900616e-04
  -1.49171131e+00  3.90262672e-03]
 [-8.47540923e-01  9.99048222e-01  1.62433548e-01  2.31323164e-02
  -1.49487882e+00  1.75196013e-01]
 [-8.47540923e-01  9.96194698e-01  2.56127987e-01  1.32377410e-01
  -1.49487882e+00  5.66368135e-01]
 [-8.47540923e-01  9.91444861e-01  1.76629675e-01  1.89388697e-01
  -1.49487882e+00  4.46291351e-01]
 [-8.47540923e-01  9.84807753e-01  2.44771086e-01  7.34551290e-02
  -1.49487882e+00  5.72591427e-01]]

 wind turbine line248 data after normalization: 
 [[-8.47540923e-01  1.00000000e+00 -2.21161067e-02  5.18900616e-04
  -1.49171131e+00  3.90262672e-03]
 [-8.47540923e-01  9.99048222e-01  1.62433548e-01  2.31323164e-02
  -1.49487882e+00  1.75196013e-01]
 [-8.47540923e-01  9.96194698e-01  2.56127987e-01  1.32377410e-01
  -1.49487882e+00  5.66368135e-01]
 [-8.47540923e-01  9.91444861e-01  1.76629675e-01  1.89388697e-01
  -1.49487882e+00  4.46291351e-01]
 [-8.47540923e-01  9.84807753e-01  2.44771086e-01  7.34551290e-02
  -1.49487882e+00  5.72591427e-01]]

Epoch: 0, 
Train Loss: 0.9999658141066047, 
Validation Loss: 0.7417893409729004
Elapsed time for epoch-0: 4.094813823699951
common line69: model saved with val loss 0.7417893409729004

Epoch: 1, 
Train Loss: 0.9616739788726598, 
Validation Loss: 0.7192256087437272
Elapsed time for epoch-1: 3.7168588638305664
common line69: model saved with val loss 0.7192256087437272

Epoch: 2, 
Train Loss: 0.9478461369245994, 
Validation Loss: 0.7061846880242229
Elapsed time for epoch-2: 3.264179229736328
common line69: model saved with val loss 0.7061846880242229

Epoch: 3, 
Train Loss: 0.9402511183704648, 
Validation Loss: 0.7011826662346721
Elapsed time for epoch-3: 3.818310499191284
common line69: model saved with val loss 0.7011826662346721

Epoch: 4, 
Train Loss: 0.9350856714138464, 
Validation Loss: 0.6975799473002553
Elapsed time for epoch-4: 3.4851841926574707
common line69: model saved with val loss 0.6975799473002553

Epoch: 5, 
Train Loss: 0.9312433559103173, 
Validation Loss: 0.7079188255593181
Elapsed time for epoch-5: 3.2221744060516357

Epoch: 6, 
Train Loss: 0.9282868609708899, 
Validation Loss: 0.6982964659109712
Elapsed time for epoch-6: 3.169393301010132

Epoch: 7, 
Train Loss: 0.926162510108547, 
Validation Loss: 0.6953948745504022
Elapsed time for epoch-7: 3.078821897506714
common line69: model saved with val loss 0.6953948745504022

Epoch: 8, 
Train Loss: 0.9243191046123745, 
Validation Loss: 0.6976283844560385
Elapsed time for epoch-8: 3.0574145317077637

Epoch: 9, 
Train Loss: 0.9232667073482225, 
Validation Loss: 0.697220990434289
Elapsed time for epoch-9: 3.308931827545166

Epoch: 10, 
Train Loss: 0.9220915802386629, 
Validation Loss: 0.6996321156620979
Elapsed time for epoch-10: 4.352720499038696

Epoch: 11, 
Train Loss: 0.9208753150300819, 
Validation Loss: 0.6947519835084677
Elapsed time for epoch-11: 5.0987958908081055
common line69: model saved with val loss 0.6947519835084677

Epoch: 12, 
Train Loss: 0.9206583919394918, 
Validation Loss: 0.7026182170957327
Elapsed time for epoch-12: 3.9080562591552734

Epoch: 13, 
Train Loss: 0.9199262960117405, 
Validation Loss: 0.6969420984387398
Elapsed time for epoch-13: 4.015403509140015

Epoch: 14, 
Train Loss: 0.9192119545045019, 
Validation Loss: 0.696407831273973
Elapsed time for epoch-14: 4.101651191711426

Epoch: 15, 
Train Loss: 0.9188802895926628, 
Validation Loss: 0.695872416254133
Elapsed time for epoch-15: 4.167030572891235

Epoch: 16, 
Train Loss: 0.9182238982004278, 
Validation Loss: 0.697750641964376
Elapsed time for epoch-16: 3.735117197036743

Epoch: 17, 
Train Loss: 0.9181348160535348, 
Validation Loss: 0.7021797001361847
Elapsed time for epoch-17: 3.960141897201538

Epoch: 18, 
Train Loss: 0.9178000687300658, 
Validation Loss: 0.6981774661689997
Elapsed time for epoch-18: 4.311366081237793

Epoch: 19, 
Train Loss: 0.9174285608680308, 
Validation Loss: 0.6977690681815147
Elapsed time for epoch-19: 4.817098140716553

Epoch: 20, 
Train Loss: 0.9171714166633221, 
Validation Loss: 0.6969567192718387
Elapsed time for epoch-20: 4.8056769371032715

Epoch: 21, 
Train Loss: 0.9168694664199813, 
Validation Loss: 0.6934043150395155
Elapsed time for epoch-21: 4.096221923828125
common line69: model saved with val loss 0.6934043150395155

Epoch: 22, 
Train Loss: 0.9165755370083977, 
Validation Loss: 0.6971627110615373
Elapsed time for epoch-22: 4.17658257484436

Epoch: 23, 
Train Loss: 0.91612939937275, 
Validation Loss: 0.6977261258289218
Elapsed time for epoch-23: 4.542185068130493

Epoch: 24, 
Train Loss: 0.9157792528887757, 
Validation Loss: 0.6953328466042876
Elapsed time for epoch-24: 4.126086711883545

Epoch: 25, 
Train Loss: 0.9157712083904683, 
Validation Loss: 0.6966240024194121
Elapsed time for epoch-25: 4.451421737670898

Epoch: 26, 
Train Loss: 0.9156548483532017, 
Validation Loss: 0.7017262373119593
Elapsed time for epoch-26: 3.875190019607544

Epoch: 27, 
Train Loss: 0.9151831249229047, 
Validation Loss: 0.6953173186630011
Elapsed time for epoch-27: 4.430095672607422

Epoch: 28, 
Train Loss: 0.9150886585732468, 
Validation Loss: 0.7033702246844769
Elapsed time for epoch-28: 3.7251644134521484

Epoch: 29, 
Train Loss: 0.9151131400541097, 
Validation Loss: 0.6880719177424908
Elapsed time for epoch-29: 4.338745594024658
common line69: model saved with val loss 0.6880719177424908

Epoch: 30, 
Train Loss: 0.9149750494906882, 
Validation Loss: 0.6965352920815349
Elapsed time for epoch-30: 3.7687575817108154

Epoch: 31, 
Train Loss: 0.9145545888097346, 
Validation Loss: 0.6879892628639936
Elapsed time for epoch-31: 4.3641040325164795
common line69: model saved with val loss 0.6879892628639936

train line101: min loss for the epoch 31 is 0.6879892628639936

Training the 36-th turbine in 223.28625679016113 secs

>>>>>>>>> Training Turbine  37 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.8542826175689697
lalalalalal
260 [[ 1.         -0.80929449 -0.03780652 -1.71198658 -0.3947501 ]
 [ 0.99904822 -1.48935289 -0.05626811  0.28115401 -0.84920683]
 [ 0.9961947  -1.48935289 -0.05626811  0.28115401 -0.84920683]
 [ 0.99144486 -1.48935289 -0.05626811  0.28115401 -0.84920683]
 [ 0.98480775 -1.48935289 -0.05626811  0.28115401 -0.84920683]]
hahahahahahah
265 [[ 0.99985184  1.         -0.80929449 -0.03780652 -1.71198658 -0.3947501 ]
 [ 0.99985184  0.99904822 -1.48935289 -0.05626811  0.28115401 -0.84920683]
 [ 0.99985184  0.9961947  -1.48935289 -0.05626811  0.28115401 -0.84920683]
 [ 0.99985184  0.99144486 -1.48935289 -0.05626811  0.28115401 -0.84920683]
 [ 0.99985184  0.98480775 -1.48935289 -0.05626811  0.28115401 -0.84920683]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.80929449 -0.03780652 -1.71198658 -0.3947501 ]
 [ 0.99985184  0.99904822 -1.48935289 -0.05626811  0.28115401 -0.84920683]
 [ 0.99985184  0.9961947  -1.48935289 -0.05626811  0.28115401 -0.84920683]
 [ 0.99985184  0.99144486 -1.48935289 -0.05626811  0.28115401 -0.84920683]
 [ 0.99985184  0.98480775 -1.48935289 -0.05626811  0.28115401 -0.84920683]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.752117156982422
lalalalalal
260 [[ 1.          0.08369806 -0.11900331  0.28115401  0.00296097]
 [ 0.99904822  0.2167819  -0.05729375  0.28115401  0.18272109]
 [ 0.9961947   0.32058729  0.0292022   0.28115401  0.47090517]
 [ 0.99144486  0.3418807   0.00287735  0.28115401  0.49573958]
 [ 0.98480775  0.33921903 -0.09045623  0.28115401  0.53090529]]
hahahahahahah
265 [[-0.84754092  1.          0.08369806 -0.11900331  0.28115401  0.00296097]
 [-0.84754092  0.99904822  0.2167819  -0.05729375  0.28115401  0.18272109]
 [-0.84754092  0.9961947   0.32058729  0.0292022   0.28115401  0.47090517]
 [-0.84754092  0.99144486  0.3418807   0.00287735  0.28115401  0.49573958]
 [-0.84754092  0.98480775  0.33921903 -0.09045623  0.28115401  0.53090529]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.08369806 -0.11900331  0.28115401  0.00296097]
 [-0.84754092  0.99904822  0.2167819  -0.05729375  0.28115401  0.18272109]
 [-0.84754092  0.9961947   0.32058729  0.0292022   0.28115401  0.47090517]
 [-0.84754092  0.99144486  0.3418807   0.00287735  0.28115401  0.49573958]
 [-0.84754092  0.98480775  0.33921903 -0.09045623  0.28115401  0.53090529]]

Epoch: 0, 
Train Loss: 0.9724614386047635, 
Validation Loss: 0.7293290430679917
Elapsed time for epoch-0: 3.441152334213257
common line69: model saved with val loss 0.7293290430679917

Epoch: 1, 
Train Loss: 0.9418935701877129, 
Validation Loss: 0.7174345497041941
Elapsed time for epoch-1: 3.426523208618164
common line69: model saved with val loss 0.7174345497041941

Epoch: 2, 
Train Loss: 0.9339907888103934, 
Validation Loss: 0.7123371129855514
Elapsed time for epoch-2: 3.7606465816497803
common line69: model saved with val loss 0.7123371129855514

Epoch: 3, 
Train Loss: 0.9292486472790983, 
Validation Loss: 0.7083618016913533
Elapsed time for epoch-3: 3.0488357543945312
common line69: model saved with val loss 0.7083618016913533

Epoch: 4, 
Train Loss: 0.9263514034888324, 
Validation Loss: 0.7122682854533195
Elapsed time for epoch-4: 3.5767219066619873

Epoch: 5, 
Train Loss: 0.923822268718431, 
Validation Loss: 0.7110615037381649
Elapsed time for epoch-5: 3.464386224746704

Epoch: 6, 
Train Loss: 0.9220945582169444, 
Validation Loss: 0.7096259975805879
Elapsed time for epoch-6: 3.119339942932129

Epoch: 7, 
Train Loss: 0.9203092422054595, 
Validation Loss: 0.7081712353974581
Elapsed time for epoch-7: 3.527787446975708
common line69: model saved with val loss 0.7081712353974581

Epoch: 8, 
Train Loss: 0.9188011728164529, 
Validation Loss: 0.7050728024914861
Elapsed time for epoch-8: 3.493037223815918
common line69: model saved with val loss 0.7050728024914861

Epoch: 9, 
Train Loss: 0.9174602786783411, 
Validation Loss: 0.7067267382517457
Elapsed time for epoch-9: 3.862218141555786

Epoch: 10, 
Train Loss: 0.9162889206860246, 
Validation Loss: 0.7110283514484763
Elapsed time for epoch-10: 3.280266761779785

Epoch: 11, 
Train Loss: 0.9151368523094835, 
Validation Loss: 0.703286649659276
Elapsed time for epoch-11: 3.6138155460357666
common line69: model saved with val loss 0.703286649659276

Epoch: 12, 
Train Loss: 0.9139572613629974, 
Validation Loss: 0.70337956212461
Elapsed time for epoch-12: 3.8332877159118652

Epoch: 13, 
Train Loss: 0.912524623279812, 
Validation Loss: 0.6987076420336962
Elapsed time for epoch-13: 4.110856056213379
common line69: model saved with val loss 0.6987076420336962

Epoch: 14, 
Train Loss: 0.9114497089836778, 
Validation Loss: 0.7039164360612631
Elapsed time for epoch-14: 3.415613889694214

Epoch: 15, 
Train Loss: 0.9105104985607773, 
Validation Loss: 0.7037945231422782
Elapsed time for epoch-15: 3.5963354110717773

Epoch: 16, 
Train Loss: 0.9096090782339833, 
Validation Loss: 0.7041527200490236
Elapsed time for epoch-16: 3.765665054321289

Epoch: 17, 
Train Loss: 0.9089366540688426, 
Validation Loss: 0.7052201488986611
Elapsed time for epoch-17: 3.274690628051758

Epoch: 18, 
Train Loss: 0.9080216451352384, 
Validation Loss: 0.7033112552016973
Elapsed time for epoch-18: 4.414795160293579

Epoch: 19, 
Train Loss: 0.9075575269320432, 
Validation Loss: 0.7087529804557562
Elapsed time for epoch-19: 3.980710506439209

Epoch: 20, 
Train Loss: 0.9068322532317218, 
Validation Loss: 0.7000530743971467
Elapsed time for epoch-20: 4.161981105804443

Epoch: 21, 
Train Loss: 0.9063665655230274, 
Validation Loss: 0.7021223353222013
Elapsed time for epoch-21: 3.646603584289551

Epoch: 22, 
Train Loss: 0.9060770841706701, 
Validation Loss: 0.7044840669259429
Elapsed time for epoch-22: 4.150628328323364

Epoch: 23, 
Train Loss: 0.9057367773366576, 
Validation Loss: 0.7048577796667814
Elapsed time for epoch-23: 4.4187331199646

Epoch: 24, 
Train Loss: 0.9053711257561916, 
Validation Loss: 0.7066484112292528
Elapsed time for epoch-24: 4.269482135772705

Epoch: 25, 
Train Loss: 0.9049451377461938, 
Validation Loss: 0.6993754114955664
Elapsed time for epoch-25: 3.630388021469116
Early stopped! 

train line101: min loss for the epoch 25 is 0.6987076420336962

Training the 37-th turbine in 189.03256702423096 secs

>>>>>>>>> Training Turbine  38 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.8121187686920166
lalalalalal
260 [[ 1.          0.17298214 -0.20460164 14.49494834  0.17150525]
 [ 0.99904822  0.24298797 -0.21273421  0.55835706  0.1699334 ]
 [ 0.9961947   0.20259999 -0.21092697  0.55835706  0.10507751]
 [ 0.99144486  0.20259999 -0.22972224  0.55835706  0.04999443]
 [ 0.98480775  0.11374644 -0.31140936  0.5499118  -0.01932643]]
hahahahahahah
265 [[ 0.99985184  1.          0.17298214 -0.20460164 14.49494834  0.17150525]
 [ 0.99985184  0.99904822  0.24298797 -0.21273421  0.55835706  0.1699334 ]
 [ 0.99985184  0.9961947   0.20259999 -0.21092697  0.55835706  0.10507751]
 [ 0.99985184  0.99144486  0.20259999 -0.22972224  0.55835706  0.04999443]
 [ 0.99985184  0.98480775  0.11374644 -0.31140936  0.5499118  -0.01932643]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.17298214 -0.20460164 14.49494834  0.17150525]
 [ 0.99985184  0.99904822  0.24298797 -0.21273421  0.55835706  0.1699334 ]
 [ 0.99985184  0.9961947   0.20259999 -0.21092697  0.55835706  0.10507751]
 [ 0.99985184  0.99144486  0.20259999 -0.22972224  0.55835706  0.04999443]
 [ 0.99985184  0.98480775  0.11374644 -0.31140936  0.5499118  -0.01932643]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.30244517326355
lalalalalal
260 [[ 1.          0.02085409 -0.10466142 -1.87809922  0.01830685]
 [ 0.99904822  0.16221201 -0.15490262 -1.88155409  0.2078856 ]
 [ 0.9961947   0.25645063 -0.09996261 -1.8892316   0.43033652]
 [ 0.99144486  0.26991329 -0.15923999 -1.88846385  0.42432249]
 [ 0.98480775  0.35876685 -0.20333657 -1.88999935  0.56410322]]
hahahahahahah
265 [[-0.84754092  1.          0.02085409 -0.10466142 -1.87809922  0.01830685]
 [-0.84754092  0.99904822  0.16221201 -0.15490262 -1.88155409  0.2078856 ]
 [-0.84754092  0.9961947   0.25645063 -0.09996261 -1.8892316   0.43033652]
 [-0.84754092  0.99144486  0.26991329 -0.15923999 -1.88846385  0.42432249]
 [-0.84754092  0.98480775  0.35876685 -0.20333657 -1.88999935  0.56410322]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.02085409 -0.10466142 -1.87809922  0.01830685]
 [-0.84754092  0.99904822  0.16221201 -0.15490262 -1.88155409  0.2078856 ]
 [-0.84754092  0.9961947   0.25645063 -0.09996261 -1.8892316   0.43033652]
 [-0.84754092  0.99144486  0.26991329 -0.15923999 -1.88846385  0.42432249]
 [-0.84754092  0.98480775  0.35876685 -0.20333657 -1.88999935  0.56410322]]

Epoch: 0, 
Train Loss: 0.9994638150229174, 
Validation Loss: 0.7346073882654309
Elapsed time for epoch-0: 3.866668701171875
common line69: model saved with val loss 0.7346073882654309

Epoch: 1, 
Train Loss: 0.9615937849553693, 
Validation Loss: 0.7219344098120928
Elapsed time for epoch-1: 3.828474760055542
common line69: model saved with val loss 0.7219344098120928

Epoch: 2, 
Train Loss: 0.9530756042785004, 
Validation Loss: 0.7148485779762268
Elapsed time for epoch-2: 3.6368777751922607
common line69: model saved with val loss 0.7148485779762268

Epoch: 3, 
Train Loss: 0.9482201692186484, 
Validation Loss: 0.708794467151165
Elapsed time for epoch-3: 4.071444749832153
common line69: model saved with val loss 0.708794467151165

Epoch: 4, 
Train Loss: 0.945289860002133, 
Validation Loss: 0.708944265730679
Elapsed time for epoch-4: 4.565064430236816

Epoch: 5, 
Train Loss: 0.9433702336890357, 
Validation Loss: 0.7030971674248576
Elapsed time for epoch-5: 3.5285685062408447
common line69: model saved with val loss 0.7030971674248576

Epoch: 6, 
Train Loss: 0.9419234478924455, 
Validation Loss: 0.7026185737922788
Elapsed time for epoch-6: 3.737198829650879
common line69: model saved with val loss 0.7026185737922788

Epoch: 7, 
Train Loss: 0.9403297591860554, 
Validation Loss: 0.6983601367101073
Elapsed time for epoch-7: 3.289902448654175
common line69: model saved with val loss 0.6983601367101073

Epoch: 8, 
Train Loss: 0.9392113296174202, 
Validation Loss: 0.7068367758765817
Elapsed time for epoch-8: 3.3127260208129883

Epoch: 9, 
Train Loss: 0.9380317809952408, 
Validation Loss: 0.7054591281339526
Elapsed time for epoch-9: 3.3140714168548584

Epoch: 10, 
Train Loss: 0.9370130757574274, 
Validation Loss: 0.6918273000046611
Elapsed time for epoch-10: 3.1613690853118896
common line69: model saved with val loss 0.6918273000046611

Epoch: 11, 
Train Loss: 0.9357150980905324, 
Validation Loss: 0.6980057610198855
Elapsed time for epoch-11: 3.4339940547943115

Epoch: 12, 
Train Loss: 0.9350849058197326, 
Validation Loss: 0.6964117037132382
Elapsed time for epoch-12: 3.097653388977051

Epoch: 13, 
Train Loss: 0.9338673904162496, 
Validation Loss: 0.6928586475551128
Elapsed time for epoch-13: 3.246211528778076

Epoch: 14, 
Train Loss: 0.9333616538959391, 
Validation Loss: 0.7033445425331593
Elapsed time for epoch-14: 3.059791326522827

Epoch: 15, 
Train Loss: 0.9322188157243889, 
Validation Loss: 0.6925200214609504
Elapsed time for epoch-15: 3.08610200881958

Epoch: 16, 
Train Loss: 0.9319223413447372, 
Validation Loss: 0.6966753909364343
Elapsed time for epoch-16: 3.3743672370910645

Epoch: 17, 
Train Loss: 0.9313677341497245, 
Validation Loss: 0.6896414514631033
Elapsed time for epoch-17: 3.090257167816162
common line69: model saved with val loss 0.6896414514631033

Epoch: 18, 
Train Loss: 0.9309885587011065, 
Validation Loss: 0.6942313648760319
Elapsed time for epoch-18: 3.077840805053711

Epoch: 19, 
Train Loss: 0.9305234275946096, 
Validation Loss: 0.6920327199622989
Elapsed time for epoch-19: 3.4689629077911377

Epoch: 20, 
Train Loss: 0.9300050828136316, 
Validation Loss: 0.6955965301021934
Elapsed time for epoch-20: 4.050187587738037

Epoch: 21, 
Train Loss: 0.9296792009297539, 
Validation Loss: 0.6893703667446971
Elapsed time for epoch-21: 4.257586717605591
common line69: model saved with val loss 0.6893703667446971

Epoch: 22, 
Train Loss: 0.9293887289632269, 
Validation Loss: 0.6834673965349793
Elapsed time for epoch-22: 4.632192850112915
common line69: model saved with val loss 0.6834673965349793

Epoch: 23, 
Train Loss: 0.9290715931844311, 
Validation Loss: 0.6938804434612393
Elapsed time for epoch-23: 4.107434272766113

Epoch: 24, 
Train Loss: 0.9287797643356964, 
Validation Loss: 0.6917576063424349
Elapsed time for epoch-24: 4.133590459823608

Epoch: 25, 
Train Loss: 0.9284769051215228, 
Validation Loss: 0.6880444483831525
Elapsed time for epoch-25: 4.367721080780029

Epoch: 26, 
Train Loss: 0.9282168077320612, 
Validation Loss: 0.6893305545672774
Elapsed time for epoch-26: 4.185887813568115

Epoch: 27, 
Train Loss: 0.9280010420484703, 
Validation Loss: 0.6896320013329387
Elapsed time for epoch-27: 4.0142502784729

Epoch: 28, 
Train Loss: 0.9275680105475819, 
Validation Loss: 0.6907174317166209
Elapsed time for epoch-28: 4.13444185256958

Epoch: 29, 
Train Loss: 0.92733478996934, 
Validation Loss: 0.6788064548745751
Elapsed time for epoch-29: 4.146390676498413
common line69: model saved with val loss 0.6788064548745751

Epoch: 30, 
Train Loss: 0.9271868903095982, 
Validation Loss: 0.6855920562520623
Elapsed time for epoch-30: 4.102162837982178

Epoch: 31, 
Train Loss: 0.9271602017038009, 
Validation Loss: 0.693944632075727
Elapsed time for epoch-31: 3.935375928878784

train line101: min loss for the epoch 31 is 0.6788064548745751

Training the 38-th turbine in 221.59526658058167 secs

>>>>>>>>> Training Turbine  39 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 6.458179950714111
lalalalalal
260 [[ 1.          0.11826422 -0.01985558  0.77523079  0.09750313]
 [ 0.99904822  0.15185038 -0.06908769  2.25101513 -0.0049666 ]
 [ 0.9961947   0.09273873 -0.07661153  2.25101513 -0.06206983]
 [ 0.99144486 -0.02011079 -0.10147293  2.25101513 -0.17560229]
 [ 0.98480775  0.01750571 -0.13091406  2.25101513 -0.14787574]]
hahahahahahah
265 [[ 0.99985184  1.          0.11826422 -0.01985558  0.77523079  0.09750313]
 [ 0.99985184  0.99904822  0.15185038 -0.06908769  2.25101513 -0.0049666 ]
 [ 0.99985184  0.9961947   0.09273873 -0.07661153  2.25101513 -0.06206983]
 [ 0.99985184  0.99144486 -0.02011079 -0.10147293  2.25101513 -0.17560229]
 [ 0.99985184  0.98480775  0.01750571 -0.13091406  2.25101513 -0.14787574]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.11826422 -0.01985558  0.77523079  0.09750313]
 [ 0.99985184  0.99904822  0.15185038 -0.06908769  2.25101513 -0.0049666 ]
 [ 0.99985184  0.9961947   0.09273873 -0.07661153  2.25101513 -0.06206983]
 [ 0.99985184  0.99144486 -0.02011079 -0.10147293  2.25101513 -0.17560229]
 [ 0.99985184  0.98480775  0.01750571 -0.13091406  2.25101513 -0.14787574]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.718635320663452
lalalalalal
260 [[ 1.          0.15185038 -0.05240438 -0.58511055  0.11803658]
 [ 0.99904822  0.19484068 -0.0471704  -0.58924815  0.19664939]
 [ 0.9961947  -0.03085837 -0.08577099 -0.59223021 -0.04431368]
 [ 0.99144486  0.07124358 -0.08577099 -0.59416855  0.08555723]
 [ 0.98480775  0.32112467 -0.1341853  -0.59528683  0.3793007 ]]
hahahahahahah
265 [[-0.84754092  1.          0.15185038 -0.05240438 -0.58511055  0.11803658]
 [-0.84754092  0.99904822  0.19484068 -0.0471704  -0.58924815  0.19664939]
 [-0.84754092  0.9961947  -0.03085837 -0.08577099 -0.59223021 -0.04431368]
 [-0.84754092  0.99144486  0.07124358 -0.08577099 -0.59416855  0.08555723]
 [-0.84754092  0.98480775  0.32112467 -0.1341853  -0.59528683  0.3793007 ]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.15185038 -0.05240438 -0.58511055  0.11803658]
 [-0.84754092  0.99904822  0.19484068 -0.0471704  -0.58924815  0.19664939]
 [-0.84754092  0.9961947  -0.03085837 -0.08577099 -0.59223021 -0.04431368]
 [-0.84754092  0.99144486  0.07124358 -0.08577099 -0.59416855  0.08555723]
 [-0.84754092  0.98480775  0.32112467 -0.1341853  -0.59528683  0.3793007 ]]

Epoch: 0, 
Train Loss: 1.0103861255054714, 
Validation Loss: 0.6519585000351071
Elapsed time for epoch-0: 3.2861688137054443
common line69: model saved with val loss 0.6519585000351071

Epoch: 1, 
Train Loss: 0.9667686410561329, 
Validation Loss: 0.5828747451305389
Elapsed time for epoch-1: 3.1794817447662354
common line69: model saved with val loss 0.5828747451305389

Epoch: 2, 
Train Loss: 0.9406335517889312, 
Validation Loss: 0.575716610532254
Elapsed time for epoch-2: 3.418790102005005
common line69: model saved with val loss 0.575716610532254

Epoch: 3, 
Train Loss: 0.9337853586473385, 
Validation Loss: 0.5677764248102903
Elapsed time for epoch-3: 3.4515583515167236
common line69: model saved with val loss 0.5677764248102903

Epoch: 4, 
Train Loss: 0.9298395644716856, 
Validation Loss: 0.5699844625778496
Elapsed time for epoch-4: 3.1668477058410645

Epoch: 5, 
Train Loss: 0.9266677745500532, 
Validation Loss: 0.5699857175350189
Elapsed time for epoch-5: 3.886582851409912

Epoch: 6, 
Train Loss: 0.9247704139527153, 
Validation Loss: 0.5739825568161905
Elapsed time for epoch-6: 4.069520473480225

Epoch: 7, 
Train Loss: 0.9229027831754765, 
Validation Loss: 0.5711357020772994
Elapsed time for epoch-7: 4.305933237075806

Epoch: 8, 
Train Loss: 0.9215177457873561, 
Validation Loss: 0.5710334405303001
Elapsed time for epoch-8: 4.123726844787598

Epoch: 9, 
Train Loss: 0.9200813150455972, 
Validation Loss: 0.5701412125490606
Elapsed time for epoch-9: 3.5495071411132812

Epoch: 10, 
Train Loss: 0.9190512749076891, 
Validation Loss: 0.5637874221429229
Elapsed time for epoch-10: 2.8623218536376953
common line69: model saved with val loss 0.5637874221429229

Epoch: 11, 
Train Loss: 0.9183984271117619, 
Validation Loss: 0.5665672202594578
Elapsed time for epoch-11: 3.333268880844116

Epoch: 12, 
Train Loss: 0.9176589015151272, 
Validation Loss: 0.5620674001984298
Elapsed time for epoch-12: 4.182781457901001
common line69: model saved with val loss 0.5620674001984298

Epoch: 13, 
Train Loss: 0.9171588821571415, 
Validation Loss: 0.5675550675950944
Elapsed time for epoch-13: 3.829214334487915

Epoch: 14, 
Train Loss: 0.9165560609402776, 
Validation Loss: 0.5708542396314442
Elapsed time for epoch-14: 3.521937608718872

Epoch: 15, 
Train Loss: 0.9160402933088672, 
Validation Loss: 0.5706470124423504
Elapsed time for epoch-15: 3.3499982357025146

Epoch: 16, 
Train Loss: 0.9155988686976313, 
Validation Loss: 0.5702797123230994
Elapsed time for epoch-16: 3.8286705017089844

Epoch: 17, 
Train Loss: 0.9153905577268922, 
Validation Loss: 0.5629447610117495
Elapsed time for epoch-17: 4.20436692237854

Epoch: 18, 
Train Loss: 0.9150420075454632, 
Validation Loss: 0.5658531789667904
Elapsed time for epoch-18: 3.6468894481658936

Epoch: 19, 
Train Loss: 0.9146000249546116, 
Validation Loss: 0.5629047998227179
Elapsed time for epoch-19: 3.6932568550109863

Epoch: 20, 
Train Loss: 0.9142222065134209, 
Validation Loss: 0.5679924241267145
Elapsed time for epoch-20: 3.5966849327087402

Epoch: 21, 
Train Loss: 0.9142059643729394, 
Validation Loss: 0.5640394045040011
Elapsed time for epoch-21: 3.900563955307007

Epoch: 22, 
Train Loss: 0.9136165295328412, 
Validation Loss: 0.5637259627692401
Elapsed time for epoch-22: 4.3188347816467285

Epoch: 23, 
Train Loss: 0.9139555094121885, 
Validation Loss: 0.5595587291754782
Elapsed time for epoch-23: 4.026674747467041
common line69: model saved with val loss 0.5595587291754782

Epoch: 24, 
Train Loss: 0.9134012939048415, 
Validation Loss: 0.570147302467376
Elapsed time for epoch-24: 3.920367479324341

Epoch: 25, 
Train Loss: 0.9133871867626655, 
Validation Loss: 0.5694258082658052
Elapsed time for epoch-25: 3.9727187156677246

Epoch: 26, 
Train Loss: 0.913141181363779, 
Validation Loss: 0.5630254670977592
Elapsed time for epoch-26: 4.162167310714722

Epoch: 27, 
Train Loss: 0.9131148929605964, 
Validation Loss: 0.5650732973590493
Elapsed time for epoch-27: 3.878762722015381

Epoch: 28, 
Train Loss: 0.9126895894022549, 
Validation Loss: 0.5663324962370098
Elapsed time for epoch-28: 3.6091842651367188

Epoch: 29, 
Train Loss: 0.9123752575461604, 
Validation Loss: 0.5648363730870187
Elapsed time for epoch-29: 3.7964000701904297

Epoch: 30, 
Train Loss: 0.9125179042335317, 
Validation Loss: 0.5650766701437533
Elapsed time for epoch-30: 3.419865369796753

Epoch: 31, 
Train Loss: 0.9123511474673488, 
Validation Loss: 0.5669724023900926
Elapsed time for epoch-31: 3.4097766876220703

train line101: min loss for the epoch 31 is 0.5595587291754782

Training the 39-th turbine in 228.9493658542633 secs

>>>>>>>>> Training Turbine  40 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.0116255283355713
lalalalalal
260 [[ 1.          0.40902512 -0.05312955 -0.35574634  0.39588692]
 [ 0.99904822  0.09190963 -0.09542811  0.56810483 -0.03673123]
 [ 0.9961947  -0.01379553 -0.12946524  0.55960182 -0.12702618]
 [ 0.99144486 -0.08841093 -0.17242473  0.55024852 -0.20037786]
 [ 0.98480775 -0.05110323 -0.19423492  0.54259582 -0.16554618]]
hahahahahahah
265 [[ 0.99985184  1.          0.40902512 -0.05312955 -0.35574634  0.39588692]
 [ 0.99985184  0.99904822  0.09190963 -0.09542811  0.56810483 -0.03673123]
 [ 0.99985184  0.9961947  -0.01379553 -0.12946524  0.55960182 -0.12702618]
 [ 0.99985184  0.99144486 -0.08841093 -0.17242473  0.55024852 -0.20037786]
 [ 0.99985184  0.98480775 -0.05110323 -0.19423492  0.54259582 -0.16554618]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.40902512 -0.05312955 -0.35574634  0.39588692]
 [ 0.99985184  0.99904822  0.09190963 -0.09542811  0.56810483 -0.03673123]
 [ 0.99985184  0.9961947  -0.01379553 -0.12946524  0.55960182 -0.12702618]
 [ 0.99985184  0.99144486 -0.08841093 -0.17242473  0.55024852 -0.20037786]
 [ 0.99985184  0.98480775 -0.05110323 -0.19423492  0.54259582 -0.16554618]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.054208278656006
lalalalalal
260 [[ 1.          0.04216603  0.07079204 -2.07845453  0.04408932]
 [ 0.99904822  0.04838398  0.15109322 -2.08398148  0.07271999]
 [ 0.9961947  -0.17546224  0.1107774  -2.09248448 -0.10261404]
 [ 0.99144486 -0.0044686   0.07277478 -2.09248448  0.06591963]
 [ 0.98480775  0.10123656  0.06847883 -2.09248448  0.2930747 ]]
hahahahahahah
265 [[-0.84754092  1.          0.04216603  0.07079204 -2.07845453  0.04408932]
 [-0.84754092  0.99904822  0.04838398  0.15109322 -2.08398148  0.07271999]
 [-0.84754092  0.9961947  -0.17546224  0.1107774  -2.09248448 -0.10261404]
 [-0.84754092  0.99144486 -0.0044686   0.07277478 -2.09248448  0.06591963]
 [-0.84754092  0.98480775  0.10123656  0.06847883 -2.09248448  0.2930747 ]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.04216603  0.07079204 -2.07845453  0.04408932]
 [-0.84754092  0.99904822  0.04838398  0.15109322 -2.08398148  0.07271999]
 [-0.84754092  0.9961947  -0.17546224  0.1107774  -2.09248448 -0.10261404]
 [-0.84754092  0.99144486 -0.0044686   0.07277478 -2.09248448  0.06591963]
 [-0.84754092  0.98480775  0.10123656  0.06847883 -2.09248448  0.2930747 ]]

Epoch: 0, 
Train Loss: 1.013342701086477, 
Validation Loss: 0.6779867988079786
Elapsed time for epoch-0: 3.014625310897827
common line69: model saved with val loss 0.6779867988079786

Epoch: 1, 
Train Loss: 0.9811732541112339, 
Validation Loss: 0.616896465420723
Elapsed time for epoch-1: 3.1101503372192383
common line69: model saved with val loss 0.616896465420723

Epoch: 2, 
Train Loss: 0.9584875368520993, 
Validation Loss: 0.60933817923069
Elapsed time for epoch-2: 3.220371723175049
common line69: model saved with val loss 0.60933817923069

Epoch: 3, 
Train Loss: 0.9509475998768285, 
Validation Loss: 0.6053672763518989
Elapsed time for epoch-3: 2.988948345184326
common line69: model saved with val loss 0.6053672763518989

Epoch: 4, 
Train Loss: 0.9463612418465254, 
Validation Loss: 0.6047779694199562
Elapsed time for epoch-4: 3.3017098903656006
common line69: model saved with val loss 0.6047779694199562

Epoch: 5, 
Train Loss: 0.9423402870903496, 
Validation Loss: 0.604047407861799
Elapsed time for epoch-5: 3.0515830516815186
common line69: model saved with val loss 0.604047407861799

Epoch: 6, 
Train Loss: 0.9395666821163242, 
Validation Loss: 0.602347893640399
Elapsed time for epoch-6: 3.2068045139312744
common line69: model saved with val loss 0.602347893640399

Epoch: 7, 
Train Loss: 0.9373154631432365, 
Validation Loss: 0.6053312192671001
Elapsed time for epoch-7: 3.2912685871124268

Epoch: 8, 
Train Loss: 0.9349521796743409, 
Validation Loss: 0.5995292775332928
Elapsed time for epoch-8: 3.0184526443481445
common line69: model saved with val loss 0.5995292775332928

Epoch: 9, 
Train Loss: 0.9326804751107672, 
Validation Loss: 0.6000361265614629
Elapsed time for epoch-9: 3.2434942722320557

Epoch: 10, 
Train Loss: 0.9306487459845904, 
Validation Loss: 0.6014870437793434
Elapsed time for epoch-10: 3.9851267337799072

Epoch: 11, 
Train Loss: 0.9284619863043312, 
Validation Loss: 0.5993393673561513
Elapsed time for epoch-11: 4.717781066894531
common line69: model saved with val loss 0.5993393673561513

Epoch: 12, 
Train Loss: 0.9270691119071817, 
Validation Loss: 0.6002051974646747
Elapsed time for epoch-12: 4.406123399734497

Epoch: 13, 
Train Loss: 0.9259764237814591, 
Validation Loss: 0.5994152501225471
Elapsed time for epoch-13: 5.250243425369263

Epoch: 14, 
Train Loss: 0.9248230155526089, 
Validation Loss: 0.600763238966465
Elapsed time for epoch-14: 3.992685556411743

Epoch: 15, 
Train Loss: 0.9240699330297839, 
Validation Loss: 0.5978847513906658
Elapsed time for epoch-15: 4.133184194564819
common line69: model saved with val loss 0.5978847513906658

Epoch: 16, 
Train Loss: 0.9230677134850446, 
Validation Loss: 0.596472105011344
Elapsed time for epoch-16: 4.8649396896362305
common line69: model saved with val loss 0.596472105011344

Epoch: 17, 
Train Loss: 0.9226323463836638, 
Validation Loss: 0.5850952006876469
Elapsed time for epoch-17: 4.783504247665405
common line69: model saved with val loss 0.5850952006876469

Epoch: 18, 
Train Loss: 0.9222497967611841, 
Validation Loss: 0.5993443760089576
Elapsed time for epoch-18: 4.793383359909058

Epoch: 19, 
Train Loss: 0.9216243404300273, 
Validation Loss: 0.5925857117399573
Elapsed time for epoch-19: 4.362711668014526

Epoch: 20, 
Train Loss: 0.9209663742730597, 
Validation Loss: 0.5887799402698874
Elapsed time for epoch-20: 4.275360107421875

Epoch: 21, 
Train Loss: 0.9206573264438564, 
Validation Loss: 0.5970835662446916
Elapsed time for epoch-21: 4.391797065734863

Epoch: 22, 
Train Loss: 0.920568846103524, 
Validation Loss: 0.589253201149404
Elapsed time for epoch-22: 4.218107223510742

Epoch: 23, 
Train Loss: 0.9201165912281565, 
Validation Loss: 0.5886249807663262
Elapsed time for epoch-23: 3.817924976348877

Epoch: 24, 
Train Loss: 0.9198120816164658, 
Validation Loss: 0.5923828487284482
Elapsed time for epoch-24: 3.634882926940918

Epoch: 25, 
Train Loss: 0.9196496074940977, 
Validation Loss: 0.5947794341482222
Elapsed time for epoch-25: 3.8872897624969482

Epoch: 26, 
Train Loss: 0.9193202927082527, 
Validation Loss: 0.5941827693022788
Elapsed time for epoch-26: 4.06412935256958

Epoch: 27, 
Train Loss: 0.919226292927726, 
Validation Loss: 0.5988275539129972
Elapsed time for epoch-27: 4.312575578689575

Epoch: 28, 
Train Loss: 0.9191079956142842, 
Validation Loss: 0.5948100062087178
Elapsed time for epoch-28: 3.6066343784332275

Epoch: 29, 
Train Loss: 0.918941704165034, 
Validation Loss: 0.5888398080132902
Elapsed time for epoch-29: 4.208993434906006
Early stopped! 

train line101: min loss for the epoch 29 is 0.5850952006876469

Training the 40-th turbine in 213.10882377624512 secs

>>>>>>>>> Training Turbine  41 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.768885374069214
lalalalalal
260 [[ 1.          0.19844425 -0.07716641 -0.37097641  0.39480688]
 [ 0.99904822  0.07863992 -0.08963015  0.41442283 -0.14873364]
 [ 0.9961947   0.04688455 -0.09991274  0.41219632 -0.17165801]
 [ 0.99144486 -0.03394729 -0.17344881  0.40496018 -0.26938336]
 [ 0.98480775 -0.0628158  -0.19588354  0.40217706 -0.28888654]]
hahahahahahah
265 [[ 0.99985184  1.          0.19844425 -0.07716641 -0.37097641  0.39480688]
 [ 0.99985184  0.99904822  0.07863992 -0.08963015  0.41442283 -0.14873364]
 [ 0.99985184  0.9961947   0.04688455 -0.09991274  0.41219632 -0.17165801]
 [ 0.99985184  0.99144486 -0.03394729 -0.17344881  0.40496018 -0.26938336]
 [ 0.99985184  0.98480775 -0.0628158  -0.19588354  0.40217706 -0.28888654]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.19844425 -0.07716641 -0.37097641  0.39480688]
 [ 0.99985184  0.99904822  0.07863992 -0.08963015  0.41442283 -0.14873364]
 [ 0.99985184  0.9961947   0.04688455 -0.09991274  0.41219632 -0.17165801]
 [ 0.99985184  0.99144486 -0.03394729 -0.17344881  0.40496018 -0.26938336]
 [ 0.99985184  0.98480775 -0.0628158  -0.19588354  0.40217706 -0.28888654]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.8155362606048584
lalalalalal
260 [[ 1.         -0.09457116 -0.06189833 -1.29247069 -0.09435515]
 [ 0.99904822 -0.14653449 -0.21862987 -1.29664539 -0.14978094]
 [ 0.9961947  -0.2879902  -0.21582553 -1.29942852 -0.28143902]
 [ 0.99144486 -0.1638556  -0.26194137 -1.3010984  -0.18645995]
 [ 0.98480775  0.13349009 -0.18466618 -1.30388153  0.14502424]]
hahahahahahah
265 [[-0.84754092  1.         -0.09457116 -0.06189833 -1.29247069 -0.09435515]
 [-0.84754092  0.99904822 -0.14653449 -0.21862987 -1.29664539 -0.14978094]
 [-0.84754092  0.9961947  -0.2879902  -0.21582553 -1.29942852 -0.28143902]
 [-0.84754092  0.99144486 -0.1638556  -0.26194137 -1.3010984  -0.18645995]
 [-0.84754092  0.98480775  0.13349009 -0.18466618 -1.30388153  0.14502424]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.09457116 -0.06189833 -1.29247069 -0.09435515]
 [-0.84754092  0.99904822 -0.14653449 -0.21862987 -1.29664539 -0.14978094]
 [-0.84754092  0.9961947  -0.2879902  -0.21582553 -1.29942852 -0.28143902]
 [-0.84754092  0.99144486 -0.1638556  -0.26194137 -1.3010984  -0.18645995]
 [-0.84754092  0.98480775  0.13349009 -0.18466618 -1.30388153  0.14502424]]

Epoch: 0, 
Train Loss: 1.003083211909823, 
Validation Loss: 0.6669882871210575
Elapsed time for epoch-0: 3.351370096206665
common line69: model saved with val loss 0.6669882871210575

Epoch: 1, 
Train Loss: 0.9562992292041538, 
Validation Loss: 0.5969059760682285
Elapsed time for epoch-1: 3.449521780014038
common line69: model saved with val loss 0.5969059760682285

Epoch: 2, 
Train Loss: 0.9410355134921915, 
Validation Loss: 0.5868106195703149
Elapsed time for epoch-2: 3.070371150970459
common line69: model saved with val loss 0.5868106195703149

Epoch: 3, 
Train Loss: 0.9351629028801157, 
Validation Loss: 0.5752666387706995
Elapsed time for epoch-3: 2.640704393386841
common line69: model saved with val loss 0.5752666387706995

Epoch: 4, 
Train Loss: 0.9310699668752045, 
Validation Loss: 0.5777119644917548
Elapsed time for epoch-4: 2.6343834400177

Epoch: 5, 
Train Loss: 0.9287725735862716, 
Validation Loss: 0.573115682695061
Elapsed time for epoch-5: 3.017296552658081
common line69: model saved with val loss 0.573115682695061

Epoch: 6, 
Train Loss: 0.9261544383123141, 
Validation Loss: 0.5771657060831785
Elapsed time for epoch-6: 2.781445264816284

Epoch: 7, 
Train Loss: 0.9248162024662274, 
Validation Loss: 0.5704734874889255
Elapsed time for epoch-7: 2.9260549545288086
common line69: model saved with val loss 0.5704734874889255

Epoch: 8, 
Train Loss: 0.9233203043206399, 
Validation Loss: 0.5606226143427193
Elapsed time for epoch-8: 3.376508951187134
common line69: model saved with val loss 0.5606226143427193

Epoch: 9, 
Train Loss: 0.9222137721396294, 
Validation Loss: 0.5650674165226519
Elapsed time for epoch-9: 3.7514054775238037

Epoch: 10, 
Train Loss: 0.9210686093869329, 
Validation Loss: 0.5599398873746395
Elapsed time for epoch-10: 3.174480438232422
common line69: model saved with val loss 0.5599398873746395

Epoch: 11, 
Train Loss: 0.9198481808690464, 
Validation Loss: 0.5566986040212214
Elapsed time for epoch-11: 3.3913872241973877
common line69: model saved with val loss 0.5566986040212214

Epoch: 12, 
Train Loss: 0.9192348405593583, 
Validation Loss: 0.5611810083501041
Elapsed time for epoch-12: 3.890669584274292

Epoch: 13, 
Train Loss: 0.9178398744899685, 
Validation Loss: 0.56520508043468
Elapsed time for epoch-13: 3.8780479431152344

Epoch: 14, 
Train Loss: 0.9171790744827575, 
Validation Loss: 0.5619814894162118
Elapsed time for epoch-14: 3.9336578845977783

Epoch: 15, 
Train Loss: 0.9165798530859106, 
Validation Loss: 0.5562243228778243
Elapsed time for epoch-15: 4.797600746154785
common line69: model saved with val loss 0.5562243228778243

Epoch: 16, 
Train Loss: 0.9158028102472049, 
Validation Loss: 0.5542938993312418
Elapsed time for epoch-16: 3.8974390029907227
common line69: model saved with val loss 0.5542938993312418

Epoch: 17, 
Train Loss: 0.9149613284012851, 
Validation Loss: 0.5541791026480496
Elapsed time for epoch-17: 4.580528259277344
common line69: model saved with val loss 0.5541791026480496

Epoch: 18, 
Train Loss: 0.9142728662040053, 
Validation Loss: 0.5530266016721725
Elapsed time for epoch-18: 3.4115235805511475
common line69: model saved with val loss 0.5530266016721725

Epoch: 19, 
Train Loss: 0.9137390562716652, 
Validation Loss: 0.5557122398167849
Elapsed time for epoch-19: 3.8685762882232666

Epoch: 20, 
Train Loss: 0.9131211388010939, 
Validation Loss: 0.5549582387320697
Elapsed time for epoch-20: 3.941850423812866

Epoch: 21, 
Train Loss: 0.9122639095582882, 
Validation Loss: 0.5505661056376994
Elapsed time for epoch-21: 4.228719234466553
common line69: model saved with val loss 0.5505661056376994

Epoch: 22, 
Train Loss: 0.9117533410547161, 
Validation Loss: 0.5532557582482696
Elapsed time for epoch-22: 3.9085400104522705

Epoch: 23, 
Train Loss: 0.9112861368085156, 
Validation Loss: 0.5497202426195145
Elapsed time for epoch-23: 3.5706684589385986
common line69: model saved with val loss 0.5497202426195145

Epoch: 24, 
Train Loss: 0.9106296423603507, 
Validation Loss: 0.5537869404070079
Elapsed time for epoch-24: 4.41672945022583

Epoch: 25, 
Train Loss: 0.9100111755503326, 
Validation Loss: 0.5484475321136415
Elapsed time for epoch-25: 5.116980791091919
common line69: model saved with val loss 0.5484475321136415

Epoch: 26, 
Train Loss: 0.9096466547050396, 
Validation Loss: 0.5520460321567953
Elapsed time for epoch-26: 5.198248624801636

Epoch: 27, 
Train Loss: 0.908894363446396, 
Validation Loss: 0.5469993781298399
Elapsed time for epoch-27: 4.7853662967681885
common line69: model saved with val loss 0.5469993781298399

Epoch: 28, 
Train Loss: 0.9083412497484383, 
Validation Loss: 0.5456451852805912
Elapsed time for epoch-28: 5.009184122085571
common line69: model saved with val loss 0.5456451852805912

Epoch: 29, 
Train Loss: 0.9080450109073094, 
Validation Loss: 0.5387732083909214
Elapsed time for epoch-29: 4.902050018310547
common line69: model saved with val loss 0.5387732083909214

Epoch: 30, 
Train Loss: 0.9075569753386393, 
Validation Loss: 0.540694304741919
Elapsed time for epoch-30: 4.036383152008057

Epoch: 31, 
Train Loss: 0.9071880841956419, 
Validation Loss: 0.5424912832677364
Elapsed time for epoch-31: 3.8880419731140137

train line101: min loss for the epoch 31 is 0.5387732083909214

Training the 41-th turbine in 228.6514015197754 secs

>>>>>>>>> Training Turbine  42 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.3270771503448486
lalalalalal
260 [[ 1.          0.29224593 -0.11072677 -0.64740752  0.52291377]
 [ 0.99904822  0.03030651 -0.21261442  0.40330179 -0.13194908]
 [ 0.9961947  -0.05991706 -0.25468821  0.39905773 -0.1975087 ]
 [ 0.99144486 -0.06573794 -0.30272768  0.39481366 -0.27140297]
 [ 0.98480775 -0.04245444 -0.33726587  0.39117589 -0.24772607]]
hahahahahahah
265 [[ 0.99985184  1.          0.29224593 -0.11072677 -0.64740752  0.52291377]
 [ 0.99985184  0.99904822  0.03030651 -0.21261442  0.40330179 -0.13194908]
 [ 0.99985184  0.9961947  -0.05991706 -0.25468821  0.39905773 -0.1975087 ]
 [ 0.99985184  0.99144486 -0.06573794 -0.30272768  0.39481366 -0.27140297]
 [ 0.99985184  0.98480775 -0.04245444 -0.33726587  0.39117589 -0.24772607]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.29224593 -0.11072677 -0.64740752  0.52291377]
 [ 0.99985184  0.99904822  0.03030651 -0.21261442  0.40330179 -0.13194908]
 [ 0.99985184  0.9961947  -0.05991706 -0.25468821  0.39905773 -0.1975087 ]
 [ 0.99985184  0.99144486 -0.06573794 -0.30272768  0.39481366 -0.27140297]
 [ 0.99985184  0.98480775 -0.04245444 -0.33726587  0.39117589 -0.24772607]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.043776750564575
lalalalalal
260 [[ 1.00000000e+00  1.75828410e-01 -4.36912878e-02 -1.34222163e+00
   2.72420610e-01]
 [ 9.99048222e-01  2.57320672e-01  1.34537110e-02 -1.34889088e+00
   4.17508521e-01]
 [ 9.96194698e-01  2.98066803e-01  3.70024742e-02 -1.38466229e+00
   4.80227846e-01]
 [ 9.91444861e-01  2.83514613e-01 -1.30351399e-03 -1.41861481e+00
   4.63698254e-01]
 [ 9.84807753e-01  3.50454686e-01 -7.72875233e-02 -1.42770924e+00
   5.19409964e-01]]
hahahahahahah
265 [[-8.47540923e-01  1.00000000e+00  1.75828410e-01 -4.36912878e-02
  -1.34222163e+00  2.72420610e-01]
 [-8.47540923e-01  9.99048222e-01  2.57320672e-01  1.34537110e-02
  -1.34889088e+00  4.17508521e-01]
 [-8.47540923e-01  9.96194698e-01  2.98066803e-01  3.70024742e-02
  -1.38466229e+00  4.80227846e-01]
 [-8.47540923e-01  9.91444861e-01  2.83514613e-01 -1.30351399e-03
  -1.41861481e+00  4.63698254e-01]
 [-8.47540923e-01  9.84807753e-01  3.50454686e-01 -7.72875233e-02
  -1.42770924e+00  5.19409964e-01]]

 wind turbine line248 data after normalization: 
 [[-8.47540923e-01  1.00000000e+00  1.75828410e-01 -4.36912878e-02
  -1.34222163e+00  2.72420610e-01]
 [-8.47540923e-01  9.99048222e-01  2.57320672e-01  1.34537110e-02
  -1.34889088e+00  4.17508521e-01]
 [-8.47540923e-01  9.96194698e-01  2.98066803e-01  3.70024742e-02
  -1.38466229e+00  4.80227846e-01]
 [-8.47540923e-01  9.91444861e-01  2.83514613e-01 -1.30351399e-03
  -1.41861481e+00  4.63698254e-01]
 [-8.47540923e-01  9.84807753e-01  3.50454686e-01 -7.72875233e-02
  -1.42770924e+00  5.19409964e-01]]

Epoch: 0, 
Train Loss: 0.9980911045264798, 
Validation Loss: 0.6908399686217308
Elapsed time for epoch-0: 4.082482814788818
common line69: model saved with val loss 0.6908399686217308

Epoch: 1, 
Train Loss: 0.9485186448618144, 
Validation Loss: 0.645175913348794
Elapsed time for epoch-1: 3.7696750164031982
common line69: model saved with val loss 0.645175913348794

Epoch: 2, 
Train Loss: 0.9381158763871473, 
Validation Loss: 0.6419213633053005
Elapsed time for epoch-2: 3.331437826156616
common line69: model saved with val loss 0.6419213633053005

Epoch: 3, 
Train Loss: 0.9330528163108505, 
Validation Loss: 0.6391997784376144
Elapsed time for epoch-3: 3.490264654159546
common line69: model saved with val loss 0.6391997784376144

Epoch: 4, 
Train Loss: 0.9293874010068028, 
Validation Loss: 0.6400415180251002
Elapsed time for epoch-4: 3.1660866737365723

Epoch: 5, 
Train Loss: 0.9266987018475011, 
Validation Loss: 0.6377170318737626
Elapsed time for epoch-5: 3.0319793224334717
common line69: model saved with val loss 0.6377170318737626

Epoch: 6, 
Train Loss: 0.9244353120066539, 
Validation Loss: 0.63515848480165
Elapsed time for epoch-6: 3.116811513900757
common line69: model saved with val loss 0.63515848480165

Epoch: 7, 
Train Loss: 0.9223319151822258, 
Validation Loss: 0.6356685338541865
Elapsed time for epoch-7: 3.0938491821289062

Epoch: 8, 
Train Loss: 0.9206781259604863, 
Validation Loss: 0.6349876499734819
Elapsed time for epoch-8: 3.0664801597595215
common line69: model saved with val loss 0.6349876499734819

Epoch: 9, 
Train Loss: 0.9192623032742188, 
Validation Loss: 0.6373794437386096
Elapsed time for epoch-9: 3.351278066635132

Epoch: 10, 
Train Loss: 0.9176742055085527, 
Validation Loss: 0.6298662493936718
Elapsed time for epoch-10: 4.223424673080444
common line69: model saved with val loss 0.6298662493936718

Epoch: 11, 
Train Loss: 0.9165547061868075, 
Validation Loss: 0.6384551879018545
Elapsed time for epoch-11: 3.5301198959350586

Epoch: 12, 
Train Loss: 0.9154555490788292, 
Validation Loss: 0.6314315246418118
Elapsed time for epoch-12: 3.4106855392456055

Epoch: 13, 
Train Loss: 0.914575468717503, 
Validation Loss: 0.6353085511364043
Elapsed time for epoch-13: 3.910755157470703

Epoch: 14, 
Train Loss: 0.913898376231434, 
Validation Loss: 0.6305336523801088
Elapsed time for epoch-14: 4.599335670471191

Epoch: 15, 
Train Loss: 0.9128204689306372, 
Validation Loss: 0.6247918289154768
Elapsed time for epoch-15: 4.105071067810059
common line69: model saved with val loss 0.6247918289154768

Epoch: 16, 
Train Loss: 0.9124106735992832, 
Validation Loss: 0.626952616032213
Elapsed time for epoch-16: 4.204507827758789

Epoch: 17, 
Train Loss: 0.9118400069595385, 
Validation Loss: 0.626206788700074
Elapsed time for epoch-17: 3.8323092460632324

Epoch: 18, 
Train Loss: 0.9111410975456238, 
Validation Loss: 0.6212170352227986
Elapsed time for epoch-18: 4.430301189422607
common line69: model saved with val loss 0.6212170352227986

Epoch: 19, 
Train Loss: 0.9105477420722737, 
Validation Loss: 0.6251610000617802
Elapsed time for epoch-19: 3.9196841716766357

Epoch: 20, 
Train Loss: 0.910293506599274, 
Validation Loss: 0.6213825764134526
Elapsed time for epoch-20: 3.6834475994110107

Epoch: 21, 
Train Loss: 0.9098023079773959, 
Validation Loss: 0.617420147638768
Elapsed time for epoch-21: 3.8788211345672607
common line69: model saved with val loss 0.617420147638768

Epoch: 22, 
Train Loss: 0.9095172984760349, 
Validation Loss: 0.6214201580733061
Elapsed time for epoch-22: 4.1811347007751465

Epoch: 23, 
Train Loss: 0.9089833183699295, 
Validation Loss: 0.6213336447253823
Elapsed time for epoch-23: 3.7150771617889404

Epoch: 24, 
Train Loss: 0.9086009175086222, 
Validation Loss: 0.6167351012118161
Elapsed time for epoch-24: 4.057988405227661
common line69: model saved with val loss 0.6167351012118161

Epoch: 25, 
Train Loss: 0.9083800864319841, 
Validation Loss: 0.6164909373037517
Elapsed time for epoch-25: 4.062780141830444
common line69: model saved with val loss 0.6164909373037517

Epoch: 26, 
Train Loss: 0.9083389177793214, 
Validation Loss: 0.6169590284116566
Elapsed time for epoch-26: 4.442401170730591

Epoch: 27, 
Train Loss: 0.9079927266144953, 
Validation Loss: 0.6142554529942572
Elapsed time for epoch-27: 3.7702088356018066
common line69: model saved with val loss 0.6142554529942572

Epoch: 28, 
Train Loss: 0.9079379410553379, 
Validation Loss: 0.6192252999171615
Elapsed time for epoch-28: 3.7373225688934326

Epoch: 29, 
Train Loss: 0.9075032622874284, 
Validation Loss: 0.6108384816907346
Elapsed time for epoch-29: 3.563342332839966
common line69: model saved with val loss 0.6108384816907346

Epoch: 30, 
Train Loss: 0.9073419813849345, 
Validation Loss: 0.6146499831229448
Elapsed time for epoch-30: 3.6665430068969727

Epoch: 31, 
Train Loss: 0.907197496470283, 
Validation Loss: 0.6147486800327897
Elapsed time for epoch-31: 4.229488134384155

train line101: min loss for the epoch 31 is 0.6108384816907346

Training the 42-th turbine in 214.428866147995 secs

>>>>>>>>> Training Turbine  43 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.402824640274048
lalalalalal
260 [[ 1.          0.3331273  -0.25965737 -0.71627452  0.43718615]
 [ 0.99904822 -0.04204808 -0.30060536  0.48806923 -0.17235279]
 [ 0.9961947  -0.08724993 -0.37702239  0.47980229 -0.21546276]
 [ 0.99144486 -0.2077882  -0.08288892  0.4745415  -0.26388064]
 [ 0.98480775 -0.17464018 -0.05434068  0.4745415  -0.22056995]]
hahahahahahah
265 [[ 0.99985184  1.          0.3331273  -0.25965737 -0.71627452  0.43718615]
 [ 0.99985184  0.99904822 -0.04204808 -0.30060536  0.48806923 -0.17235279]
 [ 0.99985184  0.9961947  -0.08724993 -0.37702239  0.47980229 -0.21546276]
 [ 0.99985184  0.99144486 -0.2077882  -0.08288892  0.4745415  -0.26388064]
 [ 0.99985184  0.98480775 -0.17464018 -0.05434068  0.4745415  -0.22056995]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.3331273  -0.25965737 -0.71627452  0.43718615]
 [ 0.99985184  0.99904822 -0.04204808 -0.30060536  0.48806923 -0.17235279]
 [ 0.99985184  0.9961947  -0.08724993 -0.37702239  0.47980229 -0.21546276]
 [ 0.99985184  0.99144486 -0.2077882  -0.08288892  0.4745415  -0.26388064]
 [ 0.99985184  0.98480775 -0.17464018 -0.05434068  0.4745415  -0.22056995]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.0262818336486816
lalalalalal
260 [[ 1.          0.18396119 -0.05174538 -1.86274965  0.23385782]
 [ 0.99904822  0.3436744  -0.09874906 -1.86650735  0.40930851]
 [ 0.9961947   0.4340781  -0.15757575 -1.86199811  0.56408515]
 [ 0.99144486  0.38586279 -0.15786412 -1.86876198  0.51856654]
 [ 0.98480775  0.41599736 -0.18756583 -1.86951352  0.51731762]]
hahahahahahah
265 [[-0.84754092  1.          0.18396119 -0.05174538 -1.86274965  0.23385782]
 [-0.84754092  0.99904822  0.3436744  -0.09874906 -1.86650735  0.40930851]
 [-0.84754092  0.9961947   0.4340781  -0.15757575 -1.86199811  0.56408515]
 [-0.84754092  0.99144486  0.38586279 -0.15786412 -1.86876198  0.51856654]
 [-0.84754092  0.98480775  0.41599736 -0.18756583 -1.86951352  0.51731762]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.18396119 -0.05174538 -1.86274965  0.23385782]
 [-0.84754092  0.99904822  0.3436744  -0.09874906 -1.86650735  0.40930851]
 [-0.84754092  0.9961947   0.4340781  -0.15757575 -1.86199811  0.56408515]
 [-0.84754092  0.99144486  0.38586279 -0.15786412 -1.86876198  0.51856654]
 [-0.84754092  0.98480775  0.41599736 -0.18756583 -1.86951352  0.51731762]]

Epoch: 0, 
Train Loss: 0.9844937365846473, 
Validation Loss: 0.6010625781491399
Elapsed time for epoch-0: 3.7798752784729004
common line69: model saved with val loss 0.6010625781491399

Epoch: 1, 
Train Loss: 0.9474845240596964, 
Validation Loss: 0.5938387149944901
Elapsed time for epoch-1: 3.993802309036255
common line69: model saved with val loss 0.5938387149944901

Epoch: 2, 
Train Loss: 0.9393970028442495, 
Validation Loss: 0.5966912885196507
Elapsed time for epoch-2: 3.082843542098999

Epoch: 3, 
Train Loss: 0.9344143356595721, 
Validation Loss: 0.5914198672398925
Elapsed time for epoch-3: 3.1639606952667236
common line69: model saved with val loss 0.5914198672398925

Epoch: 4, 
Train Loss: 0.9307692797244096, 
Validation Loss: 0.5835604919120669
Elapsed time for epoch-4: 2.7617626190185547
common line69: model saved with val loss 0.5835604919120669

Epoch: 5, 
Train Loss: 0.9283261079998577, 
Validation Loss: 0.585643945261836
Elapsed time for epoch-5: 3.2537128925323486

Epoch: 6, 
Train Loss: 0.9263850096143594, 
Validation Loss: 0.5888678729534149
Elapsed time for epoch-6: 2.9682400226593018

Epoch: 7, 
Train Loss: 0.9248324312081858, 
Validation Loss: 0.5813690768554807
Elapsed time for epoch-7: 3.710397481918335
common line69: model saved with val loss 0.5813690768554807

Epoch: 8, 
Train Loss: 0.9234275334522504, 
Validation Loss: 0.581099774222821
Elapsed time for epoch-8: 3.413539409637451
common line69: model saved with val loss 0.581099774222821

Epoch: 9, 
Train Loss: 0.9222539576913128, 
Validation Loss: 0.5781975924037397
Elapsed time for epoch-9: 3.0764694213867188
common line69: model saved with val loss 0.5781975924037397

Epoch: 10, 
Train Loss: 0.9211631020327576, 
Validation Loss: 0.5809516496956348
Elapsed time for epoch-10: 3.5776381492614746

Epoch: 11, 
Train Loss: 0.9199606212748199, 
Validation Loss: 0.5781585834920406
Elapsed time for epoch-11: 3.751514196395874
common line69: model saved with val loss 0.5781585834920406

Epoch: 12, 
Train Loss: 0.9191031501072795, 
Validation Loss: 0.5786375603638589
Elapsed time for epoch-12: 4.2616188526153564

Epoch: 13, 
Train Loss: 0.9179872304451566, 
Validation Loss: 0.5803146245889366
Elapsed time for epoch-13: 3.9125571250915527

Epoch: 14, 
Train Loss: 0.9167925496311748, 
Validation Loss: 0.5751750231720507
Elapsed time for epoch-14: 3.8702375888824463
common line69: model saved with val loss 0.5751750231720507

Epoch: 15, 
Train Loss: 0.9160456274236951, 
Validation Loss: 0.5748873264528811
Elapsed time for epoch-15: 5.3255980014801025
common line69: model saved with val loss 0.5748873264528811

Epoch: 16, 
Train Loss: 0.9153328514149209, 
Validation Loss: 0.5726066292263567
Elapsed time for epoch-16: 4.39994478225708
common line69: model saved with val loss 0.5726066292263567

Epoch: 17, 
Train Loss: 0.9144688077083155, 
Validation Loss: 0.5730215683579445
Elapsed time for epoch-17: 3.554872512817383

Epoch: 18, 
Train Loss: 0.9137315921673254, 
Validation Loss: 0.5726508740335703
Elapsed time for epoch-18: 4.038792371749878

Epoch: 19, 
Train Loss: 0.9132348396697966, 
Validation Loss: 0.5719369761645794
Elapsed time for epoch-19: 3.640336036682129
common line69: model saved with val loss 0.5719369761645794

Epoch: 20, 
Train Loss: 0.9125032273410749, 
Validation Loss: 0.5720738992094994
Elapsed time for epoch-20: 3.6245052814483643

Epoch: 21, 
Train Loss: 0.9119913484118566, 
Validation Loss: 0.5696621057577431
Elapsed time for epoch-21: 3.766407012939453
common line69: model saved with val loss 0.5696621057577431

Epoch: 22, 
Train Loss: 0.9118095739048069, 
Validation Loss: 0.5728916870430112
Elapsed time for epoch-22: 3.826420545578003

Epoch: 23, 
Train Loss: 0.9113328188908201, 
Validation Loss: 0.5661968435160816
Elapsed time for epoch-23: 4.317100524902344
common line69: model saved with val loss 0.5661968435160816

Epoch: 24, 
Train Loss: 0.9109368934100416, 
Validation Loss: 0.56452845223248
Elapsed time for epoch-24: 4.10139799118042
common line69: model saved with val loss 0.56452845223248

Epoch: 25, 
Train Loss: 0.9103434214822385, 
Validation Loss: 0.5654386836104095
Elapsed time for epoch-25: 4.234589576721191

Epoch: 26, 
Train Loss: 0.9101872427874252, 
Validation Loss: 0.5651667769998312
Elapsed time for epoch-26: 4.146223783493042

Epoch: 27, 
Train Loss: 0.909534655699209, 
Validation Loss: 0.562889136839658
Elapsed time for epoch-27: 3.664860248565674
common line69: model saved with val loss 0.562889136839658

Epoch: 28, 
Train Loss: 0.9093252605750781, 
Validation Loss: 0.5646266266703606
Elapsed time for epoch-28: 4.158813714981079

Epoch: 29, 
Train Loss: 0.9091497350390217, 
Validation Loss: 0.5605956227518618
Elapsed time for epoch-29: 4.538850784301758
common line69: model saved with val loss 0.5605956227518618

Epoch: 30, 
Train Loss: 0.9088991065235699, 
Validation Loss: 0.5571202980354428
Elapsed time for epoch-30: 4.7594873905181885
common line69: model saved with val loss 0.5571202980354428

Epoch: 31, 
Train Loss: 0.9085208713507452, 
Validation Loss: 0.5543524473905563
Elapsed time for epoch-31: 3.669579029083252
common line69: model saved with val loss 0.5543524473905563

train line101: min loss for the epoch 31 is 0.5543524473905563

Training the 43-th turbine in 219.71599006652832 secs

>>>>>>>>> Training Turbine  44 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.709702253341675
lalalalalal
260 [[ 1.          0.38045415 -0.11314404 -0.74127968  0.87494179]
 [ 0.99904822  0.14175222 -0.22110723  0.49873337 -0.2435959 ]
 [ 0.9961947   0.08075061 -0.36310041  0.48997003 -0.31884414]
 [ 0.99144486  0.25845094 -0.36171848  0.47974613 -0.15801993]
 [ 0.98480775  0.16031792 -0.31715128  0.47901585 -0.23475707]]
hahahahahahah
265 [[ 0.99985184  1.          0.38045415 -0.11314404 -0.74127968  0.87494179]
 [ 0.99985184  0.99904822  0.14175222 -0.22110723  0.49873337 -0.2435959 ]
 [ 0.99985184  0.9961947   0.08075061 -0.36310041  0.48997003 -0.31884414]
 [ 0.99985184  0.99144486  0.25845094 -0.36171848  0.47974613 -0.15801993]
 [ 0.99985184  0.98480775  0.16031792 -0.31715128  0.47901585 -0.23475707]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.38045415 -0.11314404 -0.74127968  0.87494179]
 [ 0.99985184  0.99904822  0.14175222 -0.22110723  0.49873337 -0.2435959 ]
 [ 0.99985184  0.9961947   0.08075061 -0.36310041  0.48997003 -0.31884414]
 [ 0.99985184  0.99144486  0.25845094 -0.36171848  0.47974613 -0.15801993]
 [ 0.99985184  0.98480775  0.16031792 -0.31715128  0.47901585 -0.23475707]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.9251465797424316
lalalalalal
260 [[ 1.         -0.13938561  0.06184269 -1.74249164  0.07216784]
 [ 0.99904822 -0.38604427  0.08049873 -1.75198526 -0.27975476]
 [ 0.9961947  -0.24547536  0.16341446 -1.75490637 -0.06084004]
 [ 0.99144486 -0.10490644 -0.15442916 -1.76659083  0.03227493]
 [ 0.98480775 -0.11551542  0.08222614 -1.77316334  0.17797386]]
hahahahahahah
265 [[-0.84754092  1.         -0.13938561  0.06184269 -1.74249164  0.07216784]
 [-0.84754092  0.99904822 -0.38604427  0.08049873 -1.75198526 -0.27975476]
 [-0.84754092  0.9961947  -0.24547536  0.16341446 -1.75490637 -0.06084004]
 [-0.84754092  0.99144486 -0.10490644 -0.15442916 -1.76659083  0.03227493]
 [-0.84754092  0.98480775 -0.11551542  0.08222614 -1.77316334  0.17797386]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.13938561  0.06184269 -1.74249164  0.07216784]
 [-0.84754092  0.99904822 -0.38604427  0.08049873 -1.75198526 -0.27975476]
 [-0.84754092  0.9961947  -0.24547536  0.16341446 -1.75490637 -0.06084004]
 [-0.84754092  0.99144486 -0.10490644 -0.15442916 -1.76659083  0.03227493]
 [-0.84754092  0.98480775 -0.11551542  0.08222614 -1.77316334  0.17797386]]

Epoch: 0, 
Train Loss: 0.9847545194275239, 
Validation Loss: 0.9453733395785093
Elapsed time for epoch-0: 3.5875895023345947
common line69: model saved with val loss 0.9453733395785093

Epoch: 1, 
Train Loss: 0.9419918208062148, 
Validation Loss: 0.9082865947857499
Elapsed time for epoch-1: 3.457552671432495
common line69: model saved with val loss 0.9082865947857499

Epoch: 2, 
Train Loss: 0.9316880874523595, 
Validation Loss: 0.8969897916540504
Elapsed time for epoch-2: 3.6476612091064453
common line69: model saved with val loss 0.8969897916540504

Epoch: 3, 
Train Loss: 0.9257353720795206, 
Validation Loss: 0.890420300886035
Elapsed time for epoch-3: 3.334580421447754
common line69: model saved with val loss 0.890420300886035

Epoch: 4, 
Train Loss: 0.9213689606981117, 
Validation Loss: 0.8890862185508013
Elapsed time for epoch-4: 3.3177194595336914
common line69: model saved with val loss 0.8890862185508013

Epoch: 5, 
Train Loss: 0.918254234961101, 
Validation Loss: 0.8825698476284742
Elapsed time for epoch-5: 3.0254366397857666
common line69: model saved with val loss 0.8825698476284742

Epoch: 6, 
Train Loss: 0.9159648988176795, 
Validation Loss: 0.8803423624485731
Elapsed time for epoch-6: 3.1193301677703857
common line69: model saved with val loss 0.8803423624485731

Epoch: 7, 
Train Loss: 0.9144405259304688, 
Validation Loss: 0.882931973785162
Elapsed time for epoch-7: 3.2618489265441895

Epoch: 8, 
Train Loss: 0.912748733864111, 
Validation Loss: 0.8779674889519811
Elapsed time for epoch-8: 3.1217522621154785
common line69: model saved with val loss 0.8779674889519811

Epoch: 9, 
Train Loss: 0.9113401376149234, 
Validation Loss: 0.8756143786013126
Elapsed time for epoch-9: 3.3180153369903564
common line69: model saved with val loss 0.8756143786013126

Epoch: 10, 
Train Loss: 0.9102312189941647, 
Validation Loss: 0.8737679831683636
Elapsed time for epoch-10: 3.046677350997925
common line69: model saved with val loss 0.8737679831683636

Epoch: 11, 
Train Loss: 0.9092361075537545, 
Validation Loss: 0.8741140281781554
Elapsed time for epoch-11: 3.2840182781219482

Epoch: 12, 
Train Loss: 0.908247284528588, 
Validation Loss: 0.8759095072746277
Elapsed time for epoch-12: 3.1513710021972656

Epoch: 13, 
Train Loss: 0.9072334080183205, 
Validation Loss: 0.8795707738026977
Elapsed time for epoch-13: 3.0889248847961426

Epoch: 14, 
Train Loss: 0.906919019187198, 
Validation Loss: 0.8742144415155053
Elapsed time for epoch-14: 3.3253369331359863

Epoch: 15, 
Train Loss: 0.9060131750938272, 
Validation Loss: 0.8774329600855708
Elapsed time for epoch-15: 3.404113292694092

Epoch: 16, 
Train Loss: 0.9051120249914522, 
Validation Loss: 0.8747261697426438
Elapsed time for epoch-16: 4.352057695388794

Epoch: 17, 
Train Loss: 0.9043040592379931, 
Validation Loss: 0.8756160158663988
Elapsed time for epoch-17: 4.37573504447937

Epoch: 18, 
Train Loss: 0.9041012240057232, 
Validation Loss: 0.8779578916728497
Elapsed time for epoch-18: 4.889077663421631

Epoch: 19, 
Train Loss: 0.9035785414841997, 
Validation Loss: 0.8813827885314822
Elapsed time for epoch-19: 4.4419708251953125

Epoch: 20, 
Train Loss: 0.9032716746089839, 
Validation Loss: 0.8786205286160111
Elapsed time for epoch-20: 4.6309685707092285

Epoch: 21, 
Train Loss: 0.9027890774632702, 
Validation Loss: 0.8825781587511301
Elapsed time for epoch-21: 5.482605695724487

Epoch: 22, 
Train Loss: 0.9020883427197192, 
Validation Loss: 0.8798201242461801
Elapsed time for epoch-22: 4.500884532928467
Early stopped! 

train line101: min loss for the epoch 22 is 0.8737679831683636

Training the 44-th turbine in 181.45412826538086 secs

>>>>>>>>> Training Turbine  45 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.335726022720337
lalalalalal
260 [[ 1.          0.02626613 -0.00687465 -0.32712199 -0.11900833]
 [ 0.99904822  0.2149364  -0.04189711  0.33153872  0.04642203]
 [ 0.9961947   0.13833343 -0.2120062   0.32578263  0.00764929]
 [ 0.99144486  0.30856224 -0.17543102  0.32413803  0.15270088]
 [ 0.98480775  0.22061069 -0.11608262  0.32413803  0.06419287]]
hahahahahahah
265 [[ 0.99985184  1.          0.02626613 -0.00687465 -0.32712199 -0.11900833]
 [ 0.99985184  0.99904822  0.2149364  -0.04189711  0.33153872  0.04642203]
 [ 0.99985184  0.9961947   0.13833343 -0.2120062   0.32578263  0.00764929]
 [ 0.99985184  0.99144486  0.30856224 -0.17543102  0.32413803  0.15270088]
 [ 0.99985184  0.98480775  0.22061069 -0.11608262  0.32413803  0.06419287]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.02626613 -0.00687465 -0.32712199 -0.11900833]
 [ 0.99985184  0.99904822  0.2149364  -0.04189711  0.33153872  0.04642203]
 [ 0.99985184  0.9961947   0.13833343 -0.2120062   0.32578263  0.00764929]
 [ 0.99985184  0.99144486  0.30856224 -0.17543102  0.32413803  0.15270088]
 [ 0.99985184  0.98480775  0.22061069 -0.11608262  0.32413803  0.06419287]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.573909044265747
lalalalalal
260 [[ 1.         -0.03898825  0.01055032 -0.9187654  -0.05822975]
 [ 0.99904822 -0.20779848 -0.02119417 -0.92411034 -0.30897169]
 [ 0.9961947  -0.20212419  0.19308118 -0.92945528 -0.20670858]
 [ 0.99144486 -0.13686981  0.17996932 -0.92863298 -0.09207512]
 [ 0.98480775  0.1667049   0.03435869 -0.92822183  0.34635688]]
hahahahahahah
265 [[-0.84754092  1.         -0.03898825  0.01055032 -0.9187654  -0.05822975]
 [-0.84754092  0.99904822 -0.20779848 -0.02119417 -0.92411034 -0.30897169]
 [-0.84754092  0.9961947  -0.20212419  0.19308118 -0.92945528 -0.20670858]
 [-0.84754092  0.99144486 -0.13686981  0.17996932 -0.92863298 -0.09207512]
 [-0.84754092  0.98480775  0.1667049   0.03435869 -0.92822183  0.34635688]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.03898825  0.01055032 -0.9187654  -0.05822975]
 [-0.84754092  0.99904822 -0.20779848 -0.02119417 -0.92411034 -0.30897169]
 [-0.84754092  0.9961947  -0.20212419  0.19308118 -0.92945528 -0.20670858]
 [-0.84754092  0.99144486 -0.13686981  0.17996932 -0.92863298 -0.09207512]
 [-0.84754092  0.98480775  0.1667049   0.03435869 -0.92822183  0.34635688]]

Epoch: 0, 
Train Loss: 0.9835528179126627, 
Validation Loss: 0.8757481463253498
Elapsed time for epoch-0: 4.081690549850464
common line69: model saved with val loss 0.8757481463253498

Epoch: 1, 
Train Loss: 0.9419219711748492, 
Validation Loss: 0.8700171569362283
Elapsed time for epoch-1: 3.745492696762085
common line69: model saved with val loss 0.8700171569362283

Epoch: 2, 
Train Loss: 0.9348959593462343, 
Validation Loss: 0.8666048226878047
Elapsed time for epoch-2: 3.7749578952789307
common line69: model saved with val loss 0.8666048226878047

Epoch: 3, 
Train Loss: 0.9308617620908913, 
Validation Loss: 0.8593491902574897
Elapsed time for epoch-3: 3.7260358333587646
common line69: model saved with val loss 0.8593491902574897

Epoch: 4, 
Train Loss: 0.9280656597443989, 
Validation Loss: 0.8578324411064386
Elapsed time for epoch-4: 3.1948797702789307
common line69: model saved with val loss 0.8578324411064386

Epoch: 5, 
Train Loss: 0.9258595060150162, 
Validation Loss: 0.8551710592582822
Elapsed time for epoch-5: 3.1314520835876465
common line69: model saved with val loss 0.8551710592582822

Epoch: 6, 
Train Loss: 0.92425030006581, 
Validation Loss: 0.8531998069956899
Elapsed time for epoch-6: 3.986952781677246
common line69: model saved with val loss 0.8531998069956899

Epoch: 7, 
Train Loss: 0.9229856512877119, 
Validation Loss: 0.8516724640503526
Elapsed time for epoch-7: 3.6124215126037598
common line69: model saved with val loss 0.8516724640503526

Epoch: 8, 
Train Loss: 0.921562246164354, 
Validation Loss: 0.8547468846663833
Elapsed time for epoch-8: 2.9771554470062256

Epoch: 9, 
Train Loss: 0.9204542819692307, 
Validation Loss: 0.8496293667703867
Elapsed time for epoch-9: 3.095029592514038
common line69: model saved with val loss 0.8496293667703867

Epoch: 10, 
Train Loss: 0.9197166478183089, 
Validation Loss: 0.8514064038172364
Elapsed time for epoch-10: 3.370699882507324

Epoch: 11, 
Train Loss: 0.9188420535886989, 
Validation Loss: 0.8496513180434704
Elapsed time for epoch-11: 3.022603750228882

Epoch: 12, 
Train Loss: 0.9182827477695561, 
Validation Loss: 0.8470835834741592
Elapsed time for epoch-12: 3.351569890975952
common line69: model saved with val loss 0.8470835834741592

Epoch: 13, 
Train Loss: 0.9175145902803966, 
Validation Loss: 0.8466363325715065
Elapsed time for epoch-13: 3.0891971588134766
common line69: model saved with val loss 0.8466363325715065

Epoch: 14, 
Train Loss: 0.9168047628232411, 
Validation Loss: 0.8465962847694755
Elapsed time for epoch-14: 3.3768155574798584
common line69: model saved with val loss 0.8465962847694755

Epoch: 15, 
Train Loss: 0.9159733730704844, 
Validation Loss: 0.8469886519014835
Elapsed time for epoch-15: 3.6123363971710205

Epoch: 16, 
Train Loss: 0.9153049475505572, 
Validation Loss: 0.841731084510684
Elapsed time for epoch-16: 3.3916544914245605
common line69: model saved with val loss 0.841731084510684

Epoch: 17, 
Train Loss: 0.9145854394726393, 
Validation Loss: 0.8448321036994457
Elapsed time for epoch-17: 3.3537790775299072

Epoch: 18, 
Train Loss: 0.9140840137706083, 
Validation Loss: 0.8456362569704652
Elapsed time for epoch-18: 3.5639405250549316

Epoch: 19, 
Train Loss: 0.9137221472103054, 
Validation Loss: 0.8381583159789443
Elapsed time for epoch-19: 2.962042808532715
common line69: model saved with val loss 0.8381583159789443

Epoch: 20, 
Train Loss: 0.9128757266938186, 
Validation Loss: 0.841924705542624
Elapsed time for epoch-20: 3.1995153427124023

Epoch: 21, 
Train Loss: 0.9124376944133213, 
Validation Loss: 0.837306440807879
Elapsed time for epoch-21: 3.2118330001831055
common line69: model saved with val loss 0.837306440807879

Epoch: 22, 
Train Loss: 0.9122125154533306, 
Validation Loss: 0.8405608646571636
Elapsed time for epoch-22: 3.0865519046783447

Epoch: 23, 
Train Loss: 0.9119113864017134, 
Validation Loss: 0.8412055131047964
Elapsed time for epoch-23: 3.6983160972595215

Epoch: 24, 
Train Loss: 0.91143314703172, 
Validation Loss: 0.8382528936490417
Elapsed time for epoch-24: 3.4604623317718506

Epoch: 25, 
Train Loss: 0.9111710344793416, 
Validation Loss: 0.843626206740737
Elapsed time for epoch-25: 3.4732887744903564

Epoch: 26, 
Train Loss: 0.910733617403928, 
Validation Loss: 0.8390309233218431
Elapsed time for epoch-26: 3.5977418422698975

Epoch: 27, 
Train Loss: 0.9103803230183465, 
Validation Loss: 0.8429343104362488
Elapsed time for epoch-27: 3.4053266048431396

Epoch: 28, 
Train Loss: 0.9102955886295864, 
Validation Loss: 0.8395717851817608
Elapsed time for epoch-28: 3.675260305404663

Epoch: 29, 
Train Loss: 0.9099388423086214, 
Validation Loss: 0.8395344410091639
Elapsed time for epoch-29: 3.3907253742218018

Epoch: 30, 
Train Loss: 0.9098073684868693, 
Validation Loss: 0.8438759418204427
Elapsed time for epoch-30: 3.593069553375244

Epoch: 31, 
Train Loss: 0.9093535478625979, 
Validation Loss: 0.8392275730147958
Elapsed time for epoch-31: 3.9726483821868896

train line101: min loss for the epoch 31 is 0.837306440807879

Training the 45-th turbine in 208.32676362991333 secs

>>>>>>>>> Training Turbine  46 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.677229881286621
lalalalalal
260 [[ 1.         -0.04565646 -0.08447547 -0.72471633 -0.13821708]
 [ 0.99904822  0.17609193 -0.12992399  0.48776101  0.025863  ]
 [ 0.9961947   0.10362514 -0.2442445   0.47609205 -0.06250514]
 [ 0.99144486  0.27754544 -0.21942261  0.47171619  0.11751905]
 [ 0.98480775  0.1789906  -0.23445558  0.46734034  0.01041434]]
hahahahahahah
265 [[ 0.99985184  1.         -0.04565646 -0.08447547 -0.72471633 -0.13821708]
 [ 0.99985184  0.99904822  0.17609193 -0.12992399  0.48776101  0.025863  ]
 [ 0.99985184  0.9961947   0.10362514 -0.2442445   0.47609205 -0.06250514]
 [ 0.99985184  0.99144486  0.27754544 -0.21942261  0.47171619  0.11751905]
 [ 0.99985184  0.98480775  0.1789906  -0.23445558  0.46734034  0.01041434]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.04565646 -0.08447547 -0.72471633 -0.13821708]
 [ 0.99985184  0.99904822  0.17609193 -0.12992399  0.48776101  0.025863  ]
 [ 0.99985184  0.9961947   0.10362514 -0.2442445   0.47609205 -0.06250514]
 [ 0.99985184  0.99144486  0.27754544 -0.21942261  0.47171619  0.11751905]
 [ 0.99985184  0.98480775  0.1789906  -0.23445558  0.46734034  0.01041434]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.242465257644653
lalalalalal
260 [[ 1.         -0.29639156 -0.09356518 -1.75632487 -0.17673739]
 [ 0.99904822 -0.4558185  -0.23760202 -1.76361797 -0.3716585 ]
 [ 0.9961947  -0.33697296 -0.0435718  -1.77018175 -0.18904453]
 [ 0.99144486 -0.19203938 -0.14146092 -1.77164037 -0.01170021]
 [ 0.98480775 -0.02101775 -0.0166523  -1.77747485  0.32190977]]
hahahahahahah
265 [[-0.84754092  1.         -0.29639156 -0.09356518 -1.75632487 -0.17673739]
 [-0.84754092  0.99904822 -0.4558185  -0.23760202 -1.76361797 -0.3716585 ]
 [-0.84754092  0.9961947  -0.33697296 -0.0435718  -1.77018175 -0.18904453]
 [-0.84754092  0.99144486 -0.19203938 -0.14146092 -1.77164037 -0.01170021]
 [-0.84754092  0.98480775 -0.02101775 -0.0166523  -1.77747485  0.32190977]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.29639156 -0.09356518 -1.75632487 -0.17673739]
 [-0.84754092  0.99904822 -0.4558185  -0.23760202 -1.76361797 -0.3716585 ]
 [-0.84754092  0.9961947  -0.33697296 -0.0435718  -1.77018175 -0.18904453]
 [-0.84754092  0.99144486 -0.19203938 -0.14146092 -1.77164037 -0.01170021]
 [-0.84754092  0.98480775 -0.02101775 -0.0166523  -1.77747485  0.32190977]]

Epoch: 0, 
Train Loss: 1.007015924243366, 
Validation Loss: 0.8653016053140163
Elapsed time for epoch-0: 4.671356916427612
common line69: model saved with val loss 0.8653016053140163

Epoch: 1, 
Train Loss: 0.9602914313558771, 
Validation Loss: 0.8302640421316028
Elapsed time for epoch-1: 4.267781734466553
common line69: model saved with val loss 0.8302640421316028

Epoch: 2, 
Train Loss: 0.9498515970566693, 
Validation Loss: 0.818555798381567
Elapsed time for epoch-2: 3.802750825881958
common line69: model saved with val loss 0.818555798381567

Epoch: 3, 
Train Loss: 0.9437239767373109, 
Validation Loss: 0.8063033362850547
Elapsed time for epoch-3: 3.450465202331543
common line69: model saved with val loss 0.8063033362850547

Epoch: 4, 
Train Loss: 0.9398599785416066, 
Validation Loss: 0.8116474077105522
Elapsed time for epoch-4: 3.6375060081481934

Epoch: 5, 
Train Loss: 0.9372789192349971, 
Validation Loss: 0.8122973507270217
Elapsed time for epoch-5: 3.4525575637817383

Epoch: 6, 
Train Loss: 0.9354575093553847, 
Validation Loss: 0.8127101808786392
Elapsed time for epoch-6: 3.9964399337768555

Epoch: 7, 
Train Loss: 0.9336645193711048, 
Validation Loss: 0.8026407342404127
Elapsed time for epoch-7: 3.8856699466705322
common line69: model saved with val loss 0.8026407342404127

Epoch: 8, 
Train Loss: 0.932250106535038, 
Validation Loss: 0.8068549269810319
Elapsed time for epoch-8: 3.518763542175293

Epoch: 9, 
Train Loss: 0.9310097690640378, 
Validation Loss: 0.8031817497685552
Elapsed time for epoch-9: 3.742621898651123

Epoch: 10, 
Train Loss: 0.9297128313479304, 
Validation Loss: 0.7992879543453455
Elapsed time for epoch-10: 3.899066925048828
common line69: model saved with val loss 0.7992879543453455

Epoch: 11, 
Train Loss: 0.9289423850904993, 
Validation Loss: 0.8059504944831133
Elapsed time for epoch-11: 4.411206245422363

Epoch: 12, 
Train Loss: 0.9280594894114662, 
Validation Loss: 0.8030408686026931
Elapsed time for epoch-12: 4.352160215377808

Epoch: 13, 
Train Loss: 0.9272057767174825, 
Validation Loss: 0.7969709038734436
Elapsed time for epoch-13: 4.635376214981079
common line69: model saved with val loss 0.7969709038734436

Epoch: 14, 
Train Loss: 0.9264536555073842, 
Validation Loss: 0.7972033210098743
Elapsed time for epoch-14: 3.857407331466675

Epoch: 15, 
Train Loss: 0.9262705891072249, 
Validation Loss: 0.8029259778559208
Elapsed time for epoch-15: 5.115429639816284

Epoch: 16, 
Train Loss: 0.9257616616096818, 
Validation Loss: 0.7983612017706037
Elapsed time for epoch-16: 5.224853038787842

Epoch: 17, 
Train Loss: 0.9253106524213022, 
Validation Loss: 0.7964723007753491
Elapsed time for epoch-17: 3.7398009300231934
common line69: model saved with val loss 0.7964723007753491

Epoch: 18, 
Train Loss: 0.924764255140008, 
Validation Loss: 0.7950444975867867
Elapsed time for epoch-18: 3.330461025238037
common line69: model saved with val loss 0.7950444975867867

Epoch: 19, 
Train Loss: 0.9244969260542333, 
Validation Loss: 0.7953197816386819
Elapsed time for epoch-19: 3.4500555992126465

Epoch: 20, 
Train Loss: 0.9242952034002593, 
Validation Loss: 0.7913971655070782
Elapsed time for epoch-20: 3.2360520362854004
common line69: model saved with val loss 0.7913971655070782

Epoch: 21, 
Train Loss: 0.9238317015291262, 
Validation Loss: 0.7977756904438138
Elapsed time for epoch-21: 3.438363552093506

Epoch: 22, 
Train Loss: 0.9233847323085079, 
Validation Loss: 0.7967753214761615
Elapsed time for epoch-22: 3.895789861679077

Epoch: 23, 
Train Loss: 0.9231188187078267, 
Validation Loss: 0.7961241845041513
Elapsed time for epoch-23: 4.488407850265503

Epoch: 24, 
Train Loss: 0.9232579725129264, 
Validation Loss: 0.7915294384583831
Elapsed time for epoch-24: 3.7774837017059326

Epoch: 25, 
Train Loss: 0.9229271055019203, 
Validation Loss: 0.7968108803033829
Elapsed time for epoch-25: 3.6261045932769775

Epoch: 26, 
Train Loss: 0.9222414442220656, 
Validation Loss: 0.7982539208605886
Elapsed time for epoch-26: 3.3600261211395264

Epoch: 27, 
Train Loss: 0.9222888872653496, 
Validation Loss: 0.796259424649179
Elapsed time for epoch-27: 3.299622058868408

Epoch: 28, 
Train Loss: 0.9221540293773683, 
Validation Loss: 0.7930933265015483
Elapsed time for epoch-28: 3.018132448196411

Epoch: 29, 
Train Loss: 0.921978673388978, 
Validation Loss: 0.7966834092512727
Elapsed time for epoch-29: 3.2140324115753174

Epoch: 30, 
Train Loss: 0.9219489741225203, 
Validation Loss: 0.7953485595062375
Elapsed time for epoch-30: 3.899672508239746

Epoch: 31, 
Train Loss: 0.9215680577424394, 
Validation Loss: 0.7949650594964623
Elapsed time for epoch-31: 4.212348222732544

train line101: min loss for the epoch 31 is 0.7913971655070782

Training the 46-th turbine in 230.56461310386658 secs

>>>>>>>>> Training Turbine  47 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.221847295761108
lalalalalal
260 [[ 1.         -0.01080919 -0.11592756 -0.77920692 -0.13089882]
 [ 0.99904822  0.26573502 -0.31585112  0.43331593 -0.00388173]
 [ 0.9961947   0.16203094 -0.12253373  0.4231236  -0.0055974 ]
 [ 0.99144486  0.31359844  0.05513747  0.42093953  0.19678354]
 [ 0.98480775  0.18596265  0.05235593  0.42093953  0.06250343]]
hahahahahahah
265 [[ 0.99985184  1.         -0.01080919 -0.11592756 -0.77920692 -0.13089882]
 [ 0.99985184  0.99904822  0.26573502 -0.31585112  0.43331593 -0.00388173]
 [ 0.99985184  0.9961947   0.16203094 -0.12253373  0.4231236  -0.0055974 ]
 [ 0.99985184  0.99144486  0.31359844  0.05513747  0.42093953  0.19678354]
 [ 0.99985184  0.98480775  0.18596265  0.05235593  0.42093953  0.06250343]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.01080919 -0.11592756 -0.77920692 -0.13089882]
 [ 0.99985184  0.99904822  0.26573502 -0.31585112  0.43331593 -0.00388173]
 [ 0.99985184  0.9961947   0.16203094 -0.12253373  0.4231236  -0.0055974 ]
 [ 0.99985184  0.99144486  0.31359844  0.05513747  0.42093953  0.19678354]
 [ 0.99985184  0.98480775  0.18596265  0.05235593  0.42093953  0.06250343]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.0533947944641113
lalalalalal
260 [[ 1.         -0.15041084  0.13667152 -1.60150927 -0.17570079]
 [ 0.99904822 -0.32458051  0.12850073 -1.5898609  -0.35870605]
 [ 0.9961947  -0.21821735  0.14658077 -1.56438008 -0.23474286]
 [ 0.99144486 -0.07728617  0.00437427 -1.70052044 -0.05404804]
 [ 0.98480775  0.14607646 -0.15591227 -1.74347382  0.22752842]]
hahahahahahah
265 [[-0.84754092  1.         -0.15041084  0.13667152 -1.60150927 -0.17570079]
 [-0.84754092  0.99904822 -0.32458051  0.12850073 -1.5898609  -0.35870605]
 [-0.84754092  0.9961947  -0.21821735  0.14658077 -1.56438008 -0.23474286]
 [-0.84754092  0.99144486 -0.07728617  0.00437427 -1.70052044 -0.05404804]
 [-0.84754092  0.98480775  0.14607646 -0.15591227 -1.74347382  0.22752842]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.15041084  0.13667152 -1.60150927 -0.17570079]
 [-0.84754092  0.99904822 -0.32458051  0.12850073 -1.5898609  -0.35870605]
 [-0.84754092  0.9961947  -0.21821735  0.14658077 -1.56438008 -0.23474286]
 [-0.84754092  0.99144486 -0.07728617  0.00437427 -1.70052044 -0.05404804]
 [-0.84754092  0.98480775  0.14607646 -0.15591227 -1.74347382  0.22752842]]

Epoch: 0, 
Train Loss: 1.01237413124377, 
Validation Loss: 0.8725496465340257
Elapsed time for epoch-0: 3.4117116928100586
common line69: model saved with val loss 0.8725496465340257

Epoch: 1, 
Train Loss: 0.9678381082891416, 
Validation Loss: 0.800398058257997
Elapsed time for epoch-1: 3.033982515335083
common line69: model saved with val loss 0.800398058257997

Epoch: 2, 
Train Loss: 0.9459854545963913, 
Validation Loss: 0.7909013004973531
Elapsed time for epoch-2: 3.2584428787231445
common line69: model saved with val loss 0.7909013004973531

Epoch: 3, 
Train Loss: 0.9396652459096508, 
Validation Loss: 0.7900593653321266
Elapsed time for epoch-3: 3.318711280822754
common line69: model saved with val loss 0.7900593653321266

Epoch: 4, 
Train Loss: 0.9355616182589731, 
Validation Loss: 0.786969049833715
Elapsed time for epoch-4: 3.4997470378875732
common line69: model saved with val loss 0.786969049833715

Epoch: 5, 
Train Loss: 0.9330050406836662, 
Validation Loss: 0.7857779562473297
Elapsed time for epoch-5: 3.486330270767212
common line69: model saved with val loss 0.7857779562473297

Epoch: 6, 
Train Loss: 0.9310702575104577, 
Validation Loss: 0.7870002640411258
Elapsed time for epoch-6: 3.353534698486328

Epoch: 7, 
Train Loss: 0.929721786820588, 
Validation Loss: 0.7832245519384742
Elapsed time for epoch-7: 3.6710124015808105
common line69: model saved with val loss 0.7832245519384742

Epoch: 8, 
Train Loss: 0.9283579639276537, 
Validation Loss: 0.7883623037487268
Elapsed time for epoch-8: 4.447148323059082

Epoch: 9, 
Train Loss: 0.9272843579284283, 
Validation Loss: 0.7804732723161578
Elapsed time for epoch-9: 3.660358190536499
common line69: model saved with val loss 0.7804732723161578

Epoch: 10, 
Train Loss: 0.926609566732615, 
Validation Loss: 0.7827969454228878
Elapsed time for epoch-10: 3.3507702350616455

Epoch: 11, 
Train Loss: 0.9256621471473149, 
Validation Loss: 0.7795695336535573
Elapsed time for epoch-11: 3.050752639770508
common line69: model saved with val loss 0.7795695336535573

Epoch: 12, 
Train Loss: 0.9250834803370869, 
Validation Loss: 0.7813188163563609
Elapsed time for epoch-12: 3.326138973236084

Epoch: 13, 
Train Loss: 0.924189737113584, 
Validation Loss: 0.7822543326765299
Elapsed time for epoch-13: 3.4787423610687256

Epoch: 14, 
Train Loss: 0.9237624409318972, 
Validation Loss: 0.7797196824103594
Elapsed time for epoch-14: 3.2897846698760986

Epoch: 15, 
Train Loss: 0.9231408565234738, 
Validation Loss: 0.774122865870595
Elapsed time for epoch-15: 3.2609848976135254
common line69: model saved with val loss 0.774122865870595

Epoch: 16, 
Train Loss: 0.9224222410125893, 
Validation Loss: 0.7788694323971868
Elapsed time for epoch-16: 3.191514730453491

Epoch: 17, 
Train Loss: 0.9223045687965986, 
Validation Loss: 0.779044789262116
Elapsed time for epoch-17: 3.330955982208252

Epoch: 18, 
Train Loss: 0.921827714608497, 
Validation Loss: 0.7791555905714631
Elapsed time for epoch-18: 3.2975873947143555

Epoch: 19, 
Train Loss: 0.9213699087375352, 
Validation Loss: 0.7750234538689256
Elapsed time for epoch-19: 3.487264633178711

Epoch: 20, 
Train Loss: 0.9211275407246181, 
Validation Loss: 0.7747601168230176
Elapsed time for epoch-20: 3.3920319080352783

Epoch: 21, 
Train Loss: 0.9205482238981905, 
Validation Loss: 0.7768561039119959
Elapsed time for epoch-21: 4.171284198760986

Epoch: 22, 
Train Loss: 0.9200239048785522, 
Validation Loss: 0.7783625470474362
Elapsed time for epoch-22: 4.480546951293945

Epoch: 23, 
Train Loss: 0.9196786235610978, 
Validation Loss: 0.7792863631621003
Elapsed time for epoch-23: 3.320317029953003

Epoch: 24, 
Train Loss: 0.9193879623873895, 
Validation Loss: 0.7760091526433825
Elapsed time for epoch-24: 3.3739588260650635

Epoch: 25, 
Train Loss: 0.9189215229839838, 
Validation Loss: 0.7762437416240573
Elapsed time for epoch-25: 3.498563289642334

Epoch: 26, 
Train Loss: 0.9187064059391743, 
Validation Loss: 0.7786673586815596
Elapsed time for epoch-26: 3.8777401447296143

Epoch: 27, 
Train Loss: 0.9184153759930315, 
Validation Loss: 0.7747068023309112
Elapsed time for epoch-27: 3.5668346881866455
Early stopped! 

train line101: min loss for the epoch 27 is 0.774122865870595

Training the 47-th turbine in 217.73333191871643 secs

>>>>>>>>> Training Turbine  48 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.436501979827881
lalalalalal
260 [[ 1.         -0.00903407  0.03097888 -0.47162474 -0.08531491]
 [ 0.99904822  0.154944    0.03595976  0.43233031  0.04567935]
 [ 0.9961947   0.11253588 -0.01762764  0.42359644  0.01763451]
 [ 0.99144486  0.24258745 -0.01797115  0.42047721 -0.1246975 ]
 [ 0.98480775  0.10970867 -0.01007045  0.41423873 -0.01056565]]
hahahahahahah
265 [[ 0.99985184  1.         -0.00903407  0.03097888 -0.47162474 -0.08531491]
 [ 0.99985184  0.99904822  0.154944    0.03595976  0.43233031  0.04567935]
 [ 0.99985184  0.9961947   0.11253588 -0.01762764  0.42359644  0.01763451]
 [ 0.99985184  0.99144486  0.24258745 -0.01797115  0.42047721 -0.1246975 ]
 [ 0.99985184  0.98480775  0.10970867 -0.01007045  0.41423873 -0.01056565]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.00903407  0.03097888 -0.47162474 -0.08531491]
 [ 0.99985184  0.99904822  0.154944    0.03595976  0.43233031  0.04567935]
 [ 0.99985184  0.9961947   0.11253588 -0.01762764  0.42359644  0.01763451]
 [ 0.99985184  0.99144486  0.24258745 -0.01797115  0.42047721 -0.1246975 ]
 [ 0.99985184  0.98480775  0.10970867 -0.01007045  0.41423873 -0.01056565]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.488649606704712
lalalalalal
260 [[ 1.         -0.15039447  0.01225764 -1.46447805 -0.23654405]
 [ 0.99904822 -0.14474006  0.01569273 -1.46666152 -0.30159743]
 [ 0.9961947  -0.39353437  0.17714195 -1.47352384 -0.33095132]
 [ 0.99144486 -0.17583934  0.16924124 -1.48101001 -0.09092831]
 [ 0.98480775  0.12949913  0.03321169 -1.4847531   0.3887849 ]]
hahahahahahah
265 [[-0.84754092  1.         -0.15039447  0.01225764 -1.46447805 -0.23654405]
 [-0.84754092  0.99904822 -0.14474006  0.01569273 -1.46666152 -0.30159743]
 [-0.84754092  0.9961947  -0.39353437  0.17714195 -1.47352384 -0.33095132]
 [-0.84754092  0.99144486 -0.17583934  0.16924124 -1.48101001 -0.09092831]
 [-0.84754092  0.98480775  0.12949913  0.03321169 -1.4847531   0.3887849 ]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.15039447  0.01225764 -1.46447805 -0.23654405]
 [-0.84754092  0.99904822 -0.14474006  0.01569273 -1.46666152 -0.30159743]
 [-0.84754092  0.9961947  -0.39353437  0.17714195 -1.47352384 -0.33095132]
 [-0.84754092  0.99144486 -0.17583934  0.16924124 -1.48101001 -0.09092831]
 [-0.84754092  0.98480775  0.12949913  0.03321169 -1.4847531   0.3887849 ]]

Epoch: 0, 
Train Loss: 1.0021328390145503, 
Validation Loss: 0.8759819325059652
Elapsed time for epoch-0: 4.2584569454193115
common line69: model saved with val loss 0.8759819325059652

Epoch: 1, 
Train Loss: 0.9542542464342438, 
Validation Loss: 0.8196754204109311
Elapsed time for epoch-1: 3.7455217838287354
common line69: model saved with val loss 0.8196754204109311

Epoch: 2, 
Train Loss: 0.9439470906968878, 
Validation Loss: 0.8121718997135758
Elapsed time for epoch-2: 3.6230247020721436
common line69: model saved with val loss 0.8121718997135758

Epoch: 3, 
Train Loss: 0.9386947108667438, 
Validation Loss: 0.807795736938715
Elapsed time for epoch-3: 3.4643046855926514
common line69: model saved with val loss 0.807795736938715

Epoch: 4, 
Train Loss: 0.9355823206050056, 
Validation Loss: 0.8105665501207113
Elapsed time for epoch-4: 3.504909038543701

Epoch: 5, 
Train Loss: 0.9335642488313323, 
Validation Loss: 0.8096085265278816
Elapsed time for epoch-5: 3.646650791168213

Epoch: 6, 
Train Loss: 0.9314645968314981, 
Validation Loss: 0.815414841286838
Elapsed time for epoch-6: 3.727729558944702

Epoch: 7, 
Train Loss: 0.9299117011182448, 
Validation Loss: 0.8109501972794533
Elapsed time for epoch-7: 3.2992961406707764

Epoch: 8, 
Train Loss: 0.928274408984585, 
Validation Loss: 0.8143199533224106
Elapsed time for epoch-8: 3.655843734741211

Epoch: 9, 
Train Loss: 0.9271913336104706, 
Validation Loss: 0.8135448535904288
Elapsed time for epoch-9: 4.361475467681885

Epoch: 10, 
Train Loss: 0.9260562857409486, 
Validation Loss: 0.8150986153632402
Elapsed time for epoch-10: 4.187300205230713

Epoch: 11, 
Train Loss: 0.9248978208844402, 
Validation Loss: 0.8242772053927183
Elapsed time for epoch-11: 3.5978376865386963

Epoch: 12, 
Train Loss: 0.9243829901478872, 
Validation Loss: 0.8218867126852274
Elapsed time for epoch-12: 3.8678038120269775

Epoch: 13, 
Train Loss: 0.923404091170856, 
Validation Loss: 0.8256185976788402
Elapsed time for epoch-13: 3.515273332595825

Epoch: 14, 
Train Loss: 0.922585737429747, 
Validation Loss: 0.8252551956102252
Elapsed time for epoch-14: 3.367499351501465

Epoch: 15, 
Train Loss: 0.9223639882412278, 
Validation Loss: 0.8228694945573807
Elapsed time for epoch-15: 3.415968894958496
Early stopped! 

train line101: min loss for the epoch 15 is 0.807795736938715

Training the 48-th turbine in 158.203919172287 secs

>>>>>>>>> Training Turbine  49 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.771823883056641
lalalalalal
260 [[ 1.          0.06283291 -0.07764445 -0.71669954  0.03674558]
 [ 0.99904822  0.15229142 -0.11594766  0.50736214  0.09895594]
 [ 0.9961947   0.16094869 -0.18151473  0.50073564  0.11059724]
 [ 0.99144486  0.24752144 -0.16478843  0.49779053  0.25610189]
 [ 0.98480775  0.14074839 -0.21162205  0.49558169  0.06405519]]
hahahahahahah
265 [[ 0.99985184  1.          0.06283291 -0.07764445 -0.71669954  0.03674558]
 [ 0.99985184  0.99904822  0.15229142 -0.11594766  0.50736214  0.09895594]
 [ 0.99985184  0.9961947   0.16094869 -0.18151473  0.50073564  0.11059724]
 [ 0.99985184  0.99144486  0.24752144 -0.16478843  0.49779053  0.25610189]
 [ 0.99985184  0.98480775  0.14074839 -0.21162205  0.49558169  0.06405519]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.06283291 -0.07764445 -0.71669954  0.03674558]
 [ 0.99985184  0.99904822  0.15229142 -0.11594766  0.50736214  0.09895594]
 [ 0.99985184  0.9961947   0.16094869 -0.18151473  0.50073564  0.11059724]
 [ 0.99985184  0.99144486  0.24752144 -0.16478843  0.49779053  0.25610189]
 [ 0.99985184  0.98480775  0.14074839 -0.21162205  0.49558169  0.06405519]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.8836283683776855
lalalalalal
260 [[ 1.         -0.28634385 -0.03900672 -1.76589527 -0.27553282]
 [ 0.99904822 -0.21419989  0.0078269  -1.77141735 -0.25845274]
 [ 0.9961947  -0.39888842  0.17141004 -1.77583501 -0.30140751]
 [ 0.99144486 -0.21708565 -0.17683136 -1.78246151 -0.12505226]
 [ 0.98480775  0.0772617   0.04328664 -1.78540663  0.34775108]]
hahahahahahah
265 [[-0.84754092  1.         -0.28634385 -0.03900672 -1.76589527 -0.27553282]
 [-0.84754092  0.99904822 -0.21419989  0.0078269  -1.77141735 -0.25845274]
 [-0.84754092  0.9961947  -0.39888842  0.17141004 -1.77583501 -0.30140751]
 [-0.84754092  0.99144486 -0.21708565 -0.17683136 -1.78246151 -0.12505226]
 [-0.84754092  0.98480775  0.0772617   0.04328664 -1.78540663  0.34775108]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.28634385 -0.03900672 -1.76589527 -0.27553282]
 [-0.84754092  0.99904822 -0.21419989  0.0078269  -1.77141735 -0.25845274]
 [-0.84754092  0.9961947  -0.39888842  0.17141004 -1.77583501 -0.30140751]
 [-0.84754092  0.99144486 -0.21708565 -0.17683136 -1.78246151 -0.12505226]
 [-0.84754092  0.98480775  0.0772617   0.04328664 -1.78540663  0.34775108]]

Epoch: 0, 
Train Loss: 0.9994076971246415, 
Validation Loss: 0.8808585312217474
Elapsed time for epoch-0: 3.1413414478302
common line69: model saved with val loss 0.8808585312217474

Epoch: 1, 
Train Loss: 0.9553478894864812, 
Validation Loss: 0.8278894554823637
Elapsed time for epoch-1: 3.187086582183838
common line69: model saved with val loss 0.8278894554823637

Epoch: 2, 
Train Loss: 0.9467266706608924, 
Validation Loss: 0.8193476628512144
Elapsed time for epoch-2: 3.3677144050598145
common line69: model saved with val loss 0.8193476628512144

Epoch: 3, 
Train Loss: 0.9419348785857192, 
Validation Loss: 0.8130024541169405
Elapsed time for epoch-3: 3.5064263343811035
common line69: model saved with val loss 0.8130024541169405

Epoch: 4, 
Train Loss: 0.9389857806327964, 
Validation Loss: 0.8148887604475021
Elapsed time for epoch-4: 3.676483154296875

Epoch: 5, 
Train Loss: 0.9367146220277337, 
Validation Loss: 0.8070163065567613
Elapsed time for epoch-5: 3.3410465717315674
common line69: model saved with val loss 0.8070163065567613

Epoch: 6, 
Train Loss: 0.9345774223574069, 
Validation Loss: 0.8030520360916853
Elapsed time for epoch-6: 3.5915603637695312
common line69: model saved with val loss 0.8030520360916853

Epoch: 7, 
Train Loss: 0.9330386940170737, 
Validation Loss: 0.8006229409947991
Elapsed time for epoch-7: 3.3867859840393066
common line69: model saved with val loss 0.8006229409947991

Epoch: 8, 
Train Loss: 0.9320269412353259, 
Validation Loss: 0.8043181011453271
Elapsed time for epoch-8: 3.072627305984497

Epoch: 9, 
Train Loss: 0.9308658962239739, 
Validation Loss: 0.7936178855597973
Elapsed time for epoch-9: 3.651569366455078
common line69: model saved with val loss 0.7936178855597973

Epoch: 10, 
Train Loss: 0.9296874759577903, 
Validation Loss: 0.7975378362461925
Elapsed time for epoch-10: 4.003787040710449

Epoch: 11, 
Train Loss: 0.929007561392143, 
Validation Loss: 0.7984199216589332
Elapsed time for epoch-11: 3.571017265319824

Epoch: 12, 
Train Loss: 0.9282099471873596, 
Validation Loss: 0.7942795436829329
Elapsed time for epoch-12: 3.035938024520874

Epoch: 13, 
Train Loss: 0.9272571412705574, 
Validation Loss: 0.7891772147268057
Elapsed time for epoch-13: 2.751173734664917
common line69: model saved with val loss 0.7891772147268057

Epoch: 14, 
Train Loss: 0.9266533455928835, 
Validation Loss: 0.7905327687039971
Elapsed time for epoch-14: 2.9547529220581055

Epoch: 15, 
Train Loss: 0.9260350886513206, 
Validation Loss: 0.7935389233753085
Elapsed time for epoch-15: 2.9533958435058594

Epoch: 16, 
Train Loss: 0.925452516735101, 
Validation Loss: 0.7906224438920617
Elapsed time for epoch-16: 2.7814698219299316

Epoch: 17, 
Train Loss: 0.9248160156382232, 
Validation Loss: 0.7847878113389015
Elapsed time for epoch-17: 3.027562141418457
common line69: model saved with val loss 0.7847878113389015

Epoch: 18, 
Train Loss: 0.9245420572887949, 
Validation Loss: 0.7855892805382609
Elapsed time for epoch-18: 3.560065269470215

Epoch: 19, 
Train Loss: 0.9239772161265382, 
Validation Loss: 0.7909946301952004
Elapsed time for epoch-19: 3.6959164142608643

Epoch: 20, 
Train Loss: 0.9233825566137538, 
Validation Loss: 0.7836871715262532
Elapsed time for epoch-20: 4.147524833679199
common line69: model saved with val loss 0.7836871715262532

Epoch: 21, 
Train Loss: 0.9231073256550717, 
Validation Loss: 0.786087928339839
Elapsed time for epoch-21: 3.444049119949341

Epoch: 22, 
Train Loss: 0.9230391651141543, 
Validation Loss: 0.7815586812794209
Elapsed time for epoch-22: 4.312740325927734
common line69: model saved with val loss 0.7815586812794209

Epoch: 23, 
Train Loss: 0.9226149176599598, 
Validation Loss: 0.7827602596953511
Elapsed time for epoch-23: 3.62553334236145

Epoch: 24, 
Train Loss: 0.9222649131752864, 
Validation Loss: 0.7836947394534945
Elapsed time for epoch-24: 3.8484947681427

Epoch: 25, 
Train Loss: 0.9221677003788347, 
Validation Loss: 0.7829372109845281
Elapsed time for epoch-25: 3.3193137645721436

Epoch: 26, 
Train Loss: 0.9217951746047044, 
Validation Loss: 0.7826534956693649
Elapsed time for epoch-26: 3.9641692638397217

Epoch: 27, 
Train Loss: 0.9213968211111903, 
Validation Loss: 0.7771577071398497
Elapsed time for epoch-27: 3.7550389766693115
common line69: model saved with val loss 0.7771577071398497

Epoch: 28, 
Train Loss: 0.9212324032012154, 
Validation Loss: 0.7836423013359308
Elapsed time for epoch-28: 3.8886594772338867

Epoch: 29, 
Train Loss: 0.9209326136262477, 
Validation Loss: 0.7834626520052552
Elapsed time for epoch-29: 4.002412796020508

Epoch: 30, 
Train Loss: 0.9208699929363587, 
Validation Loss: 0.7806167025119066
Elapsed time for epoch-30: 4.325606822967529

Epoch: 31, 
Train Loss: 0.9205586404359641, 
Validation Loss: 0.7724873665720224
Elapsed time for epoch-31: 4.317943811416626
common line69: model saved with val loss 0.7724873665720224

train line101: min loss for the epoch 31 is 0.7724873665720224

Training the 49-th turbine in 215.17606258392334 secs

>>>>>>>>> Training Turbine  50 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.360567092895508
lalalalalal
260 [[ 1.          0.12159261 -0.13651974 -0.68074568  0.05351045]
 [ 0.99904822  0.20752477 -0.08819318  0.50991078  0.09608284]
 [ 0.9961947   0.15122439 -0.13332042  0.50301287  0.03158601]
 [ 0.99144486  0.24308291 -0.12961595  0.49611495  0.13572152]
 [ 0.98480775  0.17789299 -0.14645447  0.49611495 -0.02610282]]
hahahahahahah
265 [[ 0.99985184  1.          0.12159261 -0.13651974 -0.68074568  0.05351045]
 [ 0.99985184  0.99904822  0.20752477 -0.08819318  0.50991078  0.09608284]
 [ 0.99985184  0.9961947   0.15122439 -0.13332042  0.50301287  0.03158601]
 [ 0.99985184  0.99144486  0.24308291 -0.12961595  0.49611495  0.13572152]
 [ 0.99985184  0.98480775  0.17789299 -0.14645447  0.49611495 -0.02610282]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.12159261 -0.13651974 -0.68074568  0.05351045]
 [ 0.99985184  0.99904822  0.20752477 -0.08819318  0.50991078  0.09608284]
 [ 0.99985184  0.9961947   0.15122439 -0.13332042  0.50301287  0.03158601]
 [ 0.99985184  0.99144486  0.24308291 -0.12961595  0.49611495  0.13572152]
 [ 0.99985184  0.98480775  0.17789299 -0.14645447  0.49611495 -0.02610282]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.8661398887634277
lalalalalal
260 [[ 1.         -0.27547326 -0.09509698 -1.86105526 -0.30489485]
 [ 0.99904822 -0.23991513 -0.14679124 -1.86986926 -0.26915286]
 [ 0.9961947  -0.27843644  0.0943364  -1.87140213 -0.28986799]
 [ 0.99144486 -0.11249847 -0.04643365 -1.87370144 -0.07389318]
 [ 0.98480775  0.04751315 -0.04609688 -1.87830005  0.1897824 ]]
hahahahahahah
265 [[-0.84754092  1.         -0.27547326 -0.09509698 -1.86105526 -0.30489485]
 [-0.84754092  0.99904822 -0.23991513 -0.14679124 -1.86986926 -0.26915286]
 [-0.84754092  0.9961947  -0.27843644  0.0943364  -1.87140213 -0.28986799]
 [-0.84754092  0.99144486 -0.11249847 -0.04643365 -1.87370144 -0.07389318]
 [-0.84754092  0.98480775  0.04751315 -0.04609688 -1.87830005  0.1897824 ]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.27547326 -0.09509698 -1.86105526 -0.30489485]
 [-0.84754092  0.99904822 -0.23991513 -0.14679124 -1.86986926 -0.26915286]
 [-0.84754092  0.9961947  -0.27843644  0.0943364  -1.87140213 -0.28986799]
 [-0.84754092  0.99144486 -0.11249847 -0.04643365 -1.87370144 -0.07389318]
 [-0.84754092  0.98480775  0.04751315 -0.04609688 -1.87830005  0.1897824 ]]

Epoch: 0, 
Train Loss: 1.0154171494626199, 
Validation Loss: 0.8807234829291701
Elapsed time for epoch-0: 2.983842372894287
common line69: model saved with val loss 0.8807234829291701

Epoch: 1, 
Train Loss: 0.9696930207374717, 
Validation Loss: 0.7869510157033801
Elapsed time for epoch-1: 3.0581748485565186
common line69: model saved with val loss 0.7869510157033801

Epoch: 2, 
Train Loss: 0.9411194453469846, 
Validation Loss: 0.7801899779587984
Elapsed time for epoch-2: 3.2872447967529297
common line69: model saved with val loss 0.7801899779587984

Epoch: 3, 
Train Loss: 0.935113937413993, 
Validation Loss: 0.7847982784733176
Elapsed time for epoch-3: 3.0349550247192383

Epoch: 4, 
Train Loss: 0.9311334719928372, 
Validation Loss: 0.7838772563263774
Elapsed time for epoch-4: 3.238732099533081

Epoch: 5, 
Train Loss: 0.9288115288530078, 
Validation Loss: 0.7799125835299492
Elapsed time for epoch-5: 3.101425886154175
common line69: model saved with val loss 0.7799125835299492

Epoch: 6, 
Train Loss: 0.9270009017792069, 
Validation Loss: 0.7761251609772444
Elapsed time for epoch-6: 3.370431423187256
common line69: model saved with val loss 0.7761251609772444

Epoch: 7, 
Train Loss: 0.9256021123723823, 
Validation Loss: 0.7759094024077058
Elapsed time for epoch-7: 3.195362091064453
common line69: model saved with val loss 0.7759094024077058

Epoch: 8, 
Train Loss: 0.9245035283956207, 
Validation Loss: 0.7769178533926606
Elapsed time for epoch-8: 3.1080780029296875

Epoch: 9, 
Train Loss: 0.9234927188949424, 
Validation Loss: 0.7712495811283588
Elapsed time for epoch-9: 3.386068344116211
common line69: model saved with val loss 0.7712495811283588

Epoch: 10, 
Train Loss: 0.9224451983175358, 
Validation Loss: 0.776877025142312
Elapsed time for epoch-10: 2.8236162662506104

Epoch: 11, 
Train Loss: 0.9216335975572842, 
Validation Loss: 0.7747811712324619
Elapsed time for epoch-11: 3.574552297592163

Epoch: 12, 
Train Loss: 0.9208218492880589, 
Validation Loss: 0.7739173639565706
Elapsed time for epoch-12: 4.051387071609497

Epoch: 13, 
Train Loss: 0.9205216484911302, 
Validation Loss: 0.7664165627211332
Elapsed time for epoch-13: 3.910222053527832
common line69: model saved with val loss 0.7664165627211332

Epoch: 14, 
Train Loss: 0.9200092011890492, 
Validation Loss: 0.7668594000861049
Elapsed time for epoch-14: 3.4379324913024902

Epoch: 15, 
Train Loss: 0.9192726754841685, 
Validation Loss: 0.7679565856233239
Elapsed time for epoch-15: 3.2211503982543945

Epoch: 16, 
Train Loss: 0.9190222264087501, 
Validation Loss: 0.771587023511529
Elapsed time for epoch-16: 2.8364126682281494

Epoch: 17, 
Train Loss: 0.9185904390922114, 
Validation Loss: 0.7662464315071702
Elapsed time for epoch-17: 3.120361328125
common line69: model saved with val loss 0.7662464315071702

Epoch: 18, 
Train Loss: 0.9181856260079295, 
Validation Loss: 0.7674569273367524
Elapsed time for epoch-18: 3.2010860443115234

Epoch: 19, 
Train Loss: 0.917589445324505, 
Validation Loss: 0.7664780784398317
Elapsed time for epoch-19: 3.4495437145233154

Epoch: 20, 
Train Loss: 0.9173693296288242, 
Validation Loss: 0.7680764673277736
Elapsed time for epoch-20: 4.320525169372559

Epoch: 21, 
Train Loss: 0.916929925815398, 
Validation Loss: 0.7602353487163782
Elapsed time for epoch-21: 3.7092928886413574
common line69: model saved with val loss 0.7602353487163782

Epoch: 22, 
Train Loss: 0.9167082826880848, 
Validation Loss: 0.755198678933084
Elapsed time for epoch-22: 3.818640947341919
common line69: model saved with val loss 0.755198678933084

Epoch: 23, 
Train Loss: 0.9163640042563447, 
Validation Loss: 0.7635332550853491
Elapsed time for epoch-23: 3.542121171951294

Epoch: 24, 
Train Loss: 0.9160292664495837, 
Validation Loss: 0.7587156100198627
Elapsed time for epoch-24: 3.8285059928894043

Epoch: 25, 
Train Loss: 0.9156345969238201, 
Validation Loss: 0.7683978453278542
Elapsed time for epoch-25: 3.721801996231079

Epoch: 26, 
Train Loss: 0.9153615912469495, 
Validation Loss: 0.7559176366776228
Elapsed time for epoch-26: 4.306354522705078

Epoch: 27, 
Train Loss: 0.9151384790404504, 
Validation Loss: 0.7573345368728042
Elapsed time for epoch-27: 5.324296474456787

Epoch: 28, 
Train Loss: 0.9149452410325283, 
Validation Loss: 0.7592499731108546
Elapsed time for epoch-28: 4.352966070175171

Epoch: 29, 
Train Loss: 0.9145341712136229, 
Validation Loss: 0.7576869763433933
Elapsed time for epoch-29: 4.762285947799683

Epoch: 30, 
Train Loss: 0.9144881626888484, 
Validation Loss: 0.7584057841449976
Elapsed time for epoch-30: 4.482528209686279

Epoch: 31, 
Train Loss: 0.9140930645355657, 
Validation Loss: 0.7599560655653477
Elapsed time for epoch-31: 4.604768514633179

train line101: min loss for the epoch 31 is 0.755198678933084

Training the 50-th turbine in 210.99574756622314 secs

>>>>>>>>> Training Turbine  51 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.6830742359161377
lalalalalal
260 [[ 1.          0.07772323  0.01939015 -0.55564913  0.06211653]
 [ 0.99904822  0.21909272  0.00368183  0.55548165  0.11294398]
 [ 0.9961947   0.23494724 -0.03665998  0.55353115  0.15304508]
 [ 0.99144486  0.36442584 -0.04737019  0.54832984  0.26381385]
 [ 0.98480775  0.21116546 -0.09985025  0.54767968  0.06134536]]
hahahahahahah
265 [[ 0.99985184  1.          0.07772323  0.01939015 -0.55564913  0.06211653]
 [ 0.99985184  0.99904822  0.21909272  0.00368183  0.55548165  0.11294398]
 [ 0.99985184  0.9961947   0.23494724 -0.03665998  0.55353115  0.15304508]
 [ 0.99985184  0.99144486  0.36442584 -0.04737019  0.54832984  0.26381385]
 [ 0.99985184  0.98480775  0.21116546 -0.09985025  0.54767968  0.06134536]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.07772323  0.01939015 -0.55564913  0.06211653]
 [ 0.99985184  0.99904822  0.21909272  0.00368183  0.55548165  0.11294398]
 [ 0.99985184  0.9961947   0.23494724 -0.03665998  0.55353115  0.15304508]
 [ 0.99985184  0.99144486  0.36442584 -0.04737019  0.54832984  0.26381385]
 [ 0.99985184  0.98480775  0.21116546 -0.09985025  0.54767968  0.06134536]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.8027946949005127
lalalalalal
260 [[ 1.         -0.16405823  0.03259941 -1.48310849 -0.24005555]
 [ 0.99904822 -0.00551301  0.00975095 -1.4866844  -0.14091282]
 [ 0.9961947  -0.26711262  0.24823175 -1.49188571 -0.277107  ]
 [ 0.99144486 -0.19048243  0.14826974 -1.50098801 -0.15741129]
 [ 0.98480775  0.13189285  0.00261081 -1.49773719  0.26486545]]
hahahahahahah
265 [[-0.84754092  1.         -0.16405823  0.03259941 -1.48310849 -0.24005555]
 [-0.84754092  0.99904822 -0.00551301  0.00975095 -1.4866844  -0.14091282]
 [-0.84754092  0.9961947  -0.26711262  0.24823175 -1.49188571 -0.277107  ]
 [-0.84754092  0.99144486 -0.19048243  0.14826974 -1.50098801 -0.15741129]
 [-0.84754092  0.98480775  0.13189285  0.00261081 -1.49773719  0.26486545]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.16405823  0.03259941 -1.48310849 -0.24005555]
 [-0.84754092  0.99904822 -0.00551301  0.00975095 -1.4866844  -0.14091282]
 [-0.84754092  0.9961947  -0.26711262  0.24823175 -1.49188571 -0.277107  ]
 [-0.84754092  0.99144486 -0.19048243  0.14826974 -1.50098801 -0.15741129]
 [-0.84754092  0.98480775  0.13189285  0.00261081 -1.49773719  0.26486545]]

Epoch: 0, 
Train Loss: 1.0226632395461828, 
Validation Loss: 0.507721567992121
Elapsed time for epoch-0: 3.619171380996704
common line69: model saved with val loss 0.507721567992121

Epoch: 1, 
Train Loss: 0.9731233036067305, 
Validation Loss: 0.4726741798222065
Elapsed time for epoch-1: 3.9597837924957275
common line69: model saved with val loss 0.4726741798222065

Epoch: 2, 
Train Loss: 0.9615715380225863, 
Validation Loss: 0.468802941031754
Elapsed time for epoch-2: 3.7858469486236572
common line69: model saved with val loss 0.468802941031754

Epoch: 3, 
Train Loss: 0.9564746928816082, 
Validation Loss: 0.4715175274759531
Elapsed time for epoch-3: 3.4019827842712402

Epoch: 4, 
Train Loss: 0.9530899103950051, 
Validation Loss: 0.4630381525494158
Elapsed time for epoch-4: 3.4893243312835693
common line69: model saved with val loss 0.4630381525494158

Epoch: 5, 
Train Loss: 0.9507051554798078, 
Validation Loss: 0.468047967646271
Elapsed time for epoch-5: 3.2315738201141357

Epoch: 6, 
Train Loss: 0.9484390221974429, 
Validation Loss: 0.4681597906164825
Elapsed time for epoch-6: 3.188683032989502

Epoch: 7, 
Train Loss: 0.9472005637753912, 
Validation Loss: 0.46257211454212666
Elapsed time for epoch-7: 3.5960605144500732
common line69: model saved with val loss 0.46257211454212666

Epoch: 8, 
Train Loss: 0.9464449890020514, 
Validation Loss: 0.4496249444782734
Elapsed time for epoch-8: 4.503119230270386
common line69: model saved with val loss 0.4496249444782734

Epoch: 9, 
Train Loss: 0.9453676325433394, 
Validation Loss: 0.4490736350417137
Elapsed time for epoch-9: 3.606808662414551
common line69: model saved with val loss 0.4490736350417137

Epoch: 10, 
Train Loss: 0.944493415726333, 
Validation Loss: 0.4552153367549181
Elapsed time for epoch-10: 3.6053988933563232

Epoch: 11, 
Train Loss: 0.9435724646103483, 
Validation Loss: 0.4442768092267215
Elapsed time for epoch-11: 3.068622350692749
common line69: model saved with val loss 0.4442768092267215

Epoch: 12, 
Train Loss: 0.9430782505694557, 
Validation Loss: 0.44492265209555626
Elapsed time for epoch-12: 3.083022356033325

Epoch: 13, 
Train Loss: 0.9426930876088744, 
Validation Loss: 0.4374357075430453
Elapsed time for epoch-13: 3.189592123031616
common line69: model saved with val loss 0.4374357075430453

Epoch: 14, 
Train Loss: 0.9417375517742974, 
Validation Loss: 0.4484244082123041
Elapsed time for epoch-14: 3.100896120071411

Epoch: 15, 
Train Loss: 0.9414446740841665, 
Validation Loss: 0.44381766440346837
Elapsed time for epoch-15: 3.5677337646484375

Epoch: 16, 
Train Loss: 0.9408844182220828, 
Validation Loss: 0.4406501562334597
Elapsed time for epoch-16: 4.545616626739502

Epoch: 17, 
Train Loss: 0.9402128366612587, 
Validation Loss: 0.4332981132902205
Elapsed time for epoch-17: 4.255559206008911
common line69: model saved with val loss 0.4332981132902205

Epoch: 18, 
Train Loss: 0.9396372119418713, 
Validation Loss: 0.43085622787475586
Elapsed time for epoch-18: 3.573587417602539
common line69: model saved with val loss 0.43085622787475586

Epoch: 19, 
Train Loss: 0.9392192852096397, 
Validation Loss: 0.43589069601148367
Elapsed time for epoch-19: 3.095651626586914

Epoch: 20, 
Train Loss: 0.9391627744967196, 
Validation Loss: 0.4354997002519667
Elapsed time for epoch-20: 3.179245710372925

Epoch: 21, 
Train Loss: 0.9385955371275669, 
Validation Loss: 0.428422802593559
Elapsed time for epoch-21: 3.3914706707000732
common line69: model saved with val loss 0.428422802593559

Epoch: 22, 
Train Loss: 0.9382689646562609, 
Validation Loss: 0.44148474372923374
Elapsed time for epoch-22: 3.2866647243499756

Epoch: 23, 
Train Loss: 0.937827744529027, 
Validation Loss: 0.4349272302351892
Elapsed time for epoch-23: 3.667550802230835

Epoch: 24, 
Train Loss: 0.93740687450441, 
Validation Loss: 0.4293182697147131
Elapsed time for epoch-24: 3.2086703777313232

Epoch: 25, 
Train Loss: 0.9368859573322184, 
Validation Loss: 0.43528662202879786
Elapsed time for epoch-25: 3.86905574798584

Epoch: 26, 
Train Loss: 0.9365628826267579, 
Validation Loss: 0.43893013056367636
Elapsed time for epoch-26: 3.6413559913635254

Epoch: 27, 
Train Loss: 0.9361515637455868, 
Validation Loss: 0.43827275186777115
Elapsed time for epoch-27: 3.7959485054016113

Epoch: 28, 
Train Loss: 0.9358454804961421, 
Validation Loss: 0.44411105709150434
Elapsed time for epoch-28: 3.9104795455932617

Epoch: 29, 
Train Loss: 0.9358032375824552, 
Validation Loss: 0.44431211007758975
Elapsed time for epoch-29: 3.8976099491119385

Epoch: 30, 
Train Loss: 0.9350961668401205, 
Validation Loss: 0.43397674011066556
Elapsed time for epoch-30: 5.268723249435425

Epoch: 31, 
Train Loss: 0.934977991365585, 
Validation Loss: 0.43649465404450893
Elapsed time for epoch-31: 5.140927076339722

train line101: min loss for the epoch 31 is 0.428422802593559

Training the 51-th turbine in 218.03998184204102 secs

>>>>>>>>> Training Turbine  52 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.406059503555298
lalalalalal
260 [[ 1.          0.21039713 -0.11239953 -0.31148949  0.17135703]
 [ 0.99904822  0.22488782 -0.21035243  0.35893132  0.02171618]
 [ 0.9961947   0.15533249  0.02441599  0.36070024  0.07619511]
 [ 0.99144486  0.20170271  0.01836362  0.3571624   0.10491991]
 [ 0.98480775  0.11475854 -0.03706339  0.3571624  -0.00501979]]
hahahahahahah
265 [[ 0.99985184  1.          0.21039713 -0.11239953 -0.31148949  0.17135703]
 [ 0.99985184  0.99904822  0.22488782 -0.21035243  0.35893132  0.02171618]
 [ 0.99985184  0.9961947   0.15533249  0.02441599  0.36070024  0.07619511]
 [ 0.99985184  0.99144486  0.20170271  0.01836362  0.3571624   0.10491991]
 [ 0.99985184  0.98480775  0.11475854 -0.03706339  0.3571624  -0.00501979]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.21039713 -0.11239953 -0.31148949  0.17135703]
 [ 0.99985184  0.99904822  0.22488782 -0.21035243  0.35893132  0.02171618]
 [ 0.99985184  0.9961947   0.15533249  0.02441599  0.36070024  0.07619511]
 [ 0.99985184  0.99144486  0.20170271  0.01836362  0.3571624   0.10491991]
 [ 0.99985184  0.98480775  0.11475854 -0.03706339  0.3571624  -0.00501979]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.8964834213256836
lalalalalal
260 [[ 1.         -0.00841237  0.07251644 -0.99561943 -0.10263627]
 [ 0.99904822  0.14953621  0.06264152 -0.99783058  0.02463649]
 [ 0.9961947  -0.24750885  0.18719301 -1.00092619 -0.17439792]
 [ 0.99144486 -0.1026019   0.15024167 -1.00490626 -0.09617886]
 [ 0.98480775  0.29154502  0.10978633 -1.00490626  0.36943478]]
hahahahahahah
265 [[-0.84754092  1.         -0.00841237  0.07251644 -0.99561943 -0.10263627]
 [-0.84754092  0.99904822  0.14953621  0.06264152 -0.99783058  0.02463649]
 [-0.84754092  0.9961947  -0.24750885  0.18719301 -1.00092619 -0.17439792]
 [-0.84754092  0.99144486 -0.1026019   0.15024167 -1.00490626 -0.09617886]
 [-0.84754092  0.98480775  0.29154502  0.10978633 -1.00490626  0.36943478]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.00841237  0.07251644 -0.99561943 -0.10263627]
 [-0.84754092  0.99904822  0.14953621  0.06264152 -0.99783058  0.02463649]
 [-0.84754092  0.9961947  -0.24750885  0.18719301 -1.00092619 -0.17439792]
 [-0.84754092  0.99144486 -0.1026019   0.15024167 -1.00490626 -0.09617886]
 [-0.84754092  0.98480775  0.29154502  0.10978633 -1.00490626  0.36943478]]

Epoch: 0, 
Train Loss: 0.9923113602049211, 
Validation Loss: 0.6722240885719657
Elapsed time for epoch-0: 3.511903762817383
common line69: model saved with val loss 0.6722240885719657

Epoch: 1, 
Train Loss: 0.9513642084197838, 
Validation Loss: 0.6550335101783276
Elapsed time for epoch-1: 3.307189702987671
common line69: model saved with val loss 0.6550335101783276

Epoch: 2, 
Train Loss: 0.9395418863336579, 
Validation Loss: 0.6624781987629831
Elapsed time for epoch-2: 3.4323501586914062

Epoch: 3, 
Train Loss: 0.9327657450647915, 
Validation Loss: 0.6525790309533477
Elapsed time for epoch-3: 3.6051695346832275
common line69: model saved with val loss 0.6525790309533477

Epoch: 4, 
Train Loss: 0.9281443282335746, 
Validation Loss: 0.6514981901273131
Elapsed time for epoch-4: 3.999852180480957
common line69: model saved with val loss 0.6514981901273131

Epoch: 5, 
Train Loss: 0.9246730631639978, 
Validation Loss: 0.6510879080742598
Elapsed time for epoch-5: 3.386094808578491
common line69: model saved with val loss 0.6510879080742598

Epoch: 6, 
Train Loss: 0.9224233364357668, 
Validation Loss: 0.651905719190836
Elapsed time for epoch-6: 4.493913173675537

Epoch: 7, 
Train Loss: 0.9205072437013898, 
Validation Loss: 0.6526473122648895
Elapsed time for epoch-7: 4.1487672328948975

Epoch: 8, 
Train Loss: 0.918874908520394, 
Validation Loss: 0.6451167436316609
Elapsed time for epoch-8: 3.126983404159546
common line69: model saved with val loss 0.6451167436316609

Epoch: 9, 
Train Loss: 0.9175419370416834, 
Validation Loss: 0.6453151535242796
Elapsed time for epoch-9: 3.3950514793395996

Epoch: 10, 
Train Loss: 0.916678326720951, 
Validation Loss: 0.6405777633190155
Elapsed time for epoch-10: 3.692368507385254
common line69: model saved with val loss 0.6405777633190155

Epoch: 11, 
Train Loss: 0.9156775036278892, 
Validation Loss: 0.6393208154477179
Elapsed time for epoch-11: 4.228659629821777
common line69: model saved with val loss 0.6393208154477179

Epoch: 12, 
Train Loss: 0.9150187106443053, 
Validation Loss: 0.6452221339568496
Elapsed time for epoch-12: 3.9630818367004395

Epoch: 13, 
Train Loss: 0.9140968501818281, 
Validation Loss: 0.6411877004429698
Elapsed time for epoch-13: 3.3590688705444336

Epoch: 14, 
Train Loss: 0.9137572028807232, 
Validation Loss: 0.6359514780342579
Elapsed time for epoch-14: 3.037818670272827
common line69: model saved with val loss 0.6359514780342579

Epoch: 15, 
Train Loss: 0.9131958767646501, 
Validation Loss: 0.6382295512594283
Elapsed time for epoch-15: 2.9421496391296387

Epoch: 16, 
Train Loss: 0.9125527641853365, 
Validation Loss: 0.6350476006045938
Elapsed time for epoch-16: 3.3937809467315674
common line69: model saved with val loss 0.6350476006045938

Epoch: 17, 
Train Loss: 0.9118423272832101, 
Validation Loss: 0.6369046689942479
Elapsed time for epoch-17: 3.3985321521759033

Epoch: 18, 
Train Loss: 0.9115566447251985, 
Validation Loss: 0.6336470087990165
Elapsed time for epoch-18: 3.225231647491455
common line69: model saved with val loss 0.6336470087990165

Epoch: 19, 
Train Loss: 0.9111083892463636, 
Validation Loss: 0.6332656918093562
Elapsed time for epoch-19: 3.5357701778411865
common line69: model saved with val loss 0.6332656918093562

Epoch: 20, 
Train Loss: 0.9107745551512021, 
Validation Loss: 0.631202660035342
Elapsed time for epoch-20: 3.5305020809173584
common line69: model saved with val loss 0.631202660035342

Epoch: 21, 
Train Loss: 0.9100791726793561, 
Validation Loss: 0.6350488178431988
Elapsed time for epoch-21: 4.0569140911102295

Epoch: 22, 
Train Loss: 0.9097379268217487, 
Validation Loss: 0.6267669936642051
Elapsed time for epoch-22: 4.058803081512451
common line69: model saved with val loss 0.6267669936642051

Epoch: 23, 
Train Loss: 0.9095176236719644, 
Validation Loss: 0.6310336701571941
Elapsed time for epoch-23: 3.985755205154419

Epoch: 24, 
Train Loss: 0.9090557551684499, 
Validation Loss: 0.6262900615110993
Elapsed time for epoch-24: 4.170140504837036
common line69: model saved with val loss 0.6262900615110993

Epoch: 25, 
Train Loss: 0.9087239138218535, 
Validation Loss: 0.6287557501345873
Elapsed time for epoch-25: 4.22200345993042

Epoch: 26, 
Train Loss: 0.9081535815190869, 
Validation Loss: 0.6273868479765952
Elapsed time for epoch-26: 4.075621604919434

Epoch: 27, 
Train Loss: 0.9078835950178259, 
Validation Loss: 0.6265195091255009
Elapsed time for epoch-27: 3.828807830810547

Epoch: 28, 
Train Loss: 0.9071607683636561, 
Validation Loss: 0.6219863789156079
Elapsed time for epoch-28: 3.9053049087524414
common line69: model saved with val loss 0.6219863789156079

Epoch: 29, 
Train Loss: 0.9067856068370723, 
Validation Loss: 0.619007330853492
Elapsed time for epoch-29: 4.564854860305786
common line69: model saved with val loss 0.619007330853492

Epoch: 30, 
Train Loss: 0.906707258910692, 
Validation Loss: 0.6204491876997054
Elapsed time for epoch-30: 4.425323724746704

Epoch: 31, 
Train Loss: 0.9064121749721655, 
Validation Loss: 0.6200177730061114
Elapsed time for epoch-31: 4.10331654548645

train line101: min loss for the epoch 31 is 0.619007330853492

Training the 52-th turbine in 233.26576805114746 secs

>>>>>>>>> Training Turbine  53 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.941929340362549
lalalalalal
260 [[ 1.          0.30798774 -0.16236366 -0.80427007  0.01553351]
 [ 0.99904822  0.29297982 -0.2601083   0.51894508  0.05809418]
 [ 0.9961947   0.24795604 -0.26935211  0.51232533  0.03036907]
 [ 0.99144486  0.33500201 -0.26284721  0.51232533  0.10711107]
 [ 0.98480775  0.15190531 -0.27346046  0.51232533 -0.08772019]]
hahahahahahah
265 [[ 0.99985184  1.          0.30798774 -0.16236366 -0.80427007  0.01553351]
 [ 0.99985184  0.99904822  0.29297982 -0.2601083   0.51894508  0.05809418]
 [ 0.99985184  0.9961947   0.24795604 -0.26935211  0.51232533  0.03036907]
 [ 0.99985184  0.99144486  0.33500201 -0.26284721  0.51232533  0.10711107]
 [ 0.99985184  0.98480775  0.15190531 -0.27346046  0.51232533 -0.08772019]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.30798774 -0.16236366 -0.80427007  0.01553351]
 [ 0.99985184  0.99904822  0.29297982 -0.2601083   0.51894508  0.05809418]
 [ 0.99985184  0.9961947   0.24795604 -0.26935211  0.51232533  0.03036907]
 [ 0.99985184  0.99144486  0.33500201 -0.26284721  0.51232533  0.10711107]
 [ 0.99985184  0.98480775  0.15190531 -0.27346046  0.51232533 -0.08772019]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.7850592136383057
lalalalalal
260 [[ 1.00000000e+00 -1.15235789e-01  6.37671233e-02 -1.80789824e+00
  -1.81140744e-01]
 [ 9.99048222e-01  4.68498198e-02  4.28829784e-02 -1.81562129e+00
  -3.95732874e-02]
 [ 9.96194698e-01 -2.65315056e-01  2.43507714e-01 -1.81709234e+00
  -2.35411894e-01]
 [ 9.91444861e-01 -1.06231033e-01 -4.40772313e-02 -1.82076998e+00
  -1.11759297e-01]
 [ 9.84807753e-01 -1.17554574e-03  4.42524306e-02 -1.81856340e+00
   1.84700151e-01]]
hahahahahahah
265 [[-8.47540923e-01  1.00000000e+00 -1.15235789e-01  6.37671233e-02
  -1.80789824e+00 -1.81140744e-01]
 [-8.47540923e-01  9.99048222e-01  4.68498198e-02  4.28829784e-02
  -1.81562129e+00 -3.95732874e-02]
 [-8.47540923e-01  9.96194698e-01 -2.65315056e-01  2.43507714e-01
  -1.81709234e+00 -2.35411894e-01]
 [-8.47540923e-01  9.91444861e-01 -1.06231033e-01 -4.40772313e-02
  -1.82076998e+00 -1.11759297e-01]
 [-8.47540923e-01  9.84807753e-01 -1.17554574e-03  4.42524306e-02
  -1.81856340e+00  1.84700151e-01]]

 wind turbine line248 data after normalization: 
 [[-8.47540923e-01  1.00000000e+00 -1.15235789e-01  6.37671233e-02
  -1.80789824e+00 -1.81140744e-01]
 [-8.47540923e-01  9.99048222e-01  4.68498198e-02  4.28829784e-02
  -1.81562129e+00 -3.95732874e-02]
 [-8.47540923e-01  9.96194698e-01 -2.65315056e-01  2.43507714e-01
  -1.81709234e+00 -2.35411894e-01]
 [-8.47540923e-01  9.91444861e-01 -1.06231033e-01 -4.40772313e-02
  -1.82076998e+00 -1.11759297e-01]
 [-8.47540923e-01  9.84807753e-01 -1.17554574e-03  4.42524306e-02
  -1.81856340e+00  1.84700151e-01]]

Epoch: 0, 
Train Loss: 0.9739708568619079, 
Validation Loss: 0.7749778544530272
Elapsed time for epoch-0: 3.2541730403900146
common line69: model saved with val loss 0.7749778544530272

Epoch: 1, 
Train Loss: 0.9394609422242942, 
Validation Loss: 0.7500400738790631
Elapsed time for epoch-1: 2.9388959407806396
common line69: model saved with val loss 0.7500400738790631

Epoch: 2, 
Train Loss: 0.9318149332739726, 
Validation Loss: 0.7439505821093917
Elapsed time for epoch-2: 3.2259466648101807
common line69: model saved with val loss 0.7439505821093917

Epoch: 3, 
Train Loss: 0.9267767707840735, 
Validation Loss: 0.73679412715137
Elapsed time for epoch-3: 2.959254741668701
common line69: model saved with val loss 0.73679412715137

Epoch: 4, 
Train Loss: 0.9238126494553911, 
Validation Loss: 0.7384698064997792
Elapsed time for epoch-4: 2.6741697788238525

Epoch: 5, 
Train Loss: 0.920987344589554, 
Validation Loss: 0.7315573645755649
Elapsed time for epoch-5: 3.0939557552337646
common line69: model saved with val loss 0.7315573645755649

Epoch: 6, 
Train Loss: 0.9191954547868055, 
Validation Loss: 0.7353125093504786
Elapsed time for epoch-6: 2.915799379348755

Epoch: 7, 
Train Loss: 0.9175866039610711, 
Validation Loss: 0.727705511264503
Elapsed time for epoch-7: 3.237581968307495
common line69: model saved with val loss 0.727705511264503

Epoch: 8, 
Train Loss: 0.9162492777119163, 
Validation Loss: 0.7316729659214616
Elapsed time for epoch-8: 3.468876361846924

Epoch: 9, 
Train Loss: 0.915071046652914, 
Validation Loss: 0.7281609699130058
Elapsed time for epoch-9: 4.295342206954956

Epoch: 10, 
Train Loss: 0.9141262991338217, 
Validation Loss: 0.7318202266469598
Elapsed time for epoch-10: 4.122231960296631

Epoch: 11, 
Train Loss: 0.9130558068511867, 
Validation Loss: 0.7261581402271986
Elapsed time for epoch-11: 3.6223161220550537
common line69: model saved with val loss 0.7261581402271986

Epoch: 12, 
Train Loss: 0.9125886774864518, 
Validation Loss: 0.7322122734040022
Elapsed time for epoch-12: 4.251618146896362

Epoch: 13, 
Train Loss: 0.9115538866329593, 
Validation Loss: 0.7274551652371883
Elapsed time for epoch-13: 3.5589942932128906

Epoch: 14, 
Train Loss: 0.911222907299755, 
Validation Loss: 0.7296915827319026
Elapsed time for epoch-14: 3.8446691036224365

Epoch: 15, 
Train Loss: 0.9105773211276832, 
Validation Loss: 0.7310258001089096
Elapsed time for epoch-15: 3.6240041255950928

Epoch: 16, 
Train Loss: 0.9102599756056521, 
Validation Loss: 0.7272444469854236
Elapsed time for epoch-16: 3.562471389770508

Epoch: 17, 
Train Loss: 0.9094713280180923, 
Validation Loss: 0.72569022141397
Elapsed time for epoch-17: 3.5026886463165283
common line69: model saved with val loss 0.72569022141397

Epoch: 18, 
Train Loss: 0.9090308991550398, 
Validation Loss: 0.7250981759279966
Elapsed time for epoch-18: 3.219508409500122
common line69: model saved with val loss 0.7250981759279966

Epoch: 19, 
Train Loss: 0.9088437132725194, 
Validation Loss: 0.7250415738672018
Elapsed time for epoch-19: 3.2366671562194824
common line69: model saved with val loss 0.7250415738672018

Epoch: 20, 
Train Loss: 0.9085176072451246, 
Validation Loss: 0.7269458053633571
Elapsed time for epoch-20: 3.225935220718384

Epoch: 21, 
Train Loss: 0.9081102650956947, 
Validation Loss: 0.7283015390858054
Elapsed time for epoch-21: 3.424234390258789

Epoch: 22, 
Train Loss: 0.9076589697799763, 
Validation Loss: 0.7241405332461
Elapsed time for epoch-22: 4.4855797290802
common line69: model saved with val loss 0.7241405332461

Epoch: 23, 
Train Loss: 0.9072637857258821, 
Validation Loss: 0.7257186360657215
Elapsed time for epoch-23: 3.6481094360351562

Epoch: 24, 
Train Loss: 0.9070407296178722, 
Validation Loss: 0.7262075012549758
Elapsed time for epoch-24: 3.9819819927215576

Epoch: 25, 
Train Loss: 0.906921498414849, 
Validation Loss: 0.7251531211659312
Elapsed time for epoch-25: 3.9825639724731445

Epoch: 26, 
Train Loss: 0.9065337556750834, 
Validation Loss: 0.7265595877543092
Elapsed time for epoch-26: 4.0412023067474365

Epoch: 27, 
Train Loss: 0.9064988652948572, 
Validation Loss: 0.7260170681402087
Elapsed time for epoch-27: 4.072066068649292

Epoch: 28, 
Train Loss: 0.9060806560666621, 
Validation Loss: 0.7247810875996947
Elapsed time for epoch-28: 4.175644397735596

Epoch: 29, 
Train Loss: 0.9058079439051011, 
Validation Loss: 0.7205546386539936
Elapsed time for epoch-29: 4.147584438323975
common line69: model saved with val loss 0.7205546386539936

Epoch: 30, 
Train Loss: 0.9055617639497548, 
Validation Loss: 0.7246669763699174
Elapsed time for epoch-30: 4.25986647605896

Epoch: 31, 
Train Loss: 0.905336809258501, 
Validation Loss: 0.7236591149121523
Elapsed time for epoch-31: 4.412046909332275

train line101: min loss for the epoch 31 is 0.7205546386539936

Training the 53-th turbine in 215.72498631477356 secs

>>>>>>>>> Training Turbine  54 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.9276697635650635
lalalalalal
260 [[ 1.          0.23311177 -0.15148331 -0.54873335  0.142069  ]
 [ 0.99904822  0.37714064 -0.29512241  0.45544122  0.05770298]
 [ 0.9961947   0.33349553 -0.28715169  0.45356192  0.02484499]
 [ 0.99144486  0.44406314 -0.30408948  0.45356192  0.13681402]
 [ 0.98480775  0.30439878 -0.3366366   0.45105618 -0.06711157]]
hahahahahahah
265 [[ 0.99985184  1.          0.23311177 -0.15148331 -0.54873335  0.142069  ]
 [ 0.99985184  0.99904822  0.37714064 -0.29512241  0.45544122  0.05770298]
 [ 0.99985184  0.9961947   0.33349553 -0.28715169  0.45356192  0.02484499]
 [ 0.99985184  0.99144486  0.44406314 -0.30408948  0.45356192  0.13681402]
 [ 0.99985184  0.98480775  0.30439878 -0.3366366   0.45105618 -0.06711157]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.23311177 -0.15148331 -0.54873335  0.142069  ]
 [ 0.99985184  0.99904822  0.37714064 -0.29512241  0.45544122  0.05770298]
 [ 0.99985184  0.9961947   0.33349553 -0.28715169  0.45356192  0.02484499]
 [ 0.99985184  0.99144486  0.44406314 -0.30408948  0.45356192  0.13681402]
 [ 0.99985184  0.98480775  0.30439878 -0.3366366   0.45105618 -0.06711157]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.818230152130127
lalalalalal
260 [[ 1.         -0.31245213 -0.05350982 -1.5018535  -0.25094455]
 [ 0.99904822 -0.14369103 -0.08887991 -1.50154029 -0.13667433]
 [ 0.9961947  -0.53940672  0.08581181 -1.51093681 -0.2996133 ]
 [ 0.99144486 -0.37646496  0.05525736 -1.51720115 -0.1256835 ]
 [ 0.98480775 -0.260078   -0.02278932 -1.51970689  0.00735127]]
hahahahahahah
265 [[-0.84754092  1.         -0.31245213 -0.05350982 -1.5018535  -0.25094455]
 [-0.84754092  0.99904822 -0.14369103 -0.08887991 -1.50154029 -0.13667433]
 [-0.84754092  0.9961947  -0.53940672  0.08581181 -1.51093681 -0.2996133 ]
 [-0.84754092  0.99144486 -0.37646496  0.05525736 -1.51720115 -0.1256835 ]
 [-0.84754092  0.98480775 -0.260078   -0.02278932 -1.51970689  0.00735127]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.31245213 -0.05350982 -1.5018535  -0.25094455]
 [-0.84754092  0.99904822 -0.14369103 -0.08887991 -1.50154029 -0.13667433]
 [-0.84754092  0.9961947  -0.53940672  0.08581181 -1.51093681 -0.2996133 ]
 [-0.84754092  0.99144486 -0.37646496  0.05525736 -1.51720115 -0.1256835 ]
 [-0.84754092  0.98480775 -0.260078   -0.02278932 -1.51970689  0.00735127]]

Epoch: 0, 
Train Loss: 1.0171670653239018, 
Validation Loss: 0.822089571505785
Elapsed time for epoch-0: 3.325012683868408
common line69: model saved with val loss 0.822089571505785

Epoch: 1, 
Train Loss: 0.9705902398133478, 
Validation Loss: 0.7509746626019478
Elapsed time for epoch-1: 4.008786201477051
common line69: model saved with val loss 0.7509746626019478

Epoch: 2, 
Train Loss: 0.9507826117156934, 
Validation Loss: 0.7483272291719913
Elapsed time for epoch-2: 3.6261606216430664
common line69: model saved with val loss 0.7483272291719913

Epoch: 3, 
Train Loss: 0.9437561404554784, 
Validation Loss: 0.7482708040624857
Elapsed time for epoch-3: 3.296980619430542
common line69: model saved with val loss 0.7482708040624857

Epoch: 4, 
Train Loss: 0.9394244073318834, 
Validation Loss: 0.7408377081155777
Elapsed time for epoch-4: 3.8427555561065674
common line69: model saved with val loss 0.7408377081155777

Epoch: 5, 
Train Loss: 0.9365702531918758, 
Validation Loss: 0.7431923737749457
Elapsed time for epoch-5: 3.5631814002990723

Epoch: 6, 
Train Loss: 0.9340773170986095, 
Validation Loss: 0.7430092860013247
Elapsed time for epoch-6: 3.1941075325012207

Epoch: 7, 
Train Loss: 0.9317603157598431, 
Validation Loss: 0.7421705201268196
Elapsed time for epoch-7: 3.1102752685546875

Epoch: 8, 
Train Loss: 0.9301030623311756, 
Validation Loss: 0.7387062190100551
Elapsed time for epoch-8: 3.1977579593658447
common line69: model saved with val loss 0.7387062190100551

Epoch: 9, 
Train Loss: 0.9288053353544042, 
Validation Loss: 0.7376090213656425
Elapsed time for epoch-9: 3.4664969444274902
common line69: model saved with val loss 0.7376090213656425

Epoch: 10, 
Train Loss: 0.9274521213369209, 
Validation Loss: 0.7416630638763309
Elapsed time for epoch-10: 3.9055824279785156

Epoch: 11, 
Train Loss: 0.9262458965057084, 
Validation Loss: 0.7408085511997342
Elapsed time for epoch-11: 3.21645450592041

Epoch: 12, 
Train Loss: 0.925471690898182, 
Validation Loss: 0.7340176291763783
Elapsed time for epoch-12: 3.571751594543457
common line69: model saved with val loss 0.7340176291763783

Epoch: 13, 
Train Loss: 0.9247518059085397, 
Validation Loss: 0.7409861022606492
Elapsed time for epoch-13: 3.4359216690063477

Epoch: 14, 
Train Loss: 0.9241830414834142, 
Validation Loss: 0.7413759380578995
Elapsed time for epoch-14: 3.568915605545044

Epoch: 15, 
Train Loss: 0.9235595124108451, 
Validation Loss: 0.7316800523549318
Elapsed time for epoch-15: 4.120207786560059
common line69: model saved with val loss 0.7316800523549318

Epoch: 16, 
Train Loss: 0.9230869551416204, 
Validation Loss: 0.7356729665771127
Elapsed time for epoch-16: 4.564742088317871

Epoch: 17, 
Train Loss: 0.9227159711994043, 
Validation Loss: 0.7337988577783108
Elapsed time for epoch-17: 3.6821913719177246

Epoch: 18, 
Train Loss: 0.9221177217589707, 
Validation Loss: 0.7314228592440486
Elapsed time for epoch-18: 3.3893303871154785
common line69: model saved with val loss 0.7314228592440486

Epoch: 19, 
Train Loss: 0.9219469305346993, 
Validation Loss: 0.7265461413189769
Elapsed time for epoch-19: 3.4196364879608154
common line69: model saved with val loss 0.7265461413189769

Epoch: 20, 
Train Loss: 0.9213684245067484, 
Validation Loss: 0.7275271648541093
Elapsed time for epoch-20: 4.065577030181885

Epoch: 21, 
Train Loss: 0.9211433209291026, 
Validation Loss: 0.7307847244665027
Elapsed time for epoch-21: 3.836812973022461

Epoch: 22, 
Train Loss: 0.9208766943266412, 
Validation Loss: 0.7252406543120742
Elapsed time for epoch-22: 3.7270619869232178
common line69: model saved with val loss 0.7252406543120742

Epoch: 23, 
Train Loss: 0.9204347667073002, 
Validation Loss: 0.7280757501721382
Elapsed time for epoch-23: 3.0260589122772217

Epoch: 24, 
Train Loss: 0.920184917309705, 
Validation Loss: 0.7260421505197883
Elapsed time for epoch-24: 4.5041961669921875

Epoch: 25, 
Train Loss: 0.9199243280567041, 
Validation Loss: 0.7259416757151484
Elapsed time for epoch-25: 4.16886305809021

Epoch: 26, 
Train Loss: 0.9198763825061942, 
Validation Loss: 0.7242823159322143
Elapsed time for epoch-26: 4.324599266052246
common line69: model saved with val loss 0.7242823159322143

Epoch: 27, 
Train Loss: 0.919791997606013, 
Validation Loss: 0.7235641861334443
Elapsed time for epoch-27: 4.0776073932647705
common line69: model saved with val loss 0.7235641861334443

Epoch: 28, 
Train Loss: 0.919320574452897, 
Validation Loss: 0.7257629977539182
Elapsed time for epoch-28: 4.0991246700286865

Epoch: 29, 
Train Loss: 0.9191779638288402, 
Validation Loss: 0.7272359002381563
Elapsed time for epoch-29: 3.729351043701172

Epoch: 30, 
Train Loss: 0.9189083841668457, 
Validation Loss: 0.7226163754239678
Elapsed time for epoch-30: 4.3940324783325195
common line69: model saved with val loss 0.7226163754239678

Epoch: 31, 
Train Loss: 0.9186265105459871, 
Validation Loss: 0.7220688918605447
Elapsed time for epoch-31: 3.755415916442871
common line69: model saved with val loss 0.7220688918605447

train line101: min loss for the epoch 31 is 0.7220688918605447

Training the 54-th turbine in 218.94612574577332 secs

>>>>>>>>> Training Turbine  55 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.415221691131592
lalalalalal
260 [[ 1.          0.32261874 -0.1772745  -0.59101471  0.20579675]
 [ 0.99904822  0.2371913  -0.12704005  0.46862335  0.11912191]
 [ 0.9961947   0.24618366 -0.1379946   0.46294503  0.12583487]
 [ 0.99144486  0.33910473 -0.1404985   0.46294503  0.23267144]
 [ 0.98480775  0.22220403 -0.21843231  0.46168318 -0.02237546]]
hahahahahahah
265 [[ 0.99985184  1.          0.32261874 -0.1772745  -0.59101471  0.20579675]
 [ 0.99985184  0.99904822  0.2371913  -0.12704005  0.46862335  0.11912191]
 [ 0.99985184  0.9961947   0.24618366 -0.1379946   0.46294503  0.12583487]
 [ 0.99985184  0.99144486  0.33910473 -0.1404985   0.46294503  0.23267144]
 [ 0.99985184  0.98480775  0.22220403 -0.21843231  0.46168318 -0.02237546]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.32261874 -0.1772745  -0.59101471  0.20579675]
 [ 0.99985184  0.99904822  0.2371913  -0.12704005  0.46862335  0.11912191]
 [ 0.99985184  0.9961947   0.24618366 -0.1379946   0.46294503  0.12583487]
 [ 0.99985184  0.99144486  0.33910473 -0.1404985   0.46294503  0.23267144]
 [ 0.99985184  0.98480775  0.22220403 -0.21843231  0.46168318 -0.02237546]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.6961395740509033
lalalalalal
260 [[ 1.         -0.40276511 -0.01233024 -1.50995657 -0.30630635]
 [ 0.99904822 -0.41625366  0.15621337 -1.51437304 -0.22593347]
 [ 0.9961947  -0.32033513 -0.00278413 -1.51878951 -0.24746518]
 [ 0.99144486 -0.19444207 -0.08103093 -1.52446783 -0.14761558]
 [ 0.98480775 -0.30834531 -0.1307959  -1.52446783 -0.15903218]]
hahahahahahah
265 [[-0.84754092  1.         -0.40276511 -0.01233024 -1.50995657 -0.30630635]
 [-0.84754092  0.99904822 -0.41625366  0.15621337 -1.51437304 -0.22593347]
 [-0.84754092  0.9961947  -0.32033513 -0.00278413 -1.51878951 -0.24746518]
 [-0.84754092  0.99144486 -0.19444207 -0.08103093 -1.52446783 -0.14761558]
 [-0.84754092  0.98480775 -0.30834531 -0.1307959  -1.52446783 -0.15903218]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.40276511 -0.01233024 -1.50995657 -0.30630635]
 [-0.84754092  0.99904822 -0.41625366  0.15621337 -1.51437304 -0.22593347]
 [-0.84754092  0.9961947  -0.32033513 -0.00278413 -1.51878951 -0.24746518]
 [-0.84754092  0.99144486 -0.19444207 -0.08103093 -1.52446783 -0.14761558]
 [-0.84754092  0.98480775 -0.30834531 -0.1307959  -1.52446783 -0.15903218]]

Epoch: 0, 
Train Loss: 1.0016281001207208, 
Validation Loss: 0.7178900577127934
Elapsed time for epoch-0: 4.016415119171143
common line69: model saved with val loss 0.7178900577127934

Epoch: 1, 
Train Loss: 0.9522894860065284, 
Validation Loss: 0.6817846670746803
Elapsed time for epoch-1: 3.3584330081939697
common line69: model saved with val loss 0.6817846670746803

Epoch: 2, 
Train Loss: 0.9397153398569893, 
Validation Loss: 0.674785740673542
Elapsed time for epoch-2: 3.190361738204956
common line69: model saved with val loss 0.674785740673542

Epoch: 3, 
Train Loss: 0.9337508718506629, 
Validation Loss: 0.6761602833867073
Elapsed time for epoch-3: 3.11869740486145

Epoch: 4, 
Train Loss: 0.9296274605919334, 
Validation Loss: 0.6778113143518567
Elapsed time for epoch-4: 3.297672986984253

Epoch: 5, 
Train Loss: 0.9267086474334493, 
Validation Loss: 0.6749241976067424
Elapsed time for epoch-5: 3.1134541034698486

Epoch: 6, 
Train Loss: 0.9246318888764421, 
Validation Loss: 0.6739939833059907
Elapsed time for epoch-6: 3.1903865337371826
common line69: model saved with val loss 0.6739939833059907

Epoch: 7, 
Train Loss: 0.9232401270575884, 
Validation Loss: 0.6786079294979572
Elapsed time for epoch-7: 3.1582260131835938

Epoch: 8, 
Train Loss: 0.9219155058640391, 
Validation Loss: 0.6730850683525205
Elapsed time for epoch-8: 3.087587594985962
common line69: model saved with val loss 0.6730850683525205

Epoch: 9, 
Train Loss: 0.9205244135956804, 
Validation Loss: 0.6736541213467717
Elapsed time for epoch-9: 3.2582271099090576

Epoch: 10, 
Train Loss: 0.9195145950848315, 
Validation Loss: 0.6666100593283772
Elapsed time for epoch-10: 3.297841787338257
common line69: model saved with val loss 0.6666100593283772

Epoch: 11, 
Train Loss: 0.9188816439704734, 
Validation Loss: 0.6696090893819928
Elapsed time for epoch-11: 3.316359758377075

Epoch: 12, 
Train Loss: 0.918267045702253, 
Validation Loss: 0.6681737955659628
Elapsed time for epoch-12: 3.6006126403808594

Epoch: 13, 
Train Loss: 0.9176813779758806, 
Validation Loss: 0.6720170490443707
Elapsed time for epoch-13: 3.9024605751037598

Epoch: 14, 
Train Loss: 0.9172176222841278, 
Validation Loss: 0.665406197309494
Elapsed time for epoch-14: 3.2777750492095947
common line69: model saved with val loss 0.665406197309494

Epoch: 15, 
Train Loss: 0.9167019366717138, 
Validation Loss: 0.670924331061542
Elapsed time for epoch-15: 2.988558530807495

Epoch: 16, 
Train Loss: 0.9163657172637827, 
Validation Loss: 0.6704536620527506
Elapsed time for epoch-16: 2.7837464809417725

Epoch: 17, 
Train Loss: 0.9159725994623008, 
Validation Loss: 0.6624520178884268
Elapsed time for epoch-17: 2.9424922466278076
common line69: model saved with val loss 0.6624520178884268

Epoch: 18, 
Train Loss: 0.915453307643658, 
Validation Loss: 0.6667441166937351
Elapsed time for epoch-18: 2.955592393875122

Epoch: 19, 
Train Loss: 0.9152098100225464, 
Validation Loss: 0.6649138787761331
Elapsed time for epoch-19: 2.8090765476226807

Epoch: 20, 
Train Loss: 0.9147413319148937, 
Validation Loss: 0.6620024209842086
Elapsed time for epoch-20: 2.987290143966675
common line69: model saved with val loss 0.6620024209842086

Epoch: 21, 
Train Loss: 0.9147795054341564, 
Validation Loss: 0.6677528759464622
Elapsed time for epoch-21: 2.690938949584961

Epoch: 22, 
Train Loss: 0.9143753381085997, 
Validation Loss: 0.6608171500265598
Elapsed time for epoch-22: 2.8101935386657715
common line69: model saved with val loss 0.6608171500265598

Epoch: 23, 
Train Loss: 0.9140835368082303, 
Validation Loss: 0.6596181374043226
Elapsed time for epoch-23: 2.6581263542175293
common line69: model saved with val loss 0.6596181374043226

Epoch: 24, 
Train Loss: 0.9140120306435753, 
Validation Loss: 0.6628057602792978
Elapsed time for epoch-24: 2.7560153007507324

Epoch: 25, 
Train Loss: 0.9134820047296396, 
Validation Loss: 0.6580100748687983
Elapsed time for epoch-25: 2.8312771320343018
common line69: model saved with val loss 0.6580100748687983

Epoch: 26, 
Train Loss: 0.9133413840993112, 
Validation Loss: 0.6595582840964198
Elapsed time for epoch-26: 2.9941978454589844

Epoch: 27, 
Train Loss: 0.9132904399092457, 
Validation Loss: 0.6618284992873669
Elapsed time for epoch-27: 2.8187923431396484

Epoch: 28, 
Train Loss: 0.91310397942527, 
Validation Loss: 0.6604829505085945
Elapsed time for epoch-28: 2.8971590995788574

Epoch: 29, 
Train Loss: 0.9126645269013253, 
Validation Loss: 0.6562437387183309
Elapsed time for epoch-29: 3.1572864055633545
common line69: model saved with val loss 0.6562437387183309

Epoch: 30, 
Train Loss: 0.9123840079087169, 
Validation Loss: 0.6585187762975693
Elapsed time for epoch-30: 3.7213165760040283

Epoch: 31, 
Train Loss: 0.9123861214944294, 
Validation Loss: 0.6589554231613874
Elapsed time for epoch-31: 3.738840103149414

train line101: min loss for the epoch 31 is 0.6562437387183309

Training the 55-th turbine in 203.37153506278992 secs

>>>>>>>>> Training Turbine  56 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 5.810760259628296
lalalalalal
260 [[ 1.          0.24550524 -0.20120635 -0.70210139  0.19245189]
 [ 0.99904822  0.32838773 -0.23581842  0.43684745  0.0522888 ]
 [ 0.9961947   0.32267169 -0.25790422  0.44056464  0.03238398]
 [ 0.99144486  0.39983814 -0.25131144  0.43610401  0.07039665]
 [ 0.98480775  0.28837549 -0.3215245   0.43238681 -0.11819228]]
hahahahahahah
265 [[ 0.99985184  1.          0.24550524 -0.20120635 -0.70210139  0.19245189]
 [ 0.99985184  0.99904822  0.32838773 -0.23581842  0.43684745  0.0522888 ]
 [ 0.99985184  0.9961947   0.32267169 -0.25790422  0.44056464  0.03238398]
 [ 0.99985184  0.99144486  0.39983814 -0.25131144  0.43610401  0.07039665]
 [ 0.99985184  0.98480775  0.28837549 -0.3215245   0.43238681 -0.11819228]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.24550524 -0.20120635 -0.70210139  0.19245189]
 [ 0.99985184  0.99904822  0.32838773 -0.23581842  0.43684745  0.0522888 ]
 [ 0.99985184  0.9961947   0.32267169 -0.25790422  0.44056464  0.03238398]
 [ 0.99985184  0.99144486  0.39983814 -0.25131144  0.43610401  0.07039665]
 [ 0.99985184  0.98480775  0.28837549 -0.3215245   0.43238681 -0.11819228]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.099609851837158
lalalalalal
260 [[ 1.         -0.17319419 -0.10775376 -1.72693232 -0.20829384]
 [ 0.99904822 -0.14604303  0.05459334 -1.73399499 -0.13855786]
 [ 0.9961947  -0.2603637   0.0058068  -1.74960721 -0.22674726]
 [ 0.99144486 -0.23178353 -0.10033688 -1.74886377 -0.17712345]
 [ 0.98480775 -0.0031422  -0.11352244 -1.73919906  0.07094956]]
hahahahahahah
265 [[-0.84754092  1.         -0.17319419 -0.10775376 -1.72693232 -0.20829384]
 [-0.84754092  0.99904822 -0.14604303  0.05459334 -1.73399499 -0.13855786]
 [-0.84754092  0.9961947  -0.2603637   0.0058068  -1.74960721 -0.22674726]
 [-0.84754092  0.99144486 -0.23178353 -0.10033688 -1.74886377 -0.17712345]
 [-0.84754092  0.98480775 -0.0031422  -0.11352244 -1.73919906  0.07094956]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.17319419 -0.10775376 -1.72693232 -0.20829384]
 [-0.84754092  0.99904822 -0.14604303  0.05459334 -1.73399499 -0.13855786]
 [-0.84754092  0.9961947  -0.2603637   0.0058068  -1.74960721 -0.22674726]
 [-0.84754092  0.99144486 -0.23178353 -0.10033688 -1.74886377 -0.17712345]
 [-0.84754092  0.98480775 -0.0031422  -0.11352244 -1.73919906  0.07094956]]

Epoch: 0, 
Train Loss: 1.0093606506325619, 
Validation Loss: 0.7454421911388636
Elapsed time for epoch-0: 3.4336466789245605
common line69: model saved with val loss 0.7454421911388636

Epoch: 1, 
Train Loss: 0.9604186505830589, 
Validation Loss: 0.689292075112462
Elapsed time for epoch-1: 3.384300947189331
common line69: model saved with val loss 0.689292075112462

Epoch: 2, 
Train Loss: 0.9451551064222801, 
Validation Loss: 0.6743840798735619
Elapsed time for epoch-2: 3.7329907417297363
common line69: model saved with val loss 0.6743840798735619

Epoch: 3, 
Train Loss: 0.9387106022664479, 
Validation Loss: 0.6688588075339794
Elapsed time for epoch-3: 5.043832063674927
common line69: model saved with val loss 0.6688588075339794

Epoch: 4, 
Train Loss: 0.9340865945114809, 
Validation Loss: 0.6704457262530923
Elapsed time for epoch-4: 4.476379632949829

Epoch: 5, 
Train Loss: 0.9310939990672744, 
Validation Loss: 0.6692451005801558
Elapsed time for epoch-5: 3.940835475921631

Epoch: 6, 
Train Loss: 0.928928031014795, 
Validation Loss: 0.6711573479697108
Elapsed time for epoch-6: 4.046457052230835

Epoch: 7, 
Train Loss: 0.9273328451799745, 
Validation Loss: 0.6688517797738314
Elapsed time for epoch-7: 3.7085535526275635
common line69: model saved with val loss 0.6688517797738314

Epoch: 8, 
Train Loss: 0.9265778583137929, 
Validation Loss: 0.6696499986574054
Elapsed time for epoch-8: 3.520272731781006

Epoch: 9, 
Train Loss: 0.9254926017352513, 
Validation Loss: 0.6673439061269164
Elapsed time for epoch-9: 3.4863908290863037
common line69: model saved with val loss 0.6673439061269164

Epoch: 10, 
Train Loss: 0.9246834065733838, 
Validation Loss: 0.6655539628118277
Elapsed time for epoch-10: 3.192591428756714
common line69: model saved with val loss 0.6655539628118277

Epoch: 11, 
Train Loss: 0.9237121899588769, 
Validation Loss: 0.6589765483513474
Elapsed time for epoch-11: 3.1852970123291016
common line69: model saved with val loss 0.6589765483513474

Epoch: 12, 
Train Loss: 0.9232200804878684, 
Validation Loss: 0.6643717950209975
Elapsed time for epoch-12: 2.9859840869903564

Epoch: 13, 
Train Loss: 0.9229526728892526, 
Validation Loss: 0.6667999364435673
Elapsed time for epoch-13: 3.19474196434021

Epoch: 14, 
Train Loss: 0.9222689788131153, 
Validation Loss: 0.6619891934096813
Elapsed time for epoch-14: 3.3099429607391357

Epoch: 15, 
Train Loss: 0.921742098922489, 
Validation Loss: 0.660372659098357
Elapsed time for epoch-15: 3.428929567337036

Epoch: 16, 
Train Loss: 0.9213085098176443, 
Validation Loss: 0.6600256031379104
Elapsed time for epoch-16: 3.003446102142334

Epoch: 17, 
Train Loss: 0.9208485332607221, 
Validation Loss: 0.6564678009599447
Elapsed time for epoch-17: 2.7798023223876953
common line69: model saved with val loss 0.6564678009599447

Epoch: 18, 
Train Loss: 0.9205695031320348, 
Validation Loss: 0.6544631700962782
Elapsed time for epoch-18: 2.929647445678711
common line69: model saved with val loss 0.6544631700962782

Epoch: 19, 
Train Loss: 0.9201822247074432, 
Validation Loss: 0.6527967639267445
Elapsed time for epoch-19: 3.179281234741211
common line69: model saved with val loss 0.6527967639267445

Epoch: 20, 
Train Loss: 0.9200091116568622, 
Validation Loss: 0.6545131104066968
Elapsed time for epoch-20: 3.311443567276001

Epoch: 21, 
Train Loss: 0.9197853355347609, 
Validation Loss: 0.6553935762494802
Elapsed time for epoch-21: 3.6146531105041504

Epoch: 22, 
Train Loss: 0.9195223810041652, 
Validation Loss: 0.6523272944614291
Elapsed time for epoch-22: 2.5610437393188477
common line69: model saved with val loss 0.6523272944614291

Epoch: 23, 
Train Loss: 0.9188630344236598, 
Validation Loss: 0.6580402050167322
Elapsed time for epoch-23: 3.2547287940979004

Epoch: 24, 
Train Loss: 0.9189084948611861, 
Validation Loss: 0.6516155721619725
Elapsed time for epoch-24: 3.0060932636260986
common line69: model saved with val loss 0.6516155721619725

Epoch: 25, 
Train Loss: 0.9184727434601102, 
Validation Loss: 0.6519701359793544
Elapsed time for epoch-25: 2.864692449569702

Epoch: 26, 
Train Loss: 0.9183114193567709, 
Validation Loss: 0.6581667494028807
Elapsed time for epoch-26: 3.294386386871338

Epoch: 27, 
Train Loss: 0.9178990651579464, 
Validation Loss: 0.6507773483172059
Elapsed time for epoch-27: 3.885376214981079
common line69: model saved with val loss 0.6507773483172059

Epoch: 28, 
Train Loss: 0.9176972026334089, 
Validation Loss: 0.653116887435317
Elapsed time for epoch-28: 3.9399755001068115

Epoch: 29, 
Train Loss: 0.9175667857923427, 
Validation Loss: 0.6510034501552582
Elapsed time for epoch-29: 3.926020383834839

Epoch: 30, 
Train Loss: 0.9170758076826063, 
Validation Loss: 0.6521083423867822
Elapsed time for epoch-30: 3.6171295642852783

Epoch: 31, 
Train Loss: 0.9170072215194461, 
Validation Loss: 0.6534388205036521
Elapsed time for epoch-31: 3.647566318511963

train line101: min loss for the epoch 31 is 0.6507773483172059

Training the 56-th turbine in 234.48736429214478 secs

>>>>>>>>> Training Turbine  57 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.3843770027160645
lalalalalal
260 [[ 1.          0.21935826 -0.40001867 -0.77924469 -0.31252167]
 [ 0.99904822  0.29571255 -0.74632376  0.59084476 -0.8528467 ]
 [ 0.9961947   0.20639243 -0.76500689  0.58464876 -0.8528467 ]
 [ 0.99144486  0.23520537 -0.74498925  0.57458027 -0.8528467 ]
 [ 0.98480775  0.13436008 -0.8520836   0.56838427 -0.8528467 ]]
hahahahahahah
265 [[ 0.99985184  1.          0.21935826 -0.40001867 -0.77924469 -0.31252167]
 [ 0.99985184  0.99904822  0.29571255 -0.74632376  0.59084476 -0.8528467 ]
 [ 0.99985184  0.9961947   0.20639243 -0.76500689  0.58464876 -0.8528467 ]
 [ 0.99985184  0.99144486  0.23520537 -0.74498925  0.57458027 -0.8528467 ]
 [ 0.99985184  0.98480775  0.13436008 -0.8520836   0.56838427 -0.8528467 ]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.21935826 -0.40001867 -0.77924469 -0.31252167]
 [ 0.99985184  0.99904822  0.29571255 -0.74632376  0.59084476 -0.8528467 ]
 [ 0.99985184  0.9961947   0.20639243 -0.76500689  0.58464876 -0.8528467 ]
 [ 0.99985184  0.99144486  0.23520537 -0.74498925  0.57458027 -0.8528467 ]
 [ 0.99985184  0.98480775  0.13436008 -0.8520836   0.56838427 -0.8528467 ]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.8144912719726562
lalalalalal
260 [[ 1.         -0.30647794 -0.06172062 -1.92821456 -0.26170305]
 [ 0.99904822 -0.22003911 -0.07673385 -1.9347978  -0.17438361]
 [ 0.9961947  -0.35545994  0.17882463 -1.9378958  -0.2608329 ]
 [ 0.99144486 -0.2747837   0.13745485 -1.94486629 -0.16683484]
 [ 0.98480775 -0.20563264  0.04704186 -1.95028779 -0.03816665]]
hahahahahahah
265 [[-0.84754092  1.         -0.30647794 -0.06172062 -1.92821456 -0.26170305]
 [-0.84754092  0.99904822 -0.22003911 -0.07673385 -1.9347978  -0.17438361]
 [-0.84754092  0.9961947  -0.35545994  0.17882463 -1.9378958  -0.2608329 ]
 [-0.84754092  0.99144486 -0.2747837   0.13745485 -1.94486629 -0.16683484]
 [-0.84754092  0.98480775 -0.20563264  0.04704186 -1.95028779 -0.03816665]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.30647794 -0.06172062 -1.92821456 -0.26170305]
 [-0.84754092  0.99904822 -0.22003911 -0.07673385 -1.9347978  -0.17438361]
 [-0.84754092  0.9961947  -0.35545994  0.17882463 -1.9378958  -0.2608329 ]
 [-0.84754092  0.99144486 -0.2747837   0.13745485 -1.94486629 -0.16683484]
 [-0.84754092  0.98480775 -0.20563264  0.04704186 -1.95028779 -0.03816665]]

Epoch: 0, 
Train Loss: 0.9883037536334591, 
Validation Loss: 0.7181420307606459
Elapsed time for epoch-0: 5.004122257232666
common line69: model saved with val loss 0.7181420307606459

Epoch: 1, 
Train Loss: 0.939216356442756, 
Validation Loss: 0.6947168642655015
Elapsed time for epoch-1: 4.254509687423706
common line69: model saved with val loss 0.6947168642655015

Epoch: 2, 
Train Loss: 0.9268896170273548, 
Validation Loss: 0.6860255179926753
Elapsed time for epoch-2: 3.671321153640747
common line69: model saved with val loss 0.6860255179926753

Epoch: 3, 
Train Loss: 0.9214455877282038, 
Validation Loss: 0.6898960126563907
Elapsed time for epoch-3: 3.591508388519287

Epoch: 4, 
Train Loss: 0.9182822046911016, 
Validation Loss: 0.6843335805460811
Elapsed time for epoch-4: 3.7186484336853027
common line69: model saved with val loss 0.6843335805460811

Epoch: 5, 
Train Loss: 0.9162064614165731, 
Validation Loss: 0.6889499053359032
Elapsed time for epoch-5: 3.1668989658355713

Epoch: 6, 
Train Loss: 0.9146828944442653, 
Validation Loss: 0.6827442673966289
Elapsed time for epoch-6: 3.218824863433838
common line69: model saved with val loss 0.6827442673966289

Epoch: 7, 
Train Loss: 0.9135091808162817, 
Validation Loss: 0.6851755119860172
Elapsed time for epoch-7: 2.730123996734619

Epoch: 8, 
Train Loss: 0.9124144574924677, 
Validation Loss: 0.6793804513290524
Elapsed time for epoch-8: 2.9091501235961914
common line69: model saved with val loss 0.6793804513290524

Epoch: 9, 
Train Loss: 0.9117600085104213, 
Validation Loss: 0.6845388440415263
Elapsed time for epoch-9: 3.574495792388916

Epoch: 10, 
Train Loss: 0.9108148878361998, 
Validation Loss: 0.6882479162886739
Elapsed time for epoch-10: 3.9163224697113037

Epoch: 11, 
Train Loss: 0.9102856232589033, 
Validation Loss: 0.6820406932383776
Elapsed time for epoch-11: 3.9377779960632324

Epoch: 12, 
Train Loss: 0.9096739571385023, 
Validation Loss: 0.6849204450845718
Elapsed time for epoch-12: 3.865565538406372

Epoch: 13, 
Train Loss: 0.908830079586566, 
Validation Loss: 0.680619397200644
Elapsed time for epoch-13: 4.1758222579956055

Epoch: 14, 
Train Loss: 0.9085439933197839, 
Validation Loss: 0.6801264937967062
Elapsed time for epoch-14: 3.9375710487365723

Epoch: 15, 
Train Loss: 0.9080722248103438, 
Validation Loss: 0.6870718626305461
Elapsed time for epoch-15: 3.4586050510406494

Epoch: 16, 
Train Loss: 0.907482990196773, 
Validation Loss: 0.6841351706534624
Elapsed time for epoch-16: 3.49072003364563

Epoch: 17, 
Train Loss: 0.907053420899295, 
Validation Loss: 0.6758139748126268
Elapsed time for epoch-17: 4.389159679412842
common line69: model saved with val loss 0.6758139748126268

Epoch: 18, 
Train Loss: 0.9064577236896804, 
Validation Loss: 0.6775168590247631
Elapsed time for epoch-18: 4.249752759933472

Epoch: 19, 
Train Loss: 0.9062083849386007, 
Validation Loss: 0.6789535721763968
Elapsed time for epoch-19: 3.8338284492492676

Epoch: 20, 
Train Loss: 0.9055952578783035, 
Validation Loss: 0.6803595684468746
Elapsed time for epoch-20: 3.4211769104003906

Epoch: 21, 
Train Loss: 0.9050422643913942, 
Validation Loss: 0.6812486751005054
Elapsed time for epoch-21: 3.5596017837524414

Epoch: 22, 
Train Loss: 0.9046084784409579, 
Validation Loss: 0.6790190553292632
Elapsed time for epoch-22: 3.394944429397583

Epoch: 23, 
Train Loss: 0.9043561585811006, 
Validation Loss: 0.6780400173738599
Elapsed time for epoch-23: 3.5594966411590576

Epoch: 24, 
Train Loss: 0.9036805845108353, 
Validation Loss: 0.680114752613008
Elapsed time for epoch-24: 3.4525580406188965

Epoch: 25, 
Train Loss: 0.9032016346434585, 
Validation Loss: 0.678162625990808
Elapsed time for epoch-25: 3.3765361309051514

Epoch: 26, 
Train Loss: 0.9030973789822153, 
Validation Loss: 0.6794437654316425
Elapsed time for epoch-26: 3.8480887413024902

Epoch: 27, 
Train Loss: 0.9027173105909043, 
Validation Loss: 0.6852280301973224
Elapsed time for epoch-27: 3.804145336151123

Epoch: 28, 
Train Loss: 0.9020968753249705, 
Validation Loss: 0.6752801965922117
Elapsed time for epoch-28: 3.697932481765747
common line69: model saved with val loss 0.6752801965922117

Epoch: 29, 
Train Loss: 0.9017943033651143, 
Validation Loss: 0.6789417983964086
Elapsed time for epoch-29: 3.235224485397339

Epoch: 30, 
Train Loss: 0.9014002365224502, 
Validation Loss: 0.6844302769750357
Elapsed time for epoch-30: 3.2575318813323975

Epoch: 31, 
Train Loss: 0.9010229657928482, 
Validation Loss: 0.6803586091846228
Elapsed time for epoch-31: 4.099666118621826

train line101: min loss for the epoch 31 is 0.6752801965922117

Training the 57-th turbine in 221.1863842010498 secs

>>>>>>>>> Training Turbine  58 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.570428371429443
lalalalalal
260 [[ 1.          0.25053731 -0.19674482 -0.70851334  0.31081837]
 [ 0.99904822  0.19540137 -0.27657543  0.49062435  0.10042743]
 [ 0.9961947   0.15665719 -0.26335296  0.48347173  0.07020072]
 [ 0.99144486  0.22222426 -0.27393093  0.47703437  0.10291611]
 [ 0.98480775  0.12089333 -0.36252142  0.4763191  -0.07005991]]
hahahahahahah
265 [[ 0.99985184  1.          0.25053731 -0.19674482 -0.70851334  0.31081837]
 [ 0.99985184  0.99904822  0.19540137 -0.27657543  0.49062435  0.10042743]
 [ 0.99985184  0.9961947   0.15665719 -0.26335296  0.48347173  0.07020072]
 [ 0.99985184  0.99144486  0.22222426 -0.27393093  0.47703437  0.10291611]
 [ 0.99985184  0.98480775  0.12089333 -0.36252142  0.4763191  -0.07005991]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.25053731 -0.19674482 -0.70851334  0.31081837]
 [ 0.99985184  0.99904822  0.19540137 -0.27657543  0.49062435  0.10042743]
 [ 0.99985184  0.9961947   0.15665719 -0.26335296  0.48347173  0.07020072]
 [ 0.99985184  0.99144486  0.22222426 -0.27393093  0.47703437  0.10291611]
 [ 0.99985184  0.98480775  0.12089333 -0.36252142  0.4763191  -0.07005991]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.7901101112365723
lalalalalal
260 [[ 1.          0.01807225 -0.06518133 -1.75422722 -0.06366905]
 [ 0.99904822  0.11195237 -0.03757944 -1.75315433  0.08172601]
 [ 0.9961947  -0.46622997  0.09629798 -1.76745958 -0.36633482]
 [ 0.99144486 -0.32615487  0.03811915 -1.77675799 -0.26045677]
 [ 0.98480775 -0.03408338 -0.0336127  -1.77675799  0.04280096]]
hahahahahahah
265 [[-0.84754092  1.          0.01807225 -0.06518133 -1.75422722 -0.06366905]
 [-0.84754092  0.99904822  0.11195237 -0.03757944 -1.75315433  0.08172601]
 [-0.84754092  0.9961947  -0.46622997  0.09629798 -1.76745958 -0.36633482]
 [-0.84754092  0.99144486 -0.32615487  0.03811915 -1.77675799 -0.26045677]
 [-0.84754092  0.98480775 -0.03408338 -0.0336127  -1.77675799  0.04280096]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.01807225 -0.06518133 -1.75422722 -0.06366905]
 [-0.84754092  0.99904822  0.11195237 -0.03757944 -1.75315433  0.08172601]
 [-0.84754092  0.9961947  -0.46622997  0.09629798 -1.76745958 -0.36633482]
 [-0.84754092  0.99144486 -0.32615487  0.03811915 -1.77675799 -0.26045677]
 [-0.84754092  0.98480775 -0.03408338 -0.0336127  -1.77675799  0.04280096]]

Epoch: 0, 
Train Loss: 0.9944515064233491, 
Validation Loss: 0.789559637196362
Elapsed time for epoch-0: 4.091886043548584
common line69: model saved with val loss 0.789559637196362

Epoch: 1, 
Train Loss: 0.9603212848931801, 
Validation Loss: 0.7601609034463763
Elapsed time for epoch-1: 4.290602445602417
common line69: model saved with val loss 0.7601609034463763

Epoch: 2, 
Train Loss: 0.9507297730746389, 
Validation Loss: 0.7569774920120835
Elapsed time for epoch-2: 3.5916285514831543
common line69: model saved with val loss 0.7569774920120835

Epoch: 3, 
Train Loss: 0.9458048307344693, 
Validation Loss: 0.7545860875397921
Elapsed time for epoch-3: 4.06056809425354
common line69: model saved with val loss 0.7545860875397921

Epoch: 4, 
Train Loss: 0.9423701495182615, 
Validation Loss: 0.7539668483659625
Elapsed time for epoch-4: 3.7494728565216064
common line69: model saved with val loss 0.7539668483659625

Epoch: 5, 
Train Loss: 0.9396335371151692, 
Validation Loss: 0.7512467112392187
Elapsed time for epoch-5: 3.5007126331329346
common line69: model saved with val loss 0.7512467112392187

Epoch: 6, 
Train Loss: 0.9375889262481898, 
Validation Loss: 0.7508654752746224
Elapsed time for epoch-6: 3.304194688796997
common line69: model saved with val loss 0.7508654752746224

Epoch: 7, 
Train Loss: 0.9359637704216132, 
Validation Loss: 0.7507872860878706
Elapsed time for epoch-7: 3.200617790222168
common line69: model saved with val loss 0.7507872860878706

Epoch: 8, 
Train Loss: 0.9345036584790013, 
Validation Loss: 0.7498817322775722
Elapsed time for epoch-8: 3.5597734451293945
common line69: model saved with val loss 0.7498817322775722

Epoch: 9, 
Train Loss: 0.9333303769846925, 
Validation Loss: 0.74466722458601
Elapsed time for epoch-9: 3.478062868118286
common line69: model saved with val loss 0.74466722458601

Epoch: 10, 
Train Loss: 0.9318593952084789, 
Validation Loss: 0.744937052950263
Elapsed time for epoch-10: 3.555318832397461

Epoch: 11, 
Train Loss: 0.9308168923153597, 
Validation Loss: 0.7441398622468114
Elapsed time for epoch-11: 3.3634674549102783
common line69: model saved with val loss 0.7441398622468114

Epoch: 12, 
Train Loss: 0.9296480876808407, 
Validation Loss: 0.740802563726902
Elapsed time for epoch-12: 2.84820294380188
common line69: model saved with val loss 0.740802563726902

Epoch: 13, 
Train Loss: 0.9284624749121546, 
Validation Loss: 0.7396617382764816
Elapsed time for epoch-13: 3.188486099243164
common line69: model saved with val loss 0.7396617382764816

Epoch: 14, 
Train Loss: 0.9275025762930638, 
Validation Loss: 0.739681476727128
Elapsed time for epoch-14: 3.0630431175231934

Epoch: 15, 
Train Loss: 0.9265262778817105, 
Validation Loss: 0.7452797824516892
Elapsed time for epoch-15: 3.195870876312256

Epoch: 16, 
Train Loss: 0.9259220241498547, 
Validation Loss: 0.7385464506223798
Elapsed time for epoch-16: 3.469771385192871
common line69: model saved with val loss 0.7385464506223798

Epoch: 17, 
Train Loss: 0.9250541232964572, 
Validation Loss: 0.7434903550893068
Elapsed time for epoch-17: 4.366032600402832

Epoch: 18, 
Train Loss: 0.9243258944078654, 
Validation Loss: 0.7341738790273666
Elapsed time for epoch-18: 3.8033909797668457
common line69: model saved with val loss 0.7341738790273666

Epoch: 19, 
Train Loss: 0.9238062926701137, 
Validation Loss: 0.7339195227250457
Elapsed time for epoch-19: 4.254112958908081
common line69: model saved with val loss 0.7339195227250457

Epoch: 20, 
Train Loss: 0.9237301815457705, 
Validation Loss: 0.7360661765560508
Elapsed time for epoch-20: 4.153132438659668

Epoch: 21, 
Train Loss: 0.9232508346062749, 
Validation Loss: 0.734514738433063
Elapsed time for epoch-21: 3.6302435398101807

Epoch: 22, 
Train Loss: 0.9229208688024714, 
Validation Loss: 0.7343920776620507
Elapsed time for epoch-22: 4.398079872131348

Epoch: 23, 
Train Loss: 0.9227764751730847, 
Validation Loss: 0.7366094496101141
Elapsed time for epoch-23: 3.608837604522705

Epoch: 24, 
Train Loss: 0.922572731721301, 
Validation Loss: 0.7350670024752617
Elapsed time for epoch-24: 3.6687917709350586

Epoch: 25, 
Train Loss: 0.9221832528084266, 
Validation Loss: 0.7349473042413592
Elapsed time for epoch-25: 3.287425994873047

Epoch: 26, 
Train Loss: 0.9217432999059934, 
Validation Loss: 0.7350245658308268
Elapsed time for epoch-26: 3.315371513366699

Epoch: 27, 
Train Loss: 0.9217544026485011, 
Validation Loss: 0.7341325050219893
Elapsed time for epoch-27: 4.244558334350586

Epoch: 28, 
Train Loss: 0.9215267936722571, 
Validation Loss: 0.7334128832444549
Elapsed time for epoch-28: 4.301317930221558
common line69: model saved with val loss 0.7334128832444549

Epoch: 29, 
Train Loss: 0.9211467207730317, 
Validation Loss: 0.732610278762877
Elapsed time for epoch-29: 3.684741258621216
common line69: model saved with val loss 0.732610278762877

Epoch: 30, 
Train Loss: 0.9210675329971714, 
Validation Loss: 0.7302976157516241
Elapsed time for epoch-30: 3.2280688285827637
common line69: model saved with val loss 0.7302976157516241

Epoch: 31, 
Train Loss: 0.920824384739419, 
Validation Loss: 0.7348201898857951
Elapsed time for epoch-31: 3.535165309906006

train line101: min loss for the epoch 31 is 0.7302976157516241

Training the 58-th turbine in 227.49426651000977 secs

>>>>>>>>> Training Turbine  59 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.05637788772583
lalalalalal
260 [[ 1.          0.33633911  0.0819703  -0.27597055  0.38768631]
 [ 0.99904822  0.42876694  0.16761397  0.34427041  0.30544101]
 [ 0.9961947   0.35366933  0.14697323  0.34427041  0.22551231]
 [ 0.99144486  0.39699488  0.15159429  0.34279145  0.32105134]
 [ 0.98480775  0.26701823  0.03021441  0.340573    0.16349867]]
hahahahahahah
265 [[ 0.99985184  1.          0.33633911  0.0819703  -0.27597055  0.38768631]
 [ 0.99985184  0.99904822  0.42876694  0.16761397  0.34427041  0.30544101]
 [ 0.99985184  0.9961947   0.35366933  0.14697323  0.34427041  0.22551231]
 [ 0.99985184  0.99144486  0.39699488  0.15159429  0.34279145  0.32105134]
 [ 0.99985184  0.98480775  0.26701823  0.03021441  0.340573    0.16349867]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.33633911  0.0819703  -0.27597055  0.38768631]
 [ 0.99985184  0.99904822  0.42876694  0.16761397  0.34427041  0.30544101]
 [ 0.99985184  0.9961947   0.35366933  0.14697323  0.34427041  0.22551231]
 [ 0.99985184  0.99144486  0.39699488  0.15159429  0.34279145  0.32105134]
 [ 0.99985184  0.98480775  0.26701823  0.03021441  0.340573    0.16349867]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.3479063510894775
lalalalalal
260 [[ 1.         -0.32798599 -0.18944004 -0.82910347 -0.30603491]
 [ 0.99904822 -0.35686969 -0.17342036 -0.83187653 -0.26779316]
 [ 0.9961947  -0.40597198 -0.06990859 -0.83483446 -0.32586264]
 [ 0.99144486 -0.44929753 -0.09455425 -0.83594368 -0.32305896]
 [ 0.98480775 -0.24133489 -0.18574319 -0.83853187 -0.1271101 ]]
hahahahahahah
265 [[-0.84754092  1.         -0.32798599 -0.18944004 -0.82910347 -0.30603491]
 [-0.84754092  0.99904822 -0.35686969 -0.17342036 -0.83187653 -0.26779316]
 [-0.84754092  0.9961947  -0.40597198 -0.06990859 -0.83483446 -0.32586264]
 [-0.84754092  0.99144486 -0.44929753 -0.09455425 -0.83594368 -0.32305896]
 [-0.84754092  0.98480775 -0.24133489 -0.18574319 -0.83853187 -0.1271101 ]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.32798599 -0.18944004 -0.82910347 -0.30603491]
 [-0.84754092  0.99904822 -0.35686969 -0.17342036 -0.83187653 -0.26779316]
 [-0.84754092  0.9961947  -0.40597198 -0.06990859 -0.83483446 -0.32586264]
 [-0.84754092  0.99144486 -0.44929753 -0.09455425 -0.83594368 -0.32305896]
 [-0.84754092  0.98480775 -0.24133489 -0.18574319 -0.83853187 -0.1271101 ]]

Epoch: 0, 
Train Loss: 1.0016027608839404, 
Validation Loss: 0.6415955424308777
Elapsed time for epoch-0: 4.686292886734009
common line69: model saved with val loss 0.6415955424308777

Epoch: 1, 
Train Loss: 0.9621504287258917, 
Validation Loss: 0.5845421440899372
Elapsed time for epoch-1: 3.597489595413208
common line69: model saved with val loss 0.5845421440899372

Epoch: 2, 
Train Loss: 0.9451589173629504, 
Validation Loss: 0.5843714810907841
Elapsed time for epoch-2: 3.8129069805145264
common line69: model saved with val loss 0.5843714810907841

Epoch: 3, 
Train Loss: 0.940151083369215, 
Validation Loss: 0.5806174231693149
Elapsed time for epoch-3: 3.8834404945373535
common line69: model saved with val loss 0.5806174231693149

Epoch: 4, 
Train Loss: 0.9369239115915379, 
Validation Loss: 0.5867218021303415
Elapsed time for epoch-4: 3.1641499996185303

Epoch: 5, 
Train Loss: 0.9349072456610303, 
Validation Loss: 0.5806858916766942
Elapsed time for epoch-5: 3.3443727493286133

Epoch: 6, 
Train Loss: 0.9327802926051516, 
Validation Loss: 0.5770463868975639
Elapsed time for epoch-6: 3.396475076675415
common line69: model saved with val loss 0.5770463868975639

Epoch: 7, 
Train Loss: 0.9312182626053065, 
Validation Loss: 0.5749158728867769
Elapsed time for epoch-7: 3.1316065788269043
common line69: model saved with val loss 0.5749158728867769

Epoch: 8, 
Train Loss: 0.9296888363461534, 
Validation Loss: 0.5713671371340752
Elapsed time for epoch-8: 3.5969817638397217
common line69: model saved with val loss 0.5713671371340752

Epoch: 9, 
Train Loss: 0.9280684095721284, 
Validation Loss: 0.5739322099834681
Elapsed time for epoch-9: 3.048917531967163

Epoch: 10, 
Train Loss: 0.9262755550757176, 
Validation Loss: 0.5693851574324071
Elapsed time for epoch-10: 2.7601218223571777
common line69: model saved with val loss 0.5693851574324071

Epoch: 11, 
Train Loss: 0.9246212656007093, 
Validation Loss: 0.5715790237300098
Elapsed time for epoch-11: 2.967292308807373

Epoch: 12, 
Train Loss: 0.9233170979413665, 
Validation Loss: 0.5591878350824118
Elapsed time for epoch-12: 2.7661967277526855
common line69: model saved with val loss 0.5591878350824118

Epoch: 13, 
Train Loss: 0.9222631676106894, 
Validation Loss: 0.560804555658251
Elapsed time for epoch-13: 2.9866228103637695

Epoch: 14, 
Train Loss: 0.9209036829591799, 
Validation Loss: 0.5593239208683372
Elapsed time for epoch-14: 2.8692739009857178

Epoch: 15, 
Train Loss: 0.9200161826961181, 
Validation Loss: 0.5584958521649241
Elapsed time for epoch-15: 2.7658004760742188
common line69: model saved with val loss 0.5584958521649241

Epoch: 16, 
Train Loss: 0.9190391199428494, 
Validation Loss: 0.5622351597994566
Elapsed time for epoch-16: 3.002516031265259

Epoch: 17, 
Train Loss: 0.9184256345033646, 
Validation Loss: 0.5562535226345062
Elapsed time for epoch-17: 2.659454584121704
common line69: model saved with val loss 0.5562535226345062

Epoch: 18, 
Train Loss: 0.9176522945406056, 
Validation Loss: 0.5623452607542276
Elapsed time for epoch-18: 2.367489814758301

Epoch: 19, 
Train Loss: 0.917014240342028, 
Validation Loss: 0.5529070096090436
Elapsed time for epoch-19: 3.524035692214966
common line69: model saved with val loss 0.5529070096090436

Epoch: 20, 
Train Loss: 0.9162960241572196, 
Validation Loss: 0.5520090665668249
Elapsed time for epoch-20: 3.3477752208709717
common line69: model saved with val loss 0.5520090665668249

Epoch: 21, 
Train Loss: 0.9155927135162995, 
Validation Loss: 0.5564649282023311
Elapsed time for epoch-21: 3.557920455932617

Epoch: 22, 
Train Loss: 0.9151660349188733, 
Validation Loss: 0.5534061389043927
Elapsed time for epoch-22: 2.9807331562042236

Epoch: 23, 
Train Loss: 0.9144040795684862, 
Validation Loss: 0.5584744019433856
Elapsed time for epoch-23: 3.320739984512329

Epoch: 24, 
Train Loss: 0.914039348979958, 
Validation Loss: 0.5514039914123714
Elapsed time for epoch-24: 3.3652350902557373
common line69: model saved with val loss 0.5514039914123714

Epoch: 25, 
Train Loss: 0.9131548008998903, 
Validation Loss: 0.5526771913282573
Elapsed time for epoch-25: 3.111636161804199

Epoch: 26, 
Train Loss: 0.912736816065652, 
Validation Loss: 0.5501626767218113
Elapsed time for epoch-26: 3.7315149307250977
common line69: model saved with val loss 0.5501626767218113

Epoch: 27, 
Train Loss: 0.912355935498446, 
Validation Loss: 0.5475983382202685
Elapsed time for epoch-27: 4.270417928695679
common line69: model saved with val loss 0.5475983382202685

Epoch: 28, 
Train Loss: 0.9120872725709146, 
Validation Loss: 0.5444157966412604
Elapsed time for epoch-28: 4.412760257720947
common line69: model saved with val loss 0.5444157966412604

Epoch: 29, 
Train Loss: 0.9112997063819099, 
Validation Loss: 0.5498105874285102
Elapsed time for epoch-29: 4.171995401382446

Epoch: 30, 
Train Loss: 0.911136878889148, 
Validation Loss: 0.5505977431312203
Elapsed time for epoch-30: 3.990189790725708

Epoch: 31, 
Train Loss: 0.9108259120658666, 
Validation Loss: 0.5470467675477266
Elapsed time for epoch-31: 2.975090265274048

train line101: min loss for the epoch 31 is 0.5444157966412604

Training the 59-th turbine in 216.43912744522095 secs

>>>>>>>>> Training Turbine  60 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.8988804817199707
lalalalalal
260 [[ 1.          0.44225766 -0.11051271 -1.6770757   0.3807695 ]
 [ 0.99904822  0.44828562 -0.204103    0.28157382  0.2515128 ]
 [ 0.9961947   0.39704793 -0.2288133   0.28157382  0.21147774]
 [ 0.99144486  0.42718775 -0.2288133   0.28157382  0.18893485]
 [ 0.98480775  0.24333485 -0.28750028  0.28157382 -0.05294363]]
hahahahahahah
265 [[ 0.99985184  1.          0.44225766 -0.11051271 -1.6770757   0.3807695 ]
 [ 0.99985184  0.99904822  0.44828562 -0.204103    0.28157382  0.2515128 ]
 [ 0.99985184  0.9961947   0.39704793 -0.2288133   0.28157382  0.21147774]
 [ 0.99985184  0.99144486  0.42718775 -0.2288133   0.28157382  0.18893485]
 [ 0.99985184  0.98480775  0.24333485 -0.28750028  0.28157382 -0.05294363]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.44225766 -0.11051271 -1.6770757   0.3807695 ]
 [ 0.99985184  0.99904822  0.44828562 -0.204103    0.28157382  0.2515128 ]
 [ 0.99985184  0.9961947   0.39704793 -0.2288133   0.28157382  0.21147774]
 [ 0.99985184  0.99144486  0.42718775 -0.2288133   0.28157382  0.18893485]
 [ 0.99985184  0.98480775  0.24333485 -0.28750028  0.28157382 -0.05294363]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.9903740882873535
lalalalalal
260 [[ 1.         -0.30370288 -0.0254166   0.28157382 -0.28351591]
 [ 0.99904822 -0.33534969  0.0525753   0.28157382 -0.26231679]
 [ 0.9961947  -0.63071992  0.09396506  0.28157382 -0.41420906]
 [ 0.99144486 -0.3835734   0.08284542  0.28157382 -0.25274822]
 [ 0.98480775 -0.09724511 -0.01630468  0.28157382  0.0529593 ]]
hahahahahahah
265 [[-0.84754092  1.         -0.30370288 -0.0254166   0.28157382 -0.28351591]
 [-0.84754092  0.99904822 -0.33534969  0.0525753   0.28157382 -0.26231679]
 [-0.84754092  0.9961947  -0.63071992  0.09396506  0.28157382 -0.41420906]
 [-0.84754092  0.99144486 -0.3835734   0.08284542  0.28157382 -0.25274822]
 [-0.84754092  0.98480775 -0.09724511 -0.01630468  0.28157382  0.0529593 ]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.30370288 -0.0254166   0.28157382 -0.28351591]
 [-0.84754092  0.99904822 -0.33534969  0.0525753   0.28157382 -0.26231679]
 [-0.84754092  0.9961947  -0.63071992  0.09396506  0.28157382 -0.41420906]
 [-0.84754092  0.99144486 -0.3835734   0.08284542  0.28157382 -0.25274822]
 [-0.84754092  0.98480775 -0.09724511 -0.01630468  0.28157382  0.0529593 ]]

Epoch: 0, 
Train Loss: 0.9794509223028391, 
Validation Loss: 0.644144807010889
Elapsed time for epoch-0: 4.300945997238159
common line69: model saved with val loss 0.644144807010889

Epoch: 1, 
Train Loss: 0.9368339512778932, 
Validation Loss: 0.6296161869540811
Elapsed time for epoch-1: 4.285021781921387
common line69: model saved with val loss 0.6296161869540811

Epoch: 2, 
Train Loss: 0.9288115863289151, 
Validation Loss: 0.6286002835258842
Elapsed time for epoch-2: 4.7549474239349365
common line69: model saved with val loss 0.6286002835258842

Epoch: 3, 
Train Loss: 0.9244909597044232, 
Validation Loss: 0.6246536578983068
Elapsed time for epoch-3: 4.302192211151123
common line69: model saved with val loss 0.6246536578983068

Epoch: 4, 
Train Loss: 0.9217500282185418, 
Validation Loss: 0.6287155505269766
Elapsed time for epoch-4: 3.994586706161499

Epoch: 5, 
Train Loss: 0.9196791926852795, 
Validation Loss: 0.6251484639942646
Elapsed time for epoch-5: 3.9096505641937256

Epoch: 6, 
Train Loss: 0.9179942617897227, 
Validation Loss: 0.6240638177841902
Elapsed time for epoch-6: 3.7860238552093506
common line69: model saved with val loss 0.6240638177841902

Epoch: 7, 
Train Loss: 0.9167122319966805, 
Validation Loss: 0.6227834904566407
Elapsed time for epoch-7: 4.16099214553833
common line69: model saved with val loss 0.6227834904566407

Epoch: 8, 
Train Loss: 0.9156444781467694, 
Validation Loss: 0.6251556230708957
Elapsed time for epoch-8: 3.4516398906707764

Epoch: 9, 
Train Loss: 0.9145023509734819, 
Validation Loss: 0.6244609742425382
Elapsed time for epoch-9: 3.842517137527466

Epoch: 10, 
Train Loss: 0.9135462476425812, 
Validation Loss: 0.6242229649797082
Elapsed time for epoch-10: 3.4698362350463867

Epoch: 11, 
Train Loss: 0.9128063741852256, 
Validation Loss: 0.6213355921208858
Elapsed time for epoch-11: 3.290189504623413
common line69: model saved with val loss 0.6213355921208858

Epoch: 12, 
Train Loss: 0.9120988213464993, 
Validation Loss: 0.6192451710812747
Elapsed time for epoch-12: 3.093125581741333
common line69: model saved with val loss 0.6192451710812747

Epoch: 13, 
Train Loss: 0.9116423077443067, 
Validation Loss: 0.618231744505465
Elapsed time for epoch-13: 3.124664783477783
common line69: model saved with val loss 0.618231744505465

Epoch: 14, 
Train Loss: 0.9110199640027615, 
Validation Loss: 0.6227143909782171
Elapsed time for epoch-14: 3.256364583969116

Epoch: 15, 
Train Loss: 0.9103770733130079, 
Validation Loss: 0.6207202915102243
Elapsed time for epoch-15: 3.8257477283477783

Epoch: 16, 
Train Loss: 0.9098342134922492, 
Validation Loss: 0.6203566459007561
Elapsed time for epoch-16: 3.7845656871795654

Epoch: 17, 
Train Loss: 0.9092654360442602, 
Validation Loss: 0.6179942404851317
Elapsed time for epoch-17: 3.7506103515625
common line69: model saved with val loss 0.6179942404851317

Epoch: 18, 
Train Loss: 0.9091556118566448, 
Validation Loss: 0.6199983935803175
Elapsed time for epoch-18: 3.2940385341644287

Epoch: 19, 
Train Loss: 0.9087132830329302, 
Validation Loss: 0.622199930716306
Elapsed time for epoch-19: 3.1885182857513428

Epoch: 20, 
Train Loss: 0.9082946138722556, 
Validation Loss: 0.6218122942373157
Elapsed time for epoch-20: 3.23982834815979

Epoch: 21, 
Train Loss: 0.908155181953887, 
Validation Loss: 0.6198197081685066
Elapsed time for epoch-21: 2.9977688789367676

Epoch: 22, 
Train Loss: 0.9075524897134605, 
Validation Loss: 0.619258351624012
Elapsed time for epoch-22: 3.0712997913360596

Epoch: 23, 
Train Loss: 0.9074593536994037, 
Validation Loss: 0.6196575341746211
Elapsed time for epoch-23: 3.5856151580810547

Epoch: 24, 
Train Loss: 0.9071845800435844, 
Validation Loss: 0.6190540641546249
Elapsed time for epoch-24: 3.7032558917999268

Epoch: 25, 
Train Loss: 0.9066815724392899, 
Validation Loss: 0.6174372714012861
Elapsed time for epoch-25: 3.586296319961548
common line69: model saved with val loss 0.6174372714012861

Epoch: 26, 
Train Loss: 0.9065088628470397, 
Validation Loss: 0.6187254069373012
Elapsed time for epoch-26: 3.074044942855835

Epoch: 27, 
Train Loss: 0.9062965042701289, 
Validation Loss: 0.6234177406877279
Elapsed time for epoch-27: 3.244011878967285

Epoch: 28, 
Train Loss: 0.9062308870694217, 
Validation Loss: 0.6196708790957928
Elapsed time for epoch-28: 3.9166903495788574

Epoch: 29, 
Train Loss: 0.9061773012415701, 
Validation Loss: 0.615819999948144
Elapsed time for epoch-29: 3.6850955486297607
common line69: model saved with val loss 0.615819999948144

Epoch: 30, 
Train Loss: 0.9058342211637176, 
Validation Loss: 0.6176170944236219
Elapsed time for epoch-30: 4.09271240234375

Epoch: 31, 
Train Loss: 0.905851228021774, 
Validation Loss: 0.6167112626135349
Elapsed time for epoch-31: 4.042788505554199

train line101: min loss for the epoch 31 is 0.615819999948144

Training the 60-th turbine in 228.5629370212555 secs

>>>>>>>>> Training Turbine  61 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.106333017349243
lalalalalal
260 [[ 1.00000000e+00  2.26005007e-01 -2.18117125e-01  1.33644525e+01
   3.19409833e-01]
 [ 9.99048222e-01  2.48079807e-01 -2.61559691e-01  4.87819511e-01
   1.39995611e-01]
 [ 9.96194698e-01  2.26005007e-01 -3.05002258e-01  4.82828844e-01
   1.20177336e-01]
 [ 9.91444861e-01  2.23245657e-01 -2.66167236e-01  4.81402940e-01
   6.57982031e-02]
 [ 9.84807753e-01  7.70001026e-02 -1.01193804e-02  4.79977035e-01
  -2.54950624e-02]]
hahahahahahah
265 [[ 9.99851839e-01  1.00000000e+00  2.26005007e-01 -2.18117125e-01
   1.33644525e+01  3.19409833e-01]
 [ 9.99851839e-01  9.99048222e-01  2.48079807e-01 -2.61559691e-01
   4.87819511e-01  1.39995611e-01]
 [ 9.99851839e-01  9.96194698e-01  2.26005007e-01 -3.05002258e-01
   4.82828844e-01  1.20177336e-01]
 [ 9.99851839e-01  9.91444861e-01  2.23245657e-01 -2.66167236e-01
   4.81402940e-01  6.57982031e-02]
 [ 9.99851839e-01  9.84807753e-01  7.70001026e-02 -1.01193804e-02
   4.79977035e-01 -2.54950624e-02]]

 wind turbine line248 data after normalization: 
 [[ 9.99851839e-01  1.00000000e+00  2.26005007e-01 -2.18117125e-01
   1.33644525e+01  3.19409833e-01]
 [ 9.99851839e-01  9.99048222e-01  2.48079807e-01 -2.61559691e-01
   4.87819511e-01  1.39995611e-01]
 [ 9.99851839e-01  9.96194698e-01  2.26005007e-01 -3.05002258e-01
   4.82828844e-01  1.20177336e-01]
 [ 9.99851839e-01  9.91444861e-01  2.23245657e-01 -2.66167236e-01
   4.81402940e-01  6.57982031e-02]
 [ 9.99851839e-01  9.84807753e-01  7.70001026e-02 -1.01193804e-02
   4.79977035e-01 -2.54950624e-02]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.9555506706237793
lalalalalal
260 [[ 1.         -0.13409018  0.00781713 -1.73730487 -0.18773268]
 [ 0.99904822 -0.0940796   0.06787977 -1.73873078 -0.1300082 ]
 [ 0.9961947  -0.1382292   0.11922099 -1.74015668 -0.09417842]
 [ 0.99144486 -0.0333739   0.08565173 -1.74300849  0.02380838]
 [ 0.98480775  0.1045936  -0.00682828 -1.74300849  0.26054333]]
hahahahahahah
265 [[-0.84754092  1.         -0.13409018  0.00781713 -1.73730487 -0.18773268]
 [-0.84754092  0.99904822 -0.0940796   0.06787977 -1.73873078 -0.1300082 ]
 [-0.84754092  0.9961947  -0.1382292   0.11922099 -1.74015668 -0.09417842]
 [-0.84754092  0.99144486 -0.0333739   0.08565173 -1.74300849  0.02380838]
 [-0.84754092  0.98480775  0.1045936  -0.00682828 -1.74300849  0.26054333]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.13409018  0.00781713 -1.73730487 -0.18773268]
 [-0.84754092  0.99904822 -0.0940796   0.06787977 -1.73873078 -0.1300082 ]
 [-0.84754092  0.9961947  -0.1382292   0.11922099 -1.74015668 -0.09417842]
 [-0.84754092  0.99144486 -0.0333739   0.08565173 -1.74300849  0.02380838]
 [-0.84754092  0.98480775  0.1045936  -0.00682828 -1.74300849  0.26054333]]

Epoch: 0, 
Train Loss: 0.992980803386504, 
Validation Loss: 0.6578055759891868
Elapsed time for epoch-0: 4.243295431137085
common line69: model saved with val loss 0.6578055759891868

Epoch: 1, 
Train Loss: 0.9577651602380416, 
Validation Loss: 0.6333357086405158
Elapsed time for epoch-1: 4.142700433731079
common line69: model saved with val loss 0.6333357086405158

Epoch: 2, 
Train Loss: 0.948447250768918, 
Validation Loss: 0.6352643854916096
Elapsed time for epoch-2: 4.11621618270874

Epoch: 3, 
Train Loss: 0.9418402190218452, 
Validation Loss: 0.6368418131023645
Elapsed time for epoch-3: 4.41441535949707

Epoch: 4, 
Train Loss: 0.937378344916496, 
Validation Loss: 0.6386538585647941
Elapsed time for epoch-4: 4.256490468978882

Epoch: 5, 
Train Loss: 0.9343493013572293, 
Validation Loss: 0.6370511008426547
Elapsed time for epoch-5: 4.2464118003845215

Epoch: 6, 
Train Loss: 0.9322881780001295, 
Validation Loss: 0.6312533374875784
Elapsed time for epoch-6: 3.673612117767334
common line69: model saved with val loss 0.6312533374875784

Epoch: 7, 
Train Loss: 0.9299867987131872, 
Validation Loss: 0.629655814729631
Elapsed time for epoch-7: 6.384233236312866
common line69: model saved with val loss 0.629655814729631

Epoch: 8, 
Train Loss: 0.9284440620857126, 
Validation Loss: 0.6279735583811998
Elapsed time for epoch-8: 4.081435441970825
common line69: model saved with val loss 0.6279735583811998

Epoch: 9, 
Train Loss: 0.9271721968881222, 
Validation Loss: 0.6368871554732323
Elapsed time for epoch-9: 3.6526496410369873

Epoch: 10, 
Train Loss: 0.9262607802613443, 
Validation Loss: 0.6357414331287146
Elapsed time for epoch-10: 3.454103708267212

Epoch: 11, 
Train Loss: 0.925134986513803, 
Validation Loss: 0.6415697047486901
Elapsed time for epoch-11: 3.2866451740264893

Epoch: 12, 
Train Loss: 0.9237716544826492, 
Validation Loss: 0.630610141903162
Elapsed time for epoch-12: 3.1118531227111816

Epoch: 13, 
Train Loss: 0.922716003130464, 
Validation Loss: 0.6325587765313685
Elapsed time for epoch-13: 3.2779619693756104

Epoch: 14, 
Train Loss: 0.9218253982918603, 
Validation Loss: 0.6382271847687662
Elapsed time for epoch-14: 3.1513075828552246

Epoch: 15, 
Train Loss: 0.9212304590379491, 
Validation Loss: 0.6280309744179249
Elapsed time for epoch-15: 3.0845038890838623

Epoch: 16, 
Train Loss: 0.9202469164082984, 
Validation Loss: 0.6275345222093165
Elapsed time for epoch-16: 3.2763116359710693
common line69: model saved with val loss 0.6275345222093165

Epoch: 17, 
Train Loss: 0.9198753921424642, 
Validation Loss: 0.6323199681937695
Elapsed time for epoch-17: 2.9763987064361572

Epoch: 18, 
Train Loss: 0.9192486917521773, 
Validation Loss: 0.6385470097884536
Elapsed time for epoch-18: 3.286722421646118

Epoch: 19, 
Train Loss: 0.9187273767565479, 
Validation Loss: 0.6276558386161923
Elapsed time for epoch-19: 4.194271087646484

Epoch: 20, 
Train Loss: 0.9181004041383246, 
Validation Loss: 0.6303595583885908
Elapsed time for epoch-20: 4.071577310562134

Epoch: 21, 
Train Loss: 0.9175191249917535, 
Validation Loss: 0.6340458961203694
Elapsed time for epoch-21: 3.7446205615997314

Epoch: 22, 
Train Loss: 0.9170737503206029, 
Validation Loss: 0.6289577055722475
Elapsed time for epoch-22: 3.4258477687835693

Epoch: 23, 
Train Loss: 0.9170485625998313, 
Validation Loss: 0.6277914382517338
Elapsed time for epoch-23: 3.6096746921539307

Epoch: 24, 
Train Loss: 0.9163881210970277, 
Validation Loss: 0.629616279155016
Elapsed time for epoch-24: 3.9694597721099854

Epoch: 25, 
Train Loss: 0.9161925102983203, 
Validation Loss: 0.6343557713553309
Elapsed time for epoch-25: 4.649154186248779

Epoch: 26, 
Train Loss: 0.9155885671116725, 
Validation Loss: 0.625713556073606
Elapsed time for epoch-26: 3.9977190494537354
common line69: model saved with val loss 0.625713556073606

Epoch: 27, 
Train Loss: 0.9156966210663819, 
Validation Loss: 0.6321589248254895
Elapsed time for epoch-27: 3.5499298572540283

Epoch: 28, 
Train Loss: 0.9153418174060453, 
Validation Loss: 0.6264296304434538
Elapsed time for epoch-28: 3.5666470527648926

Epoch: 29, 
Train Loss: 0.91496576168457, 
Validation Loss: 0.6222156938165426
Elapsed time for epoch-29: 3.538011312484741
common line69: model saved with val loss 0.6222156938165426

Epoch: 30, 
Train Loss: 0.9148467692757855, 
Validation Loss: 0.6277036061510444
Elapsed time for epoch-30: 3.07420015335083

Epoch: 31, 
Train Loss: 0.9145697009663621, 
Validation Loss: 0.6306298952549696
Elapsed time for epoch-31: 3.1207900047302246

train line101: min loss for the epoch 31 is 0.6222156938165426

Training the 61-th turbine in 219.73972630500793 secs

>>>>>>>>> Training Turbine  62 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.861300230026245
lalalalalal
260 [[ 1.          0.26319714 -0.0664823  -0.69963068  0.24539583]
 [ 0.99904822  0.1218798  -0.04941809  0.56539228 -0.04180641]
 [ 0.9961947   0.08150341 -0.05866785  0.56225423 -0.1304514 ]
 [ 0.99144486  0.11322772 -0.0829086   0.55676266 -0.1455314 ]
 [ 0.98480775  0.05554717 -0.1999659   0.54734854 -0.20615724]]
hahahahahahah
265 [[ 0.99985184  1.          0.26319714 -0.0664823  -0.69963068  0.24539583]
 [ 0.99985184  0.99904822  0.1218798  -0.04941809  0.56539228 -0.04180641]
 [ 0.99985184  0.9961947   0.08150341 -0.05866785  0.56225423 -0.1304514 ]
 [ 0.99985184  0.99144486  0.11322772 -0.0829086   0.55676266 -0.1455314 ]
 [ 0.99985184  0.98480775  0.05554717 -0.1999659   0.54734854 -0.20615724]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.26319714 -0.0664823  -0.69963068  0.24539583]
 [ 0.99985184  0.99904822  0.1218798  -0.04941809  0.56539228 -0.04180641]
 [ 0.99985184  0.9961947   0.08150341 -0.05866785  0.56225423 -0.1304514 ]
 [ 0.99985184  0.99144486  0.11322772 -0.0829086   0.55676266 -0.1455314 ]
 [ 0.99985184  0.98480775  0.05554717 -0.1999659   0.54734854 -0.20615724]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.3361563682556152
lalalalalal
260 [[ 1.          0.09448154 -0.00779418 -1.90346183 -0.02151546]
 [ 0.99904822  0.19974854  0.03701931 -1.90581536  0.15693905]
 [ 0.9961947   0.06131522  0.05583779 -1.91052243  0.06817643]
 [ 0.99144486  0.10169161  0.00703734 -1.92150557  0.09873637]
 [ 0.98480775  0.24300895  0.01373544 -1.92072106  0.39000856]]
hahahahahahah
265 [[-0.84754092  1.          0.09448154 -0.00779418 -1.90346183 -0.02151546]
 [-0.84754092  0.99904822  0.19974854  0.03701931 -1.90581536  0.15693905]
 [-0.84754092  0.9961947   0.06131522  0.05583779 -1.91052243  0.06817643]
 [-0.84754092  0.99144486  0.10169161  0.00703734 -1.92150557  0.09873637]
 [-0.84754092  0.98480775  0.24300895  0.01373544 -1.92072106  0.39000856]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.09448154 -0.00779418 -1.90346183 -0.02151546]
 [-0.84754092  0.99904822  0.19974854  0.03701931 -1.90581536  0.15693905]
 [-0.84754092  0.9961947   0.06131522  0.05583779 -1.91052243  0.06817643]
 [-0.84754092  0.99144486  0.10169161  0.00703734 -1.92150557  0.09873637]
 [-0.84754092  0.98480775  0.24300895  0.01373544 -1.92072106  0.39000856]]

Epoch: 0, 
Train Loss: 1.0038395247289114, 
Validation Loss: 0.7331074103713036
Elapsed time for epoch-0: 4.1342267990112305
common line69: model saved with val loss 0.7331074103713036

Epoch: 1, 
Train Loss: 0.9541421471273198, 
Validation Loss: 0.7028343798592687
Elapsed time for epoch-1: 3.9346253871917725
common line69: model saved with val loss 0.7028343798592687

Epoch: 2, 
Train Loss: 0.9437351136648354, 
Validation Loss: 0.6968010626733303
Elapsed time for epoch-2: 3.4478113651275635
common line69: model saved with val loss 0.6968010626733303

Epoch: 3, 
Train Loss: 0.938774656973967, 
Validation Loss: 0.6918014362454414
Elapsed time for epoch-3: 3.37862229347229
common line69: model saved with val loss 0.6918014362454414

Epoch: 4, 
Train Loss: 0.93551481634128, 
Validation Loss: 0.6895817271433771
Elapsed time for epoch-4: 3.614548444747925
common line69: model saved with val loss 0.6895817271433771

Epoch: 5, 
Train Loss: 0.9337369475294562, 
Validation Loss: 0.6928785024210811
Elapsed time for epoch-5: 3.259298801422119

Epoch: 6, 
Train Loss: 0.9321744106396908, 
Validation Loss: 0.6854066196829081
Elapsed time for epoch-6: 3.090522527694702
common line69: model saved with val loss 0.6854066196829081

Epoch: 7, 
Train Loss: 0.9306575772391648, 
Validation Loss: 0.6846672240644693
Elapsed time for epoch-7: 3.355626106262207
common line69: model saved with val loss 0.6846672240644693

Epoch: 8, 
Train Loss: 0.9294405042373833, 
Validation Loss: 0.6840782398357987
Elapsed time for epoch-8: 3.604715585708618
common line69: model saved with val loss 0.6840782398357987

Epoch: 9, 
Train Loss: 0.9285835586175197, 
Validation Loss: 0.6836014213040471
Elapsed time for epoch-9: 3.7388458251953125
common line69: model saved with val loss 0.6836014213040471

Epoch: 10, 
Train Loss: 0.9275292392287936, 
Validation Loss: 0.683407511562109
Elapsed time for epoch-10: 3.479172945022583
common line69: model saved with val loss 0.683407511562109

Epoch: 11, 
Train Loss: 0.9269995291192993, 
Validation Loss: 0.6862418223172426
Elapsed time for epoch-11: 3.1600749492645264

Epoch: 12, 
Train Loss: 0.9264613099458838, 
Validation Loss: 0.6787407593801618
Elapsed time for epoch-12: 3.847477436065674
common line69: model saved with val loss 0.6787407593801618

Epoch: 13, 
Train Loss: 0.9256710334986198, 
Validation Loss: 0.6792225064709783
Elapsed time for epoch-13: 3.3367419242858887

Epoch: 14, 
Train Loss: 0.9249622641491289, 
Validation Loss: 0.6772538833320141
Elapsed time for epoch-14: 3.809399366378784
common line69: model saved with val loss 0.6772538833320141

Epoch: 15, 
Train Loss: 0.9242007272834537, 
Validation Loss: 0.6823722664266825
Elapsed time for epoch-15: 4.191335678100586

Epoch: 16, 
Train Loss: 0.9231818062918526, 
Validation Loss: 0.676683004014194
Elapsed time for epoch-16: 4.4367101192474365
common line69: model saved with val loss 0.676683004014194

Epoch: 17, 
Train Loss: 0.9228791684663596, 
Validation Loss: 0.6820037700235844
Elapsed time for epoch-17: 3.9046547412872314

Epoch: 18, 
Train Loss: 0.9221381625207532, 
Validation Loss: 0.6741746729239821
Elapsed time for epoch-18: 4.140533685684204
common line69: model saved with val loss 0.6741746729239821

Epoch: 19, 
Train Loss: 0.9213837033309856, 
Validation Loss: 0.6735295318067074
Elapsed time for epoch-19: 3.7959651947021484
common line69: model saved with val loss 0.6735295318067074

Epoch: 20, 
Train Loss: 0.9208971693986604, 
Validation Loss: 0.6714510452002287
Elapsed time for epoch-20: 3.0118367671966553
common line69: model saved with val loss 0.6714510452002287

Epoch: 21, 
Train Loss: 0.9202230532630151, 
Validation Loss: 0.6719436952844262
Elapsed time for epoch-21: 3.2926666736602783

Epoch: 22, 
Train Loss: 0.9196955602960426, 
Validation Loss: 0.6769165005534887
Elapsed time for epoch-22: 3.668093681335449

Epoch: 23, 
Train Loss: 0.9190151973181412, 
Validation Loss: 0.6694507570937276
Elapsed time for epoch-23: 3.4353532791137695
common line69: model saved with val loss 0.6694507570937276

Epoch: 24, 
Train Loss: 0.9186035906817732, 
Validation Loss: 0.6739479340612888
Elapsed time for epoch-24: 3.795736074447632

Epoch: 25, 
Train Loss: 0.9183015233578802, 
Validation Loss: 0.6713521489873528
Elapsed time for epoch-25: 4.312231540679932

Epoch: 26, 
Train Loss: 0.9176795776902127, 
Validation Loss: 0.6686499621719122
Elapsed time for epoch-26: 3.7589707374572754
common line69: model saved with val loss 0.6686499621719122

Epoch: 27, 
Train Loss: 0.9173879545776784, 
Validation Loss: 0.6710712676867843
Elapsed time for epoch-27: 3.5001556873321533

Epoch: 28, 
Train Loss: 0.9169654712206176, 
Validation Loss: 0.6671399315819144
Elapsed time for epoch-28: 3.014434576034546
common line69: model saved with val loss 0.6671399315819144

Epoch: 29, 
Train Loss: 0.9169409550538584, 
Validation Loss: 0.6704323068261147
Elapsed time for epoch-29: 4.19987154006958

Epoch: 30, 
Train Loss: 0.9165094615030689, 
Validation Loss: 0.6749552367255092
Elapsed time for epoch-30: 3.5255908966064453

Epoch: 31, 
Train Loss: 0.9166075030044347, 
Validation Loss: 0.6728819534182549
Elapsed time for epoch-31: 3.774575710296631

train line101: min loss for the epoch 31 is 0.6671399315819144

Training the 62-th turbine in 224.1046690940857 secs

>>>>>>>>> Training Turbine  63 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.5274555683135986
lalalalalal
260 [[ 1.          0.34192735 -0.05512563 -0.61549225  0.25035593]
 [ 0.99904822  0.03371791  0.07567254  0.47105406 -0.04277867]
 [ 0.9961947  -0.02289199  0.03464387  0.47105406 -0.10037555]
 [ 0.99144486 -0.02918197  0.03279296  0.46719764 -0.10533673]
 [ 0.98480775 -0.07321189 -0.02952127  0.46012754 -0.17158023]]
hahahahahahah
265 [[ 0.99985184  1.          0.34192735 -0.05512563 -0.61549225  0.25035593]
 [ 0.99985184  0.99904822  0.03371791  0.07567254  0.47105406 -0.04277867]
 [ 0.99985184  0.9961947  -0.02289199  0.03464387  0.47105406 -0.10037555]
 [ 0.99985184  0.99144486 -0.02918197  0.03279296  0.46719764 -0.10533673]
 [ 0.99985184  0.98480775 -0.07321189 -0.02952127  0.46012754 -0.17158023]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.34192735 -0.05512563 -0.61549225  0.25035593]
 [ 0.99985184  0.99904822  0.03371791  0.07567254  0.47105406 -0.04277867]
 [ 0.99985184  0.9961947  -0.02289199  0.03464387  0.47105406 -0.10037555]
 [ 0.99985184  0.99144486 -0.02918197  0.03279296  0.46719764 -0.10533673]
 [ 0.99985184  0.98480775 -0.07321189 -0.02952127  0.46012754 -0.17158023]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 5.576809883117676
lalalalalal
260 [[ 1.         -0.02446448 -0.11435499 -1.54553218 -0.06144214]
 [ 0.99904822  0.07774783 -0.1072598  -1.54456808  0.04876683]
 [ 0.9961947   0.03057292 -0.12021623 -1.55292365  0.12368059]
 [ 0.99144486  0.02742792 -0.15106485 -1.55870828  0.11460872]
 [ 0.98480775  0.25072252 -0.16494673 -1.55935102  0.42732815]]
hahahahahahah
265 [[-0.84754092  1.         -0.02446448 -0.11435499 -1.54553218 -0.06144214]
 [-0.84754092  0.99904822  0.07774783 -0.1072598  -1.54456808  0.04876683]
 [-0.84754092  0.9961947   0.03057292 -0.12021623 -1.55292365  0.12368059]
 [-0.84754092  0.99144486  0.02742792 -0.15106485 -1.55870828  0.11460872]
 [-0.84754092  0.98480775  0.25072252 -0.16494673 -1.55935102  0.42732815]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.02446448 -0.11435499 -1.54553218 -0.06144214]
 [-0.84754092  0.99904822  0.07774783 -0.1072598  -1.54456808  0.04876683]
 [-0.84754092  0.9961947   0.03057292 -0.12021623 -1.55292365  0.12368059]
 [-0.84754092  0.99144486  0.02742792 -0.15106485 -1.55870828  0.11460872]
 [-0.84754092  0.98480775  0.25072252 -0.16494673 -1.55935102  0.42732815]]

Epoch: 0, 
Train Loss: 1.0069447110931413, 
Validation Loss: 0.679566403850913
Elapsed time for epoch-0: 4.074867486953735
common line69: model saved with val loss 0.679566403850913

Epoch: 1, 
Train Loss: 0.959811699741027, 
Validation Loss: 0.6438488904386759
Elapsed time for epoch-1: 3.742588520050049
common line69: model saved with val loss 0.6438488904386759

Epoch: 2, 
Train Loss: 0.9491937827913701, 
Validation Loss: 0.6418871097266674
Elapsed time for epoch-2: 2.8927242755889893
common line69: model saved with val loss 0.6418871097266674

Epoch: 3, 
Train Loss: 0.9429188326877707, 
Validation Loss: 0.62585126189515
Elapsed time for epoch-3: 3.2890784740448
common line69: model saved with val loss 0.62585126189515

Epoch: 4, 
Train Loss: 0.9389368491012509, 
Validation Loss: 0.6272109402343631
Elapsed time for epoch-4: 3.0035347938537598

Epoch: 5, 
Train Loss: 0.9358596706590733, 
Validation Loss: 0.628958573564887
Elapsed time for epoch-5: 2.8234591484069824

Epoch: 6, 
Train Loss: 0.9338038851733969, 
Validation Loss: 0.627291839569807
Elapsed time for epoch-6: 2.9895424842834473

Epoch: 7, 
Train Loss: 0.9320787628408239, 
Validation Loss: 0.622071242891252
Elapsed time for epoch-7: 2.7513680458068848
common line69: model saved with val loss 0.622071242891252

Epoch: 8, 
Train Loss: 0.9308790657199731, 
Validation Loss: 0.6212303582578897
Elapsed time for epoch-8: 2.890925884246826
common line69: model saved with val loss 0.6212303582578897

Epoch: 9, 
Train Loss: 0.9296122804409316, 
Validation Loss: 0.6220988519489765
Elapsed time for epoch-9: 2.9486031532287598

Epoch: 10, 
Train Loss: 0.9283717169481165, 
Validation Loss: 0.6221155766397715
Elapsed time for epoch-10: 2.742197275161743

Epoch: 11, 
Train Loss: 0.9274625868356529, 
Validation Loss: 0.6187113095074892
Elapsed time for epoch-11: 3.0019919872283936
common line69: model saved with val loss 0.6187113095074892

Epoch: 12, 
Train Loss: 0.9265718498901159, 
Validation Loss: 0.6166173908859491
Elapsed time for epoch-12: 2.891474962234497
common line69: model saved with val loss 0.6166173908859491

Epoch: 13, 
Train Loss: 0.9257928469852239, 
Validation Loss: 0.6201587081886828
Elapsed time for epoch-13: 2.7791786193847656

Epoch: 14, 
Train Loss: 0.9250354294766899, 
Validation Loss: 0.6105672242119908
Elapsed time for epoch-14: 3.007554769515991
common line69: model saved with val loss 0.6105672242119908

Epoch: 15, 
Train Loss: 0.924308886047171, 
Validation Loss: 0.6177010620012879
Elapsed time for epoch-15: 2.829272985458374

Epoch: 16, 
Train Loss: 0.923423033927669, 
Validation Loss: 0.6148486863821745
Elapsed time for epoch-16: 2.921661138534546

Epoch: 17, 
Train Loss: 0.9227139877171076, 
Validation Loss: 0.610911653842777
Elapsed time for epoch-17: 3.0457425117492676

Epoch: 18, 
Train Loss: 0.9220392105459165, 
Validation Loss: 0.6199078476056457
Elapsed time for epoch-18: 3.5423219203948975

Epoch: 19, 
Train Loss: 0.921594137654585, 
Validation Loss: 0.6171291070058942
Elapsed time for epoch-19: 4.297673463821411

Epoch: 20, 
Train Loss: 0.9209964322943648, 
Validation Loss: 0.6169790085405111
Elapsed time for epoch-20: 4.438080549240112

Epoch: 21, 
Train Loss: 0.9205985170702974, 
Validation Loss: 0.6165919904597104
Elapsed time for epoch-21: 4.287381172180176

Epoch: 22, 
Train Loss: 0.9199829305670842, 
Validation Loss: 0.6188522502779961
Elapsed time for epoch-22: 3.4960854053497314

Epoch: 23, 
Train Loss: 0.9196517368575104, 
Validation Loss: 0.6151122655719519
Elapsed time for epoch-23: 4.708448171615601

Epoch: 24, 
Train Loss: 0.9192272449741844, 
Validation Loss: 0.6149896983988583
Elapsed time for epoch-24: 3.4051246643066406

Epoch: 25, 
Train Loss: 0.9182823712334913, 
Validation Loss: 0.6181808793917298
Elapsed time for epoch-25: 3.434321641921997

Epoch: 26, 
Train Loss: 0.9181487333624303, 
Validation Loss: 0.6191512700170279
Elapsed time for epoch-26: 3.134756565093994
Early stopped! 

train line101: min loss for the epoch 26 is 0.6105672242119908

Training the 63-th turbine in 196.31291365623474 secs

>>>>>>>>> Training Turbine  64 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 5.043346166610718
lalalalalal
260 [[ 1.          0.20195524 -0.2202943  -0.38955362  0.29279226]
 [ 0.99904822  0.01886221 -0.26835836  0.35062605 -0.15572628]
 [ 0.9961947  -0.07960799 -0.01352206  0.34687409 -0.26465758]
 [ 0.99144486 -0.14730625  0.13454105  0.34103769 -0.30411491]
 [ 0.98480775 -0.15038345  0.0561547   0.33645196 -0.30660823]]
hahahahahahah
265 [[ 0.99985184  1.          0.20195524 -0.2202943  -0.38955362  0.29279226]
 [ 0.99985184  0.99904822  0.01886221 -0.26835836  0.35062605 -0.15572628]
 [ 0.99985184  0.9961947  -0.07960799 -0.01352206  0.34687409 -0.26465758]
 [ 0.99985184  0.99144486 -0.14730625  0.13454105  0.34103769 -0.30411491]
 [ 0.99985184  0.98480775 -0.15038345  0.0561547   0.33645196 -0.30660823]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.20195524 -0.2202943  -0.38955362  0.29279226]
 [ 0.99985184  0.99904822  0.01886221 -0.26835836  0.35062605 -0.15572628]
 [ 0.99985184  0.9961947  -0.07960799 -0.01352206  0.34687409 -0.26465758]
 [ 0.99985184  0.99144486 -0.14730625  0.13454105  0.34103769 -0.30411491]
 [ 0.99985184  0.98480775 -0.15038345  0.0561547   0.33645196 -0.30660823]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.807141065597534
lalalalalal
260 [[ 1.         -0.2211589  -0.08513429 -0.87835151 -0.13432734]
 [ 0.99904822 -0.31655191 -0.19513324 -0.90002954 -0.2236752 ]
 [ 0.9961947  -0.21808171 -0.22287492 -0.89044118 -0.15759022]
 [ 0.99144486 -0.10422554  0.04518706 -0.88877364  0.01771654]
 [ 0.98480775  0.03424818 -0.11158565 -0.8871061   0.21161424]]
hahahahahahah
265 [[-0.84754092  1.         -0.2211589  -0.08513429 -0.87835151 -0.13432734]
 [-0.84754092  0.99904822 -0.31655191 -0.19513324 -0.90002954 -0.2236752 ]
 [-0.84754092  0.9961947  -0.21808171 -0.22287492 -0.89044118 -0.15759022]
 [-0.84754092  0.99144486 -0.10422554  0.04518706 -0.88877364  0.01771654]
 [-0.84754092  0.98480775  0.03424818 -0.11158565 -0.8871061   0.21161424]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.2211589  -0.08513429 -0.87835151 -0.13432734]
 [-0.84754092  0.99904822 -0.31655191 -0.19513324 -0.90002954 -0.2236752 ]
 [-0.84754092  0.9961947  -0.21808171 -0.22287492 -0.89044118 -0.15759022]
 [-0.84754092  0.99144486 -0.10422554  0.04518706 -0.88877364  0.01771654]
 [-0.84754092  0.98480775  0.03424818 -0.11158565 -0.8871061   0.21161424]]

Epoch: 0, 
Train Loss: 1.007636548716481, 
Validation Loss: 0.5714683048427105
Elapsed time for epoch-0: 4.053041934967041
common line69: model saved with val loss 0.5714683048427105

Epoch: 1, 
Train Loss: 0.9656013348022429, 
Validation Loss: 0.5276424651965499
Elapsed time for epoch-1: 4.40548300743103
common line69: model saved with val loss 0.5276424651965499

Epoch: 2, 
Train Loss: 0.951302226977188, 
Validation Loss: 0.5137085071764886
Elapsed time for epoch-2: 3.733973741531372
common line69: model saved with val loss 0.5137085071764886

Epoch: 3, 
Train Loss: 0.9442296510233599, 
Validation Loss: 0.502753930632025
Elapsed time for epoch-3: 3.860933780670166
common line69: model saved with val loss 0.502753930632025

Epoch: 4, 
Train Loss: 0.9395260688136605, 
Validation Loss: 0.49745672661811113
Elapsed time for epoch-4: 3.830082893371582
common line69: model saved with val loss 0.49745672661811113

Epoch: 5, 
Train Loss: 0.935896270540582, 
Validation Loss: 0.4977726526558399
Elapsed time for epoch-5: 4.276133298873901

Epoch: 6, 
Train Loss: 0.9331849537977651, 
Validation Loss: 0.49439628701657057
Elapsed time for epoch-6: 4.15391206741333
common line69: model saved with val loss 0.49439628701657057

Epoch: 7, 
Train Loss: 0.9310489941795334, 
Validation Loss: 0.49473671708256006
Elapsed time for epoch-7: 4.01197624206543

Epoch: 8, 
Train Loss: 0.9298130419073987, 
Validation Loss: 0.4974649418145418
Elapsed time for epoch-8: 4.05145263671875

Epoch: 9, 
Train Loss: 0.9284567605046665, 
Validation Loss: 0.49277712451294065
Elapsed time for epoch-9: 3.9860100746154785
common line69: model saved with val loss 0.49277712451294065

Epoch: 10, 
Train Loss: 0.9275105089700523, 
Validation Loss: 0.4938467824831605
Elapsed time for epoch-10: 3.239814281463623

Epoch: 11, 
Train Loss: 0.9266017518874978, 
Validation Loss: 0.4999076360836625
Elapsed time for epoch-11: 3.6552443504333496

Epoch: 12, 
Train Loss: 0.9260477045503985, 
Validation Loss: 0.49477260652929544
Elapsed time for epoch-12: 3.3519158363342285

Epoch: 13, 
Train Loss: 0.9252385102650699, 
Validation Loss: 0.4968028385192156
Elapsed time for epoch-13: 3.554818630218506

Epoch: 14, 
Train Loss: 0.9247468451992804, 
Validation Loss: 0.49681587191298604
Elapsed time for epoch-14: 3.5355169773101807

Epoch: 15, 
Train Loss: 0.9242198041507176, 
Validation Loss: 0.4977334695868194
Elapsed time for epoch-15: 3.7168514728546143

Epoch: 16, 
Train Loss: 0.9237909184283569, 
Validation Loss: 0.49345523305237293
Elapsed time for epoch-16: 3.4876198768615723

Epoch: 17, 
Train Loss: 0.9234022554479727, 
Validation Loss: 0.49904677737504244
Elapsed time for epoch-17: 3.615767478942871

Epoch: 18, 
Train Loss: 0.9228532598549578, 
Validation Loss: 0.49230621801689267
Elapsed time for epoch-18: 3.6083130836486816
common line69: model saved with val loss 0.49230621801689267

Epoch: 19, 
Train Loss: 0.9228457250014073, 
Validation Loss: 0.49769962346181273
Elapsed time for epoch-19: 3.3032333850860596

Epoch: 20, 
Train Loss: 0.9223778812574739, 
Validation Loss: 0.4964213171042502
Elapsed time for epoch-20: 3.540048360824585

Epoch: 21, 
Train Loss: 0.9219011416455277, 
Validation Loss: 0.4956071893684566
Elapsed time for epoch-21: 3.3657445907592773

Epoch: 22, 
Train Loss: 0.9219096328030113, 
Validation Loss: 0.49474579654634
Elapsed time for epoch-22: 3.6863605976104736

Epoch: 23, 
Train Loss: 0.921670581738488, 
Validation Loss: 0.5047028679400682
Elapsed time for epoch-23: 3.284675359725952

Epoch: 24, 
Train Loss: 0.9215649343839213, 
Validation Loss: 0.49215985694900155
Elapsed time for epoch-24: 3.464709520339966
common line69: model saved with val loss 0.49215985694900155

Epoch: 25, 
Train Loss: 0.921283760867199, 
Validation Loss: 0.49065328715369105
Elapsed time for epoch-25: 2.9431183338165283
common line69: model saved with val loss 0.49065328715369105

Epoch: 26, 
Train Loss: 0.9208901488230008, 
Validation Loss: 0.49035486252978444
Elapsed time for epoch-26: 3.27152943611145
common line69: model saved with val loss 0.49035486252978444

Epoch: 27, 
Train Loss: 0.9205031408732679, 
Validation Loss: 0.4921581386588514
Elapsed time for epoch-27: 4.317965269088745

Epoch: 28, 
Train Loss: 0.9202891995175546, 
Validation Loss: 0.4950073193758726
Elapsed time for epoch-28: 4.056734800338745

Epoch: 29, 
Train Loss: 0.9198067333517956, 
Validation Loss: 0.4964015195146203
Elapsed time for epoch-29: 3.6181538105010986

Epoch: 30, 
Train Loss: 0.9197535740227258, 
Validation Loss: 0.49278904823586345
Elapsed time for epoch-30: 3.7385518550872803

Epoch: 31, 
Train Loss: 0.9196845974240985, 
Validation Loss: 0.4941531331278384
Elapsed time for epoch-31: 3.52225399017334

train line101: min loss for the epoch 31 is 0.49035486252978444

Training the 64-th turbine in 221.10692739486694 secs

>>>>>>>>> Training Turbine  65 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.0997231006622314
lalalalalal
260 [[ 1.          0.29639067 -0.02329756 -0.32432219  0.75657031]
 [ 0.99904822 -0.20427047 -0.19351562  0.39235886 -0.24493622]
 [ 0.9961947  -0.25017636 -0.24618327  0.3893581  -0.28925098]
 [ 0.99144486 -0.34198814 -0.20493752  0.38385671 -0.35213193]
 [ 0.98480775 -0.37928668  0.06696718  0.37935557 -0.36588641]]
hahahahahahah
265 [[ 0.99985184  1.          0.29639067 -0.02329756 -0.32432219  0.75657031]
 [ 0.99985184  0.99904822 -0.20427047 -0.19351562  0.39235886 -0.24493622]
 [ 0.99985184  0.9961947  -0.25017636 -0.24618327  0.3893581  -0.28925098]
 [ 0.99985184  0.99144486 -0.34198814 -0.20493752  0.38385671 -0.35213193]
 [ 0.99985184  0.98480775 -0.37928668  0.06696718  0.37935557 -0.36588641]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.29639067 -0.02329756 -0.32432219  0.75657031]
 [ 0.99985184  0.99904822 -0.20427047 -0.19351562  0.39235886 -0.24493622]
 [ 0.99985184  0.9961947  -0.25017636 -0.24618327  0.3893581  -0.28925098]
 [ 0.99985184  0.99144486 -0.34198814 -0.20493752  0.38385671 -0.35213193]
 [ 0.99985184  0.98480775 -0.37928668  0.06696718  0.37935557 -0.36588641]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.112409830093384
lalalalalal
260 [[ 1.          0.06542665 -0.06724016 -1.18153875  0.08192034]
 [ 0.99904822  0.1055943  -0.15544261 -1.18353926  0.10636622]
 [ 0.9961947  -0.03212337 -0.14433799 -1.18603989  0.09791638]
 [ 0.99144486  0.16297667 -0.18526647 -1.18603989  0.27055147]
 [ 0.98480775  0.22035903 -0.17130636 -1.18754027  0.41255587]]
hahahahahahah
265 [[-0.84754092  1.          0.06542665 -0.06724016 -1.18153875  0.08192034]
 [-0.84754092  0.99904822  0.1055943  -0.15544261 -1.18353926  0.10636622]
 [-0.84754092  0.9961947  -0.03212337 -0.14433799 -1.18603989  0.09791638]
 [-0.84754092  0.99144486  0.16297667 -0.18526647 -1.18603989  0.27055147]
 [-0.84754092  0.98480775  0.22035903 -0.17130636 -1.18754027  0.41255587]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.06542665 -0.06724016 -1.18153875  0.08192034]
 [-0.84754092  0.99904822  0.1055943  -0.15544261 -1.18353926  0.10636622]
 [-0.84754092  0.9961947  -0.03212337 -0.14433799 -1.18603989  0.09791638]
 [-0.84754092  0.99144486  0.16297667 -0.18526647 -1.18603989  0.27055147]
 [-0.84754092  0.98480775  0.22035903 -0.17130636 -1.18754027  0.41255587]]

Epoch: 0, 
Train Loss: 0.9851573658089677, 
Validation Loss: 0.657881498336792
Elapsed time for epoch-0: 4.952479839324951
common line69: model saved with val loss 0.657881498336792

Epoch: 1, 
Train Loss: 0.9491630724999083, 
Validation Loss: 0.6379853608086705
Elapsed time for epoch-1: 4.86630654335022
common line69: model saved with val loss 0.6379853608086705

Epoch: 2, 
Train Loss: 0.9403224994404977, 
Validation Loss: 0.6314624515362084
Elapsed time for epoch-2: 4.774477958679199
common line69: model saved with val loss 0.6314624515362084

Epoch: 3, 
Train Loss: 0.9349239044079259, 
Validation Loss: 0.6274409769102931
Elapsed time for epoch-3: 3.833098888397217
common line69: model saved with val loss 0.6274409769102931

Epoch: 4, 
Train Loss: 0.9312406161001751, 
Validation Loss: 0.6209778669290245
Elapsed time for epoch-4: 3.284606695175171
common line69: model saved with val loss 0.6209778669290245

Epoch: 5, 
Train Loss: 0.9277389649333072, 
Validation Loss: 0.6197086917236447
Elapsed time for epoch-5: 3.2930376529693604
common line69: model saved with val loss 0.6197086917236447

Epoch: 6, 
Train Loss: 0.9249155989715031, 
Validation Loss: 0.610347434412688
Elapsed time for epoch-6: 3.155123233795166
common line69: model saved with val loss 0.610347434412688

Epoch: 7, 
Train Loss: 0.9221585473092664, 
Validation Loss: 0.6068125171586871
Elapsed time for epoch-7: 3.131129264831543
common line69: model saved with val loss 0.6068125171586871

Epoch: 8, 
Train Loss: 0.9194415695026141, 
Validation Loss: 0.6105132596567273
Elapsed time for epoch-8: 3.176407814025879

Epoch: 9, 
Train Loss: 0.9179517570413461, 
Validation Loss: 0.6071061114780605
Elapsed time for epoch-9: 3.080390453338623

Epoch: 10, 
Train Loss: 0.9164502521773347, 
Validation Loss: 0.6116850068792701
Elapsed time for epoch-10: 3.3434793949127197

Epoch: 11, 
Train Loss: 0.914990983966018, 
Validation Loss: 0.6107030780985951
Elapsed time for epoch-11: 3.1406710147857666

Epoch: 12, 
Train Loss: 0.9138858921888495, 
Validation Loss: 0.6072547328658402
Elapsed time for epoch-12: 3.2492363452911377

Epoch: 13, 
Train Loss: 0.9127089800704428, 
Validation Loss: 0.6065778988413513
Elapsed time for epoch-13: 3.5521163940429688
common line69: model saved with val loss 0.6065778988413513

Epoch: 14, 
Train Loss: 0.9118392377340493, 
Validation Loss: 0.6003704620525241
Elapsed time for epoch-14: 4.279008388519287
common line69: model saved with val loss 0.6003704620525241

Epoch: 15, 
Train Loss: 0.9108998022910928, 
Validation Loss: 0.6052635181695223
Elapsed time for epoch-15: 3.820815324783325

Epoch: 16, 
Train Loss: 0.9103520889492596, 
Validation Loss: 0.6094527603127062
Elapsed time for epoch-16: 3.7166507244110107

Epoch: 17, 
Train Loss: 0.9098191543036148, 
Validation Loss: 0.6104945060797036
Elapsed time for epoch-17: 4.111887693405151

Epoch: 18, 
Train Loss: 0.9090424394156752, 
Validation Loss: 0.6110758753493428
Elapsed time for epoch-18: 4.061050653457642

Epoch: 19, 
Train Loss: 0.9086180052586964, 
Validation Loss: 0.6074085221625865
Elapsed time for epoch-19: 4.250776767730713

Epoch: 20, 
Train Loss: 0.908089687468625, 
Validation Loss: 0.6028267084620893
Elapsed time for epoch-20: 3.591667413711548

Epoch: 21, 
Train Loss: 0.9073721765219664, 
Validation Loss: 0.6015438176691532
Elapsed time for epoch-21: 3.4339449405670166

Epoch: 22, 
Train Loss: 0.906847178685565, 
Validation Loss: 0.5991717088036239
Elapsed time for epoch-22: 3.657921075820923
common line69: model saved with val loss 0.5991717088036239

Epoch: 23, 
Train Loss: 0.9061663525194681, 
Validation Loss: 0.6040613888762891
Elapsed time for epoch-23: 3.2052078247070312

Epoch: 24, 
Train Loss: 0.9056736034255067, 
Validation Loss: 0.5993195855990052
Elapsed time for epoch-24: 3.2174081802368164

Epoch: 25, 
Train Loss: 0.904877812797282, 
Validation Loss: 0.597779524512589
Elapsed time for epoch-25: 3.2124545574188232
common line69: model saved with val loss 0.597779524512589

Epoch: 26, 
Train Loss: 0.9043152025517296, 
Validation Loss: 0.5942234825342894
Elapsed time for epoch-26: 3.1097400188446045
common line69: model saved with val loss 0.5942234825342894

Epoch: 27, 
Train Loss: 0.9032619835949746, 
Validation Loss: 0.5947824716567993
Elapsed time for epoch-27: 3.2684574127197266

Epoch: 28, 
Train Loss: 0.903153814062351, 
Validation Loss: 0.5976986913010478
Elapsed time for epoch-28: 2.997758388519287

Epoch: 29, 
Train Loss: 0.9023479908203879, 
Validation Loss: 0.6020546178333461
Elapsed time for epoch-29: 3.437182903289795

Epoch: 30, 
Train Loss: 0.9016668281885756, 
Validation Loss: 0.5954583366401494
Elapsed time for epoch-30: 3.8103396892547607

Epoch: 31, 
Train Loss: 0.9014989093822592, 
Validation Loss: 0.5938300057314336
Elapsed time for epoch-31: 4.579717397689819
common line69: model saved with val loss 0.5938300057314336

train line101: min loss for the epoch 31 is 0.5938300057314336

Training the 65-th turbine in 219.62812972068787 secs

>>>>>>>>> Training Turbine  66 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.815013647079468
lalalalalal
260 [[ 1.          0.48218775 -0.06358129 -1.74899857  0.79468444]
 [ 0.99904822  0.00224193 -0.17638042  0.27781391 -0.22624328]
 [ 0.9961947  -0.06060812 -0.25040485  0.27781391 -0.2825147 ]
 [ 0.99144486 -0.12345817 -0.2507253   0.27781391 -0.35442102]
 [ 0.98480775 -0.10060361 -0.26770926  0.27781391 -0.33410275]]
hahahahahahah
265 [[ 0.99985184  1.          0.48218775 -0.06358129 -1.74899857  0.79468444]
 [ 0.99985184  0.99904822  0.00224193 -0.17638042  0.27781391 -0.22624328]
 [ 0.99985184  0.9961947  -0.06060812 -0.25040485  0.27781391 -0.2825147 ]
 [ 0.99985184  0.99144486 -0.12345817 -0.2507253   0.27781391 -0.35442102]
 [ 0.99985184  0.98480775 -0.10060361 -0.26770926  0.27781391 -0.33410275]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.48218775 -0.06358129 -1.74899857  0.79468444]
 [ 0.99985184  0.99904822  0.00224193 -0.17638042  0.27781391 -0.22624328]
 [ 0.99985184  0.9961947  -0.06060812 -0.25040485  0.27781391 -0.2825147 ]
 [ 0.99985184  0.99144486 -0.12345817 -0.2507253   0.27781391 -0.35442102]
 [ 0.99985184  0.98480775 -0.10060361 -0.26770926  0.27781391 -0.33410275]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.2268261909484863
lalalalalal
260 [[ 1.         -0.08917632 -0.0882561   0.27781391 -0.1411502 ]
 [ 0.99904822 -0.14916955 -0.11805814  0.27781391 -0.16975898]
 [ 0.9961947  -0.25487191  0.135099    0.27781391 -0.1939091 ]
 [ 0.99144486 -0.05203766  0.04505197  0.27781391  0.03351827]
 [ 0.98480775  0.07080562  0.01557038  0.27781391  0.1247021 ]]
hahahahahahah
265 [[-0.84754092  1.         -0.08917632 -0.0882561   0.27781391 -0.1411502 ]
 [-0.84754092  0.99904822 -0.14916955 -0.11805814  0.27781391 -0.16975898]
 [-0.84754092  0.9961947  -0.25487191  0.135099    0.27781391 -0.1939091 ]
 [-0.84754092  0.99144486 -0.05203766  0.04505197  0.27781391  0.03351827]
 [-0.84754092  0.98480775  0.07080562  0.01557038  0.27781391  0.1247021 ]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.08917632 -0.0882561   0.27781391 -0.1411502 ]
 [-0.84754092  0.99904822 -0.14916955 -0.11805814  0.27781391 -0.16975898]
 [-0.84754092  0.9961947  -0.25487191  0.135099    0.27781391 -0.1939091 ]
 [-0.84754092  0.99144486 -0.05203766  0.04505197  0.27781391  0.03351827]
 [-0.84754092  0.98480775  0.07080562  0.01557038  0.27781391  0.1247021 ]]

Epoch: 0, 
Train Loss: 1.006385521227572, 
Validation Loss: 0.6227872185409069
Elapsed time for epoch-0: 3.9413771629333496
common line69: model saved with val loss 0.6227872185409069

Epoch: 1, 
Train Loss: 0.9617034158035487, 
Validation Loss: 0.5788403484039009
Elapsed time for epoch-1: 3.8480312824249268
common line69: model saved with val loss 0.5788403484039009

Epoch: 2, 
Train Loss: 0.9461672746834635, 
Validation Loss: 0.5809880853630602
Elapsed time for epoch-2: 3.6484811305999756

Epoch: 3, 
Train Loss: 0.9386451862940267, 
Validation Loss: 0.5712445606477559
Elapsed time for epoch-3: 3.5768320560455322
common line69: model saved with val loss 0.5712445606477559

Epoch: 4, 
Train Loss: 0.9338033568708837, 
Validation Loss: 0.5759851182810962
Elapsed time for epoch-4: 3.7473864555358887

Epoch: 5, 
Train Loss: 0.9307738994600392, 
Validation Loss: 0.5723524601198733
Elapsed time for epoch-5: 4.087685585021973

Epoch: 6, 
Train Loss: 0.9287108141584557, 
Validation Loss: 0.5649537038989365
Elapsed time for epoch-6: 5.003519296646118
common line69: model saved with val loss 0.5649537038989365

Epoch: 7, 
Train Loss: 0.9267353440533165, 
Validation Loss: 0.5649399673566222
Elapsed time for epoch-7: 5.011476993560791
common line69: model saved with val loss 0.5649399673566222

Epoch: 8, 
Train Loss: 0.9257936239743433, 
Validation Loss: 0.5661234436556697
Elapsed time for epoch-8: 4.542308807373047

Epoch: 9, 
Train Loss: 0.9245644696369892, 
Validation Loss: 0.567124757450074
Elapsed time for epoch-9: 3.890432596206665

Epoch: 10, 
Train Loss: 0.9238916301176328, 
Validation Loss: 0.5634385528974235
Elapsed time for epoch-10: 3.399287223815918
common line69: model saved with val loss 0.5634385528974235

Epoch: 11, 
Train Loss: 0.922961830717175, 
Validation Loss: 0.5628789607435465
Elapsed time for epoch-11: 3.286607503890991
common line69: model saved with val loss 0.5628789607435465

Epoch: 12, 
Train Loss: 0.9226615044499645, 
Validation Loss: 0.5658206073567271
Elapsed time for epoch-12: 3.2813305854797363

Epoch: 13, 
Train Loss: 0.9217016599258455, 
Validation Loss: 0.5616056509315968
Elapsed time for epoch-13: 2.7955682277679443
common line69: model saved with val loss 0.5616056509315968

Epoch: 14, 
Train Loss: 0.9215903166963273, 
Validation Loss: 0.5613201009109616
Elapsed time for epoch-14: 3.2336668968200684
common line69: model saved with val loss 0.5613201009109616

Epoch: 15, 
Train Loss: 0.9210186926256708, 
Validation Loss: 0.5659745652228594
Elapsed time for epoch-15: 3.050985813140869

Epoch: 16, 
Train Loss: 0.9205251367402678, 
Validation Loss: 0.5653358553536236
Elapsed time for epoch-16: 3.3844590187072754

Epoch: 17, 
Train Loss: 0.9202872899149647, 
Validation Loss: 0.5648868796415627
Elapsed time for epoch-17: 3.5211567878723145

Epoch: 18, 
Train Loss: 0.9196019319175672, 
Validation Loss: 0.5641172043979168
Elapsed time for epoch-18: 3.298701763153076

Epoch: 19, 
Train Loss: 0.9196872282929781, 
Validation Loss: 0.564630888402462
Elapsed time for epoch-19: 3.286458730697632

Epoch: 20, 
Train Loss: 0.9192651912194341, 
Validation Loss: 0.5650188736617565
Elapsed time for epoch-20: 3.0633955001831055

Epoch: 21, 
Train Loss: 0.9189907725618667, 
Validation Loss: 0.5602123863063753
Elapsed time for epoch-21: 3.1690237522125244
common line69: model saved with val loss 0.5602123863063753

Epoch: 22, 
Train Loss: 0.9185975324205992, 
Validation Loss: 0.5645444933325052
Elapsed time for epoch-22: 3.806854248046875

Epoch: 23, 
Train Loss: 0.9182591956703603, 
Validation Loss: 0.566546194255352
Elapsed time for epoch-23: 4.489084482192993

Epoch: 24, 
Train Loss: 0.9177470596648064, 
Validation Loss: 0.5650793830864131
Elapsed time for epoch-24: 3.9863362312316895

Epoch: 25, 
Train Loss: 0.9177698456690091, 
Validation Loss: 0.568465759512037
Elapsed time for epoch-25: 3.5175466537475586

Epoch: 26, 
Train Loss: 0.9175654761180156, 
Validation Loss: 0.562789052259177
Elapsed time for epoch-26: 4.202902555465698

Epoch: 27, 
Train Loss: 0.9169197548337343, 
Validation Loss: 0.5616407142952085
Elapsed time for epoch-27: 4.328101634979248

Epoch: 28, 
Train Loss: 0.916783683941144, 
Validation Loss: 0.5629191561602056
Elapsed time for epoch-28: 4.390897989273071

Epoch: 29, 
Train Loss: 0.9162996647989049, 
Validation Loss: 0.5607519657351077
Elapsed time for epoch-29: 4.39175820350647

Epoch: 30, 
Train Loss: 0.9156233313955179, 
Validation Loss: 0.564390133600682
Elapsed time for epoch-30: 4.259697198867798

Epoch: 31, 
Train Loss: 0.9152743123910007, 
Validation Loss: 0.5661551156081259
Elapsed time for epoch-31: 4.18300461769104

train line101: min loss for the epoch 31 is 0.5602123863063753

Training the 66-th turbine in 224.28180646896362 secs

>>>>>>>>> Training Turbine  67 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.350757598876953
lalalalalal
260 [[ 1.          0.59080512 -0.13387418 -0.06805448  0.84395494]
 [ 0.99904822  0.0921335  -0.18289287  0.28083964 -0.19229474]
 [ 0.9961947   0.04197126 -0.24901876  0.28083964 -0.26298833]
 [ 0.99144486  0.02426695 -0.28520706  0.28083964 -0.3214303 ]
 [ 0.98480775  0.05672486 -0.29968238  0.28083964 -0.28768415]]
hahahahahahah
265 [[ 0.99985184  1.          0.59080512 -0.13387418 -0.06805448  0.84395494]
 [ 0.99985184  0.99904822  0.0921335  -0.18289287  0.28083964 -0.19229474]
 [ 0.99985184  0.9961947   0.04197126 -0.24901876  0.28083964 -0.26298833]
 [ 0.99985184  0.99144486  0.02426695 -0.28520706  0.28083964 -0.3214303 ]
 [ 0.99985184  0.98480775  0.05672486 -0.29968238  0.28083964 -0.28768415]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.59080512 -0.13387418 -0.06805448  0.84395494]
 [ 0.99985184  0.99904822  0.0921335  -0.18289287  0.28083964 -0.19229474]
 [ 0.99985184  0.9961947   0.04197126 -0.24901876  0.28083964 -0.26298833]
 [ 0.99985184  0.99144486  0.02426695 -0.28520706  0.28083964 -0.3214303 ]
 [ 0.99985184  0.98480775  0.05672486 -0.29968238  0.28083964 -0.28768415]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.9183566570281982
lalalalalal
260 [[ 1.          0.17917973 -0.06988669  0.28083964  0.22207034]
 [ 0.99904822  0.2573738   0.0260123   0.28083964  0.37628684]
 [ 0.9961947   0.18655653 -0.01445279  0.28083964  0.29685584]
 [ 0.99144486  0.21016228 -0.05064109  0.28083964  0.29642258]
 [ 0.98480775  0.2721274  -0.0845265   0.28083964  0.32407901]]
hahahahahahah
265 [[-0.84754092  1.          0.17917973 -0.06988669  0.28083964  0.22207034]
 [-0.84754092  0.99904822  0.2573738   0.0260123   0.28083964  0.37628684]
 [-0.84754092  0.9961947   0.18655653 -0.01445279  0.28083964  0.29685584]
 [-0.84754092  0.99144486  0.21016228 -0.05064109  0.28083964  0.29642258]
 [-0.84754092  0.98480775  0.2721274  -0.0845265   0.28083964  0.32407901]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.17917973 -0.06988669  0.28083964  0.22207034]
 [-0.84754092  0.99904822  0.2573738   0.0260123   0.28083964  0.37628684]
 [-0.84754092  0.9961947   0.18655653 -0.01445279  0.28083964  0.29685584]
 [-0.84754092  0.99144486  0.21016228 -0.05064109  0.28083964  0.29642258]
 [-0.84754092  0.98480775  0.2721274  -0.0845265   0.28083964  0.32407901]]

Epoch: 0, 
Train Loss: 1.0010519048997335, 
Validation Loss: 0.6333728516474366
Elapsed time for epoch-0: 3.1460375785827637
common line69: model saved with val loss 0.6333728516474366

Epoch: 1, 
Train Loss: 0.9564404702987992, 
Validation Loss: 0.6249479949474335
Elapsed time for epoch-1: 3.2056446075439453
common line69: model saved with val loss 0.6249479949474335

Epoch: 2, 
Train Loss: 0.9469050748758957, 
Validation Loss: 0.6214595623314381
Elapsed time for epoch-2: 3.0235838890075684
common line69: model saved with val loss 0.6214595623314381

Epoch: 3, 
Train Loss: 0.9420531661320133, 
Validation Loss: 0.619421049952507
Elapsed time for epoch-3: 3.1025850772857666
common line69: model saved with val loss 0.619421049952507

Epoch: 4, 
Train Loss: 0.9386517644679847, 
Validation Loss: 0.6204166086390615
Elapsed time for epoch-4: 3.2462542057037354

Epoch: 5, 
Train Loss: 0.9365308904597739, 
Validation Loss: 0.6180324153974652
Elapsed time for epoch-5: 2.6988344192504883
common line69: model saved with val loss 0.6180324153974652

Epoch: 6, 
Train Loss: 0.9346792151947984, 
Validation Loss: 0.6158805773593485
Elapsed time for epoch-6: 2.497634172439575
common line69: model saved with val loss 0.6158805773593485

Epoch: 7, 
Train Loss: 0.9331802451560477, 
Validation Loss: 0.6187689499929547
Elapsed time for epoch-7: 3.200172185897827

Epoch: 8, 
Train Loss: 0.9321877508103347, 
Validation Loss: 0.612198153976351
Elapsed time for epoch-8: 3.3477020263671875
common line69: model saved with val loss 0.612198153976351

Epoch: 9, 
Train Loss: 0.9312028934975632, 
Validation Loss: 0.6155881471931934
Elapsed time for epoch-9: 3.678447961807251

Epoch: 10, 
Train Loss: 0.9301829833944305, 
Validation Loss: 0.6172957313247025
Elapsed time for epoch-10: 4.796405076980591

Epoch: 11, 
Train Loss: 0.9296484789928469, 
Validation Loss: 0.6190493647009134
Elapsed time for epoch-11: 4.842870712280273

Epoch: 12, 
Train Loss: 0.9288166008827066, 
Validation Loss: 0.6167096658609807
Elapsed time for epoch-12: 4.599429130554199

Epoch: 13, 
Train Loss: 0.9277374450148654, 
Validation Loss: 0.6207901365123689
Elapsed time for epoch-13: 3.922752857208252

Epoch: 14, 
Train Loss: 0.9272522340301707, 
Validation Loss: 0.6175856878980994
Elapsed time for epoch-14: 3.963834047317505

Epoch: 15, 
Train Loss: 0.9261572885663569, 
Validation Loss: 0.612302933819592
Elapsed time for epoch-15: 3.4645092487335205

Epoch: 16, 
Train Loss: 0.9252540447882244, 
Validation Loss: 0.6186991082504392
Elapsed time for epoch-16: 4.038172006607056

Epoch: 17, 
Train Loss: 0.924457378998524, 
Validation Loss: 0.6168708959594369
Elapsed time for epoch-17: 4.32826828956604

Epoch: 18, 
Train Loss: 0.9232836033867187, 
Validation Loss: 0.6136376676149666
Elapsed time for epoch-18: 3.8147897720336914

Epoch: 19, 
Train Loss: 0.9221893311047754, 
Validation Loss: 0.6180736180394888
Elapsed time for epoch-19: 3.3191945552825928

Epoch: 20, 
Train Loss: 0.9211021153365865, 
Validation Loss: 0.6139974324032664
Elapsed time for epoch-20: 3.087721824645996
Early stopped! 

train line101: min loss for the epoch 20 is 0.612198153976351

Training the 67-th turbine in 180.03984761238098 secs

>>>>>>>>> Training Turbine  68 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.5019233226776123
lalalalalal
260 [[ 1.00000000e+00  4.35637324e-01 -9.28063035e-02  1.41155248e+01
   7.28214704e-01]
 [ 9.99048222e-01  9.98585291e-03 -1.10747168e-01  5.05767634e-01
  -1.29758580e-01]
 [ 9.96194698e-01  2.11504816e-02 -2.45303655e-01  5.00507970e-01
  -1.20819748e-01]
 [ 9.91444861e-01  1.41170241e-01 -2.50478905e-01  4.91491402e-01
  -4.04109385e-03]
 [ 9.84807753e-01  9.93028828e-02 -2.41853489e-01  4.86983118e-01
  -6.21545313e-02]]
hahahahahahah
265 [[ 9.99851839e-01  1.00000000e+00  4.35637324e-01 -9.28063035e-02
   1.41155248e+01  7.28214704e-01]
 [ 9.99851839e-01  9.99048222e-01  9.98585291e-03 -1.10747168e-01
   5.05767634e-01 -1.29758580e-01]
 [ 9.99851839e-01  9.96194698e-01  2.11504816e-02 -2.45303655e-01
   5.00507970e-01 -1.20819748e-01]
 [ 9.99851839e-01  9.91444861e-01  1.41170241e-01 -2.50478905e-01
   4.91491402e-01 -4.04109385e-03]
 [ 9.99851839e-01  9.84807753e-01  9.93028828e-02 -2.41853489e-01
   4.86983118e-01 -6.21545313e-02]]

 wind turbine line248 data after normalization: 
 [[ 9.99851839e-01  1.00000000e+00  4.35637324e-01 -9.28063035e-02
   1.41155248e+01  7.28214704e-01]
 [ 9.99851839e-01  9.99048222e-01  9.98585291e-03 -1.10747168e-01
   5.05767634e-01 -1.29758580e-01]
 [ 9.99851839e-01  9.96194698e-01  2.11504816e-02 -2.45303655e-01
   5.00507970e-01 -1.20819748e-01]
 [ 9.99851839e-01  9.91444861e-01  1.41170241e-01 -2.50478905e-01
   4.91491402e-01 -4.04109385e-03]
 [ 9.99851839e-01  9.84807753e-01  9.93028828e-02 -2.41853489e-01
   4.86983118e-01 -6.21545313e-02]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.082085371017456
lalalalalal
260 [[ 1.         -0.01094783  0.00949113 -1.81412003 -0.00409627]
 [ 0.99904822 -0.11003391  0.06797145 -1.82351229 -0.18281772]
 [ 0.9961947  -0.12398969  0.2101183  -1.82351229 -0.09592345]
 [ 0.99144486  0.24723421 -0.19734634 -1.82726919  0.3646581 ]
 [ 0.98480775  0.40074786 -0.01897274 -1.82877195  0.69382779]]
hahahahahahah
265 [[-0.84754092  1.         -0.01094783  0.00949113 -1.81412003 -0.00409627]
 [-0.84754092  0.99904822 -0.11003391  0.06797145 -1.82351229 -0.18281772]
 [-0.84754092  0.9961947  -0.12398969  0.2101183  -1.82351229 -0.09592345]
 [-0.84754092  0.99144486  0.24723421 -0.19734634 -1.82726919  0.3646581 ]
 [-0.84754092  0.98480775  0.40074786 -0.01897274 -1.82877195  0.69382779]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.01094783  0.00949113 -1.81412003 -0.00409627]
 [-0.84754092  0.99904822 -0.11003391  0.06797145 -1.82351229 -0.18281772]
 [-0.84754092  0.9961947  -0.12398969  0.2101183  -1.82351229 -0.09592345]
 [-0.84754092  0.99144486  0.24723421 -0.19734634 -1.82726919  0.3646581 ]
 [-0.84754092  0.98480775  0.40074786 -0.01897274 -1.82877195  0.69382779]]

Epoch: 0, 
Train Loss: 1.0015457514203896, 
Validation Loss: 0.9489580783993006
Elapsed time for epoch-0: 3.8285233974456787
common line69: model saved with val loss 0.9489580783993006

Epoch: 1, 
Train Loss: 0.9615923817418203, 
Validation Loss: 0.8889753082767129
Elapsed time for epoch-1: 3.6653435230255127
common line69: model saved with val loss 0.8889753082767129

Epoch: 2, 
Train Loss: 0.9429541276533062, 
Validation Loss: 0.8747010827064514
Elapsed time for epoch-2: 3.4855406284332275
common line69: model saved with val loss 0.8747010827064514

Epoch: 3, 
Train Loss: 0.9358121499794871, 
Validation Loss: 0.8705219216644764
Elapsed time for epoch-3: 4.096071720123291
common line69: model saved with val loss 0.8705219216644764

Epoch: 4, 
Train Loss: 0.9315969391780741, 
Validation Loss: 0.8675874248147011
Elapsed time for epoch-4: 3.2137696743011475
common line69: model saved with val loss 0.8675874248147011

Epoch: 5, 
Train Loss: 0.9290347762969362, 
Validation Loss: 0.8751375554129481
Elapsed time for epoch-5: 3.350832462310791

Epoch: 6, 
Train Loss: 0.9271814332288855, 
Validation Loss: 0.8709891112521291
Elapsed time for epoch-6: 3.376851797103882

Epoch: 7, 
Train Loss: 0.9255356695972571, 
Validation Loss: 0.8639616435393691
Elapsed time for epoch-7: 3.1819558143615723
common line69: model saved with val loss 0.8639616435393691

Epoch: 8, 
Train Loss: 0.9244486236271738, 
Validation Loss: 0.8697903966531157
Elapsed time for epoch-8: 3.1726996898651123

Epoch: 9, 
Train Loss: 0.9235832415708974, 
Validation Loss: 0.8659356087446213
Elapsed time for epoch-9: 3.0152995586395264

Epoch: 10, 
Train Loss: 0.9224517515727452, 
Validation Loss: 0.8698613559827209
Elapsed time for epoch-10: 3.2662737369537354

Epoch: 11, 
Train Loss: 0.9218309644390555, 
Validation Loss: 0.8677964871749282
Elapsed time for epoch-11: 4.036984205245972

Epoch: 12, 
Train Loss: 0.9214080902708679, 
Validation Loss: 0.8706476641818881
Elapsed time for epoch-12: 4.295970678329468

Epoch: 13, 
Train Loss: 0.9208016498249119, 
Validation Loss: 0.8662010384723544
Elapsed time for epoch-13: 3.6182572841644287

Epoch: 14, 
Train Loss: 0.9201677083468237, 
Validation Loss: 0.8709130445495248
Elapsed time for epoch-14: 3.3964743614196777

Epoch: 15, 
Train Loss: 0.9196362201155734, 
Validation Loss: 0.8743585683405399
Elapsed time for epoch-15: 3.4133546352386475

Epoch: 16, 
Train Loss: 0.9189910853610319, 
Validation Loss: 0.8679475905373693
Elapsed time for epoch-16: 3.5410189628601074

Epoch: 17, 
Train Loss: 0.9186468537615127, 
Validation Loss: 0.8732893075793982
Elapsed time for epoch-17: 2.920793056488037

Epoch: 18, 
Train Loss: 0.9181538480920952, 
Validation Loss: 0.8654258418828249
Elapsed time for epoch-18: 3.039848804473877

Epoch: 19, 
Train Loss: 0.9178014440195901, 
Validation Loss: 0.8656914196908474
Elapsed time for epoch-19: 3.825134038925171
Early stopped! 

train line101: min loss for the epoch 19 is 0.8639616435393691

Training the 68-th turbine in 184.04329013824463 secs

>>>>>>>>> Training Turbine  69 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.637322902679443
lalalalalal
260 [[ 1.          0.10339045 -0.88758095 -0.79352017 -0.4920486 ]
 [ 0.99904822  0.26357649 -1.73134144  0.35098008 -0.89479942]
 [ 0.9961947   0.21110175 -1.80329665  0.33987517 -0.89479942]
 [ 0.99144486  0.33262219 -1.78582182  0.33501677 -0.89479942]
 [ 0.98480775  0.24148186 -1.79233205  0.33015837 -0.89479942]]
hahahahahahah
265 [[ 0.99985184  1.          0.10339045 -0.88758095 -0.79352017 -0.4920486 ]
 [ 0.99985184  0.99904822  0.26357649 -1.73134144  0.35098008 -0.89479942]
 [ 0.99985184  0.9961947   0.21110175 -1.80329665  0.33987517 -0.89479942]
 [ 0.99985184  0.99144486  0.33262219 -1.78582182  0.33501677 -0.89479942]
 [ 0.99985184  0.98480775  0.24148186 -1.79233205  0.33015837 -0.89479942]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.10339045 -0.88758095 -0.79352017 -0.4920486 ]
 [ 0.99985184  0.99904822  0.26357649 -1.73134144  0.35098008 -0.89479942]
 [ 0.99985184  0.9961947   0.21110175 -1.80329665  0.33987517 -0.89479942]
 [ 0.99985184  0.99144486  0.33262219 -1.78582182  0.33501677 -0.89479942]
 [ 0.99985184  0.98480775  0.24148186 -1.79233205  0.33015837 -0.89479942]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.8747737407684326
lalalalalal
260 [[ 1.         -0.14103135  0.00928935 -1.46987887 -0.05019135]
 [ 0.99904822 -0.15898323  0.07302111 -1.45495664 -0.11538323]
 [ 0.9961947  -0.23079076  0.23680487 -1.45495664 -0.12497537]
 [ 0.99144486  0.19453078  0.0120305  -1.47647241  0.48317108]
 [ 0.98480775  0.34919316  0.07370639 -1.56878201  0.77840087]]
hahahahahahah
265 [[-0.84754092  1.         -0.14103135  0.00928935 -1.46987887 -0.05019135]
 [-0.84754092  0.99904822 -0.15898323  0.07302111 -1.45495664 -0.11538323]
 [-0.84754092  0.9961947  -0.23079076  0.23680487 -1.45495664 -0.12497537]
 [-0.84754092  0.99144486  0.19453078  0.0120305  -1.47647241  0.48317108]
 [-0.84754092  0.98480775  0.34919316  0.07370639 -1.56878201  0.77840087]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.14103135  0.00928935 -1.46987887 -0.05019135]
 [-0.84754092  0.99904822 -0.15898323  0.07302111 -1.45495664 -0.11538323]
 [-0.84754092  0.9961947  -0.23079076  0.23680487 -1.45495664 -0.12497537]
 [-0.84754092  0.99144486  0.19453078  0.0120305  -1.47647241  0.48317108]
 [-0.84754092  0.98480775  0.34919316  0.07370639 -1.56878201  0.77840087]]

Epoch: 0, 
Train Loss: 1.0114359141898757, 
Validation Loss: 0.7221879549324512
Elapsed time for epoch-0: 4.037585020065308
common line69: model saved with val loss 0.7221879549324512

Epoch: 1, 
Train Loss: 0.9625382181726584, 
Validation Loss: 0.6699595740064979
Elapsed time for epoch-1: 4.339357137680054
common line69: model saved with val loss 0.6699595740064979

Epoch: 2, 
Train Loss: 0.9492058969345414, 
Validation Loss: 0.6668925229460001
Elapsed time for epoch-2: 4.163130283355713
common line69: model saved with val loss 0.6668925229460001

Epoch: 3, 
Train Loss: 0.9429647367791969, 
Validation Loss: 0.6644038772210479
Elapsed time for epoch-3: 3.8008651733398438
common line69: model saved with val loss 0.6644038772210479

Epoch: 4, 
Train Loss: 0.9391545103628094, 
Validation Loss: 0.6685036001726985
Elapsed time for epoch-4: 3.7692747116088867

Epoch: 5, 
Train Loss: 0.9359606910152596, 
Validation Loss: 0.6598483398556709
Elapsed time for epoch-5: 4.341087102890015
common line69: model saved with val loss 0.6598483398556709

Epoch: 6, 
Train Loss: 0.9336622066858435, 
Validation Loss: 0.6680098064243793
Elapsed time for epoch-6: 4.3898961544036865

Epoch: 7, 
Train Loss: 0.9319346830123613, 
Validation Loss: 0.6624787617474794
Elapsed time for epoch-7: 4.152006149291992

Epoch: 8, 
Train Loss: 0.9303624758950803, 
Validation Loss: 0.6573133626952767
Elapsed time for epoch-8: 4.112776756286621
common line69: model saved with val loss 0.6573133626952767

Epoch: 9, 
Train Loss: 0.9289158342265281, 
Validation Loss: 0.6540358681231737
Elapsed time for epoch-9: 4.454224109649658
common line69: model saved with val loss 0.6540358681231737

Epoch: 10, 
Train Loss: 0.9278051119391658, 
Validation Loss: 0.6589653138071299
Elapsed time for epoch-10: 4.817593336105347

Epoch: 11, 
Train Loss: 0.9268220698132235, 
Validation Loss: 0.6617985516786575
Elapsed time for epoch-11: 4.132188558578491

Epoch: 12, 
Train Loss: 0.9256270321226922, 
Validation Loss: 0.6587034091353416
Elapsed time for epoch-12: 5.0213165283203125

Epoch: 13, 
Train Loss: 0.9247505240330175, 
Validation Loss: 0.6644143927842379
Elapsed time for epoch-13: 5.333089113235474

Epoch: 14, 
Train Loss: 0.9240941331416619, 
Validation Loss: 0.6617936994880438
Elapsed time for epoch-14: 4.531311988830566

Epoch: 15, 
Train Loss: 0.9233088736273661, 
Validation Loss: 0.6609624978154898
Elapsed time for epoch-15: 4.846285104751587

Epoch: 16, 
Train Loss: 0.9223054174114677, 
Validation Loss: 0.6619305731728673
Elapsed time for epoch-16: 3.680043935775757

Epoch: 17, 
Train Loss: 0.9219411780603793, 
Validation Loss: 0.6610003309324384
Elapsed time for epoch-17: 3.7651381492614746

Epoch: 18, 
Train Loss: 0.9214694531274443, 
Validation Loss: 0.661055195145309
Elapsed time for epoch-18: 3.4632081985473633

Epoch: 19, 
Train Loss: 0.9208440973478205, 
Validation Loss: 0.6614980855956674
Elapsed time for epoch-19: 3.5824832916259766

Epoch: 20, 
Train Loss: 0.9204079634001275, 
Validation Loss: 0.6633717929944396
Elapsed time for epoch-20: 3.4112017154693604

Epoch: 21, 
Train Loss: 0.9201714000782045, 
Validation Loss: 0.6618719389662147
Elapsed time for epoch-21: 3.509997844696045
Early stopped! 

train line101: min loss for the epoch 21 is 0.6540358681231737

Training the 69-th turbine in 191.435364484787 secs

>>>>>>>>> Training Turbine  70 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.732900381088257
lalalalalal
260 [[ 1.         -0.06464456 -0.05545261 -0.48115751 -0.08156772]
 [ 0.99904822 -0.10838924 -0.14249197  0.39881932 -0.22036924]
 [ 0.9961947  -0.0238162  -0.22602168  0.39183537 -0.2193031 ]
 [ 0.99144486  0.0228448  -0.22286299  0.38612124 -0.14719164]
 [ 0.98480775 -0.08214243 -0.23023326  0.38294672 -0.25287497]]
hahahahahahah
265 [[ 0.99985184  1.         -0.06464456 -0.05545261 -0.48115751 -0.08156772]
 [ 0.99985184  0.99904822 -0.10838924 -0.14249197  0.39881932 -0.22036924]
 [ 0.99985184  0.9961947  -0.0238162  -0.22602168  0.39183537 -0.2193031 ]
 [ 0.99985184  0.99144486  0.0228448  -0.22286299  0.38612124 -0.14719164]
 [ 0.99985184  0.98480775 -0.08214243 -0.23023326  0.38294672 -0.25287497]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.06464456 -0.05545261 -0.48115751 -0.08156772]
 [ 0.99985184  0.99904822 -0.10838924 -0.14249197  0.39881932 -0.22036924]
 [ 0.99985184  0.9961947  -0.0238162  -0.22602168  0.39183537 -0.2193031 ]
 [ 0.99985184  0.99144486  0.0228448  -0.22286299  0.38612124 -0.14719164]
 [ 0.99985184  0.98480775 -0.08214243 -0.23023326  0.38294672 -0.25287497]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.915775537490845
lalalalalal
260 [[ 1.         -0.22795803 -0.08493369 -1.44684636 -0.08401756]
 [ 0.99904822 -0.33586157 -0.25409889 -1.44684636 -0.23130278]
 [ 0.9961947  -0.30378214 -0.0505391  -1.44430674 -0.15513094]
 [ 0.99144486 -0.03839776 -0.10528966 -1.44938597  0.17736663]
 [ 0.98480775  0.27073131 -0.11371283 -1.50970184  0.7022219 ]]
hahahahahahah
265 [[-0.84754092  1.         -0.22795803 -0.08493369 -1.44684636 -0.08401756]
 [-0.84754092  0.99904822 -0.33586157 -0.25409889 -1.44684636 -0.23130278]
 [-0.84754092  0.9961947  -0.30378214 -0.0505391  -1.44430674 -0.15513094]
 [-0.84754092  0.99144486 -0.03839776 -0.10528966 -1.44938597  0.17736663]
 [-0.84754092  0.98480775  0.27073131 -0.11371283 -1.50970184  0.7022219 ]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.22795803 -0.08493369 -1.44684636 -0.08401756]
 [-0.84754092  0.99904822 -0.33586157 -0.25409889 -1.44684636 -0.23130278]
 [-0.84754092  0.9961947  -0.30378214 -0.0505391  -1.44430674 -0.15513094]
 [-0.84754092  0.99144486 -0.03839776 -0.10528966 -1.44938597  0.17736663]
 [-0.84754092  0.98480775  0.27073131 -0.11371283 -1.50970184  0.7022219 ]]

Epoch: 0, 
Train Loss: 1.012627222207414, 
Validation Loss: 0.9425022704526782
Elapsed time for epoch-0: 4.885619878768921
common line69: model saved with val loss 0.9425022704526782

Epoch: 1, 
Train Loss: 0.9690775885051038, 
Validation Loss: 0.8709842078387737
Elapsed time for epoch-1: 4.095313549041748
common line69: model saved with val loss 0.8709842078387737

Epoch: 2, 
Train Loss: 0.9496299777211261, 
Validation Loss: 0.863026550039649
Elapsed time for epoch-2: 4.045468091964722
common line69: model saved with val loss 0.863026550039649

Epoch: 3, 
Train Loss: 0.9440856107643673, 
Validation Loss: 0.8604295747354627
Elapsed time for epoch-3: 4.039728164672852
common line69: model saved with val loss 0.8604295747354627

Epoch: 4, 
Train Loss: 0.9407728435862966, 
Validation Loss: 0.8536500260233879
Elapsed time for epoch-4: 3.747361183166504
common line69: model saved with val loss 0.8536500260233879

Epoch: 5, 
Train Loss: 0.9381865965468543, 
Validation Loss: 0.8574739350005984
Elapsed time for epoch-5: 3.9877166748046875

Epoch: 6, 
Train Loss: 0.9362989958344388, 
Validation Loss: 0.8555067395791411
Elapsed time for epoch-6: 4.028284072875977

Epoch: 7, 
Train Loss: 0.9350024012206983, 
Validation Loss: 0.8562679337337613
Elapsed time for epoch-7: 4.051037788391113

Epoch: 8, 
Train Loss: 0.933804244053464, 
Validation Loss: 0.8602071339264512
Elapsed time for epoch-8: 3.8188822269439697

Epoch: 9, 
Train Loss: 0.9327893940841451, 
Validation Loss: 0.8578071901574731
Elapsed time for epoch-9: 3.569256544113159

Epoch: 10, 
Train Loss: 0.9320201699723717, 
Validation Loss: 0.8566350266337395
Elapsed time for epoch-10: 3.883462429046631

Epoch: 11, 
Train Loss: 0.9314735117329269, 
Validation Loss: 0.8589623803272843
Elapsed time for epoch-11: 4.206448793411255

Epoch: 12, 
Train Loss: 0.9307286431308553, 
Validation Loss: 0.8561738627031446
Elapsed time for epoch-12: 3.671091318130493

Epoch: 13, 
Train Loss: 0.9300218777997153, 
Validation Loss: 0.859801291488111
Elapsed time for epoch-13: 4.1092445850372314

Epoch: 14, 
Train Loss: 0.9296161370868442, 
Validation Loss: 0.8550588674843311
Elapsed time for epoch-14: 3.984569787979126

Epoch: 15, 
Train Loss: 0.9292820970050427, 
Validation Loss: 0.8548914939165115
Elapsed time for epoch-15: 3.814288854598999

Epoch: 16, 
Train Loss: 0.9286180941247139, 
Validation Loss: 0.8535028118640184
Elapsed time for epoch-16: 3.5712392330169678
common line69: model saved with val loss 0.8535028118640184

Epoch: 17, 
Train Loss: 0.9283792611931553, 
Validation Loss: 0.8520092666149139
Elapsed time for epoch-17: 4.059802293777466
common line69: model saved with val loss 0.8520092666149139

Epoch: 18, 
Train Loss: 0.9278744767193033, 
Validation Loss: 0.8543511256575584
Elapsed time for epoch-18: 3.5831644535064697

Epoch: 19, 
Train Loss: 0.9274979817266223, 
Validation Loss: 0.8557703644037247
Elapsed time for epoch-19: 4.067596435546875

Epoch: 20, 
Train Loss: 0.9272271966984292, 
Validation Loss: 0.8579345559701324
Elapsed time for epoch-20: 4.367379665374756

Epoch: 21, 
Train Loss: 0.9267557871942761, 
Validation Loss: 0.8534712288528681
Elapsed time for epoch-21: 4.0115814208984375

Epoch: 22, 
Train Loss: 0.9264059042980691, 
Validation Loss: 0.8599212057888508
Elapsed time for epoch-22: 3.936945915222168

Epoch: 23, 
Train Loss: 0.9261981799822896, 
Validation Loss: 0.8656783057376742
Elapsed time for epoch-23: 3.530724287033081

Epoch: 24, 
Train Loss: 0.925778346777964, 
Validation Loss: 0.8560250485315919
Elapsed time for epoch-24: 3.9272189140319824

Epoch: 25, 
Train Loss: 0.9254902085336316, 
Validation Loss: 0.861689985729754
Elapsed time for epoch-25: 4.180948257446289

Epoch: 26, 
Train Loss: 0.9253324108714817, 
Validation Loss: 0.8595381053164601
Elapsed time for epoch-26: 3.7853918075561523

Epoch: 27, 
Train Loss: 0.9246386407303209, 
Validation Loss: 0.8569227633997798
Elapsed time for epoch-27: 3.77168869972229

Epoch: 28, 
Train Loss: 0.9246240479855978, 
Validation Loss: 0.8590424321591854
Elapsed time for epoch-28: 3.6472487449645996

Epoch: 29, 
Train Loss: 0.9244802534079352, 
Validation Loss: 0.8625991465523839
Elapsed time for epoch-29: 3.6496925354003906
Early stopped! 

train line101: min loss for the epoch 29 is 0.8520092666149139

Training the 70-th turbine in 214.83577346801758 secs

>>>>>>>>> Training Turbine  71 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.4354827404022217
lalalalalal
260 [[ 1.         -0.04884214 -0.18167797 -0.54094532 -0.03484349]
 [ 0.99904822  0.01149664 -0.20504821  0.40984097 -0.08898458]
 [ 0.9961947   0.0402294  -0.24472719  0.40383664 -0.08907415]
 [ 0.99144486  0.09769491 -0.22623275  0.39783231 -0.01258698]
 [ 0.98480775  0.11206129 -0.25347002  0.39723187 -0.06166774]]
hahahahahahah
265 [[ 0.99985184  1.         -0.04884214 -0.18167797 -0.54094532 -0.03484349]
 [ 0.99985184  0.99904822  0.01149664 -0.20504821  0.40984097 -0.08898458]
 [ 0.99985184  0.9961947   0.0402294  -0.24472719  0.40383664 -0.08907415]
 [ 0.99985184  0.99144486  0.09769491 -0.22623275  0.39783231 -0.01258698]
 [ 0.99985184  0.98480775  0.11206129 -0.25347002  0.39723187 -0.06166774]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.04884214 -0.18167797 -0.54094532 -0.03484349]
 [ 0.99985184  0.99904822  0.01149664 -0.20504821  0.40984097 -0.08898458]
 [ 0.99985184  0.9961947   0.0402294  -0.24472719  0.40383664 -0.08907415]
 [ 0.99985184  0.99144486  0.09769491 -0.22623275  0.39783231 -0.01258698]
 [ 0.99985184  0.98480775  0.11206129 -0.25347002  0.39723187 -0.06166774]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.211098909378052
lalalalalal
260 [[ 1.         -0.08475809 -0.02985544 -1.41307484 -0.12833651]
 [ 0.99904822 -0.12642059 -0.03691696 -1.416077   -0.20615593]
 [ 0.9961947  -0.2068723   0.16114166 -1.42028004 -0.22570314]
 [ 0.99144486 -0.06895507  0.11742754 -1.42268177  0.10796538]
 [ 0.98480775  0.40800868  0.00545212 -1.42808567  0.72250479]]
hahahahahahah
265 [[-0.84754092  1.         -0.08475809 -0.02985544 -1.41307484 -0.12833651]
 [-0.84754092  0.99904822 -0.12642059 -0.03691696 -1.416077   -0.20615593]
 [-0.84754092  0.9961947  -0.2068723   0.16114166 -1.42028004 -0.22570314]
 [-0.84754092  0.99144486 -0.06895507  0.11742754 -1.42268177  0.10796538]
 [-0.84754092  0.98480775  0.40800868  0.00545212 -1.42808567  0.72250479]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.08475809 -0.02985544 -1.41307484 -0.12833651]
 [-0.84754092  0.99904822 -0.12642059 -0.03691696 -1.416077   -0.20615593]
 [-0.84754092  0.9961947  -0.2068723   0.16114166 -1.42028004 -0.22570314]
 [-0.84754092  0.99144486 -0.06895507  0.11742754 -1.42268177  0.10796538]
 [-0.84754092  0.98480775  0.40800868  0.00545212 -1.42808567  0.72250479]]

Epoch: 0, 
Train Loss: 1.006196034180016, 
Validation Loss: 0.8552820133045316
Elapsed time for epoch-0: 4.536075115203857
common line69: model saved with val loss 0.8552820133045316

Epoch: 1, 
Train Loss: 0.9590185661526287, 
Validation Loss: 0.8277605669572949
Elapsed time for epoch-1: 4.789381504058838
common line69: model saved with val loss 0.8277605669572949

Epoch: 2, 
Train Loss: 0.9467206664946901, 
Validation Loss: 0.818944682367146
Elapsed time for epoch-2: 5.067117214202881
common line69: model saved with val loss 0.818944682367146

Epoch: 3, 
Train Loss: 0.9403951135503144, 
Validation Loss: 0.8173087341710925
Elapsed time for epoch-3: 4.9028120040893555
common line69: model saved with val loss 0.8173087341710925

Epoch: 4, 
Train Loss: 0.9362328192766975, 
Validation Loss: 0.8134421873837709
Elapsed time for epoch-4: 4.838894367218018
common line69: model saved with val loss 0.8134421873837709

Epoch: 5, 
Train Loss: 0.9333755573054322, 
Validation Loss: 0.8110599657520652
Elapsed time for epoch-5: 4.256545066833496
common line69: model saved with val loss 0.8110599657520652

Epoch: 6, 
Train Loss: 0.9313248102905369, 
Validation Loss: 0.8091253191232681
Elapsed time for epoch-6: 3.772326946258545
common line69: model saved with val loss 0.8091253191232681

Epoch: 7, 
Train Loss: 0.9292850876305284, 
Validation Loss: 0.79990369733423
Elapsed time for epoch-7: 4.21770977973938
common line69: model saved with val loss 0.79990369733423

Epoch: 8, 
Train Loss: 0.9284386723732748, 
Validation Loss: 0.8091452373191714
Elapsed time for epoch-8: 4.0144524574279785

Epoch: 9, 
Train Loss: 0.9274061649036007, 
Validation Loss: 0.8097949903458357
Elapsed time for epoch-9: 3.954911231994629

Epoch: 10, 
Train Loss: 0.926343837580761, 
Validation Loss: 0.8077250681817532
Elapsed time for epoch-10: 4.0073065757751465

Epoch: 11, 
Train Loss: 0.9255497114998954, 
Validation Loss: 0.801553008146584
Elapsed time for epoch-11: 3.8420634269714355

Epoch: 12, 
Train Loss: 0.9248473309919614, 
Validation Loss: 0.7977436138316989
Elapsed time for epoch-12: 4.019479513168335
common line69: model saved with val loss 0.7977436138316989

Epoch: 13, 
Train Loss: 0.9242659454085246, 
Validation Loss: 0.8015184868127108
Elapsed time for epoch-13: 3.777825117111206

Epoch: 14, 
Train Loss: 0.9238140922384102, 
Validation Loss: 0.8085420299321413
Elapsed time for epoch-14: 3.7326436042785645

Epoch: 15, 
Train Loss: 0.9229988107661239, 
Validation Loss: 0.7983723320066929
Elapsed time for epoch-15: 4.61352276802063

Epoch: 16, 
Train Loss: 0.9227693044588345, 
Validation Loss: 0.8033324191346765
Elapsed time for epoch-16: 4.140210151672363

Epoch: 17, 
Train Loss: 0.9223937635161296, 
Validation Loss: 0.8015651889145374
Elapsed time for epoch-17: 3.9284071922302246

Epoch: 18, 
Train Loss: 0.9220740864006411, 
Validation Loss: 0.7994211725890636
Elapsed time for epoch-18: 3.6158108711242676

Epoch: 19, 
Train Loss: 0.9215281663321647, 
Validation Loss: 0.7987519688904285
Elapsed time for epoch-19: 3.720888376235962

Epoch: 20, 
Train Loss: 0.9213968849733096, 
Validation Loss: 0.7978819888085127
Elapsed time for epoch-20: 4.503071546554565

Epoch: 21, 
Train Loss: 0.9209418509687696, 
Validation Loss: 0.8007133342325687
Elapsed time for epoch-21: 4.585084438323975

Epoch: 22, 
Train Loss: 0.9206765190142543, 
Validation Loss: 0.8081889133900404
Elapsed time for epoch-22: 3.487154960632324

Epoch: 23, 
Train Loss: 0.9201241205720341, 
Validation Loss: 0.8016100479289889
Elapsed time for epoch-23: 3.7488420009613037

Epoch: 24, 
Train Loss: 0.9200947086851136, 
Validation Loss: 0.7982401335611939
Elapsed time for epoch-24: 4.161989212036133
Early stopped! 

train line101: min loss for the epoch 24 is 0.7977436138316989

Training the 71-th turbine in 192.29415917396545 secs

>>>>>>>>> Training Turbine  72 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.7146732807159424
lalalalalal
260 [[ 1.          0.12936064 -0.17652851 -0.62740868 -0.01255135]
 [ 0.99904822  0.20698175 -0.35745859  0.45449163 -0.05417028]
 [ 0.9961947   0.06069581 -0.1615343   0.4465777  -0.05265562]
 [ 0.99144486  0.09652094 -0.01492429  0.44130174  0.10188639]
 [ 0.98480775 -0.02588159  0.01073246  0.43272832 -0.08265063]]
hahahahahahah
265 [[ 0.99985184  1.          0.12936064 -0.17652851 -0.62740868 -0.01255135]
 [ 0.99985184  0.99904822  0.20698175 -0.35745859  0.45449163 -0.05417028]
 [ 0.99985184  0.9961947   0.06069581 -0.1615343   0.4465777  -0.05265562]
 [ 0.99985184  0.99144486  0.09652094 -0.01492429  0.44130174  0.10188639]
 [ 0.99985184  0.98480775 -0.02588159  0.01073246  0.43272832 -0.08265063]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.12936064 -0.17652851 -0.62740868 -0.01255135]
 [ 0.99985184  0.99904822  0.20698175 -0.35745859  0.45449163 -0.05417028]
 [ 0.99985184  0.9961947   0.06069581 -0.1615343   0.4465777  -0.05265562]
 [ 0.99985184  0.99144486  0.09652094 -0.01492429  0.44130174  0.10188639]
 [ 0.99985184  0.98480775 -0.02588159  0.01073246  0.43272832 -0.08265063]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.0487871170043945
lalalalalal
260 [[ 1.         -0.18560196 -0.03541637 -1.62159626 -0.1575693 ]
 [ 0.99904822 -0.1572404  -0.15120496 -1.62489373 -0.13727046]
 [ 0.9961947  -0.23187608  0.06104635 -1.62489373 -0.20077176]
 [ 0.99144486  0.05771038 -0.04291347 -1.63280766  0.23386903]
 [ 0.98480775  0.3323697  -0.07023625 -1.63742412  0.70272753]]
hahahahahahah
265 [[-0.84754092  1.         -0.18560196 -0.03541637 -1.62159626 -0.1575693 ]
 [-0.84754092  0.99904822 -0.1572404  -0.15120496 -1.62489373 -0.13727046]
 [-0.84754092  0.9961947  -0.23187608  0.06104635 -1.62489373 -0.20077176]
 [-0.84754092  0.99144486  0.05771038 -0.04291347 -1.63280766  0.23386903]
 [-0.84754092  0.98480775  0.3323697  -0.07023625 -1.63742412  0.70272753]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.18560196 -0.03541637 -1.62159626 -0.1575693 ]
 [-0.84754092  0.99904822 -0.1572404  -0.15120496 -1.62489373 -0.13727046]
 [-0.84754092  0.9961947  -0.23187608  0.06104635 -1.62489373 -0.20077176]
 [-0.84754092  0.99144486  0.05771038 -0.04291347 -1.63280766  0.23386903]
 [-0.84754092  0.98480775  0.3323697  -0.07023625 -1.63742412  0.70272753]]

Epoch: 0, 
Train Loss: 1.0016473249978377, 
Validation Loss: 0.9110621213912964
Elapsed time for epoch-0: 3.578568935394287
common line69: model saved with val loss 0.9110621213912964

Epoch: 1, 
Train Loss: 0.9620712652426808, 
Validation Loss: 0.8530873833224177
Elapsed time for epoch-1: 4.068389892578125
common line69: model saved with val loss 0.8530873833224177

Epoch: 2, 
Train Loss: 0.9418652803957963, 
Validation Loss: 0.8356061289086938
Elapsed time for epoch-2: 4.249277591705322
common line69: model saved with val loss 0.8356061289086938

Epoch: 3, 
Train Loss: 0.9342957972979345, 
Validation Loss: 0.8223317991942167
Elapsed time for epoch-3: 3.986647605895996
common line69: model saved with val loss 0.8223317991942167

Epoch: 4, 
Train Loss: 0.929897860944772, 
Validation Loss: 0.8207846377044916
Elapsed time for epoch-4: 3.459289789199829
common line69: model saved with val loss 0.8207846377044916

Epoch: 5, 
Train Loss: 0.9262708670952741, 
Validation Loss: 0.8169143199920654
Elapsed time for epoch-5: 4.2295708656311035
common line69: model saved with val loss 0.8169143199920654

Epoch: 6, 
Train Loss: 0.9238981908860326, 
Validation Loss: 0.8153254967182875
Elapsed time for epoch-6: 4.324571371078491
common line69: model saved with val loss 0.8153254967182875

Epoch: 7, 
Train Loss: 0.9221023524007878, 
Validation Loss: 0.8169906632974744
Elapsed time for epoch-7: 4.433438539505005

Epoch: 8, 
Train Loss: 0.9203209689184397, 
Validation Loss: 0.8112751645967364
Elapsed time for epoch-8: 3.9626317024230957
common line69: model saved with val loss 0.8112751645967364

Epoch: 9, 
Train Loss: 0.9192308677094323, 
Validation Loss: 0.8124422831460834
Elapsed time for epoch-9: 3.502497673034668

Epoch: 10, 
Train Loss: 0.918012057783223, 
Validation Loss: 0.8134613167494535
Elapsed time for epoch-10: 4.151468753814697

Epoch: 11, 
Train Loss: 0.916900742579909, 
Validation Loss: 0.813108935020864
Elapsed time for epoch-11: 4.108502149581909

Epoch: 12, 
Train Loss: 0.9160112642190036, 
Validation Loss: 0.8162340968847275
Elapsed time for epoch-12: 4.366713285446167

Epoch: 13, 
Train Loss: 0.9146942789314174, 
Validation Loss: 0.8216864829882979
Elapsed time for epoch-13: 4.21602725982666

Epoch: 14, 
Train Loss: 0.9138602415303222, 
Validation Loss: 0.8235151041299105
Elapsed time for epoch-14: 4.268096923828125

Epoch: 15, 
Train Loss: 0.9129020899784666, 
Validation Loss: 0.8325336324051023
Elapsed time for epoch-15: 4.684398889541626

Epoch: 16, 
Train Loss: 0.9120461533800894, 
Validation Loss: 0.8391052884981036
Elapsed time for epoch-16: 5.221450567245483

Epoch: 17, 
Train Loss: 0.9115156631509796, 
Validation Loss: 0.8519579647108912
Elapsed time for epoch-17: 5.006441831588745

Epoch: 18, 
Train Loss: 0.9106685983784059, 
Validation Loss: 0.8431326430290937
Elapsed time for epoch-18: 5.6488587856292725

Epoch: 19, 
Train Loss: 0.9103047602316913, 
Validation Loss: 0.8504727529361844
Elapsed time for epoch-19: 5.054240465164185

Epoch: 20, 
Train Loss: 0.9093756154805672, 
Validation Loss: 0.8526909425854683
Elapsed time for epoch-20: 4.202403545379639
Early stopped! 

train line101: min loss for the epoch 20 is 0.8112751645967364

Training the 72-th turbine in 176.63818788528442 secs

>>>>>>>>> Training Turbine  73 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.9717938899993896
lalalalalal
260 [[ 1.          0.08739758 -0.09005599 -0.54205357  0.01843963]
 [ 0.99904822  0.1237869  -0.00982427  0.39667527 -0.00684754]
 [ 0.9961947   0.05683055 -0.03709671  0.38825618 -0.04010997]
 [ 0.99144486  0.19074325 -0.01109276  0.38713364  0.06655217]
 [ 0.98480775  0.02480795 -0.03773096  0.38208218 -0.06180089]]
hahahahahahah
265 [[ 0.99985184  1.          0.08739758 -0.09005599 -0.54205357  0.01843963]
 [ 0.99985184  0.99904822  0.1237869  -0.00982427  0.39667527 -0.00684754]
 [ 0.99985184  0.9961947   0.05683055 -0.03709671  0.38825618 -0.04010997]
 [ 0.99985184  0.99144486  0.19074325 -0.01109276  0.38713364  0.06655217]
 [ 0.99985184  0.98480775  0.02480795 -0.03773096  0.38208218 -0.06180089]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.08739758 -0.09005599 -0.54205357  0.01843963]
 [ 0.99985184  0.99904822  0.1237869  -0.00982427  0.39667527 -0.00684754]
 [ 0.99985184  0.9961947   0.05683055 -0.03709671  0.38825618 -0.04010997]
 [ 0.99985184  0.99144486  0.19074325 -0.01109276  0.38713364  0.06655217]
 [ 0.99985184  0.98480775  0.02480795 -0.03773096  0.38208218 -0.06180089]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.024430990219116
lalalalalal
260 [[ 1.         -0.14549406 -0.04375626 -1.35842493 -0.14273343]
 [ 0.99904822 -0.05670412 -0.12049965 -1.36403766 -0.10495584]
 [ 0.9961947  -0.17314994  0.01649681 -1.36403766 -0.15580244]
 [ 0.99144486  0.05683055 -0.05136718 -1.36628275  0.16082599]
 [ 0.98480775  0.43236833 -0.06880886 -1.36965038  0.71433015]]
hahahahahahah
265 [[-0.84754092  1.         -0.14549406 -0.04375626 -1.35842493 -0.14273343]
 [-0.84754092  0.99904822 -0.05670412 -0.12049965 -1.36403766 -0.10495584]
 [-0.84754092  0.9961947  -0.17314994  0.01649681 -1.36403766 -0.15580244]
 [-0.84754092  0.99144486  0.05683055 -0.05136718 -1.36628275  0.16082599]
 [-0.84754092  0.98480775  0.43236833 -0.06880886 -1.36965038  0.71433015]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.14549406 -0.04375626 -1.35842493 -0.14273343]
 [-0.84754092  0.99904822 -0.05670412 -0.12049965 -1.36403766 -0.10495584]
 [-0.84754092  0.9961947  -0.17314994  0.01649681 -1.36403766 -0.15580244]
 [-0.84754092  0.99144486  0.05683055 -0.05136718 -1.36628275  0.16082599]
 [-0.84754092  0.98480775  0.43236833 -0.06880886 -1.36965038  0.71433015]]

Epoch: 0, 
Train Loss: 1.0188051284361286, 
Validation Loss: 0.730966211296618
Elapsed time for epoch-0: 4.57262659072876
common line69: model saved with val loss 0.730966211296618

Epoch: 1, 
Train Loss: 0.9841519516556203, 
Validation Loss: 0.6606906428933144
Elapsed time for epoch-1: 4.207991361618042
common line69: model saved with val loss 0.6606906428933144

Epoch: 2, 
Train Loss: 0.9608076625511426, 
Validation Loss: 0.6454649977385998
Elapsed time for epoch-2: 5.6075825691223145
common line69: model saved with val loss 0.6454649977385998

Epoch: 3, 
Train Loss: 0.9507096583853248, 
Validation Loss: 0.6384835354983807
Elapsed time for epoch-3: 3.6667978763580322
common line69: model saved with val loss 0.6384835354983807

Epoch: 4, 
Train Loss: 0.9444928742757365, 
Validation Loss: 0.6327218310907483
Elapsed time for epoch-4: 4.424982786178589
common line69: model saved with val loss 0.6327218310907483

Epoch: 5, 
Train Loss: 0.940883931492557, 
Validation Loss: 0.6328925071284175
Elapsed time for epoch-5: 4.670869827270508

Epoch: 6, 
Train Loss: 0.9381615251553159, 
Validation Loss: 0.6292264834046364
Elapsed time for epoch-6: 5.048506259918213
common line69: model saved with val loss 0.6292264834046364

Epoch: 7, 
Train Loss: 0.936329794531109, 
Validation Loss: 0.6300280317664146
Elapsed time for epoch-7: 4.0177953243255615

Epoch: 8, 
Train Loss: 0.9344803998951151, 
Validation Loss: 0.6276850933209062
Elapsed time for epoch-8: 3.622535228729248
common line69: model saved with val loss 0.6276850933209062

Epoch: 9, 
Train Loss: 0.9329746006166234, 
Validation Loss: 0.6319881267845631
Elapsed time for epoch-9: 3.897264242172241

Epoch: 10, 
Train Loss: 0.9315373741027688, 
Validation Loss: 0.6233973535709083
Elapsed time for epoch-10: 4.033130168914795
common line69: model saved with val loss 0.6233973535709083

Epoch: 11, 
Train Loss: 0.9308369207282027, 
Validation Loss: 0.6377032054588199
Elapsed time for epoch-11: 3.7533373832702637

Epoch: 12, 
Train Loss: 0.9295775152805472, 
Validation Loss: 0.6289064483717084
Elapsed time for epoch-12: 4.453269958496094

Epoch: 13, 
Train Loss: 0.9288340910893529, 
Validation Loss: 0.6358628952875733
Elapsed time for epoch-13: 3.9464616775512695

Epoch: 14, 
Train Loss: 0.9281306735106877, 
Validation Loss: 0.6326918099075556
Elapsed time for epoch-14: 3.5118203163146973

Epoch: 15, 
Train Loss: 0.9274775488536899, 
Validation Loss: 0.6303984122350812
Elapsed time for epoch-15: 3.8519256114959717

Epoch: 16, 
Train Loss: 0.9266806626770677, 
Validation Loss: 0.6283278847113252
Elapsed time for epoch-16: 3.6714565753936768

Epoch: 17, 
Train Loss: 0.9258605671279571, 
Validation Loss: 0.6240425202995539
Elapsed time for epoch-17: 3.6099941730499268

Epoch: 18, 
Train Loss: 0.9255075884215972, 
Validation Loss: 0.6313753798604012
Elapsed time for epoch-18: 3.944871664047241

Epoch: 19, 
Train Loss: 0.9248995327648997, 
Validation Loss: 0.6288420623168349
Elapsed time for epoch-19: 4.020247459411621

Epoch: 20, 
Train Loss: 0.9245761611631939, 
Validation Loss: 0.6266785217449069
Elapsed time for epoch-20: 4.322739362716675

Epoch: 21, 
Train Loss: 0.9240872926321351, 
Validation Loss: 0.6298751886934042
Elapsed time for epoch-21: 3.739219903945923

Epoch: 22, 
Train Loss: 0.9237902895743105, 
Validation Loss: 0.6252840217202902
Elapsed time for epoch-22: 4.722099304199219
Early stopped! 

train line101: min loss for the epoch 22 is 0.6233973535709083

Training the 73-th turbine in 179.86704015731812 secs

>>>>>>>>> Training Turbine  74 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.425598621368408
lalalalalal
260 [[ 1.          0.07603329 -0.16688649 -0.82383949  0.01000173]
 [ 0.99904822  0.11348639 -0.21829764  0.53773477 -0.02510021]
 [ 0.9961947   0.10484337 -0.23577071  0.52945269 -0.041433  ]
 [ 0.99144486  0.18551159 -0.24921153  0.52531165  0.06597083]
 [ 0.98480775  0.08467631 -0.3009587   0.51951419 -0.09338658]]
hahahahahahah
265 [[ 0.99985184  1.          0.07603329 -0.16688649 -0.82383949  0.01000173]
 [ 0.99985184  0.99904822  0.11348639 -0.21829764  0.53773477 -0.02510021]
 [ 0.99985184  0.9961947   0.10484337 -0.23577071  0.52945269 -0.041433  ]
 [ 0.99985184  0.99144486  0.18551159 -0.24921153  0.52531165  0.06597083]
 [ 0.99985184  0.98480775  0.08467631 -0.3009587   0.51951419 -0.09338658]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.07603329 -0.16688649 -0.82383949  0.01000173]
 [ 0.99985184  0.99904822  0.11348639 -0.21829764  0.53773477 -0.02510021]
 [ 0.99985184  0.9961947   0.10484337 -0.23577071  0.52945269 -0.041433  ]
 [ 0.99985184  0.99144486  0.18551159 -0.24921153  0.52531165  0.06597083]
 [ 0.99985184  0.98480775  0.08467631 -0.3009587   0.51951419 -0.09338658]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.3746330738067627
lalalalalal
260 [[ 1.         -0.11267274  0.02296512 -2.00569257 -0.14892706]
 [ 0.99904822 -0.05073106 -0.00895683 -2.01397465 -0.0962967 ]
 [ 0.9961947  -0.22071054  0.16846202 -2.01231824 -0.20397123]
 [ 0.99144486  0.04722321  0.01859685 -2.01645928  0.14046094]
 [ 0.98480775  0.30075191  0.03338176 -2.01480286  0.5548263 ]]
hahahahahahah
265 [[-0.84754092  1.         -0.11267274  0.02296512 -2.00569257 -0.14892706]
 [-0.84754092  0.99904822 -0.05073106 -0.00895683 -2.01397465 -0.0962967 ]
 [-0.84754092  0.9961947  -0.22071054  0.16846202 -2.01231824 -0.20397123]
 [-0.84754092  0.99144486  0.04722321  0.01859685 -2.01645928  0.14046094]
 [-0.84754092  0.98480775  0.30075191  0.03338176 -2.01480286  0.5548263 ]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.11267274  0.02296512 -2.00569257 -0.14892706]
 [-0.84754092  0.99904822 -0.05073106 -0.00895683 -2.01397465 -0.0962967 ]
 [-0.84754092  0.9961947  -0.22071054  0.16846202 -2.01231824 -0.20397123]
 [-0.84754092  0.99144486  0.04722321  0.01859685 -2.01645928  0.14046094]
 [-0.84754092  0.98480775  0.30075191  0.03338176 -2.01480286  0.5548263 ]]

Epoch: 0, 
Train Loss: 1.0114918806973625, 
Validation Loss: 0.8602436194196343
Elapsed time for epoch-0: 3.647590398788452
common line69: model saved with val loss 0.8602436194196343

Epoch: 1, 
Train Loss: 0.9636357484244499, 
Validation Loss: 0.8169411616399884
Elapsed time for epoch-1: 3.379749298095703
common line69: model saved with val loss 0.8169411616399884

Epoch: 2, 
Train Loss: 0.9520615482029795, 
Validation Loss: 0.8081871336326003
Elapsed time for epoch-2: 3.506086826324463
common line69: model saved with val loss 0.8081871336326003

Epoch: 3, 
Train Loss: 0.9459504632889724, 
Validation Loss: 0.8046881183981895
Elapsed time for epoch-3: 4.027954816818237
common line69: model saved with val loss 0.8046881183981895

Epoch: 4, 
Train Loss: 0.9417122716412825, 
Validation Loss: 0.8096184162423015
Elapsed time for epoch-4: 4.099906921386719

Epoch: 5, 
Train Loss: 0.9389652087658393, 
Validation Loss: 0.8031325154006481
Elapsed time for epoch-5: 3.737685441970825
common line69: model saved with val loss 0.8031325154006481

Epoch: 6, 
Train Loss: 0.9371700743917658, 
Validation Loss: 0.7990510072559118
Elapsed time for epoch-6: 4.194866895675659
common line69: model saved with val loss 0.7990510072559118

Epoch: 7, 
Train Loss: 0.9357766382584051, 
Validation Loss: 0.7958942912518978
Elapsed time for epoch-7: 3.8274331092834473
common line69: model saved with val loss 0.7958942912518978

Epoch: 8, 
Train Loss: 0.9348572994731054, 
Validation Loss: 0.7937602056190372
Elapsed time for epoch-8: 4.141643047332764
common line69: model saved with val loss 0.7937602056190372

Epoch: 9, 
Train Loss: 0.9339311045257985, 
Validation Loss: 0.7956612585112453
Elapsed time for epoch-9: 3.9151928424835205

Epoch: 10, 
Train Loss: 0.9328193573140297, 
Validation Loss: 0.7948159724473953
Elapsed time for epoch-10: 3.426013469696045

Epoch: 11, 
Train Loss: 0.9322788457409674, 
Validation Loss: 0.8010342149063945
Elapsed time for epoch-11: 3.9283676147460938

Epoch: 12, 
Train Loss: 0.9314624441771948, 
Validation Loss: 0.7950308043509722
Elapsed time for epoch-12: 4.346492528915405

Epoch: 13, 
Train Loss: 0.9307757103893938, 
Validation Loss: 0.7891142573207617
Elapsed time for epoch-13: 4.331129312515259
common line69: model saved with val loss 0.7891142573207617

Epoch: 14, 
Train Loss: 0.9303400482700652, 
Validation Loss: 0.7865113839507103
Elapsed time for epoch-14: 4.275223970413208
common line69: model saved with val loss 0.7865113839507103

Epoch: 15, 
Train Loss: 0.9295813513904059, 
Validation Loss: 0.7846045782789588
Elapsed time for epoch-15: 3.5880489349365234
common line69: model saved with val loss 0.7846045782789588

Epoch: 16, 
Train Loss: 0.9292571013715086, 
Validation Loss: 0.7875706069171429
Elapsed time for epoch-16: 4.485419988632202

Epoch: 17, 
Train Loss: 0.9289554125871979, 
Validation Loss: 0.787693970836699
Elapsed time for epoch-17: 5.484293222427368

Epoch: 18, 
Train Loss: 0.9283487071760562, 
Validation Loss: 0.7893098462373018
Elapsed time for epoch-18: 4.9483420848846436

Epoch: 19, 
Train Loss: 0.9281835177866351, 
Validation Loss: 0.7889591762796044
Elapsed time for epoch-19: 4.076914548873901

Epoch: 20, 
Train Loss: 0.9280096767078928, 
Validation Loss: 0.7848723251372576
Elapsed time for epoch-20: 4.149230241775513

Epoch: 21, 
Train Loss: 0.9273282201851115, 
Validation Loss: 0.7828175965696573
Elapsed time for epoch-21: 4.087592124938965
common line69: model saved with val loss 0.7828175965696573

Epoch: 22, 
Train Loss: 0.9271594672894278, 
Validation Loss: 0.7835940597578883
Elapsed time for epoch-22: 4.448673963546753

Epoch: 23, 
Train Loss: 0.9270973121669112, 
Validation Loss: 0.7915261462330818
Elapsed time for epoch-23: 4.194093465805054

Epoch: 24, 
Train Loss: 0.9264121831966048, 
Validation Loss: 0.784848527982831
Elapsed time for epoch-24: 4.245454549789429

Epoch: 25, 
Train Loss: 0.9262331421134853, 
Validation Loss: 0.788528136909008
Elapsed time for epoch-25: 3.751504898071289

Epoch: 26, 
Train Loss: 0.925877483952947, 
Validation Loss: 0.7883531413972378
Elapsed time for epoch-26: 3.8031821250915527

Epoch: 27, 
Train Loss: 0.9253875889948436, 
Validation Loss: 0.7886891374364495
Elapsed time for epoch-27: 4.173211097717285

Epoch: 28, 
Train Loss: 0.9254343452072945, 
Validation Loss: 0.7865969864651561
Elapsed time for epoch-28: 4.323044300079346

Epoch: 29, 
Train Loss: 0.9253086576692197, 
Validation Loss: 0.7913119364529848
Elapsed time for epoch-29: 4.3652637004852295

Epoch: 30, 
Train Loss: 0.9247680611971045, 
Validation Loss: 0.7891476843506098
Elapsed time for epoch-30: 3.7410497665405273

Epoch: 31, 
Train Loss: 0.9247161579482696, 
Validation Loss: 0.7896539056673646
Elapsed time for epoch-31: 3.6097984313964844

train line101: min loss for the epoch 31 is 0.7828175965696573

Training the 74-th turbine in 221.20727348327637 secs

>>>>>>>>> Training Turbine  75 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.7013776302337646
lalalalalal
260 [[ 1.          0.10539517 -0.10506916 -0.47372655  0.04000455]
 [ 0.99904822  0.1652458  -0.05894073  0.37094261 -0.06705042]
 [ 0.9961947   0.11269403 -0.07796276  0.36781517 -0.08818897]
 [ 0.99144486  0.22363667 -0.05767259  0.36416649 -0.01514056]
 [ 0.98480775  0.1243722  -0.16197674  0.36208154 -0.11100596]]
hahahahahahah
265 [[ 0.99985184  1.          0.10539517 -0.10506916 -0.47372655  0.04000455]
 [ 0.99985184  0.99904822  0.1652458  -0.05894073  0.37094261 -0.06705042]
 [ 0.99985184  0.9961947   0.11269403 -0.07796276  0.36781517 -0.08818897]
 [ 0.99985184  0.99144486  0.22363667 -0.05767259  0.36416649 -0.01514056]
 [ 0.99985184  0.98480775  0.1243722  -0.16197674  0.36208154 -0.11100596]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.10539517 -0.10506916 -0.47372655  0.04000455]
 [ 0.99985184  0.99904822  0.1652458  -0.05894073  0.37094261 -0.06705042]
 [ 0.99985184  0.9961947   0.11269403 -0.07796276  0.36781517 -0.08818897]
 [ 0.99985184  0.99144486  0.22363667 -0.05767259  0.36416649 -0.01514056]
 [ 0.99985184  0.98480775  0.1243722  -0.16197674  0.36208154 -0.11100596]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.8259949684143066
lalalalalal
260 [[ 1.         -0.1121108   0.01080673 -1.24802834 -0.15241952]
 [ 0.99904822 -0.01576588  0.19119901 -1.25324073 -0.07539395]
 [ 0.9961947  -0.23473162  0.03743757 -1.25376197 -0.21044715]
 [ 0.99144486 -0.01284633 -0.17338996 -1.25793189  0.00709262]
 [ 0.98480775  0.2732689   0.09069927 -1.25480445  0.43030151]]
hahahahahahah
265 [[-0.84754092  1.         -0.1121108   0.01080673 -1.24802834 -0.15241952]
 [-0.84754092  0.99904822 -0.01576588  0.19119901 -1.25324073 -0.07539395]
 [-0.84754092  0.9961947  -0.23473162  0.03743757 -1.25376197 -0.21044715]
 [-0.84754092  0.99144486 -0.01284633 -0.17338996 -1.25793189  0.00709262]
 [-0.84754092  0.98480775  0.2732689   0.09069927 -1.25480445  0.43030151]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.1121108   0.01080673 -1.24802834 -0.15241952]
 [-0.84754092  0.99904822 -0.01576588  0.19119901 -1.25324073 -0.07539395]
 [-0.84754092  0.9961947  -0.23473162  0.03743757 -1.25376197 -0.21044715]
 [-0.84754092  0.99144486 -0.01284633 -0.17338996 -1.25793189  0.00709262]
 [-0.84754092  0.98480775  0.2732689   0.09069927 -1.25480445  0.43030151]]

Epoch: 0, 
Train Loss: 1.0021177855860286, 
Validation Loss: 0.7626077607274055
Elapsed time for epoch-0: 4.05700159072876
common line69: model saved with val loss 0.7626077607274055

Epoch: 1, 
Train Loss: 0.9501009756276587, 
Validation Loss: 0.7240938264876604
Elapsed time for epoch-1: 3.7683653831481934
common line69: model saved with val loss 0.7240938264876604

Epoch: 2, 
Train Loss: 0.933724506061618, 
Validation Loss: 0.7239228468388319
Elapsed time for epoch-2: 4.553827524185181
common line69: model saved with val loss 0.7239228468388319

Epoch: 3, 
Train Loss: 0.9271984906757579, 
Validation Loss: 0.7224571136757731
Elapsed time for epoch-3: 3.495851516723633
common line69: model saved with val loss 0.7224571136757731

Epoch: 4, 
Train Loss: 0.9237256748836582, 
Validation Loss: 0.72450933419168
Elapsed time for epoch-4: 4.177446126937866

Epoch: 5, 
Train Loss: 0.921140141597315, 
Validation Loss: 0.7200372349470854
Elapsed time for epoch-5: 4.438907861709595
common line69: model saved with val loss 0.7200372349470854

Epoch: 6, 
Train Loss: 0.9191583791951171, 
Validation Loss: 0.7248475607484579
Elapsed time for epoch-6: 4.213224172592163

Epoch: 7, 
Train Loss: 0.9175878902192877, 
Validation Loss: 0.7283843066543341
Elapsed time for epoch-7: 3.9770829677581787

Epoch: 8, 
Train Loss: 0.9164471522349269, 
Validation Loss: 0.7237365460023284
Elapsed time for epoch-8: 4.071898460388184

Epoch: 9, 
Train Loss: 0.9153124379510639, 
Validation Loss: 0.7233985727652907
Elapsed time for epoch-9: 3.4744226932525635

Epoch: 10, 
Train Loss: 0.9141982925288817, 
Validation Loss: 0.7237080968916416
Elapsed time for epoch-10: 3.6776843070983887

Epoch: 11, 
Train Loss: 0.9134028240913102, 
Validation Loss: 0.7231877176091075
Elapsed time for epoch-11: 3.9124722480773926

Epoch: 12, 
Train Loss: 0.9123021857578213, 
Validation Loss: 0.727399424649775
Elapsed time for epoch-12: 3.6747887134552

Epoch: 13, 
Train Loss: 0.9119747383754795, 
Validation Loss: 0.7334764637053013
Elapsed time for epoch-13: 3.412712335586548

Epoch: 14, 
Train Loss: 0.9112464619033477, 
Validation Loss: 0.7275015311315656
Elapsed time for epoch-14: 4.068429231643677

Epoch: 15, 
Train Loss: 0.9101663101621035, 
Validation Loss: 0.7270029513165355
Elapsed time for epoch-15: 3.552849054336548

Epoch: 16, 
Train Loss: 0.9093574498380933, 
Validation Loss: 0.7348377099260688
Elapsed time for epoch-16: 3.431879758834839

Epoch: 17, 
Train Loss: 0.9090799006844769, 
Validation Loss: 0.7289073225110769
Elapsed time for epoch-17: 3.36651611328125
Early stopped! 

train line101: min loss for the epoch 17 is 0.7200372349470854

Training the 75-th turbine in 153.57802295684814 secs

>>>>>>>>> Training Turbine  76 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.8740780353546143
lalalalalal
260 [[ 1.          0.15865467 -0.12761638 -0.52819657  0.08025976]
 [ 0.99904822  0.26888971 -0.28350408  0.39615113  0.08240026]
 [ 0.9961947   0.27770851 -0.32580988  0.38924012  0.08462174]
 [ 0.99144486  0.2571313  -0.32642301  0.38693645  0.07818869]
 [ 0.98480775  0.33062133 -0.30864231  0.38175319  0.12354407]]
hahahahahahah
265 [[ 0.99985184  1.          0.15865467 -0.12761638 -0.52819657  0.08025976]
 [ 0.99985184  0.99904822  0.26888971 -0.28350408  0.39615113  0.08240026]
 [ 0.99985184  0.9961947   0.27770851 -0.32580988  0.38924012  0.08462174]
 [ 0.99985184  0.99144486  0.2571313  -0.32642301  0.38693645  0.07818869]
 [ 0.99985184  0.98480775  0.33062133 -0.30864231  0.38175319  0.12354407]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.15865467 -0.12761638 -0.52819657  0.08025976]
 [ 0.99985184  0.99904822  0.26888971 -0.28350408  0.39615113  0.08240026]
 [ 0.99985184  0.9961947   0.27770851 -0.32580988  0.38924012  0.08462174]
 [ 0.99985184  0.99144486  0.2571313  -0.32642301  0.38693645  0.07818869]
 [ 0.99985184  0.98480775  0.33062133 -0.30864231  0.38175319  0.12354407]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.083744764328003
lalalalalal
260 [[ 1.         -0.11766784 -0.06967582 -1.37018806 -0.21651717]
 [ 0.99904822 -0.10150003 -0.17773957 -1.37709907 -0.26454528]
 [ 0.9961947  -0.0044932  -0.0275233  -1.37997866 -0.11387747]
 [ 0.99144486 -0.14559405  0.16377252 -1.38746559 -0.20236675]
 [ 0.98480775 -0.03388921  0.0901972  -1.39322476 -0.02131547]]
hahahahahahah
265 [[-0.84754092  1.         -0.11766784 -0.06967582 -1.37018806 -0.21651717]
 [-0.84754092  0.99904822 -0.10150003 -0.17773957 -1.37709907 -0.26454528]
 [-0.84754092  0.9961947  -0.0044932  -0.0275233  -1.37997866 -0.11387747]
 [-0.84754092  0.99144486 -0.14559405  0.16377252 -1.38746559 -0.20236675]
 [-0.84754092  0.98480775 -0.03388921  0.0901972  -1.39322476 -0.02131547]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.11766784 -0.06967582 -1.37018806 -0.21651717]
 [-0.84754092  0.99904822 -0.10150003 -0.17773957 -1.37709907 -0.26454528]
 [-0.84754092  0.9961947  -0.0044932  -0.0275233  -1.37997866 -0.11387747]
 [-0.84754092  0.99144486 -0.14559405  0.16377252 -1.38746559 -0.20236675]
 [-0.84754092  0.98480775 -0.03388921  0.0901972  -1.39322476 -0.02131547]]

Epoch: 0, 
Train Loss: 0.9853610819628259, 
Validation Loss: 0.6934617413207889
Elapsed time for epoch-0: 3.3486039638519287
common line69: model saved with val loss 0.6934617413207889

Epoch: 1, 
Train Loss: 0.945479363703928, 
Validation Loss: 0.6882918747141957
Elapsed time for epoch-1: 3.864776849746704
common line69: model saved with val loss 0.6882918747141957

Epoch: 2, 
Train Loss: 0.9382367367003145, 
Validation Loss: 0.6866492936387658
Elapsed time for epoch-2: 3.8530032634735107
common line69: model saved with val loss 0.6866492936387658

Epoch: 3, 
Train Loss: 0.9335163755326712, 
Validation Loss: 0.6837656460702419
Elapsed time for epoch-3: 3.771941900253296
common line69: model saved with val loss 0.6837656460702419

Epoch: 4, 
Train Loss: 0.9305778680478826, 
Validation Loss: 0.6825858680531383
Elapsed time for epoch-4: 3.886667013168335
common line69: model saved with val loss 0.6825858680531383

Epoch: 5, 
Train Loss: 0.9277908673056033, 
Validation Loss: 0.6838450562208891
Elapsed time for epoch-5: 4.321824312210083

Epoch: 6, 
Train Loss: 0.9260123013949194, 
Validation Loss: 0.6814234182238579
Elapsed time for epoch-6: 4.460519790649414
common line69: model saved with val loss 0.6814234182238579

Epoch: 7, 
Train Loss: 0.9245872612760848, 
Validation Loss: 0.6742630489170551
Elapsed time for epoch-7: 5.099093914031982
common line69: model saved with val loss 0.6742630489170551

Epoch: 8, 
Train Loss: 0.9232037081187513, 
Validation Loss: 0.6802064031362534
Elapsed time for epoch-8: 3.74364972114563

Epoch: 9, 
Train Loss: 0.922192941443259, 
Validation Loss: 0.6784215066581964
Elapsed time for epoch-9: 4.858112335205078

Epoch: 10, 
Train Loss: 0.9213788748538795, 
Validation Loss: 0.6816863538697362
Elapsed time for epoch-10: 4.58469820022583

Epoch: 11, 
Train Loss: 0.920647408155834, 
Validation Loss: 0.6823030281811953
Elapsed time for epoch-11: 3.9181487560272217

Epoch: 12, 
Train Loss: 0.9199628131229336, 
Validation Loss: 0.6804569335654378
Elapsed time for epoch-12: 4.0659143924713135

Epoch: 13, 
Train Loss: 0.9195037391506323, 
Validation Loss: 0.6796737015247345
Elapsed time for epoch-13: 4.1677587032318115

Epoch: 14, 
Train Loss: 0.9189012442566767, 
Validation Loss: 0.6785146938636899
Elapsed time for epoch-14: 4.187340021133423

Epoch: 15, 
Train Loss: 0.9183389476868284, 
Validation Loss: 0.6767966421321034
Elapsed time for epoch-15: 3.6387600898742676

Epoch: 16, 
Train Loss: 0.9175753176462751, 
Validation Loss: 0.6845439709722996
Elapsed time for epoch-16: 4.303249359130859

Epoch: 17, 
Train Loss: 0.9174410683267257, 
Validation Loss: 0.6855482375249267
Elapsed time for epoch-17: 3.973856210708618

Epoch: 18, 
Train Loss: 0.9169959626277956, 
Validation Loss: 0.6766689782962203
Elapsed time for epoch-18: 3.9305899143218994

Epoch: 19, 
Train Loss: 0.9166384738783876, 
Validation Loss: 0.6767244413495064
Elapsed time for epoch-19: 3.7293646335601807
Early stopped! 

train line101: min loss for the epoch 19 is 0.6742630489170551

Training the 76-th turbine in 173.1803081035614 secs

>>>>>>>>> Training Turbine  77 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.7103793621063232
lalalalalal
260 [[ 1.          0.20393538 -0.14127737 -0.68643607  0.06835263]
 [ 0.99904822  0.29963059 -0.30716705  0.52111506 -0.08290392]
 [ 0.9961947   0.26773218 -0.30485154  0.51798263 -0.12215574]
 [ 0.99144486  0.39822564 -0.32932978  0.51171777 -0.03672675]
 [ 0.98480775  0.16913712 -0.36075455  0.50936845 -0.24412025]]
hahahahahahah
265 [[ 0.99985184  1.          0.20393538 -0.14127737 -0.68643607  0.06835263]
 [ 0.99985184  0.99904822  0.29963059 -0.30716705  0.52111506 -0.08290392]
 [ 0.99985184  0.9961947   0.26773218 -0.30485154  0.51798263 -0.12215574]
 [ 0.99985184  0.99144486  0.39822564 -0.32932978  0.51171777 -0.03672675]
 [ 0.99985184  0.98480775  0.16913712 -0.36075455  0.50936845 -0.24412025]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.20393538 -0.14127737 -0.68643607  0.06835263]
 [ 0.99985184  0.99904822  0.29963059 -0.30716705  0.52111506 -0.08290392]
 [ 0.99985184  0.9961947   0.26773218 -0.30485154  0.51798263 -0.12215574]
 [ 0.99985184  0.99144486  0.39822564 -0.32932978  0.51171777 -0.03672675]
 [ 0.99985184  0.98480775  0.16913712 -0.36075455  0.50936845 -0.24412025]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.667546033859253
lalalalalal
260 [[ 1.         -0.17449566  0.02097365 -1.87440951 -0.1086354 ]
 [ 0.99904822 -0.05125183 -0.00813561 -1.87832505  0.01684073]
 [ 0.9961947  -0.38473512  0.11855582 -1.88067437 -0.18379872]
 [ 0.99144486 -0.20204428  0.11723267 -1.88615612 -0.02617965]
 [ 0.98480775  0.13143901  0.04644425 -1.88615612  0.47866141]]
hahahahahahah
265 [[-0.84754092  1.         -0.17449566  0.02097365 -1.87440951 -0.1086354 ]
 [-0.84754092  0.99904822 -0.05125183 -0.00813561 -1.87832505  0.01684073]
 [-0.84754092  0.9961947  -0.38473512  0.11855582 -1.88067437 -0.18379872]
 [-0.84754092  0.99144486 -0.20204428  0.11723267 -1.88615612 -0.02617965]
 [-0.84754092  0.98480775  0.13143901  0.04644425 -1.88615612  0.47866141]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.17449566  0.02097365 -1.87440951 -0.1086354 ]
 [-0.84754092  0.99904822 -0.05125183 -0.00813561 -1.87832505  0.01684073]
 [-0.84754092  0.9961947  -0.38473512  0.11855582 -1.88067437 -0.18379872]
 [-0.84754092  0.99144486 -0.20204428  0.11723267 -1.88615612 -0.02617965]
 [-0.84754092  0.98480775  0.13143901  0.04644425 -1.88615612  0.47866141]]

Epoch: 0, 
Train Loss: 0.9796585757441881, 
Validation Loss: 0.7899770131334662
Elapsed time for epoch-0: 3.23149037361145
common line69: model saved with val loss 0.7899770131334662

Epoch: 1, 
Train Loss: 0.9459860150804039, 
Validation Loss: 0.7662157025188208
Elapsed time for epoch-1: 3.1631758213043213
common line69: model saved with val loss 0.7662157025188208

Epoch: 2, 
Train Loss: 0.9381506396692341, 
Validation Loss: 0.7453714068979025
Elapsed time for epoch-2: 4.02682900428772
common line69: model saved with val loss 0.7453714068979025

Epoch: 3, 
Train Loss: 0.933386701120048, 
Validation Loss: 0.7511034915223718
Elapsed time for epoch-3: 4.274427890777588

Epoch: 4, 
Train Loss: 0.9300715467509102, 
Validation Loss: 0.7379540605470538
Elapsed time for epoch-4: 4.124508619308472
common line69: model saved with val loss 0.7379540605470538

Epoch: 5, 
Train Loss: 0.9281970722084286, 
Validation Loss: 0.7367383446544409
Elapsed time for epoch-5: 4.176100254058838
common line69: model saved with val loss 0.7367383446544409

Epoch: 6, 
Train Loss: 0.926446081585243, 
Validation Loss: 0.738182527013123
Elapsed time for epoch-6: 4.137818098068237

Epoch: 7, 
Train Loss: 0.924933807439163, 
Validation Loss: 0.7351806750521064
Elapsed time for epoch-7: 3.965444564819336
common line69: model saved with val loss 0.7351806750521064

Epoch: 8, 
Train Loss: 0.9237948038748333, 
Validation Loss: 0.7348677339032292
Elapsed time for epoch-8: 3.7960164546966553
common line69: model saved with val loss 0.7348677339032292

Epoch: 9, 
Train Loss: 0.9227173983299432, 
Validation Loss: 0.7278075646609068
Elapsed time for epoch-9: 3.927222490310669
common line69: model saved with val loss 0.7278075646609068

Epoch: 10, 
Train Loss: 0.921892881142993, 
Validation Loss: 0.7274326998740435
Elapsed time for epoch-10: 4.295244455337524
common line69: model saved with val loss 0.7274326998740435

Epoch: 11, 
Train Loss: 0.9209489059798858, 
Validation Loss: 0.7309578033164144
Elapsed time for epoch-11: 3.821051836013794

Epoch: 12, 
Train Loss: 0.920620418897196, 
Validation Loss: 0.7288673901930451
Elapsed time for epoch-12: 4.41094446182251

Epoch: 13, 
Train Loss: 0.9201020037426668, 
Validation Loss: 0.7308732382953167
Elapsed time for epoch-13: 4.178516149520874

Epoch: 14, 
Train Loss: 0.919425198010036, 
Validation Loss: 0.7244398025795817
Elapsed time for epoch-14: 3.6792728900909424
common line69: model saved with val loss 0.7244398025795817

Epoch: 15, 
Train Loss: 0.9188126537228832, 
Validation Loss: 0.7294752709567547
Elapsed time for epoch-15: 3.4897549152374268

Epoch: 16, 
Train Loss: 0.9184568879985008, 
Validation Loss: 0.7204151628538966
Elapsed time for epoch-16: 4.112823486328125
common line69: model saved with val loss 0.7204151628538966

Epoch: 17, 
Train Loss: 0.918159634000113, 
Validation Loss: 0.7219607997685671
Elapsed time for epoch-17: 4.215938568115234

Epoch: 18, 
Train Loss: 0.9176136820005769, 
Validation Loss: 0.7247318932786584
Elapsed time for epoch-18: 4.080209493637085

Epoch: 19, 
Train Loss: 0.9173055996163553, 
Validation Loss: 0.7236098814755678
Elapsed time for epoch-19: 4.536222219467163

Epoch: 20, 
Train Loss: 0.9170504451549354, 
Validation Loss: 0.7229254953563213
Elapsed time for epoch-20: 4.225185394287109

Epoch: 21, 
Train Loss: 0.91659457555839, 
Validation Loss: 0.7176665384322405
Elapsed time for epoch-21: 3.675163507461548
common line69: model saved with val loss 0.7176665384322405

Epoch: 22, 
Train Loss: 0.9161062002682886, 
Validation Loss: 0.7219216749072075
Elapsed time for epoch-22: 3.321742296218872

Epoch: 23, 
Train Loss: 0.9160438753476664, 
Validation Loss: 0.718854489736259
Elapsed time for epoch-23: 3.8028504848480225

Epoch: 24, 
Train Loss: 0.9158228586952225, 
Validation Loss: 0.7222593948245049
Elapsed time for epoch-24: 4.259988307952881

Epoch: 25, 
Train Loss: 0.9153343396527427, 
Validation Loss: 0.7206051675602794
Elapsed time for epoch-25: 4.1764748096466064

Epoch: 26, 
Train Loss: 0.9153447143670892, 
Validation Loss: 0.7196786887943745
Elapsed time for epoch-26: 4.293195962905884

Epoch: 27, 
Train Loss: 0.9151661233240816, 
Validation Loss: 0.7202329970896244
Elapsed time for epoch-27: 4.624998331069946

Epoch: 28, 
Train Loss: 0.9146711165163698, 
Validation Loss: 0.7218387695029378
Elapsed time for epoch-28: 4.071141958236694

Epoch: 29, 
Train Loss: 0.9143787048944906, 
Validation Loss: 0.7163987597450614
Elapsed time for epoch-29: 4.420877933502197
common line69: model saved with val loss 0.7163987597450614

Epoch: 30, 
Train Loss: 0.9142406038126024, 
Validation Loss: 0.7166006658226252
Elapsed time for epoch-30: 4.880528688430786

Epoch: 31, 
Train Loss: 0.9139446275574821, 
Validation Loss: 0.7204250767827034
Elapsed time for epoch-31: 5.28533411026001

train line101: min loss for the epoch 31 is 0.7163987597450614

Training the 77-th turbine in 215.5501515865326 secs

>>>>>>>>> Training Turbine  78 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.9531638622283936
lalalalalal
260 [[ 1.          0.14115657 -0.22119954 -0.21678229  0.02842158]
 [ 0.99904822  0.15337438 -0.24722488  0.31461174 -0.01701482]
 [ 0.9961947   0.10450313 -0.24035026  0.31331486 -0.07310593]
 [ 0.99144486  0.26197716 -0.18404388  0.30845159  0.06433978]
 [ 0.98480775  0.06106202 -0.29207357  0.30812737 -0.15881712]]
hahahahahahah
265 [[ 0.99985184  1.          0.14115657 -0.22119954 -0.21678229  0.02842158]
 [ 0.99985184  0.99904822  0.15337438 -0.24722488  0.31461174 -0.01701482]
 [ 0.99985184  0.9961947   0.10450313 -0.24035026  0.31331486 -0.07310593]
 [ 0.99985184  0.99144486  0.26197716 -0.18404388  0.30845159  0.06433978]
 [ 0.99985184  0.98480775  0.06106202 -0.29207357  0.30812737 -0.15881712]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.14115657 -0.22119954 -0.21678229  0.02842158]
 [ 0.99985184  0.99904822  0.15337438 -0.24722488  0.31461174 -0.01701482]
 [ 0.99985184  0.9961947   0.10450313 -0.24035026  0.31331486 -0.07310593]
 [ 0.99985184  0.99144486  0.26197716 -0.18404388  0.30845159  0.06433978]
 [ 0.99985184  0.98480775  0.06106202 -0.29207357  0.30812737 -0.15881712]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.052130699157715
lalalalalal
260 [[ 1.         -0.08962434  0.09372338 -0.64685805 -0.11713354]
 [ 0.99904822  0.01219077  0.0601687  -0.64928969 -0.00413446]
 [ 0.9961947  -0.18329424 -0.04327791 -0.64928969 -0.14539219]
 [ 0.99144486 -0.02853528 -0.13755837 -0.6548014  -0.02568065]
 [ 0.98480775  0.34071418 -0.18175234 -0.65512562  0.39638778]]
hahahahahahah
265 [[-0.84754092  1.         -0.08962434  0.09372338 -0.64685805 -0.11713354]
 [-0.84754092  0.99904822  0.01219077  0.0601687  -0.64928969 -0.00413446]
 [-0.84754092  0.9961947  -0.18329424 -0.04327791 -0.64928969 -0.14539219]
 [-0.84754092  0.99144486 -0.02853528 -0.13755837 -0.6548014  -0.02568065]
 [-0.84754092  0.98480775  0.34071418 -0.18175234 -0.65512562  0.39638778]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.08962434  0.09372338 -0.64685805 -0.11713354]
 [-0.84754092  0.99904822  0.01219077  0.0601687  -0.64928969 -0.00413446]
 [-0.84754092  0.9961947  -0.18329424 -0.04327791 -0.64928969 -0.14539219]
 [-0.84754092  0.99144486 -0.02853528 -0.13755837 -0.6548014  -0.02568065]
 [-0.84754092  0.98480775  0.34071418 -0.18175234 -0.65512562  0.39638778]]

Epoch: 0, 
Train Loss: 1.0082292951205198, 
Validation Loss: 0.7693546582013369
Elapsed time for epoch-0: 3.9848639965057373
common line69: model saved with val loss 0.7693546582013369

Epoch: 1, 
Train Loss: 0.9554365438823941, 
Validation Loss: 0.7473107650876045
Elapsed time for epoch-1: 4.202986717224121
common line69: model saved with val loss 0.7473107650876045

Epoch: 2, 
Train Loss: 0.9446421935528266, 
Validation Loss: 0.7394427927210927
Elapsed time for epoch-2: 5.0545196533203125
common line69: model saved with val loss 0.7394427927210927

Epoch: 3, 
Train Loss: 0.939462534269365, 
Validation Loss: 0.7433780515566468
Elapsed time for epoch-3: 5.0800535678863525

Epoch: 4, 
Train Loss: 0.9364997629357987, 
Validation Loss: 0.7381840944290161
Elapsed time for epoch-4: 4.811544418334961
common line69: model saved with val loss 0.7381840944290161

Epoch: 5, 
Train Loss: 0.9341592971517259, 
Validation Loss: 0.7401200840249658
Elapsed time for epoch-5: 5.023867607116699

Epoch: 6, 
Train Loss: 0.9323379595239624, 
Validation Loss: 0.7367004742845893
Elapsed time for epoch-6: 4.485885143280029
common line69: model saved with val loss 0.7367004742845893

Epoch: 7, 
Train Loss: 0.9311305620089299, 
Validation Loss: 0.7330893455073237
Elapsed time for epoch-7: 4.409313917160034
common line69: model saved with val loss 0.7330893455073237

Epoch: 8, 
Train Loss: 0.930086967699668, 
Validation Loss: 0.73438018001616
Elapsed time for epoch-8: 4.098137855529785

Epoch: 9, 
Train Loss: 0.9291138108037099, 
Validation Loss: 0.7302494579926133
Elapsed time for epoch-9: 5.03714394569397
common line69: model saved with val loss 0.7302494579926133

Epoch: 10, 
Train Loss: 0.9281510331300127, 
Validation Loss: 0.7310865772888064
Elapsed time for epoch-10: 5.152053594589233

Epoch: 11, 
Train Loss: 0.9278641563503682, 
Validation Loss: 0.7345740627497435
Elapsed time for epoch-11: 5.000247478485107

Epoch: 12, 
Train Loss: 0.9272227064401162, 
Validation Loss: 0.7309869816526771
Elapsed time for epoch-12: 4.14351749420166

Epoch: 13, 
Train Loss: 0.9265866376021329, 
Validation Loss: 0.7255709199234843
Elapsed time for epoch-13: 4.518687725067139
common line69: model saved with val loss 0.7255709199234843

Epoch: 14, 
Train Loss: 0.926147937899878, 
Validation Loss: 0.728442226536572
Elapsed time for epoch-14: 3.9732730388641357

Epoch: 15, 
Train Loss: 0.925867108862941, 
Validation Loss: 0.7212036680430174
Elapsed time for epoch-15: 3.4676384925842285
common line69: model saved with val loss 0.7212036680430174

Epoch: 16, 
Train Loss: 0.9257128351375836, 
Validation Loss: 0.7300883047282696
Elapsed time for epoch-16: 3.8511457443237305

Epoch: 17, 
Train Loss: 0.9252237151650822, 
Validation Loss: 0.7338262470439076
Elapsed time for epoch-17: 3.934288740158081

Epoch: 18, 
Train Loss: 0.9249252020811835, 
Validation Loss: 0.7297947145998478
Elapsed time for epoch-18: 3.973562002182007

Epoch: 19, 
Train Loss: 0.9246274652350851, 
Validation Loss: 0.7267369125038385
Elapsed time for epoch-19: 4.1785078048706055

Epoch: 20, 
Train Loss: 0.9241999852306703, 
Validation Loss: 0.7262023352086544
Elapsed time for epoch-20: 4.081579208374023

Epoch: 21, 
Train Loss: 0.9241934943349421, 
Validation Loss: 0.7290225522592664
Elapsed time for epoch-21: 4.322169780731201

Epoch: 22, 
Train Loss: 0.9240675785210954, 
Validation Loss: 0.7248416235670447
Elapsed time for epoch-22: 3.7553036212921143

Epoch: 23, 
Train Loss: 0.9234605484149035, 
Validation Loss: 0.7258889582008123
Elapsed time for epoch-23: 4.54571533203125

Epoch: 24, 
Train Loss: 0.9236402587980783, 
Validation Loss: 0.7299381708726287
Elapsed time for epoch-24: 4.243589639663696

Epoch: 25, 
Train Loss: 0.9230697277714225, 
Validation Loss: 0.7233093567192554
Elapsed time for epoch-25: 4.038686990737915

Epoch: 26, 
Train Loss: 0.9232055519809242, 
Validation Loss: 0.7295654020272195
Elapsed time for epoch-26: 4.060116291046143

Epoch: 27, 
Train Loss: 0.9230802170619243, 
Validation Loss: 0.7258839253336191
Elapsed time for epoch-27: 4.623213052749634
Early stopped! 

train line101: min loss for the epoch 27 is 0.7212036680430174

Training the 78-th turbine in 205.0477797985077 secs

>>>>>>>>> Training Turbine  79 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.9828379154205322
lalalalalal
260 [[ 1.          0.18978867 -0.15695891 -0.30687178  0.16344971]
 [ 0.99904822  0.1570724  -0.27135734  0.3458073   0.06353713]
 [ 0.9961947   0.1124593  -0.27961605  0.34314175  0.01685062]
 [ 0.99144486  0.21060811 -0.30072164  0.34161858  0.13569348]
 [ 0.98480775  0.00836208 -0.14288851  0.33819144 -0.07738288]]
hahahahahahah
265 [[ 0.99985184  1.          0.18978867 -0.15695891 -0.30687178  0.16344971]
 [ 0.99985184  0.99904822  0.1570724  -0.27135734  0.3458073   0.06353713]
 [ 0.99985184  0.9961947   0.1124593  -0.27961605  0.34314175  0.01685062]
 [ 0.99985184  0.99144486  0.21060811 -0.30072164  0.34161858  0.13569348]
 [ 0.99985184  0.98480775  0.00836208 -0.14288851  0.33819144 -0.07738288]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.18978867 -0.15695891 -0.30687178  0.16344971]
 [ 0.99985184  0.99904822  0.1570724  -0.27135734  0.3458073   0.06353713]
 [ 0.99985184  0.9961947   0.1124593  -0.27961605  0.34314175  0.01685062]
 [ 0.99985184  0.99144486  0.21060811 -0.30072164  0.34161858  0.13569348]
 [ 0.99985184  0.98480775  0.00836208 -0.14288851  0.33819144 -0.07738288]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.318244218826294
lalalalalal
260 [[ 1.          0.07230752  0.05960282 -0.85007288  0.02791377]
 [ 0.99904822  0.23142755  0.05256763 -0.85330962  0.17441452]
 [ 0.9961947   0.00836208 -0.09180686 -0.85369042  0.06958499]
 [ 0.99144486  0.02918152 -0.16307647 -0.85369042  0.11644359]
 [ 0.98480775  0.40095732 -0.14961783 -0.85369042  0.53222154]]
hahahahahahah
265 [[-0.84754092  1.          0.07230752  0.05960282 -0.85007288  0.02791377]
 [-0.84754092  0.99904822  0.23142755  0.05256763 -0.85330962  0.17441452]
 [-0.84754092  0.9961947   0.00836208 -0.09180686 -0.85369042  0.06958499]
 [-0.84754092  0.99144486  0.02918152 -0.16307647 -0.85369042  0.11644359]
 [-0.84754092  0.98480775  0.40095732 -0.14961783 -0.85369042  0.53222154]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.07230752  0.05960282 -0.85007288  0.02791377]
 [-0.84754092  0.99904822  0.23142755  0.05256763 -0.85330962  0.17441452]
 [-0.84754092  0.9961947   0.00836208 -0.09180686 -0.85369042  0.06958499]
 [-0.84754092  0.99144486  0.02918152 -0.16307647 -0.85369042  0.11644359]
 [-0.84754092  0.98480775  0.40095732 -0.14961783 -0.85369042  0.53222154]]

Epoch: 0, 
Train Loss: 0.9947129098557624, 
Validation Loss: 0.8108597500249743
Elapsed time for epoch-0: 3.475815773010254
common line69: model saved with val loss 0.8108597500249743

Epoch: 1, 
Train Loss: 0.9526877145306403, 
Validation Loss: 0.7564589669927955
Elapsed time for epoch-1: 3.2873122692108154
common line69: model saved with val loss 0.7564589669927955

Epoch: 2, 
Train Loss: 0.935100094110024, 
Validation Loss: 0.7519698366522789
Elapsed time for epoch-2: 3.308628559112549
common line69: model saved with val loss 0.7519698366522789

Epoch: 3, 
Train Loss: 0.9281935297390994, 
Validation Loss: 0.7486097989603877
Elapsed time for epoch-3: 3.3576245307922363
common line69: model saved with val loss 0.7486097989603877

Epoch: 4, 
Train Loss: 0.9237462576447415, 
Validation Loss: 0.7449928317219019
Elapsed time for epoch-4: 3.18684458732605
common line69: model saved with val loss 0.7449928317219019

Epoch: 5, 
Train Loss: 0.9207297920429406, 
Validation Loss: 0.753354063257575
Elapsed time for epoch-5: 3.7611050605773926

Epoch: 6, 
Train Loss: 0.9184415873860111, 
Validation Loss: 0.7465158244594932
Elapsed time for epoch-6: 3.0543999671936035

Epoch: 7, 
Train Loss: 0.9165203722835589, 
Validation Loss: 0.7442065998911858
Elapsed time for epoch-7: 3.454192638397217
common line69: model saved with val loss 0.7442065998911858

Epoch: 8, 
Train Loss: 0.9150449214111857, 
Validation Loss: 0.7519444255158305
Elapsed time for epoch-8: 4.135014772415161

Epoch: 9, 
Train Loss: 0.9133921891701322, 
Validation Loss: 0.7519167652353644
Elapsed time for epoch-9: 4.306628942489624

Epoch: 10, 
Train Loss: 0.9124661562573008, 
Validation Loss: 0.7474721167236567
Elapsed time for epoch-10: 3.8442935943603516

Epoch: 11, 
Train Loss: 0.9117103986629919, 
Validation Loss: 0.7463401602581143
Elapsed time for epoch-11: 3.668994188308716

Epoch: 12, 
Train Loss: 0.9105193949296695, 
Validation Loss: 0.74820685852319
Elapsed time for epoch-12: 4.404745101928711

Epoch: 13, 
Train Loss: 0.9098538543496814, 
Validation Loss: 0.7453670725226402
Elapsed time for epoch-13: 3.9619219303131104

Epoch: 14, 
Train Loss: 0.9091441623803949, 
Validation Loss: 0.7536131031811237
Elapsed time for epoch-14: 3.501185894012451

Epoch: 15, 
Train Loss: 0.9085066294720193, 
Validation Loss: 0.7464092280715704
Elapsed time for epoch-15: 3.989941358566284

Epoch: 16, 
Train Loss: 0.9082591533660889, 
Validation Loss: 0.7493447307497263
Elapsed time for epoch-16: 3.4338293075561523

Epoch: 17, 
Train Loss: 0.9077905196101725, 
Validation Loss: 0.7496998012065887
Elapsed time for epoch-17: 3.652712106704712

Epoch: 18, 
Train Loss: 0.9074151340652915, 
Validation Loss: 0.7462060451507568
Elapsed time for epoch-18: 3.7950708866119385

Epoch: 19, 
Train Loss: 0.9070251579044246, 
Validation Loss: 0.7461528144776821
Elapsed time for epoch-19: 4.3291168212890625
Early stopped! 

train line101: min loss for the epoch 19 is 0.7442065998911858

Training the 79-th turbine in 166.23836994171143 secs

>>>>>>>>> Training Turbine  80 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.962909698486328
lalalalalal
260 [[ 1.          0.14082249  0.1023285  -0.30292568  0.18614575]
 [ 0.99904822  0.13791647  0.10610371  0.32685544  0.0707865 ]
 [ 0.9961947   0.1175743   0.07432905  0.32536129  0.06017848]
 [ 0.99144486  0.16407068  0.07244145  0.32162594  0.11829305]
 [ 0.98480775  0.04782975 -0.05371339  0.32087887 -0.02582143]]
hahahahahahah
265 [[ 0.99985184  1.          0.14082249  0.1023285  -0.30292568  0.18614575]
 [ 0.99985184  0.99904822  0.13791647  0.10610371  0.32685544  0.0707865 ]
 [ 0.99985184  0.9961947   0.1175743   0.07432905  0.32536129  0.06017848]
 [ 0.99985184  0.99144486  0.16407068  0.07244145  0.32162594  0.11829305]
 [ 0.99985184  0.98480775  0.04782975 -0.05371339  0.32087887 -0.02582143]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.14082249  0.1023285  -0.30292568  0.18614575]
 [ 0.99985184  0.99904822  0.13791647  0.10610371  0.32685544  0.0707865 ]
 [ 0.99985184  0.9961947   0.1175743   0.07432905  0.32536129  0.06017848]
 [ 0.99985184  0.99144486  0.16407068  0.07244145  0.32162594  0.11829305]
 [ 0.99985184  0.98480775  0.04782975 -0.05371339  0.32087887 -0.02582143]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.961393356323242
lalalalalal
260 [[ 1.          0.14663454 -0.18364344 -0.84698037  0.12449114]
 [ 0.99904822  0.31518388 -0.13079054 -0.85127603  0.33953924]
 [ 0.9961947  -0.14396779 -0.06157841 -0.85127603 -0.06373485]
 [ 0.99144486 -0.01029072 -0.1647674  -0.85164956  0.11396769]
 [ 0.98480775  0.30937184 -0.17200322 -0.85501138  0.51062082]]
hahahahahahah
265 [[-0.84754092  1.          0.14663454 -0.18364344 -0.84698037  0.12449114]
 [-0.84754092  0.99904822  0.31518388 -0.13079054 -0.85127603  0.33953924]
 [-0.84754092  0.9961947  -0.14396779 -0.06157841 -0.85127603 -0.06373485]
 [-0.84754092  0.99144486 -0.01029072 -0.1647674  -0.85164956  0.11396769]
 [-0.84754092  0.98480775  0.30937184 -0.17200322 -0.85501138  0.51062082]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.14663454 -0.18364344 -0.84698037  0.12449114]
 [-0.84754092  0.99904822  0.31518388 -0.13079054 -0.85127603  0.33953924]
 [-0.84754092  0.9961947  -0.14396779 -0.06157841 -0.85127603 -0.06373485]
 [-0.84754092  0.99144486 -0.01029072 -0.1647674  -0.85164956  0.11396769]
 [-0.84754092  0.98480775  0.30937184 -0.17200322 -0.85501138  0.51062082]]

Epoch: 0, 
Train Loss: 1.0331901201680929, 
Validation Loss: 0.8538592662662268
Elapsed time for epoch-0: 3.1353487968444824
common line69: model saved with val loss 0.8538592662662268

Epoch: 1, 
Train Loss: 1.0058570554276474, 
Validation Loss: 0.7864156411960721
Elapsed time for epoch-1: 3.051008701324463
common line69: model saved with val loss 0.7864156411960721

Epoch: 2, 
Train Loss: 0.9629474343622432, 
Validation Loss: 0.7652189768850803
Elapsed time for epoch-2: 3.8899552822113037
common line69: model saved with val loss 0.7652189768850803

Epoch: 3, 
Train Loss: 0.9549862697344869, 
Validation Loss: 0.7531375447288156
Elapsed time for epoch-3: 3.771035671234131
common line69: model saved with val loss 0.7531375447288156

Epoch: 4, 
Train Loss: 0.9504743852034336, 
Validation Loss: 0.7577443709596992
Elapsed time for epoch-4: 4.395126104354858

Epoch: 5, 
Train Loss: 0.9474679097658446, 
Validation Loss: 0.7472408069297671
Elapsed time for epoch-5: 4.3036723136901855
common line69: model saved with val loss 0.7472408069297671

Epoch: 6, 
Train Loss: 0.9450112064095104, 
Validation Loss: 0.7478651031851768
Elapsed time for epoch-6: 3.4225471019744873

Epoch: 7, 
Train Loss: 0.9428055901236895, 
Validation Loss: 0.7415573345497251
Elapsed time for epoch-7: 2.9954278469085693
common line69: model saved with val loss 0.7415573345497251

Epoch: 8, 
Train Loss: 0.9412843944395289, 
Validation Loss: 0.7459570551291108
Elapsed time for epoch-8: 3.5164778232574463

Epoch: 9, 
Train Loss: 0.9399236016163305, 
Validation Loss: 0.7396665439009666
Elapsed time for epoch-9: 3.1665215492248535
common line69: model saved with val loss 0.7396665439009666

Epoch: 10, 
Train Loss: 0.9388438618483663, 
Validation Loss: 0.7395890401676297
Elapsed time for epoch-10: 3.3165030479431152
common line69: model saved with val loss 0.7395890401676297

Epoch: 11, 
Train Loss: 0.9377518355095086, 
Validation Loss: 0.7382357269525528
Elapsed time for epoch-11: 3.2151572704315186
common line69: model saved with val loss 0.7382357269525528

Epoch: 12, 
Train Loss: 0.9370843750589034, 
Validation Loss: 0.7364597655832767
Elapsed time for epoch-12: 3.0498173236846924
common line69: model saved with val loss 0.7364597655832767

Epoch: 13, 
Train Loss: 0.9361596387975356, 
Validation Loss: 0.7371391365304589
Elapsed time for epoch-13: 3.310136318206787

Epoch: 14, 
Train Loss: 0.9353966856954479, 
Validation Loss: 0.7358531225472689
Elapsed time for epoch-14: 4.299892902374268
common line69: model saved with val loss 0.7358531225472689

Epoch: 15, 
Train Loss: 0.9351548329621804, 
Validation Loss: 0.7387270797044039
Elapsed time for epoch-15: 3.903339147567749

Epoch: 16, 
Train Loss: 0.9343111627743024, 
Validation Loss: 0.7316319206729531
Elapsed time for epoch-16: 4.467405557632446
common line69: model saved with val loss 0.7316319206729531

Epoch: 17, 
Train Loss: 0.933845848220737, 
Validation Loss: 0.7338841883465648
Elapsed time for epoch-17: 3.572669267654419

Epoch: 18, 
Train Loss: 0.933058753860097, 
Validation Loss: 0.7282866947352886
Elapsed time for epoch-18: 4.440422534942627
common line69: model saved with val loss 0.7282866947352886

Epoch: 19, 
Train Loss: 0.9329199874851885, 
Validation Loss: 0.7356606833636761
Elapsed time for epoch-19: 4.0458831787109375

Epoch: 20, 
Train Loss: 0.9323861131898495, 
Validation Loss: 0.7318266052752733
Elapsed time for epoch-20: 4.300082206726074

Epoch: 21, 
Train Loss: 0.9319861393515804, 
Validation Loss: 0.7311436189338565
Elapsed time for epoch-21: 4.300537824630737

Epoch: 22, 
Train Loss: 0.9315910321824691, 
Validation Loss: 0.7334108483046293
Elapsed time for epoch-22: 4.538002014160156

Epoch: 23, 
Train Loss: 0.9313117698961947, 
Validation Loss: 0.7340091038495302
Elapsed time for epoch-23: 4.294481992721558

Epoch: 24, 
Train Loss: 0.9305986403918066, 
Validation Loss: 0.7418761635199189
Elapsed time for epoch-24: 3.3040404319763184

Epoch: 25, 
Train Loss: 0.9306778559664718, 
Validation Loss: 0.7323483293876052
Elapsed time for epoch-25: 3.4646542072296143

Epoch: 26, 
Train Loss: 0.9303700206409983, 
Validation Loss: 0.73304857686162
Elapsed time for epoch-26: 4.604594945907593

Epoch: 27, 
Train Loss: 0.930019777487306, 
Validation Loss: 0.7314186887815595
Elapsed time for epoch-27: 4.134619951248169

Epoch: 28, 
Train Loss: 0.930132980607137, 
Validation Loss: 0.7294350787997246
Elapsed time for epoch-28: 3.705756187438965

Epoch: 29, 
Train Loss: 0.9296535917189943, 
Validation Loss: 0.7300701476633549
Elapsed time for epoch-29: 4.256402492523193

Epoch: 30, 
Train Loss: 0.9293413701928964, 
Validation Loss: 0.7346227774396539
Elapsed time for epoch-30: 4.142518758773804
Early stopped! 

train line101: min loss for the epoch 30 is 0.7282866947352886

Training the 80-th turbine in 212.68061017990112 secs

>>>>>>>>> Training Turbine  81 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.9158406257629395
lalalalalal
260 [[ 1.          0.12635249 -0.12508421 -0.42623604  0.2118284 ]
 [ 0.99904822  0.09007893 -0.11394373  0.37960069  0.04346857]
 [ 0.9961947   0.04364879 -0.14127504  0.37519319 -0.01706614]
 [ 0.99144486  0.05815821 -0.12612399  0.37127542 -0.00657112]
 [ 0.98480775 -0.04921151 -0.24852074  0.36539876 -0.14391035]]
hahahahahahah
265 [[ 0.99985184  1.          0.12635249 -0.12508421 -0.42623604  0.2118284 ]
 [ 0.99985184  0.99904822  0.09007893 -0.11394373  0.37960069  0.04346857]
 [ 0.99985184  0.9961947   0.04364879 -0.14127504  0.37519319 -0.01706614]
 [ 0.99985184  0.99144486  0.05815821 -0.12612399  0.37127542 -0.00657112]
 [ 0.99985184  0.98480775 -0.04921151 -0.24852074  0.36539876 -0.14391035]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.12635249 -0.12508421 -0.42623604  0.2118284 ]
 [ 0.99985184  0.99904822  0.09007893 -0.11394373  0.37960069  0.04346857]
 [ 0.99985184  0.9961947   0.04364879 -0.14127504  0.37519319 -0.01706614]
 [ 0.99985184  0.99144486  0.05815821 -0.12612399  0.37127542 -0.00657112]
 [ 0.99985184  0.98480775 -0.04921151 -0.24852074  0.36539876 -0.14391035]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.744457483291626
lalalalalal
260 [[ 1.          0.09878459 -0.08334454 -1.16424634  0.08571232]
 [ 0.99904822  0.24097692  0.03251647 -1.16791925  0.26778096]
 [ 0.9961947   0.21485996 -0.11216125 -1.16791925  0.43452134]
 [ 0.99144486  0.38897301 -0.18256909 -1.16840897  0.61574888]
 [ 0.98480775  0.39477678 -0.16117937 -1.17428563  0.64070596]]
hahahahahahah
265 [[-0.84754092  1.          0.09878459 -0.08334454 -1.16424634  0.08571232]
 [-0.84754092  0.99904822  0.24097692  0.03251647 -1.16791925  0.26778096]
 [-0.84754092  0.9961947   0.21485996 -0.11216125 -1.16791925  0.43452134]
 [-0.84754092  0.99144486  0.38897301 -0.18256909 -1.16840897  0.61574888]
 [-0.84754092  0.98480775  0.39477678 -0.16117937 -1.17428563  0.64070596]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.09878459 -0.08334454 -1.16424634  0.08571232]
 [-0.84754092  0.99904822  0.24097692  0.03251647 -1.16791925  0.26778096]
 [-0.84754092  0.9961947   0.21485996 -0.11216125 -1.16791925  0.43452134]
 [-0.84754092  0.99144486  0.38897301 -0.18256909 -1.16840897  0.61574888]
 [-0.84754092  0.98480775  0.39477678 -0.16117937 -1.17428563  0.64070596]]

Epoch: 0, 
Train Loss: 1.0181698400934203, 
Validation Loss: 0.7398190461099148
Elapsed time for epoch-0: 3.620177984237671
common line69: model saved with val loss 0.7398190461099148

Epoch: 1, 
Train Loss: 0.9801288004181966, 
Validation Loss: 0.7288350453600287
Elapsed time for epoch-1: 3.3069238662719727
common line69: model saved with val loss 0.7288350453600287

Epoch: 2, 
Train Loss: 0.9712344245249483, 
Validation Loss: 0.7233025766909122
Elapsed time for epoch-2: 3.540233850479126
common line69: model saved with val loss 0.7233025766909122

Epoch: 3, 
Train Loss: 0.9657191466383573, 
Validation Loss: 0.7264173030853271
Elapsed time for epoch-3: 3.5932483673095703

Epoch: 4, 
Train Loss: 0.9620164452480668, 
Validation Loss: 0.7131550014019012
Elapsed time for epoch-4: 4.527013540267944
common line69: model saved with val loss 0.7131550014019012

Epoch: 5, 
Train Loss: 0.9587100283438418, 
Validation Loss: 0.7174845477566123
Elapsed time for epoch-5: 3.945858955383301

Epoch: 6, 
Train Loss: 0.9566855320409566, 
Validation Loss: 0.7192628839984536
Elapsed time for epoch-6: 4.257015705108643

Epoch: 7, 
Train Loss: 0.954652655400148, 
Validation Loss: 0.7039805483072996
Elapsed time for epoch-7: 4.293982028961182
common line69: model saved with val loss 0.7039805483072996

Epoch: 8, 
Train Loss: 0.9535833041207129, 
Validation Loss: 0.7090199934318662
Elapsed time for epoch-8: 4.313028335571289

Epoch: 9, 
Train Loss: 0.9523947347863382, 
Validation Loss: 0.709630586206913
Elapsed time for epoch-9: 3.9664039611816406

Epoch: 10, 
Train Loss: 0.9514787964710668, 
Validation Loss: 0.710727846249938
Elapsed time for epoch-10: 5.1735358238220215

Epoch: 11, 
Train Loss: 0.9507295836170181, 
Validation Loss: 0.7066174745559692
Elapsed time for epoch-11: 5.350556373596191

Epoch: 12, 
Train Loss: 0.9496557676241177, 
Validation Loss: 0.7080317325890064
Elapsed time for epoch-12: 4.2216956615448

Epoch: 13, 
Train Loss: 0.948652697460992, 
Validation Loss: 0.704993843100965
Elapsed time for epoch-13: 3.905275583267212

Epoch: 14, 
Train Loss: 0.9483612961127978, 
Validation Loss: 0.7103492524474859
Elapsed time for epoch-14: 4.375817537307739

Epoch: 15, 
Train Loss: 0.947541407552086, 
Validation Loss: 0.7030621385201812
Elapsed time for epoch-15: 4.2503132820129395
common line69: model saved with val loss 0.7030621385201812

Epoch: 16, 
Train Loss: 0.9467731994741103, 
Validation Loss: 0.7007160512730479
Elapsed time for epoch-16: 3.9977333545684814
common line69: model saved with val loss 0.7007160512730479

Epoch: 17, 
Train Loss: 0.9462618162902463, 
Validation Loss: 0.7022364409640431
Elapsed time for epoch-17: 4.352052688598633

Epoch: 18, 
Train Loss: 0.9457429453354924, 
Validation Loss: 0.7082545189186931
Elapsed time for epoch-18: 4.049458265304565

Epoch: 19, 
Train Loss: 0.9452676299740287, 
Validation Loss: 0.7059500068426132
Elapsed time for epoch-19: 3.58616304397583

Epoch: 20, 
Train Loss: 0.9448898488483509, 
Validation Loss: 0.7065842356532812
Elapsed time for epoch-20: 3.6900553703308105

Epoch: 21, 
Train Loss: 0.9442051084352141, 
Validation Loss: 0.715651186183095
Elapsed time for epoch-21: 4.144351482391357

Epoch: 22, 
Train Loss: 0.9437969623743987, 
Validation Loss: 0.7050493881106377
Elapsed time for epoch-22: 4.068628787994385

Epoch: 23, 
Train Loss: 0.9435040402312239, 
Validation Loss: 0.7043433925136924
Elapsed time for epoch-23: 4.166034698486328

Epoch: 24, 
Train Loss: 0.9431153646036357, 
Validation Loss: 0.6989353336393833
Elapsed time for epoch-24: 3.7161929607391357
common line69: model saved with val loss 0.6989353336393833

Epoch: 25, 
Train Loss: 0.9427564028932267, 
Validation Loss: 0.700582591816783
Elapsed time for epoch-25: 3.676635265350342

Epoch: 26, 
Train Loss: 0.9424133309546638, 
Validation Loss: 0.6956107998266816
Elapsed time for epoch-26: 3.3464856147766113
common line69: model saved with val loss 0.6956107998266816

Epoch: 27, 
Train Loss: 0.9419983715570274, 
Validation Loss: 0.7102863611653447
Elapsed time for epoch-27: 3.64585018157959

Epoch: 28, 
Train Loss: 0.941879800638231, 
Validation Loss: 0.7029897598549724
Elapsed time for epoch-28: 4.042726993560791

Epoch: 29, 
Train Loss: 0.9416009289126436, 
Validation Loss: 0.703121654689312
Elapsed time for epoch-29: 4.1212122440338135

Epoch: 30, 
Train Loss: 0.9411963513668846, 
Validation Loss: 0.6946347774937749
Elapsed time for epoch-30: 3.780350685119629
common line69: model saved with val loss 0.6946347774937749

Epoch: 31, 
Train Loss: 0.9408434668258459, 
Validation Loss: 0.7074124496430159
Elapsed time for epoch-31: 4.17940616607666

train line101: min loss for the epoch 31 is 0.6946347774937749

Training the 81-th turbine in 224.89413285255432 secs

>>>>>>>>> Training Turbine  82 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.685087203979492
lalalalalal
260 [[ 1.          0.16450174 -0.17191152 -0.33484942  0.07899595]
 [ 0.99904822  0.17053972 -0.3293568   0.35618926 -0.02735144]
 [ 0.9961947   0.12223589 -0.32547725  0.35569742 -0.1233564 ]
 [ 0.99144486  0.20072962 -0.31771814  0.35176268 -0.03908632]
 [ 0.98480775 -0.01965662 -0.07750901  0.34930347 -0.19944182]]
hahahahahahah
265 [[ 0.99985184  1.          0.16450174 -0.17191152 -0.33484942  0.07899595]
 [ 0.99985184  0.99904822  0.17053972 -0.3293568   0.35618926 -0.02735144]
 [ 0.99985184  0.9961947   0.12223589 -0.32547725  0.35569742 -0.1233564 ]
 [ 0.99985184  0.99144486  0.20072962 -0.31771814  0.35176268 -0.03908632]
 [ 0.99985184  0.98480775 -0.01965662 -0.07750901  0.34930347 -0.19944182]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.16450174 -0.17191152 -0.33484942  0.07899595]
 [ 0.99985184  0.99904822  0.17053972 -0.3293568   0.35618926 -0.02735144]
 [ 0.99985184  0.9961947   0.12223589 -0.32547725  0.35569742 -0.1233564 ]
 [ 0.99985184  0.99144486  0.20072962 -0.31771814  0.35176268 -0.03908632]
 [ 0.99985184  0.98480775 -0.01965662 -0.07750901  0.34930347 -0.19944182]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.6702470779418945
lalalalalal
260 [[ 1.00000000e+00 -4.38085400e-02 -4.74424590e-02 -1.12819134e+00
  -8.32303225e-02]
 [ 9.99048222e-01  8.60080132e-02 -2.73980906e-02 -1.12966687e+00
   8.65747297e-02]
 [ 9.96194698e-01 -8.00364153e-02 -5.64500653e-04 -1.13163424e+00
  -7.86702995e-02]
 [ 9.91444861e-01  1.13178920e-01 -3.80668673e-02 -1.13458529e+00
   1.37447154e-01]
 [ 9.84807753e-01  2.42995473e-01 -2.77213869e-02 -1.13458529e+00
   3.17360789e-01]]
hahahahahahah
265 [[-8.47540923e-01  1.00000000e+00 -4.38085400e-02 -4.74424590e-02
  -1.12819134e+00 -8.32303225e-02]
 [-8.47540923e-01  9.99048222e-01  8.60080132e-02 -2.73980906e-02
  -1.12966687e+00  8.65747297e-02]
 [-8.47540923e-01  9.96194698e-01 -8.00364153e-02 -5.64500653e-04
  -1.13163424e+00 -7.86702995e-02]
 [-8.47540923e-01  9.91444861e-01  1.13178920e-01 -3.80668673e-02
  -1.13458529e+00  1.37447154e-01]
 [-8.47540923e-01  9.84807753e-01  2.42995473e-01 -2.77213869e-02
  -1.13458529e+00  3.17360789e-01]]

 wind turbine line248 data after normalization: 
 [[-8.47540923e-01  1.00000000e+00 -4.38085400e-02 -4.74424590e-02
  -1.12819134e+00 -8.32303225e-02]
 [-8.47540923e-01  9.99048222e-01  8.60080132e-02 -2.73980906e-02
  -1.12966687e+00  8.65747297e-02]
 [-8.47540923e-01  9.96194698e-01 -8.00364153e-02 -5.64500653e-04
  -1.13163424e+00 -7.86702995e-02]
 [-8.47540923e-01  9.91444861e-01  1.13178920e-01 -3.80668673e-02
  -1.13458529e+00  1.37447154e-01]
 [-8.47540923e-01  9.84807753e-01  2.42995473e-01 -2.77213869e-02
  -1.13458529e+00  3.17360789e-01]]

Epoch: 0, 
Train Loss: 0.9860540877620713, 
Validation Loss: 0.6426243400201201
Elapsed time for epoch-0: 3.9156084060668945
common line69: model saved with val loss 0.6426243400201201

Epoch: 1, 
Train Loss: 0.9408110974966979, 
Validation Loss: 0.6294845482334495
Elapsed time for epoch-1: 3.332587718963623
common line69: model saved with val loss 0.6294845482334495

Epoch: 2, 
Train Loss: 0.9306062074268565, 
Validation Loss: 0.6251795771531761
Elapsed time for epoch-2: 3.1019325256347656
common line69: model saved with val loss 0.6251795771531761

Epoch: 3, 
Train Loss: 0.9241521935753462, 
Validation Loss: 0.6217258051037788
Elapsed time for epoch-3: 3.315777063369751
common line69: model saved with val loss 0.6217258051037788

Epoch: 4, 
Train Loss: 0.9204136525132075, 
Validation Loss: 0.6213446408510208
Elapsed time for epoch-4: 4.323589324951172
common line69: model saved with val loss 0.6213446408510208

Epoch: 5, 
Train Loss: 0.9174786714696083, 
Validation Loss: 0.6224602349102497
Elapsed time for epoch-5: 4.139645338058472

Epoch: 6, 
Train Loss: 0.9155820020857979, 
Validation Loss: 0.6228698119521141
Elapsed time for epoch-6: 3.433847427368164

Epoch: 7, 
Train Loss: 0.9139318489978293, 
Validation Loss: 0.6224843957461417
Elapsed time for epoch-7: 3.7904016971588135

Epoch: 8, 
Train Loss: 0.9125581928411451, 
Validation Loss: 0.6134308087639511
Elapsed time for epoch-8: 4.415902137756348
common line69: model saved with val loss 0.6134308087639511

Epoch: 9, 
Train Loss: 0.9114282633326635, 
Validation Loss: 0.6209830241277814
Elapsed time for epoch-9: 3.770540237426758

Epoch: 10, 
Train Loss: 0.9105046069672128, 
Validation Loss: 0.6131491493433714
Elapsed time for epoch-10: 3.716153860092163
common line69: model saved with val loss 0.6131491493433714

Epoch: 11, 
Train Loss: 0.9093421537335179, 
Validation Loss: 0.6136620412580669
Elapsed time for epoch-11: 4.1752331256866455

Epoch: 12, 
Train Loss: 0.9089597637663368, 
Validation Loss: 0.6169289331883192
Elapsed time for epoch-12: 4.793540954589844

Epoch: 13, 
Train Loss: 0.9083129021049547, 
Validation Loss: 0.6133346254937351
Elapsed time for epoch-13: 4.44976282119751

Epoch: 14, 
Train Loss: 0.907706623818694, 
Validation Loss: 0.613295775372535
Elapsed time for epoch-14: 4.692070722579956

Epoch: 15, 
Train Loss: 0.9068704365181322, 
Validation Loss: 0.611198244150728
Elapsed time for epoch-15: 3.9078662395477295
common line69: model saved with val loss 0.611198244150728

Epoch: 16, 
Train Loss: 0.9067134008187205, 
Validation Loss: 0.6150164161808789
Elapsed time for epoch-16: 4.153146982192993

Epoch: 17, 
Train Loss: 0.9059678148321745, 
Validation Loss: 0.6136007644236088
Elapsed time for epoch-17: 4.956773519515991

Epoch: 18, 
Train Loss: 0.905538684931122, 
Validation Loss: 0.6083570029586554
Elapsed time for epoch-18: 4.688363790512085
common line69: model saved with val loss 0.6083570029586554

Epoch: 19, 
Train Loss: 0.9051204668123181, 
Validation Loss: 0.6053781043738127
Elapsed time for epoch-19: 4.145001649856567
common line69: model saved with val loss 0.6053781043738127

Epoch: 20, 
Train Loss: 0.9048703850066963, 
Validation Loss: 0.6138470619916916
Elapsed time for epoch-20: 4.2343056201934814

Epoch: 21, 
Train Loss: 0.9043369993191808, 
Validation Loss: 0.6036356254480779
Elapsed time for epoch-21: 4.170176982879639
common line69: model saved with val loss 0.6036356254480779

Epoch: 22, 
Train Loss: 0.9040475343706227, 
Validation Loss: 0.6062547345645726
Elapsed time for epoch-22: 4.39389967918396

Epoch: 23, 
Train Loss: 0.9036292455026081, 
Validation Loss: 0.6098605883307755
Elapsed time for epoch-23: 4.35305118560791

Epoch: 24, 
Train Loss: 0.903433949005704, 
Validation Loss: 0.6094016125425696
Elapsed time for epoch-24: 4.131593465805054

Epoch: 25, 
Train Loss: 0.9030923918515694, 
Validation Loss: 0.60413490049541
Elapsed time for epoch-25: 4.178772687911987

Epoch: 26, 
Train Loss: 0.9027563582698838, 
Validation Loss: 0.6061421344056726
Elapsed time for epoch-26: 3.8650901317596436

Epoch: 27, 
Train Loss: 0.9026195558429766, 
Validation Loss: 0.6029859851114452
Elapsed time for epoch-27: 3.666325569152832
common line69: model saved with val loss 0.6029859851114452

Epoch: 28, 
Train Loss: 0.90220921593053, 
Validation Loss: 0.601747240871191
Elapsed time for epoch-28: 3.6418581008911133
common line69: model saved with val loss 0.601747240871191

Epoch: 29, 
Train Loss: 0.9021316630249264, 
Validation Loss: 0.6091432394459844
Elapsed time for epoch-29: 3.667832612991333

Epoch: 30, 
Train Loss: 0.9016872971248227, 
Validation Loss: 0.6029679076746106
Elapsed time for epoch-30: 3.367382049560547

Epoch: 31, 
Train Loss: 0.9015451823713398, 
Validation Loss: 0.6039152289740741
Elapsed time for epoch-31: 3.6290109157562256

train line101: min loss for the epoch 31 is 0.601747240871191

Training the 82-th turbine in 217.48048329353333 secs

>>>>>>>>> Training Turbine  83 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.626382350921631
lalalalalal
260 [[ 1.          0.10673251 -0.15584748 -0.60499706  0.17490963]
 [ 0.99904822  0.25596725 -0.19211358  0.40678385  0.12794621]
 [ 0.9961947   0.17069025 -0.23550337  0.40348725  0.04155498]
 [ 0.99144486  0.19467441 -0.23129391  0.40019065  0.10585264]
 [ 0.98480775  0.03478004 -0.30576894  0.39139972 -0.10810738]]
hahahahahahah
265 [[ 0.99985184  1.          0.10673251 -0.15584748 -0.60499706  0.17490963]
 [ 0.99985184  0.99904822  0.25596725 -0.19211358  0.40678385  0.12794621]
 [ 0.99985184  0.9961947   0.17069025 -0.23550337  0.40348725  0.04155498]
 [ 0.99985184  0.99144486  0.19467441 -0.23129391  0.40019065  0.10585264]
 [ 0.99985184  0.98480775  0.03478004 -0.30576894  0.39139972 -0.10810738]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.10673251 -0.15584748 -0.60499706  0.17490963]
 [ 0.99985184  0.99904822  0.25596725 -0.19211358  0.40678385  0.12794621]
 [ 0.99985184  0.9961947   0.17069025 -0.23550337  0.40348725  0.04155498]
 [ 0.99985184  0.99144486  0.19467441 -0.23129391  0.40019065  0.10585264]
 [ 0.99985184  0.98480775  0.03478004 -0.30576894  0.39139972 -0.10810738]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.740769624710083
lalalalalal
260 [[ 1.          0.04410721 -0.21283706 -1.3044253  -0.05897427]
 [ 0.99904822  0.25063744 -0.1503428  -1.30634831  0.15673551]
 [ 0.9961947   0.13071666 -0.15584748 -1.30634831  0.155639  ]
 [ 0.99144486  0.19467441 -0.15876172 -1.31019434  0.23139172]
 [ 0.98480775  0.44251068 -0.15681889 -1.31184264  0.46270931]]
hahahahahahah
265 [[-0.84754092  1.          0.04410721 -0.21283706 -1.3044253  -0.05897427]
 [-0.84754092  0.99904822  0.25063744 -0.1503428  -1.30634831  0.15673551]
 [-0.84754092  0.9961947   0.13071666 -0.15584748 -1.30634831  0.155639  ]
 [-0.84754092  0.99144486  0.19467441 -0.15876172 -1.31019434  0.23139172]
 [-0.84754092  0.98480775  0.44251068 -0.15681889 -1.31184264  0.46270931]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.04410721 -0.21283706 -1.3044253  -0.05897427]
 [-0.84754092  0.99904822  0.25063744 -0.1503428  -1.30634831  0.15673551]
 [-0.84754092  0.9961947   0.13071666 -0.15584748 -1.30634831  0.155639  ]
 [-0.84754092  0.99144486  0.19467441 -0.15876172 -1.31019434  0.23139172]
 [-0.84754092  0.98480775  0.44251068 -0.15681889 -1.31184264  0.46270931]]

Epoch: 0, 
Train Loss: 1.0049610367091764, 
Validation Loss: 0.7019644817337394
Elapsed time for epoch-0: 5.5768373012542725
common line69: model saved with val loss 0.7019644817337394

Epoch: 1, 
Train Loss: 0.9547394172233694, 
Validation Loss: 0.6775476895272732
Elapsed time for epoch-1: 4.206836700439453
common line69: model saved with val loss 0.6775476895272732

Epoch: 2, 
Train Loss: 0.9450878603618686, 
Validation Loss: 0.6662462810054421
Elapsed time for epoch-2: 4.321797132492065
common line69: model saved with val loss 0.6662462810054421

Epoch: 3, 
Train Loss: 0.9395446995226275, 
Validation Loss: 0.6646431805565953
Elapsed time for epoch-3: 3.9028408527374268
common line69: model saved with val loss 0.6646431805565953

Epoch: 4, 
Train Loss: 0.935752281371285, 
Validation Loss: 0.666423412039876
Elapsed time for epoch-4: 3.964538335800171

Epoch: 5, 
Train Loss: 0.9327568746164066, 
Validation Loss: 0.6644005067646503
Elapsed time for epoch-5: 4.434961795806885
common line69: model saved with val loss 0.6644005067646503

Epoch: 6, 
Train Loss: 0.9304404139769178, 
Validation Loss: 0.6541034998372197
Elapsed time for epoch-6: 3.8145506381988525
common line69: model saved with val loss 0.6541034998372197

Epoch: 7, 
Train Loss: 0.9289954562648004, 
Validation Loss: 0.6604496678337455
Elapsed time for epoch-7: 3.843536138534546

Epoch: 8, 
Train Loss: 0.9272053355679792, 
Validation Loss: 0.6498637776821852
Elapsed time for epoch-8: 3.5622572898864746
common line69: model saved with val loss 0.6498637776821852

Epoch: 9, 
Train Loss: 0.9259949695913732, 
Validation Loss: 0.6498377122916281
Elapsed time for epoch-9: 4.050586462020874
common line69: model saved with val loss 0.6498377122916281

Epoch: 10, 
Train Loss: 0.9252319457400747, 
Validation Loss: 0.6480615972541273
Elapsed time for epoch-10: 3.624166250228882
common line69: model saved with val loss 0.6480615972541273

Epoch: 11, 
Train Loss: 0.924287723768659, 
Validation Loss: 0.6433799639344215
Elapsed time for epoch-11: 3.7995963096618652
common line69: model saved with val loss 0.6433799639344215

Epoch: 12, 
Train Loss: 0.9234330642874501, 
Validation Loss: 0.639876127243042
Elapsed time for epoch-12: 4.077182054519653
common line69: model saved with val loss 0.639876127243042

Epoch: 13, 
Train Loss: 0.9228875121148694, 
Validation Loss: 0.6395330941304564
Elapsed time for epoch-13: 4.1590681076049805
common line69: model saved with val loss 0.6395330941304564

Epoch: 14, 
Train Loss: 0.9223336624999007, 
Validation Loss: 0.6413808092474937
Elapsed time for epoch-14: 4.0525853633880615

Epoch: 15, 
Train Loss: 0.9217441639229029, 
Validation Loss: 0.6432453906163573
Elapsed time for epoch-15: 4.0994179248809814

Epoch: 16, 
Train Loss: 0.9212837806519341, 
Validation Loss: 0.6374807944521308
Elapsed time for epoch-16: 3.4370603561401367
common line69: model saved with val loss 0.6374807944521308

Epoch: 17, 
Train Loss: 0.9209835178711835, 
Validation Loss: 0.6352574490010738
Elapsed time for epoch-17: 3.6143620014190674
common line69: model saved with val loss 0.6352574490010738

Epoch: 18, 
Train Loss: 0.9205709469168126, 
Validation Loss: 0.6390086743049324
Elapsed time for epoch-18: 4.728094100952148

Epoch: 19, 
Train Loss: 0.9202543217845324, 
Validation Loss: 0.6378641286864877
Elapsed time for epoch-19: 5.600500106811523

Epoch: 20, 
Train Loss: 0.9199049370128567, 
Validation Loss: 0.6376532949507236
Elapsed time for epoch-20: 5.673085451126099

Epoch: 21, 
Train Loss: 0.9193963810425847, 
Validation Loss: 0.6352446833625436
Elapsed time for epoch-21: 4.861237287521362
common line69: model saved with val loss 0.6352446833625436

Epoch: 22, 
Train Loss: 0.9193219323368633, 
Validation Loss: 0.6348916199058294
Elapsed time for epoch-22: 4.050299406051636
common line69: model saved with val loss 0.6348916199058294

Epoch: 23, 
Train Loss: 0.9189947703305412, 
Validation Loss: 0.6307730097323656
Elapsed time for epoch-23: 4.412027597427368
common line69: model saved with val loss 0.6307730097323656

Epoch: 24, 
Train Loss: 0.9188078212387422, 
Validation Loss: 0.6333711189217865
Elapsed time for epoch-24: 3.7222273349761963

Epoch: 25, 
Train Loss: 0.9187704876941793, 
Validation Loss: 0.636312295217067
Elapsed time for epoch-25: 3.5390329360961914

Epoch: 26, 
Train Loss: 0.9184079775038887, 
Validation Loss: 0.6336566004902124
Elapsed time for epoch-26: 3.08524489402771

Epoch: 27, 
Train Loss: 0.9182000816369257, 
Validation Loss: 0.6307059028185904
Elapsed time for epoch-27: 3.1803433895111084
common line69: model saved with val loss 0.6307059028185904

Epoch: 28, 
Train Loss: 0.9179823201994936, 
Validation Loss: 0.6284517450258136
Elapsed time for epoch-28: 3.028700351715088
common line69: model saved with val loss 0.6284517450258136

Epoch: 29, 
Train Loss: 0.9178005762460852, 
Validation Loss: 0.6356209944933653
Elapsed time for epoch-29: 3.2316601276397705

Epoch: 30, 
Train Loss: 0.9175173642755556, 
Validation Loss: 0.6282023787498474
Elapsed time for epoch-30: 3.070775270462036
common line69: model saved with val loss 0.6282023787498474

Epoch: 31, 
Train Loss: 0.9177056123979953, 
Validation Loss: 0.6329808738082647
Elapsed time for epoch-31: 2.97251033782959

train line101: min loss for the epoch 31 is 0.6282023787498474

Training the 83-th turbine in 221.4842870235443 secs

>>>>>>>>> Training Turbine  84 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.756321907043457
lalalalalal
260 [[ 1.          0.29892109 -0.26014121 -0.61330468  0.29029225]
 [ 0.99904822  0.20202763 -0.30283467  0.46726315  0.12717918]
 [ 0.9961947   0.1513449  -0.13043749  0.46525653  0.00472437]
 [ 0.99144486  0.13643821  0.14357987  0.46191215  0.01917318]
 [ 0.98480775 -0.03946068  0.00754518  0.45054127 -0.14564399]]
hahahahahahah
265 [[ 0.99985184  1.          0.29892109 -0.26014121 -0.61330468  0.29029225]
 [ 0.99985184  0.99904822  0.20202763 -0.30283467  0.46726315  0.12717918]
 [ 0.99985184  0.9961947   0.1513449  -0.13043749  0.46525653  0.00472437]
 [ 0.99985184  0.99144486  0.13643821  0.14357987  0.46191215  0.01917318]
 [ 0.99985184  0.98480775 -0.03946068  0.00754518  0.45054127 -0.14564399]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.29892109 -0.26014121 -0.61330468  0.29029225]
 [ 0.99985184  0.99904822  0.20202763 -0.30283467  0.46726315  0.12717918]
 [ 0.99985184  0.9961947   0.1513449  -0.13043749  0.46525653  0.00472437]
 [ 0.99985184  0.99144486  0.13643821  0.14357987  0.46191215  0.01917318]
 [ 0.99985184  0.98480775 -0.03946068  0.00754518  0.45054127 -0.14564399]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.608378887176514
lalalalalal
260 [[ 1.00000000e+00 -1.22938117e-01 -8.36857176e-02 -1.51595172e+00
  -1.56852614e-01]
 [ 9.99048222e-01 -3.94606772e-02 -6.03098290e-02 -1.53802460e+00
  -3.93660800e-02]
 [ 9.96194698e-01 -1.13994106e-01  2.28044415e-02 -1.56411073e+00
  -3.60058931e-02]
 [ 9.91444861e-01  5.29607742e-02 -2.03760193e-02 -1.54939547e+00
   9.96256501e-02]
 [ 9.84807753e-01  2.34822340e-01  1.05187853e-03 -1.60089886e+00
   3.05485099e-01]]
hahahahahahah
265 [[-8.47540923e-01  1.00000000e+00 -1.22938117e-01 -8.36857176e-02
  -1.51595172e+00 -1.56852614e-01]
 [-8.47540923e-01  9.99048222e-01 -3.94606772e-02 -6.03098290e-02
  -1.53802460e+00 -3.93660800e-02]
 [-8.47540923e-01  9.96194698e-01 -1.13994106e-01  2.28044415e-02
  -1.56411073e+00 -3.60058931e-02]
 [-8.47540923e-01  9.91444861e-01  5.29607742e-02 -2.03760193e-02
  -1.54939547e+00  9.96256501e-02]
 [-8.47540923e-01  9.84807753e-01  2.34822340e-01  1.05187853e-03
  -1.60089886e+00  3.05485099e-01]]

 wind turbine line248 data after normalization: 
 [[-8.47540923e-01  1.00000000e+00 -1.22938117e-01 -8.36857176e-02
  -1.51595172e+00 -1.56852614e-01]
 [-8.47540923e-01  9.99048222e-01 -3.94606772e-02 -6.03098290e-02
  -1.53802460e+00 -3.93660800e-02]
 [-8.47540923e-01  9.96194698e-01 -1.13994106e-01  2.28044415e-02
  -1.56411073e+00 -3.60058931e-02]
 [-8.47540923e-01  9.91444861e-01  5.29607742e-02 -2.03760193e-02
  -1.54939547e+00  9.96256501e-02]
 [-8.47540923e-01  9.84807753e-01  2.34822340e-01  1.05187853e-03
  -1.60089886e+00  3.05485099e-01]]

Epoch: 0, 
Train Loss: 0.979536656822477, 
Validation Loss: 0.6807813979685307
Elapsed time for epoch-0: 4.1140053272247314
common line69: model saved with val loss 0.6807813979685307

Epoch: 1, 
Train Loss: 0.9368837979160437, 
Validation Loss: 0.6665583243593574
Elapsed time for epoch-1: 3.9721856117248535
common line69: model saved with val loss 0.6665583243593574

Epoch: 2, 
Train Loss: 0.9300094829136584, 
Validation Loss: 0.6612184029072523
Elapsed time for epoch-2: 3.9468250274658203
common line69: model saved with val loss 0.6612184029072523

Epoch: 3, 
Train Loss: 0.9261518059407964, 
Validation Loss: 0.6655827974900603
Elapsed time for epoch-3: 3.6196274757385254

Epoch: 4, 
Train Loss: 0.9234581237831035, 
Validation Loss: 0.6616488359868526
Elapsed time for epoch-4: 3.885232925415039

Epoch: 5, 
Train Loss: 0.9216023699826553, 
Validation Loss: 0.6613522954285145
Elapsed time for epoch-5: 3.554863214492798

Epoch: 6, 
Train Loss: 0.9199094377896365, 
Validation Loss: 0.658918384462595
Elapsed time for epoch-6: 3.6651065349578857
common line69: model saved with val loss 0.658918384462595

Epoch: 7, 
Train Loss: 0.9186645701151936, 
Validation Loss: 0.6585095208138227
Elapsed time for epoch-7: 3.766664505004883
common line69: model saved with val loss 0.6585095208138227

Epoch: 8, 
Train Loss: 0.9175658467687479, 
Validation Loss: 0.651433146558702
Elapsed time for epoch-8: 4.057360887527466
common line69: model saved with val loss 0.651433146558702

Epoch: 9, 
Train Loss: 0.9167730054434609, 
Validation Loss: 0.6631471980363131
Elapsed time for epoch-9: 4.016979217529297

Epoch: 10, 
Train Loss: 0.915659506280883, 
Validation Loss: 0.6508677043020725
Elapsed time for epoch-10: 4.19720196723938
common line69: model saved with val loss 0.6508677043020725

Epoch: 11, 
Train Loss: 0.9150625625077415, 
Validation Loss: 0.6499201534315944
Elapsed time for epoch-11: 4.156564950942993
common line69: model saved with val loss 0.6499201534315944

Epoch: 12, 
Train Loss: 0.914300335054638, 
Validation Loss: 0.6494182292371988
Elapsed time for epoch-12: 3.7528131008148193
common line69: model saved with val loss 0.6494182292371988

Epoch: 13, 
Train Loss: 0.9135539236188936, 
Validation Loss: 0.6468647476285696
Elapsed time for epoch-13: 4.387226343154907
common line69: model saved with val loss 0.6468647476285696

Epoch: 14, 
Train Loss: 0.9131252760646724, 
Validation Loss: 0.6473785052075982
Elapsed time for epoch-14: 3.5056638717651367

Epoch: 15, 
Train Loss: 0.9126461257203287, 
Validation Loss: 0.6433210344985127
Elapsed time for epoch-15: 3.8982698917388916
common line69: model saved with val loss 0.6433210344985127

Epoch: 16, 
Train Loss: 0.9119363096581787, 
Validation Loss: 0.6460302593186498
Elapsed time for epoch-16: 4.16309118270874

Epoch: 17, 
Train Loss: 0.9112666787720528, 
Validation Loss: 0.6474348595365882
Elapsed time for epoch-17: 4.221754789352417

Epoch: 18, 
Train Loss: 0.91106768090184, 
Validation Loss: 0.6439308933913708
Elapsed time for epoch-18: 3.8169362545013428

Epoch: 19, 
Train Loss: 0.9106169100068197, 
Validation Loss: 0.6422453625127673
Elapsed time for epoch-19: 4.01710319519043
common line69: model saved with val loss 0.6422453625127673

Epoch: 20, 
Train Loss: 0.9102455954842207, 
Validation Loss: 0.6401110608130693
Elapsed time for epoch-20: 3.374767303466797
common line69: model saved with val loss 0.6401110608130693

Epoch: 21, 
Train Loss: 0.9098949755440239, 
Validation Loss: 0.6449597142636776
Elapsed time for epoch-21: 3.3479065895080566

Epoch: 22, 
Train Loss: 0.9095623220215324, 
Validation Loss: 0.6459714723750949
Elapsed time for epoch-22: 3.394089698791504

Epoch: 23, 
Train Loss: 0.9090872715000345, 
Validation Loss: 0.6429280415177345
Elapsed time for epoch-23: 3.2673563957214355

Epoch: 24, 
Train Loss: 0.9085450067239649, 
Validation Loss: 0.6447227774187922
Elapsed time for epoch-24: 3.9963419437408447

Epoch: 25, 
Train Loss: 0.9081960297933146, 
Validation Loss: 0.644795527216047
Elapsed time for epoch-25: 4.414187908172607

Epoch: 26, 
Train Loss: 0.9077298896653312, 
Validation Loss: 0.6461384985595942
Elapsed time for epoch-26: 4.269169330596924

Epoch: 27, 
Train Loss: 0.9069938478099198, 
Validation Loss: 0.6474776780232787
Elapsed time for epoch-27: 3.9781782627105713

Epoch: 28, 
Train Loss: 0.9069230368658274, 
Validation Loss: 0.6467118728905916
Elapsed time for epoch-28: 3.510742425918579

Epoch: 29, 
Train Loss: 0.9066069008422499, 
Validation Loss: 0.6462697526440024
Elapsed time for epoch-29: 3.05710768699646

Epoch: 30, 
Train Loss: 0.9063905116890659, 
Validation Loss: 0.644518518820405
Elapsed time for epoch-30: 3.0965635776519775

Epoch: 31, 
Train Loss: 0.906000791477556, 
Validation Loss: 0.6475077355280519
Elapsed time for epoch-31: 3.1085710525512695

train line101: min loss for the epoch 31 is 0.6401110608130693

Training the 84-th turbine in 214.0165672302246 secs

>>>>>>>>> Training Turbine  85 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.9641988277435303
lalalalalal
260 [[ 1.          0.24916356 -0.00177106 -0.68431673  0.28080211]
 [ 0.99904822  0.22870293  0.09772027  0.52130393  0.06290764]
 [ 0.9961947   0.11763094  0.02735634  0.5199057  -0.03651886]
 [ 0.99144486  0.19362757  0.04993825  0.51641014  0.04496732]
 [ 0.98480775  0.02117369 -0.04726216  0.50732166 -0.12141987]]
hahahahahahah
265 [[ 0.99985184  1.          0.24916356 -0.00177106 -0.68431673  0.28080211]
 [ 0.99985184  0.99904822  0.22870293  0.09772027  0.52130393  0.06290764]
 [ 0.99985184  0.9961947   0.11763094  0.02735634  0.5199057  -0.03651886]
 [ 0.99985184  0.99144486  0.19362757  0.04993825  0.51641014  0.04496732]
 [ 0.99985184  0.98480775  0.02117369 -0.04726216  0.50732166 -0.12141987]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.24916356 -0.00177106 -0.68431673  0.28080211]
 [ 0.99985184  0.99904822  0.22870293  0.09772027  0.52130393  0.06290764]
 [ 0.99985184  0.9961947   0.11763094  0.02735634  0.5199057  -0.03651886]
 [ 0.99985184  0.99144486  0.19362757  0.04993825  0.51641014  0.04496732]
 [ 0.99985184  0.98480775  0.02117369 -0.04726216  0.50732166 -0.12141987]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.454601049423218
lalalalalal
260 [[ 1.         -0.01536315 -0.02189842 -1.70432284 -0.11201667]
 [ 0.99904822  0.12639978  0.04404732 -1.70816796 -0.00402832]
 [ 0.9961947   0.12055389  0.03259272 -1.70816796  0.15379701]
 [ 0.99144486  0.114708    0.02604724 -1.71376087  0.16762962]
 [ 0.98480775  0.2579324   0.01819266 -1.7151591   0.35453064]]
hahahahahahah
265 [[-0.84754092  1.         -0.01536315 -0.02189842 -1.70432284 -0.11201667]
 [-0.84754092  0.99904822  0.12639978  0.04404732 -1.70816796 -0.00402832]
 [-0.84754092  0.9961947   0.12055389  0.03259272 -1.70816796  0.15379701]
 [-0.84754092  0.99144486  0.114708    0.02604724 -1.71376087  0.16762962]
 [-0.84754092  0.98480775  0.2579324   0.01819266 -1.7151591   0.35453064]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.01536315 -0.02189842 -1.70432284 -0.11201667]
 [-0.84754092  0.99904822  0.12639978  0.04404732 -1.70816796 -0.00402832]
 [-0.84754092  0.9961947   0.12055389  0.03259272 -1.70816796  0.15379701]
 [-0.84754092  0.99144486  0.114708    0.02604724 -1.71376087  0.16762962]
 [-0.84754092  0.98480775  0.2579324   0.01819266 -1.7151591   0.35453064]]

Epoch: 0, 
Train Loss: 0.9901250336600953, 
Validation Loss: 0.7078817319124937
Elapsed time for epoch-0: 4.353457689285278
common line69: model saved with val loss 0.7078817319124937

Epoch: 1, 
Train Loss: 0.9503040425166362, 
Validation Loss: 0.669400648213923
Elapsed time for epoch-1: 4.21680760383606
common line69: model saved with val loss 0.669400648213923

Epoch: 2, 
Train Loss: 0.9412735160909781, 
Validation Loss: 0.661840345710516
Elapsed time for epoch-2: 3.8537795543670654
common line69: model saved with val loss 0.661840345710516

Epoch: 3, 
Train Loss: 0.9364199555721604, 
Validation Loss: 0.6543680736795068
Elapsed time for epoch-3: 4.578162908554077
common line69: model saved with val loss 0.6543680736795068

Epoch: 4, 
Train Loss: 0.9333109665317696, 
Validation Loss: 0.6446117348968983
Elapsed time for epoch-4: 3.901343822479248
common line69: model saved with val loss 0.6446117348968983

Epoch: 5, 
Train Loss: 0.931211361614596, 
Validation Loss: 0.6445586117915809
Elapsed time for epoch-5: 4.049291372299194
common line69: model saved with val loss 0.6445586117915809

Epoch: 6, 
Train Loss: 0.9291776935843861, 
Validation Loss: 0.6382432961836457
Elapsed time for epoch-6: 3.5707550048828125
common line69: model saved with val loss 0.6382432961836457

Epoch: 7, 
Train Loss: 0.9280260912760967, 
Validation Loss: 0.6415585372596979
Elapsed time for epoch-7: 3.97589111328125

Epoch: 8, 
Train Loss: 0.9269442311605486, 
Validation Loss: 0.6321015479043126
Elapsed time for epoch-8: 4.065520524978638
common line69: model saved with val loss 0.6321015479043126

Epoch: 9, 
Train Loss: 0.9261903064090664, 
Validation Loss: 0.6365869697183371
Elapsed time for epoch-9: 3.7616539001464844

Epoch: 10, 
Train Loss: 0.9254630665067866, 
Validation Loss: 0.6311547141522169
Elapsed time for epoch-10: 3.9166102409362793
common line69: model saved with val loss 0.6311547141522169

Epoch: 11, 
Train Loss: 0.9242975589107064, 
Validation Loss: 0.6351655516773462
Elapsed time for epoch-11: 3.759660482406616

Epoch: 12, 
Train Loss: 0.9238597515250454, 
Validation Loss: 0.6353805242106318
Elapsed time for epoch-12: 4.031550884246826

Epoch: 13, 
Train Loss: 0.9231359187294456, 
Validation Loss: 0.6330407913774252
Elapsed time for epoch-13: 4.2983057498931885

Epoch: 14, 
Train Loss: 0.9226361232645371, 
Validation Loss: 0.6293227537535131
Elapsed time for epoch-14: 4.274515628814697
common line69: model saved with val loss 0.6293227537535131

Epoch: 15, 
Train Loss: 0.9220428873761362, 
Validation Loss: 0.6269934503361583
Elapsed time for epoch-15: 4.04883885383606
common line69: model saved with val loss 0.6269934503361583

Epoch: 16, 
Train Loss: 0.9214216204000121, 
Validation Loss: 0.6284525841474533
Elapsed time for epoch-16: 4.061789512634277

Epoch: 17, 
Train Loss: 0.9211458736608008, 
Validation Loss: 0.6248219981789589
Elapsed time for epoch-17: 4.181148052215576
common line69: model saved with val loss 0.6248219981789589

Epoch: 18, 
Train Loss: 0.9206788199288505, 
Validation Loss: 0.62914998549968
Elapsed time for epoch-18: 3.835294723510742

Epoch: 19, 
Train Loss: 0.920061262966204, 
Validation Loss: 0.6227895505726337
Elapsed time for epoch-19: 4.363536357879639
common line69: model saved with val loss 0.6227895505726337

Epoch: 20, 
Train Loss: 0.9197686717790716, 
Validation Loss: 0.6274218326434493
Elapsed time for epoch-20: 3.994070529937744

Epoch: 21, 
Train Loss: 0.919016555577767, 
Validation Loss: 0.6232178951613605
Elapsed time for epoch-21: 3.989166021347046

Epoch: 22, 
Train Loss: 0.9185440083261297, 
Validation Loss: 0.6253348458558321
Elapsed time for epoch-22: 3.372608184814453

Epoch: 23, 
Train Loss: 0.9179538935422897, 
Validation Loss: 0.6213709311559796
Elapsed time for epoch-23: 3.5477025508880615
common line69: model saved with val loss 0.6213709311559796

Epoch: 24, 
Train Loss: 0.9177256037457651, 
Validation Loss: 0.6219609966501594
Elapsed time for epoch-24: 3.1073050498962402

Epoch: 25, 
Train Loss: 0.9170617695365634, 
Validation Loss: 0.6258780504576862
Elapsed time for epoch-25: 3.390458345413208

Epoch: 26, 
Train Loss: 0.9168477841034657, 
Validation Loss: 0.6250428040511906
Elapsed time for epoch-26: 3.895078182220459

Epoch: 27, 
Train Loss: 0.9165488216055542, 
Validation Loss: 0.6240056515671313
Elapsed time for epoch-27: 3.784252882003784

Epoch: 28, 
Train Loss: 0.9161906989933062, 
Validation Loss: 0.6246123746968806
Elapsed time for epoch-28: 4.39688777923584

Epoch: 29, 
Train Loss: 0.9157563010935023, 
Validation Loss: 0.6143389586359262
Elapsed time for epoch-29: 3.5313704013824463
common line69: model saved with val loss 0.6143389586359262

Epoch: 30, 
Train Loss: 0.9154240894718331, 
Validation Loss: 0.6150714224204421
Elapsed time for epoch-30: 3.6087088584899902

Epoch: 31, 
Train Loss: 0.9151726805863261, 
Validation Loss: 0.6179882558062673
Elapsed time for epoch-31: 3.7722902297973633

train line101: min loss for the epoch 31 is 0.6143389586359262

Training the 85-th turbine in 218.16196656227112 secs

>>>>>>>>> Training Turbine  86 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.8500490188598633
lalalalalal
260 [[ 1.          0.22555361 -0.17039212 -0.54461732  0.29840842]
 [ 0.99904822  0.09719599 -0.28202959  0.40905588 -0.01430584]
 [ 0.9961947   0.01958441 -0.34117087  0.40905588 -0.13601846]
 [ 0.99144486  0.03152465 -0.34183538  0.40386504 -0.13320343]
 [ 0.98480775 -0.1326537  -0.16341478  0.39694392 -0.2200493 ]]
hahahahahahah
265 [[ 0.99985184  1.          0.22555361 -0.17039212 -0.54461732  0.29840842]
 [ 0.99985184  0.99904822  0.09719599 -0.28202959  0.40905588 -0.01430584]
 [ 0.99985184  0.9961947   0.01958441 -0.34117087  0.40905588 -0.13601846]
 [ 0.99985184  0.99144486  0.03152465 -0.34183538  0.40386504 -0.13320343]
 [ 0.99985184  0.98480775 -0.1326537  -0.16341478  0.39694392 -0.2200493 ]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.22555361 -0.17039212 -0.54461732  0.29840842]
 [ 0.99985184  0.99904822  0.09719599 -0.28202959  0.40905588 -0.01430584]
 [ 0.99985184  0.9961947   0.01958441 -0.34117087  0.40905588 -0.13601846]
 [ 0.99985184  0.99144486  0.03152465 -0.34183538  0.40386504 -0.13320343]
 [ 0.99985184  0.98480775 -0.1326537  -0.16341478  0.39694392 -0.2200493 ]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.2824065685272217
lalalalalal
260 [[ 1.         -0.04608693 -0.03848713 -1.33939305 -0.10723857]
 [ 0.99904822  0.1807777   0.05686987 -1.34025819  0.09204763]
 [ 0.9961947   0.20167312  0.00802848 -1.34429551  0.35821527]
 [ 0.99144486  0.17182251 -0.02453245 -1.34429551  0.28411108]
 [ 0.98480775  0.21958349 -0.03549684 -1.34544903  0.35537556]]
hahahahahahah
265 [[-0.84754092  1.         -0.04608693 -0.03848713 -1.33939305 -0.10723857]
 [-0.84754092  0.99904822  0.1807777   0.05686987 -1.34025819  0.09204763]
 [-0.84754092  0.9961947   0.20167312  0.00802848 -1.34429551  0.35821527]
 [-0.84754092  0.99144486  0.17182251 -0.02453245 -1.34429551  0.28411108]
 [-0.84754092  0.98480775  0.21958349 -0.03549684 -1.34544903  0.35537556]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.04608693 -0.03848713 -1.33939305 -0.10723857]
 [-0.84754092  0.99904822  0.1807777   0.05686987 -1.34025819  0.09204763]
 [-0.84754092  0.9961947   0.20167312  0.00802848 -1.34429551  0.35821527]
 [-0.84754092  0.99144486  0.17182251 -0.02453245 -1.34429551  0.28411108]
 [-0.84754092  0.98480775  0.21958349 -0.03549684 -1.34544903  0.35537556]]

Epoch: 0, 
Train Loss: 1.0001655858354408, 
Validation Loss: 0.608082611579448
Elapsed time for epoch-0: 3.7380526065826416
common line69: model saved with val loss 0.608082611579448

Epoch: 1, 
Train Loss: 0.9640247776728719, 
Validation Loss: 0.5918758250772953
Elapsed time for epoch-1: 3.6210975646972656
common line69: model saved with val loss 0.5918758250772953

Epoch: 2, 
Train Loss: 0.9569985388206834, 
Validation Loss: 0.5914840968325734
Elapsed time for epoch-2: 3.6360702514648438
common line69: model saved with val loss 0.5914840968325734

Epoch: 3, 
Train Loss: 0.9527483350839936, 
Validation Loss: 0.5865346547216177
Elapsed time for epoch-3: 3.5968594551086426
common line69: model saved with val loss 0.5865346547216177

Epoch: 4, 
Train Loss: 0.9502611925371555, 
Validation Loss: 0.5852935798466206
Elapsed time for epoch-4: 3.8453383445739746
common line69: model saved with val loss 0.5852935798466206

Epoch: 5, 
Train Loss: 0.9477224700591144, 
Validation Loss: 0.5901191080920398
Elapsed time for epoch-5: 3.615879535675049

Epoch: 6, 
Train Loss: 0.9465056903222028, 
Validation Loss: 0.5820486592128873
Elapsed time for epoch-6: 3.6822476387023926
common line69: model saved with val loss 0.5820486592128873

Epoch: 7, 
Train Loss: 0.9454308540380302, 
Validation Loss: 0.5840886235237122
Elapsed time for epoch-7: 3.3076887130737305

Epoch: 8, 
Train Loss: 0.9444175564190921, 
Validation Loss: 0.5773859801702201
Elapsed time for epoch-8: 3.547236680984497
common line69: model saved with val loss 0.5773859801702201

Epoch: 9, 
Train Loss: 0.9432700260096237, 
Validation Loss: 0.5799190420657396
Elapsed time for epoch-9: 3.454559087753296

Epoch: 10, 
Train Loss: 0.9426492400029126, 
Validation Loss: 0.5778951533138752
Elapsed time for epoch-10: 3.773390054702759

Epoch: 11, 
Train Loss: 0.9419225175090197, 
Validation Loss: 0.5786367692053318
Elapsed time for epoch-11: 3.3914761543273926

Epoch: 12, 
Train Loss: 0.9410795488026964, 
Validation Loss: 0.5803497876040637
Elapsed time for epoch-12: 3.4411025047302246

Epoch: 13, 
Train Loss: 0.9408346094003245, 
Validation Loss: 0.5731157176196575
Elapsed time for epoch-13: 3.461651086807251
common line69: model saved with val loss 0.5731157176196575

Epoch: 14, 
Train Loss: 0.9400961298902496, 
Validation Loss: 0.5760534582659602
Elapsed time for epoch-14: 3.8506879806518555

Epoch: 15, 
Train Loss: 0.9396092782751853, 
Validation Loss: 0.5750968866050243
Elapsed time for epoch-15: 3.6841492652893066

Epoch: 16, 
Train Loss: 0.9392912431674845, 
Validation Loss: 0.5775883593596518
Elapsed time for epoch-16: 3.4504616260528564

Epoch: 17, 
Train Loss: 0.9389739374653632, 
Validation Loss: 0.5627173068933189
Elapsed time for epoch-17: 3.7465083599090576
common line69: model saved with val loss 0.5627173068933189

Epoch: 18, 
Train Loss: 0.9381680846715174, 
Validation Loss: 0.568147418089211
Elapsed time for epoch-18: 3.3994174003601074

Epoch: 19, 
Train Loss: 0.9381157570526379, 
Validation Loss: 0.5690686074085534
Elapsed time for epoch-19: 3.7005152702331543

Epoch: 20, 
Train Loss: 0.9372718296632045, 
Validation Loss: 0.5730293802917004
Elapsed time for epoch-20: 3.1322922706604004

Epoch: 21, 
Train Loss: 0.9370964530135403, 
Validation Loss: 0.5646838592365384
Elapsed time for epoch-21: 3.278036594390869

Epoch: 22, 
Train Loss: 0.9368676809954042, 
Validation Loss: 0.5710594900883734
Elapsed time for epoch-22: 3.0917792320251465

Epoch: 23, 
Train Loss: 0.9363147668978747, 
Validation Loss: 0.5659966520033777
Elapsed time for epoch-23: 2.749053955078125

Epoch: 24, 
Train Loss: 0.9356822804743502, 
Validation Loss: 0.5611884165555239
Elapsed time for epoch-24: 3.1375038623809814
common line69: model saved with val loss 0.5611884165555239

Epoch: 25, 
Train Loss: 0.9353296650307519, 
Validation Loss: 0.5643329136073589
Elapsed time for epoch-25: 3.017988443374634

Epoch: 26, 
Train Loss: 0.935212958885842, 
Validation Loss: 0.5627002180553973
Elapsed time for epoch-26: 2.8835835456848145

Epoch: 27, 
Train Loss: 0.9346209862152067, 
Validation Loss: 0.5624277153983712
Elapsed time for epoch-27: 3.289179801940918

Epoch: 28, 
Train Loss: 0.9342667192471128, 
Validation Loss: 0.5629273913800716
Elapsed time for epoch-28: 2.9347150325775146

Epoch: 29, 
Train Loss: 0.9337303400540552, 
Validation Loss: 0.5721675418317318
Elapsed time for epoch-29: 3.018446445465088

Epoch: 30, 
Train Loss: 0.9336112244289463, 
Validation Loss: 0.5658402275294065
Elapsed time for epoch-30: 3.202657461166382

Epoch: 31, 
Train Loss: 0.9332588797106462, 
Validation Loss: 0.5578845147974789
Elapsed time for epoch-31: 2.8862080574035645
common line69: model saved with val loss 0.5578845147974789

train line101: min loss for the epoch 31 is 0.5578845147974789

Training the 86-th turbine in 191.36252188682556 secs

>>>>>>>>> Training Turbine  87 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.7375621795654297
lalalalalal
260 [[ 1.00000000e+00  2.76689185e-01 -1.11075612e-01 -8.18011798e-02
   2.12447990e-01]
 [ 9.99048222e-01  2.08020710e-01 -1.13571316e-01  3.72962875e-01
   2.24402648e-04]
 [ 9.96194698e-01  1.19732671e-01 -1.84861623e-01  3.68876945e-01
  -1.29971191e-01]
 [ 9.91444861e-01  1.60933756e-01 -1.93325313e-01  3.64382422e-01
  -1.05236696e-01]
 [ 9.84807753e-01  1.49162018e-01 -2.43130870e-01  3.59479305e-01
  -1.54196447e-01]]
hahahahahahah
265 [[ 9.99851839e-01  1.00000000e+00  2.76689185e-01 -1.11075612e-01
  -8.18011798e-02  2.12447990e-01]
 [ 9.99851839e-01  9.99048222e-01  2.08020710e-01 -1.13571316e-01
   3.72962875e-01  2.24402648e-04]
 [ 9.99851839e-01  9.96194698e-01  1.19732671e-01 -1.84861623e-01
   3.68876945e-01 -1.29971191e-01]
 [ 9.99851839e-01  9.91444861e-01  1.60933756e-01 -1.93325313e-01
   3.64382422e-01 -1.05236696e-01]
 [ 9.99851839e-01  9.84807753e-01  1.49162018e-01 -2.43130870e-01
   3.59479305e-01 -1.54196447e-01]]

 wind turbine line248 data after normalization: 
 [[ 9.99851839e-01  1.00000000e+00  2.76689185e-01 -1.11075612e-01
  -8.18011798e-02  2.12447990e-01]
 [ 9.99851839e-01  9.99048222e-01  2.08020710e-01 -1.13571316e-01
   3.72962875e-01  2.24402648e-04]
 [ 9.99851839e-01  9.96194698e-01  1.19732671e-01 -1.84861623e-01
   3.68876945e-01 -1.29971191e-01]
 [ 9.99851839e-01  9.91444861e-01  1.60933756e-01 -1.93325313e-01
   3.64382422e-01 -1.05236696e-01]
 [ 9.99851839e-01  9.84807753e-01  1.49162018e-01 -2.43130870e-01
   3.59479305e-01 -1.54196447e-01]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.9588499069213867
lalalalalal
260 [[ 1.          0.03438757 -0.11650105 -0.88713806  0.03695028]
 [ 0.99904822  0.27276527 -0.15947055 -0.88918103  0.30399796]
 [ 0.9961947   0.26982234 -0.18551268 -0.891224    0.43453304]
 [ 0.99144486  0.20213484 -0.00451993 -0.8908154   0.33154539]
 [ 0.98480775  0.24039299  0.05342379 -0.89490133  0.4657664 ]]
hahahahahahah
265 [[-0.84754092  1.          0.03438757 -0.11650105 -0.88713806  0.03695028]
 [-0.84754092  0.99904822  0.27276527 -0.15947055 -0.88918103  0.30399796]
 [-0.84754092  0.9961947   0.26982234 -0.18551268 -0.891224    0.43453304]
 [-0.84754092  0.99144486  0.20213484 -0.00451993 -0.8908154   0.33154539]
 [-0.84754092  0.98480775  0.24039299  0.05342379 -0.89490133  0.4657664 ]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.03438757 -0.11650105 -0.88713806  0.03695028]
 [-0.84754092  0.99904822  0.27276527 -0.15947055 -0.88918103  0.30399796]
 [-0.84754092  0.9961947   0.26982234 -0.18551268 -0.891224    0.43453304]
 [-0.84754092  0.99144486  0.20213484 -0.00451993 -0.8908154   0.33154539]
 [-0.84754092  0.98480775  0.24039299  0.05342379 -0.89490133  0.4657664 ]]

Epoch: 0, 
Train Loss: 0.992623465151346, 
Validation Loss: 0.5964035983197391
Elapsed time for epoch-0: 3.542699098587036
common line69: model saved with val loss 0.5964035983197391

Epoch: 1, 
Train Loss: 0.9582980084819954, 
Validation Loss: 0.5918014156632125
Elapsed time for epoch-1: 3.381613254547119
common line69: model saved with val loss 0.5918014156632125

Epoch: 2, 
Train Loss: 0.9503333008840305, 
Validation Loss: 0.5892417882569134
Elapsed time for epoch-2: 3.6343648433685303
common line69: model saved with val loss 0.5892417882569134

Epoch: 3, 
Train Loss: 0.9452938989681356, 
Validation Loss: 0.5861676121130586
Elapsed time for epoch-3: 3.245659351348877
common line69: model saved with val loss 0.5861676121130586

Epoch: 4, 
Train Loss: 0.9420071132794148, 
Validation Loss: 0.5788704017177224
Elapsed time for epoch-4: 3.5163345336914062
common line69: model saved with val loss 0.5788704017177224

Epoch: 5, 
Train Loss: 0.9393772136013047, 
Validation Loss: 0.5790975405834615
Elapsed time for epoch-5: 3.777747869491577

Epoch: 6, 
Train Loss: 0.9374931663775644, 
Validation Loss: 0.5824755751527846
Elapsed time for epoch-6: 3.1342275142669678

Epoch: 7, 
Train Loss: 0.9359137750222903, 
Validation Loss: 0.5793782640248537
Elapsed time for epoch-7: 3.3016998767852783

Epoch: 8, 
Train Loss: 0.9342961614372349, 
Validation Loss: 0.5733617716468871
Elapsed time for epoch-8: 3.0658373832702637
common line69: model saved with val loss 0.5733617716468871

Epoch: 9, 
Train Loss: 0.9328484744334421, 
Validation Loss: 0.5845353812910616
Elapsed time for epoch-9: 3.1260945796966553

Epoch: 10, 
Train Loss: 0.9316817639755601, 
Validation Loss: 0.572060929145664
Elapsed time for epoch-10: 2.9543802738189697
common line69: model saved with val loss 0.572060929145664

Epoch: 11, 
Train Loss: 0.9306288561901125, 
Validation Loss: 0.5735473576933146
Elapsed time for epoch-11: 3.0567126274108887

Epoch: 12, 
Train Loss: 0.9299207928300905, 
Validation Loss: 0.5760870496742427
Elapsed time for epoch-12: 3.1752219200134277

Epoch: 13, 
Train Loss: 0.9292513094529384, 
Validation Loss: 0.568032446783036
Elapsed time for epoch-13: 3.0310680866241455
common line69: model saved with val loss 0.568032446783036

Epoch: 14, 
Train Loss: 0.9284737328020465, 
Validation Loss: 0.5663898820057511
Elapsed time for epoch-14: 3.0989491939544678
common line69: model saved with val loss 0.5663898820057511

Epoch: 15, 
Train Loss: 0.9277636976051731, 
Validation Loss: 0.5631109108217061
Elapsed time for epoch-15: 3.025446653366089
common line69: model saved with val loss 0.5631109108217061

Epoch: 16, 
Train Loss: 0.9275716047327057, 
Validation Loss: 0.5687895072624087
Elapsed time for epoch-16: 2.9523768424987793

Epoch: 17, 
Train Loss: 0.9271882663504416, 
Validation Loss: 0.5647087497636676
Elapsed time for epoch-17: 3.258814573287964

Epoch: 18, 
Train Loss: 0.9266884586139887, 
Validation Loss: 0.5634030075743794
Elapsed time for epoch-18: 2.9458587169647217

Epoch: 19, 
Train Loss: 0.9262099046917522, 
Validation Loss: 0.5619491552934051
Elapsed time for epoch-19: 3.1231813430786133
common line69: model saved with val loss 0.5619491552934051

Epoch: 20, 
Train Loss: 0.9260674088942904, 
Validation Loss: 0.5630599022842944
Elapsed time for epoch-20: 3.0974628925323486

Epoch: 21, 
Train Loss: 0.9256490035718229, 
Validation Loss: 0.5661020465195179
Elapsed time for epoch-21: 3.167776107788086

Epoch: 22, 
Train Loss: 0.925428932203966, 
Validation Loss: 0.5612823218107224
Elapsed time for epoch-22: 3.0837302207946777
common line69: model saved with val loss 0.5612823218107224

Epoch: 23, 
Train Loss: 0.924965532512224, 
Validation Loss: 0.5626742793247104
Elapsed time for epoch-23: 3.19881010055542

Epoch: 24, 
Train Loss: 0.9248291294113928, 
Validation Loss: 0.5622443719767034
Elapsed time for epoch-24: 3.140483856201172

Epoch: 25, 
Train Loss: 0.9247126893586471, 
Validation Loss: 0.5599828059785068
Elapsed time for epoch-25: 3.0401415824890137
common line69: model saved with val loss 0.5599828059785068

Epoch: 26, 
Train Loss: 0.9245238423097033, 
Validation Loss: 0.565604948438704
Elapsed time for epoch-26: 3.220311403274536

Epoch: 27, 
Train Loss: 0.924259072216619, 
Validation Loss: 0.5551836770027876
Elapsed time for epoch-27: 2.873396873474121
common line69: model saved with val loss 0.5551836770027876

Epoch: 28, 
Train Loss: 0.9242499225279864, 
Validation Loss: 0.5574326352216303
Elapsed time for epoch-28: 3.055006742477417

Epoch: 29, 
Train Loss: 0.9239595682681108, 
Validation Loss: 0.5579973631538451
Elapsed time for epoch-29: 3.1590256690979004

Epoch: 30, 
Train Loss: 0.9236727477121753, 
Validation Loss: 0.5610722983255982
Elapsed time for epoch-30: 2.939472198486328

Epoch: 31, 
Train Loss: 0.9235561480041311, 
Validation Loss: 0.5577535033226013
Elapsed time for epoch-31: 3.1846048831939697

train line101: min loss for the epoch 31 is 0.5551836770027876

Training the 87-th turbine in 183.47859692573547 secs

>>>>>>>>> Training Turbine  88 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.0908753871917725
lalalalalal
260 [[ 1.          0.16023268 -0.0219659  -0.6845696   0.31400485]
 [ 0.99904822  0.02204528 -0.06718095  0.55768353 -0.10533326]
 [ 0.9961947   0.01340857 -0.16847546  0.55254873 -0.1567363 ]
 [ 0.99144486  0.00189295 -0.15856969  0.54374623 -0.18034432]
 [ 0.98480775 -0.0326539  -0.22631239  0.53861144 -0.22396476]]
hahahahahahah
265 [[ 0.99985184  1.          0.16023268 -0.0219659  -0.6845696   0.31400485]
 [ 0.99985184  0.99904822  0.02204528 -0.06718095  0.55768353 -0.10533326]
 [ 0.99985184  0.9961947   0.01340857 -0.16847546  0.55254873 -0.1567363 ]
 [ 0.99985184  0.99144486  0.00189295 -0.15856969  0.54374623 -0.18034432]
 [ 0.99985184  0.98480775 -0.0326539  -0.22631239  0.53861144 -0.22396476]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.16023268 -0.0219659  -0.6845696   0.31400485]
 [ 0.99985184  0.99904822  0.02204528 -0.06718095  0.55768353 -0.10533326]
 [ 0.99985184  0.9961947   0.01340857 -0.16847546  0.55254873 -0.1567363 ]
 [ 0.99985184  0.99144486  0.00189295 -0.15856969  0.54374623 -0.18034432]
 [ 0.99985184  0.98480775 -0.0326539  -0.22631239  0.53861144 -0.22396476]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.2118608951568604
lalalalalal
260 [[ 1.          0.01772693 -0.0690982  -1.79515197 -0.05908708]
 [ 0.99904822  0.25235762 -0.06174875 -1.79038395  0.14962393]
 [ 0.9961947   0.26675214 -0.09146607 -1.77351248  0.34137407]
 [ 0.99144486  0.30129899 -0.14738575 -1.7720454   0.34298263]
 [ 0.98480775  0.37039269 -0.15058116 -1.7720454   0.43798245]]
hahahahahahah
265 [[-0.84754092  1.          0.01772693 -0.0690982  -1.79515197 -0.05908708]
 [-0.84754092  0.99904822  0.25235762 -0.06174875 -1.79038395  0.14962393]
 [-0.84754092  0.9961947   0.26675214 -0.09146607 -1.77351248  0.34137407]
 [-0.84754092  0.99144486  0.30129899 -0.14738575 -1.7720454   0.34298263]
 [-0.84754092  0.98480775  0.37039269 -0.15058116 -1.7720454   0.43798245]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.          0.01772693 -0.0690982  -1.79515197 -0.05908708]
 [-0.84754092  0.99904822  0.25235762 -0.06174875 -1.79038395  0.14962393]
 [-0.84754092  0.9961947   0.26675214 -0.09146607 -1.77351248  0.34137407]
 [-0.84754092  0.99144486  0.30129899 -0.14738575 -1.7720454   0.34298263]
 [-0.84754092  0.98480775  0.37039269 -0.15058116 -1.7720454   0.43798245]]

Epoch: 0, 
Train Loss: 0.9896881137074542, 
Validation Loss: 0.6200566552579403
Elapsed time for epoch-0: 3.4357848167419434
common line69: model saved with val loss 0.6200566552579403

Epoch: 1, 
Train Loss: 0.9450686402431056, 
Validation Loss: 0.5985623737797141
Elapsed time for epoch-1: 4.252490282058716
common line69: model saved with val loss 0.5985623737797141

Epoch: 2, 
Train Loss: 0.934196234250269, 
Validation Loss: 0.5921954908408225
Elapsed time for epoch-2: 3.4880003929138184
common line69: model saved with val loss 0.5921954908408225

Epoch: 3, 
Train Loss: 0.92850466360565, 
Validation Loss: 0.5921774092130363
Elapsed time for epoch-3: 3.3413407802581787
common line69: model saved with val loss 0.5921774092130363

Epoch: 4, 
Train Loss: 0.925275372106488, 
Validation Loss: 0.5921365865506232
Elapsed time for epoch-4: 3.4828741550445557
common line69: model saved with val loss 0.5921365865506232

Epoch: 5, 
Train Loss: 0.9224866495913818, 
Validation Loss: 0.5889809303916991
Elapsed time for epoch-5: 3.329987049102783
common line69: model saved with val loss 0.5889809303916991

Epoch: 6, 
Train Loss: 0.9203176200389862, 
Validation Loss: 0.594538098666817
Elapsed time for epoch-6: 3.766814708709717

Epoch: 7, 
Train Loss: 0.918531500867435, 
Validation Loss: 0.5922597078606486
Elapsed time for epoch-7: 3.487252950668335

Epoch: 8, 
Train Loss: 0.917314106551539, 
Validation Loss: 0.5914557497017086
Elapsed time for epoch-8: 3.289719343185425

Epoch: 9, 
Train Loss: 0.9160732651958946, 
Validation Loss: 0.5900403936393559
Elapsed time for epoch-9: 3.2650036811828613

Epoch: 10, 
Train Loss: 0.9153277930341849, 
Validation Loss: 0.5923265535384417
Elapsed time for epoch-10: 3.028961420059204

Epoch: 11, 
Train Loss: 0.9146340187607693, 
Validation Loss: 0.5896506579592824
Elapsed time for epoch-11: 3.38931941986084

Epoch: 12, 
Train Loss: 0.9137052167363527, 
Validation Loss: 0.5898199994117022
Elapsed time for epoch-12: 2.974783182144165

Epoch: 13, 
Train Loss: 0.913069883564941, 
Validation Loss: 0.5866578524000943
Elapsed time for epoch-13: 3.0619986057281494
common line69: model saved with val loss 0.5866578524000943

Epoch: 14, 
Train Loss: 0.9125407033858179, 
Validation Loss: 0.5888727148994803
Elapsed time for epoch-14: 3.133352756500244

Epoch: 15, 
Train Loss: 0.9122633544587287, 
Validation Loss: 0.5848258715122938
Elapsed time for epoch-15: 2.9164373874664307
common line69: model saved with val loss 0.5848258715122938

Epoch: 16, 
Train Loss: 0.9116759708448618, 
Validation Loss: 0.5922069647349417
Elapsed time for epoch-16: 3.2415812015533447

Epoch: 17, 
Train Loss: 0.9113854997548736, 
Validation Loss: 0.5847943155094981
Elapsed time for epoch-17: 2.9192728996276855
common line69: model saved with val loss 0.5847943155094981

Epoch: 18, 
Train Loss: 0.9106118099278763, 
Validation Loss: 0.5902112005278468
Elapsed time for epoch-18: 3.0126616954803467

Epoch: 19, 
Train Loss: 0.9107437212677563, 
Validation Loss: 0.5852618985809386
Elapsed time for epoch-19: 3.1280055046081543

Epoch: 20, 
Train Loss: 0.9101257762488197, 
Validation Loss: 0.5822065193206072
Elapsed time for epoch-20: 2.8403427600860596
common line69: model saved with val loss 0.5822065193206072

Epoch: 21, 
Train Loss: 0.909920003609497, 
Validation Loss: 0.5880376151762903
Elapsed time for epoch-21: 3.127924919128418

Epoch: 22, 
Train Loss: 0.9097172353698426, 
Validation Loss: 0.5865720114670694
Elapsed time for epoch-22: 3.6643927097320557

Epoch: 23, 
Train Loss: 0.9095054574373389, 
Validation Loss: 0.5868363659828901
Elapsed time for epoch-23: 4.062185049057007

Epoch: 24, 
Train Loss: 0.9092482045418074, 
Validation Loss: 0.5862197480164468
Elapsed time for epoch-24: 3.417445659637451

Epoch: 25, 
Train Loss: 0.908629348172861, 
Validation Loss: 0.5843226537108421
Elapsed time for epoch-25: 3.1370837688446045

Epoch: 26, 
Train Loss: 0.9087111199853801, 
Validation Loss: 0.5853621228598058
Elapsed time for epoch-26: 2.7977943420410156

Epoch: 27, 
Train Loss: 0.9083967369143703, 
Validation Loss: 0.582330169621855
Elapsed time for epoch-27: 3.1900572776794434

Epoch: 28, 
Train Loss: 0.9083386680909565, 
Validation Loss: 0.5837206556461751
Elapsed time for epoch-28: 3.1126961708068848

Epoch: 29, 
Train Loss: 0.9079080674828601, 
Validation Loss: 0.5852996474131942
Elapsed time for epoch-29: 3.131359338760376

Epoch: 30, 
Train Loss: 0.9076204884703419, 
Validation Loss: 0.5844067418947816
Elapsed time for epoch-30: 3.166916847229004

Epoch: 31, 
Train Loss: 0.9075834702293412, 
Validation Loss: 0.5842409548349679
Elapsed time for epoch-31: 3.0139524936676025

train line101: min loss for the epoch 31 is 0.5822065193206072

Training the 88-th turbine in 192.49877190589905 secs

>>>>>>>>> Training Turbine  89 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.035383939743042
lalalalalal
260 [[ 1.          0.2351959  -0.1224233  -0.6721415   0.37895445]
 [ 0.99904822 -0.06336704 -0.12043563  0.56771473 -0.16513338]
 [ 0.9961947  -0.16192179 -0.2045804   0.56110216 -0.26349762]
 [ 0.99144486 -0.15032711 -0.20126761  0.55779588 -0.26785217]
 [ 0.98480775 -0.16482046 -0.24168361  0.55118331 -0.25662713]]
hahahahahahah
265 [[ 0.99985184  1.          0.2351959  -0.1224233  -0.6721415   0.37895445]
 [ 0.99985184  0.99904822 -0.06336704 -0.12043563  0.56771473 -0.16513338]
 [ 0.99985184  0.9961947  -0.16192179 -0.2045804   0.56110216 -0.26349762]
 [ 0.99985184  0.99144486 -0.15032711 -0.20126761  0.55779588 -0.26785217]
 [ 0.99985184  0.98480775 -0.16482046 -0.24168361  0.55118331 -0.25662713]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.2351959  -0.1224233  -0.6721415   0.37895445]
 [ 0.99985184  0.99904822 -0.06336704 -0.12043563  0.56771473 -0.16513338]
 [ 0.99985184  0.9961947  -0.16192179 -0.2045804   0.56110216 -0.26349762]
 [ 0.99985184  0.99144486 -0.15032711 -0.20126761  0.55779588 -0.26785217]
 [ 0.99985184  0.98480775 -0.16482046 -0.24168361  0.55118331 -0.25662713]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.5313899517059326
lalalalalal
260 [[ 1.         -0.024235   -0.07306278 -1.99796109 -0.03125543]
 [ 0.99904822  0.07576909  0.05712973 -2.00126737  0.03457072]
 [ 0.9961947   0.06997175  0.03725301 -2.00292051  0.18250416]
 [ 0.99144486  0.17142518 -0.04821688 -2.00457365  0.35804056]
 [ 0.98480775  0.21780388 -0.07471917 -2.01118622  0.48173372]]
hahahahahahah
265 [[-0.84754092  1.         -0.024235   -0.07306278 -1.99796109 -0.03125543]
 [-0.84754092  0.99904822  0.07576909  0.05712973 -2.00126737  0.03457072]
 [-0.84754092  0.9961947   0.06997175  0.03725301 -2.00292051  0.18250416]
 [-0.84754092  0.99144486  0.17142518 -0.04821688 -2.00457365  0.35804056]
 [-0.84754092  0.98480775  0.21780388 -0.07471917 -2.01118622  0.48173372]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.024235   -0.07306278 -1.99796109 -0.03125543]
 [-0.84754092  0.99904822  0.07576909  0.05712973 -2.00126737  0.03457072]
 [-0.84754092  0.9961947   0.06997175  0.03725301 -2.00292051  0.18250416]
 [-0.84754092  0.99144486  0.17142518 -0.04821688 -2.00457365  0.35804056]
 [-0.84754092  0.98480775  0.21780388 -0.07471917 -2.01118622  0.48173372]]

Epoch: 0, 
Train Loss: 1.0178439708567466, 
Validation Loss: 0.5023289918899536
Elapsed time for epoch-0: 3.480354070663452
common line69: model saved with val loss 0.5023289918899536

Epoch: 1, 
Train Loss: 0.9874798810782552, 
Validation Loss: 0.43239765195176005
Elapsed time for epoch-1: 3.5797603130340576
common line69: model saved with val loss 0.43239765195176005

Epoch: 2, 
Train Loss: 0.9561197594935152, 
Validation Loss: 0.4305782513692975
Elapsed time for epoch-2: 3.817636251449585
common line69: model saved with val loss 0.4305782513692975

Epoch: 3, 
Train Loss: 0.9473004507667878, 
Validation Loss: 0.42296216171234846
Elapsed time for epoch-3: 3.849534273147583
common line69: model saved with val loss 0.42296216171234846

Epoch: 4, 
Train Loss: 0.9421284355285788, 
Validation Loss: 0.4145532106049359
Elapsed time for epoch-4: 3.80230450630188
common line69: model saved with val loss 0.4145532106049359

Epoch: 5, 
Train Loss: 0.9383080740686224, 
Validation Loss: 0.41748697962611914
Elapsed time for epoch-5: 3.6255452632904053

Epoch: 6, 
Train Loss: 0.9357574218962373, 
Validation Loss: 0.40862641809508204
Elapsed time for epoch-6: 3.6344621181488037
common line69: model saved with val loss 0.40862641809508204

Epoch: 7, 
Train Loss: 0.9331517760493174, 
Validation Loss: 0.40304866805672646
Elapsed time for epoch-7: 3.6509478092193604
common line69: model saved with val loss 0.40304866805672646

Epoch: 8, 
Train Loss: 0.9309420286356902, 
Validation Loss: 0.39691768819466233
Elapsed time for epoch-8: 3.6409411430358887
common line69: model saved with val loss 0.39691768819466233

Epoch: 9, 
Train Loss: 0.9291430712998414, 
Validation Loss: 0.3934361692517996
Elapsed time for epoch-9: 3.360377550125122
common line69: model saved with val loss 0.3934361692517996

Epoch: 10, 
Train Loss: 0.9272671192884445, 
Validation Loss: 0.40029522171244025
Elapsed time for epoch-10: 3.2234652042388916

Epoch: 11, 
Train Loss: 0.9258581647852889, 
Validation Loss: 0.39441034430637956
Elapsed time for epoch-11: 3.275693655014038

Epoch: 12, 
Train Loss: 0.9245451507197708, 
Validation Loss: 0.393772394862026
Elapsed time for epoch-12: 2.9339914321899414

Epoch: 13, 
Train Loss: 0.9232715697599059, 
Validation Loss: 0.38559724297374487
Elapsed time for epoch-13: 3.2013957500457764
common line69: model saved with val loss 0.38559724297374487

Epoch: 14, 
Train Loss: 0.9223906977587387, 
Validation Loss: 0.38841414358466864
Elapsed time for epoch-14: 3.0170087814331055

Epoch: 15, 
Train Loss: 0.9213220986748943, 
Validation Loss: 0.39356309827417135
Elapsed time for epoch-15: 3.097494125366211

Epoch: 16, 
Train Loss: 0.920670607510735, 
Validation Loss: 0.38293413119390607
Elapsed time for epoch-16: 3.03442120552063
common line69: model saved with val loss 0.38293413119390607

Epoch: 17, 
Train Loss: 0.9198087248481622, 
Validation Loss: 0.3914502486586571
Elapsed time for epoch-17: 2.991209030151367

Epoch: 18, 
Train Loss: 0.9192372524187344, 
Validation Loss: 0.3790299743413925
Elapsed time for epoch-18: 3.205683469772339
common line69: model saved with val loss 0.3790299743413925

Epoch: 19, 
Train Loss: 0.9188461996176663, 
Validation Loss: 0.3874077801592648
Elapsed time for epoch-19: 3.002473831176758

Epoch: 20, 
Train Loss: 0.9183861226344309, 
Validation Loss: 0.38603825122117996
Elapsed time for epoch-20: 3.017075538635254

Epoch: 21, 
Train Loss: 0.9176022663336842, 
Validation Loss: 0.3854063251055777
Elapsed time for epoch-21: 3.0614843368530273

Epoch: 22, 
Train Loss: 0.9176922922625261, 
Validation Loss: 0.3765942035242915
Elapsed time for epoch-22: 2.858539581298828
common line69: model saved with val loss 0.3765942035242915

Epoch: 23, 
Train Loss: 0.9171941860132858, 
Validation Loss: 0.37854373967275023
Elapsed time for epoch-23: 3.104250907897949

Epoch: 24, 
Train Loss: 0.9169638759198309, 
Validation Loss: 0.3773469808511436
Elapsed time for epoch-24: 3.213507652282715

Epoch: 25, 
Train Loss: 0.9165840279154417, 
Validation Loss: 0.373226682189852
Elapsed time for epoch-25: 3.134186267852783
common line69: model saved with val loss 0.373226682189852

Epoch: 26, 
Train Loss: 0.9162730381769293, 
Validation Loss: 0.38007324282079935
Elapsed time for epoch-26: 3.141918659210205

Epoch: 27, 
Train Loss: 0.916129040367463, 
Validation Loss: 0.37565352441743016
Elapsed time for epoch-27: 2.9684789180755615

Epoch: 28, 
Train Loss: 0.9159632634465434, 
Validation Loss: 0.37731223180890083
Elapsed time for epoch-28: 3.0687801837921143

Epoch: 29, 
Train Loss: 0.9155042547137797, 
Validation Loss: 0.3672792185097933
Elapsed time for epoch-29: 3.2205758094787598
common line69: model saved with val loss 0.3672792185097933

Epoch: 30, 
Train Loss: 0.9151740970731783, 
Validation Loss: 0.37035789201036096
Elapsed time for epoch-30: 2.9224681854248047

Epoch: 31, 
Train Loss: 0.9151406531073466, 
Validation Loss: 0.3604967053979635
Elapsed time for epoch-31: 3.0333471298217773
common line69: model saved with val loss 0.3604967053979635

train line101: min loss for the epoch 31 is 0.3604967053979635

Training the 89-th turbine in 192.0869493484497 secs

>>>>>>>>> Training Turbine  90 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.4001028537750244
lalalalalal
260 [[ 1.          0.31480454 -0.16569955 -0.68476502  0.42443148]
 [ 0.99904822  0.07834082 -0.25883851  0.46180166 -0.08023311]
 [ 0.9961947   0.11582897 -0.27375462  0.4535232  -0.05643931]
 [ 0.99144486  0.10573601 -0.29838354  0.4497289  -0.07005036]
 [ 0.98480775  0.09564305 -0.32301247  0.44593461 -0.08366141]]
hahahahahahah
265 [[ 0.99985184  1.          0.31480454 -0.16569955 -0.68476502  0.42443148]
 [ 0.99985184  0.99904822  0.07834082 -0.25883851  0.46180166 -0.08023311]
 [ 0.99985184  0.9961947   0.11582897 -0.27375462  0.4535232  -0.05643931]
 [ 0.99985184  0.99144486  0.10573601 -0.29838354  0.4497289  -0.07005036]
 [ 0.99985184  0.98480775  0.09564305 -0.32301247  0.44593461 -0.08366141]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.31480454 -0.16569955 -0.68476502  0.42443148]
 [ 0.99985184  0.99904822  0.07834082 -0.25883851  0.46180166 -0.08023311]
 [ 0.99985184  0.9961947   0.11582897 -0.27375462  0.4535232  -0.05643931]
 [ 0.99985184  0.99144486  0.10573601 -0.29838354  0.4497289  -0.07005036]
 [ 0.99985184  0.98480775  0.09564305 -0.32301247  0.44593461 -0.08366141]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.033015251159668
lalalalalal
260 [[ 1.         -0.22588993  0.05023716 -1.66507264 -0.38033462]
 [ 0.99904822 -0.44937698 -0.02746537 -1.68576879 -0.55878809]
 [ 0.9961947  -0.12928585  0.11406423 -1.66714225 -0.31615041]
 [ 0.99144486  0.12448008 -0.01809944 -1.67404097 -0.15597366]
 [ 0.98480775  0.16196823  0.04121811 -1.68576879  0.01446529]]
hahahahahahah
265 [[-0.84754092  1.         -0.22588993  0.05023716 -1.66507264 -0.38033462]
 [-0.84754092  0.99904822 -0.44937698 -0.02746537 -1.68576879 -0.55878809]
 [-0.84754092  0.9961947  -0.12928585  0.11406423 -1.66714225 -0.31615041]
 [-0.84754092  0.99144486  0.12448008 -0.01809944 -1.67404097 -0.15597366]
 [-0.84754092  0.98480775  0.16196823  0.04121811 -1.68576879  0.01446529]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.22588993  0.05023716 -1.66507264 -0.38033462]
 [-0.84754092  0.99904822 -0.44937698 -0.02746537 -1.68576879 -0.55878809]
 [-0.84754092  0.9961947  -0.12928585  0.11406423 -1.66714225 -0.31615041]
 [-0.84754092  0.99144486  0.12448008 -0.01809944 -1.67404097 -0.15597366]
 [-0.84754092  0.98480775  0.16196823  0.04121811 -1.68576879  0.01446529]]

Epoch: 0, 
Train Loss: 0.9930095423419937, 
Validation Loss: 0.671818976290524
Elapsed time for epoch-0: 3.628525972366333
common line69: model saved with val loss 0.671818976290524

Epoch: 1, 
Train Loss: 0.9546495145108519, 
Validation Loss: 0.6669243387877941
Elapsed time for epoch-1: 3.7489848136901855
common line69: model saved with val loss 0.6669243387877941

Epoch: 2, 
Train Loss: 0.9442558684268919, 
Validation Loss: 0.6602135682478547
Elapsed time for epoch-2: 3.742968797683716
common line69: model saved with val loss 0.6602135682478547

Epoch: 3, 
Train Loss: 0.9386652030614244, 
Validation Loss: 0.6678572557866573
Elapsed time for epoch-3: 3.3335258960723877

Epoch: 4, 
Train Loss: 0.9351657828112611, 
Validation Loss: 0.6670283917337656
Elapsed time for epoch-4: 3.8218679428100586

Epoch: 5, 
Train Loss: 0.932628201962519, 
Validation Loss: 0.6643343009054661
Elapsed time for epoch-5: 3.317326545715332

Epoch: 6, 
Train Loss: 0.93035471890153, 
Validation Loss: 0.6662271926179528
Elapsed time for epoch-6: 3.9989099502563477

Epoch: 7, 
Train Loss: 0.9287445144493038, 
Validation Loss: 0.6632770774886012
Elapsed time for epoch-7: 3.978691339492798

Epoch: 8, 
Train Loss: 0.9274004704060674, 
Validation Loss: 0.6607200996950269
Elapsed time for epoch-8: 3.7781991958618164

Epoch: 9, 
Train Loss: 0.9259852480237224, 
Validation Loss: 0.6593436109833419
Elapsed time for epoch-9: 3.542607069015503
common line69: model saved with val loss 0.6593436109833419

Epoch: 10, 
Train Loss: 0.9251939501582074, 
Validation Loss: 0.6616952233016491
Elapsed time for epoch-10: 3.4530649185180664

Epoch: 11, 
Train Loss: 0.9243201123816627, 
Validation Loss: 0.6532402550801635
Elapsed time for epoch-11: 3.130079507827759
common line69: model saved with val loss 0.6532402550801635

Epoch: 12, 
Train Loss: 0.9233529115674877, 
Validation Loss: 0.6558835739269853
Elapsed time for epoch-12: 3.2655413150787354

Epoch: 13, 
Train Loss: 0.9228512644767761, 
Validation Loss: 0.6583289448171854
Elapsed time for epoch-13: 3.189140558242798

Epoch: 14, 
Train Loss: 0.9222405701875687, 
Validation Loss: 0.6539326692000031
Elapsed time for epoch-14: 2.8787951469421387

Epoch: 15, 
Train Loss: 0.9214548901850436, 
Validation Loss: 0.6531701013445854
Elapsed time for epoch-15: 3.053382396697998
common line69: model saved with val loss 0.6531701013445854

Epoch: 16, 
Train Loss: 0.9209381597382682, 
Validation Loss: 0.6575874974951148
Elapsed time for epoch-16: 3.1492559909820557

Epoch: 17, 
Train Loss: 0.9206205486249524, 
Validation Loss: 0.6559184193611145
Elapsed time for epoch-17: 3.0538322925567627

Epoch: 18, 
Train Loss: 0.9199751262404338, 
Validation Loss: 0.6519912164658308
Elapsed time for epoch-18: 3.1251323223114014
common line69: model saved with val loss 0.6519912164658308

Epoch: 19, 
Train Loss: 0.9198083649663364, 
Validation Loss: 0.6496406821534038
Elapsed time for epoch-19: 3.0749874114990234
common line69: model saved with val loss 0.6496406821534038

Epoch: 20, 
Train Loss: 0.919478494204393, 
Validation Loss: 0.6465487601235509
Elapsed time for epoch-20: 3.1165313720703125
common line69: model saved with val loss 0.6465487601235509

Epoch: 21, 
Train Loss: 0.9188066888757113, 
Validation Loss: 0.6457803482189775
Elapsed time for epoch-21: 3.2254395484924316
common line69: model saved with val loss 0.6457803482189775

Epoch: 22, 
Train Loss: 0.9187230643104104, 
Validation Loss: 0.6488783089444041
Elapsed time for epoch-22: 2.800847291946411

Epoch: 23, 
Train Loss: 0.9183383813174832, 
Validation Loss: 0.6409474005922675
Elapsed time for epoch-23: 3.007230520248413
common line69: model saved with val loss 0.6409474005922675

Epoch: 24, 
Train Loss: 0.9180728288508263, 
Validation Loss: 0.6442627338692546
Elapsed time for epoch-24: 3.410900592803955

Epoch: 25, 
Train Loss: 0.9179096481128901, 
Validation Loss: 0.6509699579328299
Elapsed time for epoch-25: 3.969271659851074

Epoch: 26, 
Train Loss: 0.9175434436868218, 
Validation Loss: 0.6498865596950054
Elapsed time for epoch-26: 3.6692392826080322

Epoch: 27, 
Train Loss: 0.9174043136734923, 
Validation Loss: 0.645924880169332
Elapsed time for epoch-27: 3.097564220428467

Epoch: 28, 
Train Loss: 0.9170666897998137, 
Validation Loss: 0.6467195572331548
Elapsed time for epoch-28: 2.92694354057312

Epoch: 29, 
Train Loss: 0.916882047633163, 
Validation Loss: 0.6470816228538752
Elapsed time for epoch-29: 3.109438896179199

Epoch: 30, 
Train Loss: 0.91664372534812, 
Validation Loss: 0.6537723122164607
Elapsed time for epoch-30: 3.0131561756134033

Epoch: 31, 
Train Loss: 0.9165115063430882, 
Validation Loss: 0.6479275915771723
Elapsed time for epoch-31: 2.8385190963745117

train line101: min loss for the epoch 31 is 0.6409474005922675

Training the 90-th turbine in 192.9890308380127 secs

>>>>>>>>> Training Turbine  91 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.3231725692749023
lalalalalal
260 [[ 1.         -0.0279164  -0.14845532 -0.73706433 -0.00965163]
 [ 0.99904822 -0.0381426  -0.22044797  0.40410723 -0.07638521]
 [ 0.9961947  -0.00600312 -0.23598823  0.39870204 -0.08174907]
 [ 0.99144486  0.04658874 -0.24042831  0.39464814  0.02322073]
 [ 0.98480775  0.07288468 -0.26738591  0.38924295 -0.01594442]]
hahahahahahah
265 [[ 0.99985184  1.         -0.0279164  -0.14845532 -0.73706433 -0.00965163]
 [ 0.99985184  0.99904822 -0.0381426  -0.22044797  0.40410723 -0.07638521]
 [ 0.99985184  0.9961947  -0.00600312 -0.23598823  0.39870204 -0.08174907]
 [ 0.99985184  0.99144486  0.04658874 -0.24042831  0.39464814  0.02322073]
 [ 0.99985184  0.98480775  0.07288468 -0.26738591  0.38924295 -0.01594442]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.         -0.0279164  -0.14845532 -0.73706433 -0.00965163]
 [ 0.99985184  0.99904822 -0.0381426  -0.22044797  0.40410723 -0.07638521]
 [ 0.99985184  0.9961947  -0.00600312 -0.23598823  0.39870204 -0.08174907]
 [ 0.99985184  0.99144486  0.04658874 -0.24042831  0.39464814  0.02322073]
 [ 0.99985184  0.98480775  0.07288468 -0.26738591  0.38924295 -0.01594442]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.010897397994995
lalalalalal
260 [[ 1.         -0.15939607 -0.00367716 -1.41271357 -0.31333888]
 [ 0.99904822 -0.30402371 -0.0720226  -1.40190319 -0.43603338]
 [ 0.9961947  -0.30110194  0.06752261 -1.38230936 -0.32477079]
 [ 0.99144486 -0.10534332 -0.03047619 -1.37555287 -0.23652184]
 [ 0.98480775  0.10210238 -0.07995131 -1.40663273 -0.01888106]]
hahahahahahah
265 [[-0.84754092  1.         -0.15939607 -0.00367716 -1.41271357 -0.31333888]
 [-0.84754092  0.99904822 -0.30402371 -0.0720226  -1.40190319 -0.43603338]
 [-0.84754092  0.9961947  -0.30110194  0.06752261 -1.38230936 -0.32477079]
 [-0.84754092  0.99144486 -0.10534332 -0.03047619 -1.37555287 -0.23652184]
 [-0.84754092  0.98480775  0.10210238 -0.07995131 -1.40663273 -0.01888106]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.15939607 -0.00367716 -1.41271357 -0.31333888]
 [-0.84754092  0.99904822 -0.30402371 -0.0720226  -1.40190319 -0.43603338]
 [-0.84754092  0.9961947  -0.30110194  0.06752261 -1.38230936 -0.32477079]
 [-0.84754092  0.99144486 -0.10534332 -0.03047619 -1.37555287 -0.23652184]
 [-0.84754092  0.98480775  0.10210238 -0.07995131 -1.40663273 -0.01888106]]

Epoch: 0, 
Train Loss: 0.9926078577502435, 
Validation Loss: 0.5939771886914968
Elapsed time for epoch-0: 3.9304652214050293
common line69: model saved with val loss 0.5939771886914968

Epoch: 1, 
Train Loss: 0.9681567505878561, 
Validation Loss: 0.5544199822470546
Elapsed time for epoch-1: 3.7122490406036377
common line69: model saved with val loss 0.5544199822470546

Epoch: 2, 
Train Loss: 0.9603952066738064, 
Validation Loss: 0.5362359788268805
Elapsed time for epoch-2: 3.3884470462799072
common line69: model saved with val loss 0.5362359788268805

Epoch: 3, 
Train Loss: 0.9559624565749609, 
Validation Loss: 0.5235656616277993
Elapsed time for epoch-3: 3.700817823410034
common line69: model saved with val loss 0.5235656616277993

Epoch: 4, 
Train Loss: 0.9526987368820095, 
Validation Loss: 0.5154908271506429
Elapsed time for epoch-4: 3.7733447551727295
common line69: model saved with val loss 0.5154908271506429

Epoch: 5, 
Train Loss: 0.9503224621049496, 
Validation Loss: 0.5097004109993577
Elapsed time for epoch-5: 3.467512607574463
common line69: model saved with val loss 0.5097004109993577

Epoch: 6, 
Train Loss: 0.9485957434698313, 
Validation Loss: 0.5111736869439483
Elapsed time for epoch-6: 3.721367597579956

Epoch: 7, 
Train Loss: 0.9473122402149088, 
Validation Loss: 0.502831201069057
Elapsed time for epoch-7: 3.902151584625244
common line69: model saved with val loss 0.502831201069057

Epoch: 8, 
Train Loss: 0.9465003752407908, 
Validation Loss: 0.5061241895891726
Elapsed time for epoch-8: 3.3563876152038574

Epoch: 9, 
Train Loss: 0.9454496367638853, 
Validation Loss: 0.5019294247031212
Elapsed time for epoch-9: 3.755065441131592
common line69: model saved with val loss 0.5019294247031212

Epoch: 10, 
Train Loss: 0.9443022673871336, 
Validation Loss: 0.4994583996012807
Elapsed time for epoch-10: 4.024752140045166
common line69: model saved with val loss 0.4994583996012807

Epoch: 11, 
Train Loss: 0.9440379811435187, 
Validation Loss: 0.4986094976775348
Elapsed time for epoch-11: 4.1585071086883545
common line69: model saved with val loss 0.4986094976775348

Epoch: 12, 
Train Loss: 0.9432908143816876, 
Validation Loss: 0.4990567625500262
Elapsed time for epoch-12: 3.3061089515686035

Epoch: 13, 
Train Loss: 0.9428686286721911, 
Validation Loss: 0.4989263527095318
Elapsed time for epoch-13: 3.316033124923706

Epoch: 14, 
Train Loss: 0.9423755130597523, 
Validation Loss: 0.49255557730793953
Elapsed time for epoch-14: 3.289292335510254
common line69: model saved with val loss 0.49255557730793953

Epoch: 15, 
Train Loss: 0.9419508279622102, 
Validation Loss: 0.5015757568180561
Elapsed time for epoch-15: 3.03625750541687

Epoch: 16, 
Train Loss: 0.9415912713323321, 
Validation Loss: 0.493013808503747
Elapsed time for epoch-16: 3.1126577854156494

Epoch: 17, 
Train Loss: 0.9413678841430599, 
Validation Loss: 0.49923016782850027
Elapsed time for epoch-17: 3.001716136932373

Epoch: 18, 
Train Loss: 0.9412773927720655, 
Validation Loss: 0.4958366546779871
Elapsed time for epoch-18: 2.9858601093292236

Epoch: 19, 
Train Loss: 0.9407587106488332, 
Validation Loss: 0.49677615240216255
Elapsed time for epoch-19: 3.238096237182617

Epoch: 20, 
Train Loss: 0.9406931883647662, 
Validation Loss: 0.5034898612648249
Elapsed time for epoch-20: 3.059843063354492

Epoch: 21, 
Train Loss: 0.9403872740368883, 
Validation Loss: 0.4941578498110175
Elapsed time for epoch-21: 2.995593786239624

Epoch: 22, 
Train Loss: 0.9400676783142972, 
Validation Loss: 0.49630060978233814
Elapsed time for epoch-22: 2.9947521686553955

Epoch: 23, 
Train Loss: 0.9397965958889793, 
Validation Loss: 0.49212376214563847
Elapsed time for epoch-23: 3.099020004272461
common line69: model saved with val loss 0.49212376214563847

Epoch: 24, 
Train Loss: 0.9397078866467756, 
Validation Loss: 0.5024969391524792
Elapsed time for epoch-24: 3.160444736480713

Epoch: 25, 
Train Loss: 0.9395257759244502, 
Validation Loss: 0.49734316021203995
Elapsed time for epoch-25: 2.8726673126220703

Epoch: 26, 
Train Loss: 0.9392800560268033, 
Validation Loss: 0.49545221077278256
Elapsed time for epoch-26: 3.148442506790161

Epoch: 27, 
Train Loss: 0.9390620884775114, 
Validation Loss: 0.4953040978871286
Elapsed time for epoch-27: 3.321341037750244

Epoch: 28, 
Train Loss: 0.9386741997314101, 
Validation Loss: 0.4951046803034842
Elapsed time for epoch-28: 3.066967010498047

Epoch: 29, 
Train Loss: 0.9388059629362171, 
Validation Loss: 0.4951997296884656
Elapsed time for epoch-29: 3.1624231338500977

Epoch: 30, 
Train Loss: 0.938376200424523, 
Validation Loss: 0.49803265603259206
Elapsed time for epoch-30: 2.8324968814849854

Epoch: 31, 
Train Loss: 0.9382898736150325, 
Validation Loss: 0.4996272148564458
Elapsed time for epoch-31: 3.139822483062744

train line101: min loss for the epoch 31 is 0.49212376214563847

Training the 91-th turbine in 193.7571828365326 secs

>>>>>>>>> Training Turbine  92 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.050612449645996
lalalalalal
260 [[ 1.          0.03660709 -0.21273254 -0.45468415 -0.1685567 ]
 [ 0.99904822  0.0381485  -0.22804809  0.42979508 -0.04341124]
 [ 0.9961947   0.01348587 -0.24674918  0.42185157 -0.07756451]
 [ 0.99144486  0.09055659 -0.26254838  0.41635222  0.02817926]
 [ 0.98480775 -0.00192827 -0.25900162  0.41268598 -0.10409897]]
hahahahahahah
265 [[ 0.99985184  1.          0.03660709 -0.21273254 -0.45468415 -0.1685567 ]
 [ 0.99985184  0.99904822  0.0381485  -0.22804809  0.42979508 -0.04341124]
 [ 0.99985184  0.9961947   0.01348587 -0.24674918  0.42185157 -0.07756451]
 [ 0.99985184  0.99144486  0.09055659 -0.26254838  0.41635222  0.02817926]
 [ 0.99985184  0.98480775 -0.00192827 -0.25900162  0.41268598 -0.10409897]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.03660709 -0.21273254 -0.45468415 -0.1685567 ]
 [ 0.99985184  0.99904822  0.0381485  -0.22804809  0.42979508 -0.04341124]
 [ 0.99985184  0.9961947   0.01348587 -0.24674918  0.42185157 -0.07756451]
 [ 0.99985184  0.99144486  0.09055659 -0.26254838  0.41635222  0.02817926]
 [ 0.99985184  0.98480775 -0.00192827 -0.25900162  0.41268598 -0.10409897]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.426697015762329
lalalalalal
260 [[ 1.         -0.29017273 -0.0168547  -1.39843417 -0.26649776]
 [ 0.99904822 -0.49518082 -0.11713126 -1.40454457 -0.43848573]
 [ 0.9961947  -0.14065555  0.14017    -1.40454457 -0.18885162]
 [ 0.99144486 -0.13140706  0.01796802 -1.40637768 -0.11933658]
 [ 0.98480775 -0.06358484 -0.06070554 -1.40943288 -0.00153408]]
hahahahahahah
265 [[-0.84754092  1.         -0.29017273 -0.0168547  -1.39843417 -0.26649776]
 [-0.84754092  0.99904822 -0.49518082 -0.11713126 -1.40454457 -0.43848573]
 [-0.84754092  0.9961947  -0.14065555  0.14017    -1.40454457 -0.18885162]
 [-0.84754092  0.99144486 -0.13140706  0.01796802 -1.40637768 -0.11933658]
 [-0.84754092  0.98480775 -0.06358484 -0.06070554 -1.40943288 -0.00153408]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.29017273 -0.0168547  -1.39843417 -0.26649776]
 [-0.84754092  0.99904822 -0.49518082 -0.11713126 -1.40454457 -0.43848573]
 [-0.84754092  0.9961947  -0.14065555  0.14017    -1.40454457 -0.18885162]
 [-0.84754092  0.99144486 -0.13140706  0.01796802 -1.40637768 -0.11933658]
 [-0.84754092  0.98480775 -0.06358484 -0.06070554 -1.40943288 -0.00153408]]

Epoch: 0, 
Train Loss: 1.0142070321726198, 
Validation Loss: 0.8440175661817193
Elapsed time for epoch-0: 3.7332236766815186
common line69: model saved with val loss 0.8440175661817193

Epoch: 1, 
Train Loss: 0.9639648949148274, 
Validation Loss: 0.8077386869117618
Elapsed time for epoch-1: 3.5547144412994385
common line69: model saved with val loss 0.8077386869117618

Epoch: 2, 
Train Loss: 0.953311237717877, 
Validation Loss: 0.7984149465337396
Elapsed time for epoch-2: 3.4405875205993652
common line69: model saved with val loss 0.7984149465337396

Epoch: 3, 
Train Loss: 0.9477983532833452, 
Validation Loss: 0.795808513648808
Elapsed time for epoch-3: 3.924774646759033
common line69: model saved with val loss 0.795808513648808

Epoch: 4, 
Train Loss: 0.9438600607779848, 
Validation Loss: 0.7943684551864862
Elapsed time for epoch-4: 3.552734375
common line69: model saved with val loss 0.7943684551864862

Epoch: 5, 
Train Loss: 0.9411190060757789, 
Validation Loss: 0.7933815363794565
Elapsed time for epoch-5: 3.693025588989258
common line69: model saved with val loss 0.7933815363794565

Epoch: 6, 
Train Loss: 0.9391399207485824, 
Validation Loss: 0.791807065717876
Elapsed time for epoch-6: 3.6288397312164307
common line69: model saved with val loss 0.791807065717876

Epoch: 7, 
Train Loss: 0.9375838165273186, 
Validation Loss: 0.7928335005417466
Elapsed time for epoch-7: 3.6042428016662598

Epoch: 8, 
Train Loss: 0.9366374427781385, 
Validation Loss: 0.7952416446059942
Elapsed time for epoch-8: 3.410414934158325

Epoch: 9, 
Train Loss: 0.9355046924422769, 
Validation Loss: 0.795763392932713
Elapsed time for epoch-9: 3.47391414642334

Epoch: 10, 
Train Loss: 0.9346904382735741, 
Validation Loss: 0.7902470687404275
Elapsed time for epoch-10: 3.6446495056152344
common line69: model saved with val loss 0.7902470687404275

Epoch: 11, 
Train Loss: 0.9340300785393274, 
Validation Loss: 0.7933529075235128
Elapsed time for epoch-11: 3.476595640182495

Epoch: 12, 
Train Loss: 0.9332852879492175, 
Validation Loss: 0.7937450399622321
Elapsed time for epoch-12: 3.473088264465332

Epoch: 13, 
Train Loss: 0.9327461929882274, 
Validation Loss: 0.7958977660164237
Elapsed time for epoch-13: 3.0585591793060303

Epoch: 14, 
Train Loss: 0.932260464219486, 
Validation Loss: 0.8008794570341706
Elapsed time for epoch-14: 3.2855489253997803

Epoch: 15, 
Train Loss: 0.9318351904634669, 
Validation Loss: 0.7955865226686001
Elapsed time for epoch-15: 3.063500165939331

Epoch: 16, 
Train Loss: 0.9312948670958271, 
Validation Loss: 0.797481638379395
Elapsed time for epoch-16: 3.0266170501708984

Epoch: 17, 
Train Loss: 0.9310010433697901, 
Validation Loss: 0.7981378920376301
Elapsed time for epoch-17: 3.2684316635131836

Epoch: 18, 
Train Loss: 0.9305028374455556, 
Validation Loss: 0.7979906881228089
Elapsed time for epoch-18: 2.9213902950286865

Epoch: 19, 
Train Loss: 0.9303457964869106, 
Validation Loss: 0.7984328428283334
Elapsed time for epoch-19: 3.007265090942383

Epoch: 20, 
Train Loss: 0.9296631945782349, 
Validation Loss: 0.8052722085267305
Elapsed time for epoch-20: 3.079214096069336

Epoch: 21, 
Train Loss: 0.9297135757798908, 
Validation Loss: 0.807719161733985
Elapsed time for epoch-21: 3.0200388431549072

Epoch: 22, 
Train Loss: 0.9292489861239907, 
Validation Loss: 0.8008678006008267
Elapsed time for epoch-22: 3.08479905128479
Early stopped! 

train line101: min loss for the epoch 22 is 0.7902470687404275

Training the 92-th turbine in 165.4773063659668 secs

>>>>>>>>> Training Turbine  93 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.719992160797119
lalalalalal
260 [[ 1.          0.07783255 -0.19407067 -0.4837116   0.02337886]
 [ 0.99904822  0.15256479 -0.28505374  0.42585996  0.00890547]
 [ 0.9961947  -0.02740266 -0.05343078  0.41273977  0.03417054]
 [ 0.99144486  0.08545829 -0.06519161  0.40931711  0.16385746]
 [ 0.98480775  0.03665355 -0.1318363   0.40874667  0.03670505]]
hahahahahahah
265 [[ 0.99985184  1.          0.07783255 -0.19407067 -0.4837116   0.02337886]
 [ 0.99985184  0.99904822  0.15256479 -0.28505374  0.42585996  0.00890547]
 [ 0.99985184  0.9961947  -0.02740266 -0.05343078  0.41273977  0.03417054]
 [ 0.99985184  0.99144486  0.08545829 -0.06519161  0.40931711  0.16385746]
 [ 0.99985184  0.98480775  0.03665355 -0.1318363   0.40874667  0.03670505]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.07783255 -0.19407067 -0.4837116   0.02337886]
 [ 0.99985184  0.99904822  0.15256479 -0.28505374  0.42585996  0.00890547]
 [ 0.99985184  0.9961947  -0.02740266 -0.05343078  0.41273977  0.03417054]
 [ 0.99985184  0.99144486  0.08545829 -0.06519161  0.40931711  0.16385746]
 [ 0.99985184  0.98480775  0.03665355 -0.1318363   0.40874667  0.03670505]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.1562671661376953
lalalalalal
260 [[ 1.         -0.38581241 -0.02043513 -1.3462216  -0.23884964]
 [ 0.99904822 -0.54595294  0.0827988  -1.35392259 -0.32362236]
 [ 0.9961947  -0.15551508  0.02366797 -1.3567748  -0.02692451]
 [ 0.99144486 -0.0670565  -0.19880767 -1.35107037 -0.01121054]
 [ 0.98480775 -0.01825177 -0.19815429 -1.34764771  0.09772007]]
hahahahahahah
265 [[-0.84754092  1.         -0.38581241 -0.02043513 -1.3462216  -0.23884964]
 [-0.84754092  0.99904822 -0.54595294  0.0827988  -1.35392259 -0.32362236]
 [-0.84754092  0.9961947  -0.15551508  0.02366797 -1.3567748  -0.02692451]
 [-0.84754092  0.99144486 -0.0670565  -0.19880767 -1.35107037 -0.01121054]
 [-0.84754092  0.98480775 -0.01825177 -0.19815429 -1.34764771  0.09772007]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.38581241 -0.02043513 -1.3462216  -0.23884964]
 [-0.84754092  0.99904822 -0.54595294  0.0827988  -1.35392259 -0.32362236]
 [-0.84754092  0.9961947  -0.15551508  0.02366797 -1.3567748  -0.02692451]
 [-0.84754092  0.99144486 -0.0670565  -0.19880767 -1.35107037 -0.01121054]
 [-0.84754092  0.98480775 -0.01825177 -0.19815429 -1.34764771  0.09772007]]

Epoch: 0, 
Train Loss: 0.9867817274913067, 
Validation Loss: 0.8325486415997148
Elapsed time for epoch-0: 3.4455580711364746
common line69: model saved with val loss 0.8325486415997148

Epoch: 1, 
Train Loss: 0.9484550981711941, 
Validation Loss: 0.8131987042725086
Elapsed time for epoch-1: 3.9391350746154785
common line69: model saved with val loss 0.8131987042725086

Epoch: 2, 
Train Loss: 0.9413299923684416, 
Validation Loss: 0.8078147796913981
Elapsed time for epoch-2: 3.709981679916382
common line69: model saved with val loss 0.8078147796913981

Epoch: 3, 
Train Loss: 0.9367804955534574, 
Validation Loss: 0.8011685833334923
Elapsed time for epoch-3: 3.873878240585327
common line69: model saved with val loss 0.8011685833334923

Epoch: 4, 
Train Loss: 0.9337179608204785, 
Validation Loss: 0.796079508960247
Elapsed time for epoch-4: 3.319424629211426
common line69: model saved with val loss 0.796079508960247

Epoch: 5, 
Train Loss: 0.9314001411700449, 
Validation Loss: 0.7968238638713956
Elapsed time for epoch-5: 3.3974199295043945

Epoch: 6, 
Train Loss: 0.9297702644302064, 
Validation Loss: 0.7979689687490463
Elapsed time for epoch-6: 3.3935179710388184

Epoch: 7, 
Train Loss: 0.9283237258175842, 
Validation Loss: 0.7889575362205505
Elapsed time for epoch-7: 3.5895121097564697
common line69: model saved with val loss 0.7889575362205505

Epoch: 8, 
Train Loss: 0.9272617281985884, 
Validation Loss: 0.786972526460886
Elapsed time for epoch-8: 3.564950466156006
common line69: model saved with val loss 0.786972526460886

Epoch: 9, 
Train Loss: 0.9260853400000003, 
Validation Loss: 0.7814454473555088
Elapsed time for epoch-9: 3.593744993209839
common line69: model saved with val loss 0.7814454473555088

Epoch: 10, 
Train Loss: 0.9255923179267835, 
Validation Loss: 0.7824842557311058
Elapsed time for epoch-10: 3.869410991668701

Epoch: 11, 
Train Loss: 0.9245151268834827, 
Validation Loss: 0.7793874060735106
Elapsed time for epoch-11: 3.4027464389801025
common line69: model saved with val loss 0.7793874060735106

Epoch: 12, 
Train Loss: 0.9241448061055496, 
Validation Loss: 0.7822172371670604
Elapsed time for epoch-12: 3.7513160705566406

Epoch: 13, 
Train Loss: 0.9235929771631706, 
Validation Loss: 0.7781635066494346
Elapsed time for epoch-13: 3.5361711978912354
common line69: model saved with val loss 0.7781635066494346

Epoch: 14, 
Train Loss: 0.9230510711419482, 
Validation Loss: 0.7816100036725402
Elapsed time for epoch-14: 3.4442217350006104

Epoch: 15, 
Train Loss: 0.9226265270419481, 
Validation Loss: 0.7761867716908455
Elapsed time for epoch-15: 3.698331117630005
common line69: model saved with val loss 0.7761867716908455

Epoch: 16, 
Train Loss: 0.9225367487979537, 
Validation Loss: 0.7781719798222184
Elapsed time for epoch-16: 3.689013719558716

Epoch: 17, 
Train Loss: 0.9218361822246504, 
Validation Loss: 0.7748610498383641
Elapsed time for epoch-17: 3.543654203414917
common line69: model saved with val loss 0.7748610498383641

Epoch: 18, 
Train Loss: 0.9217290205865347, 
Validation Loss: 0.7791245616972446
Elapsed time for epoch-18: 3.5713376998901367

Epoch: 19, 
Train Loss: 0.9214790787766961, 
Validation Loss: 0.7688523977994919
Elapsed time for epoch-19: 3.481874942779541
common line69: model saved with val loss 0.7688523977994919

Epoch: 20, 
Train Loss: 0.9209375063411328, 
Validation Loss: 0.7736310847103596
Elapsed time for epoch-20: 3.311769485473633

Epoch: 21, 
Train Loss: 0.9203994985388106, 
Validation Loss: 0.7737878235056996
Elapsed time for epoch-21: 4.05670166015625

Epoch: 22, 
Train Loss: 0.9204312462766632, 
Validation Loss: 0.776052325963974
Elapsed time for epoch-22: 4.430904388427734

Epoch: 23, 
Train Loss: 0.9201270838995942, 
Validation Loss: 0.773785712197423
Elapsed time for epoch-23: 4.1869587898254395

Epoch: 24, 
Train Loss: 0.9198798274292665, 
Validation Loss: 0.7751074936240911
Elapsed time for epoch-24: 3.6869351863861084

Epoch: 25, 
Train Loss: 0.9196145793720454, 
Validation Loss: 0.7699897717684507
Elapsed time for epoch-25: 3.686960220336914

Epoch: 26, 
Train Loss: 0.9194374997325304, 
Validation Loss: 0.7718757288530469
Elapsed time for epoch-26: 2.949953079223633

Epoch: 27, 
Train Loss: 0.9190524808999871, 
Validation Loss: 0.766192409209907
Elapsed time for epoch-27: 2.939128875732422
common line69: model saved with val loss 0.766192409209907

Epoch: 28, 
Train Loss: 0.9186802733094752, 
Validation Loss: 0.7688334891572595
Elapsed time for epoch-28: 3.189629554748535

Epoch: 29, 
Train Loss: 0.9184418612418055, 
Validation Loss: 0.7645576447248459
Elapsed time for epoch-29: 3.0588021278381348
common line69: model saved with val loss 0.7645576447248459

Epoch: 30, 
Train Loss: 0.9180479581866946, 
Validation Loss: 0.769248771481216
Elapsed time for epoch-30: 3.1146695613861084

Epoch: 31, 
Train Loss: 0.9178416318252307, 
Validation Loss: 0.7684699920937419
Elapsed time for epoch-31: 2.9654107093811035

train line101: min loss for the epoch 31 is 0.7645576447248459

Training the 93-th turbine in 194.6230866909027 secs

>>>>>>>>> Training Turbine  94 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.8565175533294678
lalalalalal
260 [[ 1.          0.16204426 -0.23660628 -0.58644065  0.16094275]
 [ 0.99904822  0.16204426 -0.32200275  0.45511935 -0.05398008]
 [ 0.9961947   0.14547468 -0.28419362  0.45385533 -0.06805439]
 [ 0.99144486  0.19242183 -0.31157264  0.45322331  0.00840534]
 [ 0.98480775  0.13442829 -0.35720434  0.45069525 -0.13189407]]
hahahahahahah
265 [[ 0.99985184  1.          0.16204426 -0.23660628 -0.58644065  0.16094275]
 [ 0.99985184  0.99904822  0.16204426 -0.32200275  0.45511935 -0.05398008]
 [ 0.99985184  0.9961947   0.14547468 -0.28419362  0.45385533 -0.06805439]
 [ 0.99985184  0.99144486  0.19242183 -0.31157264  0.45322331  0.00840534]
 [ 0.99985184  0.98480775  0.13442829 -0.35720434  0.45069525 -0.13189407]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.16204426 -0.23660628 -0.58644065  0.16094275]
 [ 0.99985184  0.99904822  0.16204426 -0.32200275  0.45511935 -0.05398008]
 [ 0.99985184  0.9961947   0.14547468 -0.28419362  0.45385533 -0.06805439]
 [ 0.99985184  0.99144486  0.19242183 -0.31157264  0.45322331  0.00840534]
 [ 0.99985184  0.98480775  0.13442829 -0.35720434  0.45069525 -0.13189407]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.0790679454803467
lalalalalal
260 [[ 1.         -0.40132162  0.05788114 -1.30630524 -0.31649921]
 [ 0.99904822 -0.45931517 -0.01040344 -1.3132574  -0.35981899]
 [ 0.9961947  -0.22181779  0.0355542  -1.31641748 -0.21197713]
 [ 0.99144486 -0.13344667 -0.19130053 -1.34928223 -0.04636368]
 [ 0.98480775 -0.07269152  0.04142113 -1.37456282  0.12873945]]
hahahahahahah
265 [[-0.84754092  1.         -0.40132162  0.05788114 -1.30630524 -0.31649921]
 [-0.84754092  0.99904822 -0.45931517 -0.01040344 -1.3132574  -0.35981899]
 [-0.84754092  0.9961947  -0.22181779  0.0355542  -1.31641748 -0.21197713]
 [-0.84754092  0.99144486 -0.13344667 -0.19130053 -1.34928223 -0.04636368]
 [-0.84754092  0.98480775 -0.07269152  0.04142113 -1.37456282  0.12873945]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.40132162  0.05788114 -1.30630524 -0.31649921]
 [-0.84754092  0.99904822 -0.45931517 -0.01040344 -1.3132574  -0.35981899]
 [-0.84754092  0.9961947  -0.22181779  0.0355542  -1.31641748 -0.21197713]
 [-0.84754092  0.99144486 -0.13344667 -0.19130053 -1.34928223 -0.04636368]
 [-0.84754092  0.98480775 -0.07269152  0.04142113 -1.37456282  0.12873945]]

Epoch: 0, 
Train Loss: 0.992686386118416, 
Validation Loss: 0.7838472714647651
Elapsed time for epoch-0: 3.537761926651001
common line69: model saved with val loss 0.7838472714647651

Epoch: 1, 
Train Loss: 0.9518514543521304, 
Validation Loss: 0.7601426327601075
Elapsed time for epoch-1: 3.592991590499878
common line69: model saved with val loss 0.7601426327601075

Epoch: 2, 
Train Loss: 0.9440423346617642, 
Validation Loss: 0.7567583322525024
Elapsed time for epoch-2: 3.6749138832092285
common line69: model saved with val loss 0.7567583322525024

Epoch: 3, 
Train Loss: 0.9396141212777931, 
Validation Loss: 0.7498116362839937
Elapsed time for epoch-3: 3.6481573581695557
common line69: model saved with val loss 0.7498116362839937

Epoch: 4, 
Train Loss: 0.9367083779403141, 
Validation Loss: 0.7495109438896179
Elapsed time for epoch-4: 3.5899479389190674
common line69: model saved with val loss 0.7495109438896179

Epoch: 5, 
Train Loss: 0.9345718151381036, 
Validation Loss: 0.7548463046550751
Elapsed time for epoch-5: 3.901653289794922

Epoch: 6, 
Train Loss: 0.9325551075093886, 
Validation Loss: 0.748870980925858
Elapsed time for epoch-6: 3.6639811992645264
common line69: model saved with val loss 0.748870980925858

Epoch: 7, 
Train Loss: 0.9313222809749491, 
Validation Loss: 0.7461042953655124
Elapsed time for epoch-7: 3.7156925201416016
common line69: model saved with val loss 0.7461042953655124

Epoch: 8, 
Train Loss: 0.930293593461774, 
Validation Loss: 0.7435114607214928
Elapsed time for epoch-8: 3.3110015392303467
common line69: model saved with val loss 0.7435114607214928

Epoch: 9, 
Train Loss: 0.9294871173235548, 
Validation Loss: 0.7464737147092819
Elapsed time for epoch-9: 3.5101656913757324

Epoch: 10, 
Train Loss: 0.9284043886831829, 
Validation Loss: 0.7439888706430793
Elapsed time for epoch-10: 3.7082631587982178

Epoch: 11, 
Train Loss: 0.9276318858150675, 
Validation Loss: 0.7456815140321851
Elapsed time for epoch-11: 3.409142017364502

Epoch: 12, 
Train Loss: 0.9270861121285864, 
Validation Loss: 0.7424401352182031
Elapsed time for epoch-12: 3.6722512245178223
common line69: model saved with val loss 0.7424401352182031

Epoch: 13, 
Train Loss: 0.9261092278135925, 
Validation Loss: 0.7378090564161539
Elapsed time for epoch-13: 3.5524818897247314
common line69: model saved with val loss 0.7378090564161539

Epoch: 14, 
Train Loss: 0.9255910224022985, 
Validation Loss: 0.7428044648841023
Elapsed time for epoch-14: 3.74188232421875

Epoch: 15, 
Train Loss: 0.9245929884559968, 
Validation Loss: 0.7391041629016399
Elapsed time for epoch-15: 3.895115852355957

Epoch: 16, 
Train Loss: 0.9242630779993635, 
Validation Loss: 0.7385245738551021
Elapsed time for epoch-16: 3.6170859336853027

Epoch: 17, 
Train Loss: 0.9234027351651873, 
Validation Loss: 0.7378649618476629
Elapsed time for epoch-17: 3.6811306476593018

Epoch: 18, 
Train Loss: 0.9230125418731144, 
Validation Loss: 0.7333931177854538
Elapsed time for epoch-18: 3.5345280170440674
common line69: model saved with val loss 0.7333931177854538

Epoch: 19, 
Train Loss: 0.9226019893373761, 
Validation Loss: 0.7337945681065321
Elapsed time for epoch-19: 3.598289728164673

Epoch: 20, 
Train Loss: 0.9222156610809454, 
Validation Loss: 0.738476512953639
Elapsed time for epoch-20: 3.50347638130188

Epoch: 21, 
Train Loss: 0.9219613106561309, 
Validation Loss: 0.7345077404752374
Elapsed time for epoch-21: 3.464251756668091

Epoch: 22, 
Train Loss: 0.9214262650543902, 
Validation Loss: 0.7348315948620439
Elapsed time for epoch-22: 3.6129608154296875

Epoch: 23, 
Train Loss: 0.921241324614076, 
Validation Loss: 0.7364824675023556
Elapsed time for epoch-23: 3.500570058822632

Epoch: 24, 
Train Loss: 0.9208845684007436, 
Validation Loss: 0.7318846164271235
Elapsed time for epoch-24: 3.068908452987671
common line69: model saved with val loss 0.7318846164271235

Epoch: 25, 
Train Loss: 0.9209444045770068, 
Validation Loss: 0.7280564866960049
Elapsed time for epoch-25: 3.383960723876953
common line69: model saved with val loss 0.7280564866960049

Epoch: 26, 
Train Loss: 0.9204286852804553, 
Validation Loss: 0.7331653842702508
Elapsed time for epoch-26: 3.1814329624176025

Epoch: 27, 
Train Loss: 0.9203822531369554, 
Validation Loss: 0.7294089607894421
Elapsed time for epoch-27: 2.9611239433288574

Epoch: 28, 
Train Loss: 0.9202362672120583, 
Validation Loss: 0.731297617778182
Elapsed time for epoch-28: 3.251232624053955

Epoch: 29, 
Train Loss: 0.9198580527005076, 
Validation Loss: 0.7309222593903542
Elapsed time for epoch-29: 2.8738317489624023

Epoch: 30, 
Train Loss: 0.9197682782131082, 
Validation Loss: 0.7313395729288459
Elapsed time for epoch-30: 3.1483137607574463

Epoch: 31, 
Train Loss: 0.9195036901896741, 
Validation Loss: 0.7287160968407989
Elapsed time for epoch-31: 3.0506575107574463

train line101: min loss for the epoch 31 is 0.7280564866960049

Training the 94-th turbine in 192.17700266838074 secs

>>>>>>>>> Training Turbine  95 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.9110546112060547
lalalalalal
260 [[ 1.          0.18380668 -0.18324578 -0.52877563  0.19845185]
 [ 0.99904822  0.26007736 -0.26501747  0.47996859  0.15752552]
 [ 0.9961947   0.25409535 -0.25335716  0.47381959  0.11718404]
 [ 0.99144486  0.34382556 -0.27518288  0.46767058  0.23794855]
 [ 0.98480775  0.23016729 -0.32840175  0.46275138  0.0502255 ]]
hahahahahahah
265 [[ 0.99985184  1.          0.18380668 -0.18324578 -0.52877563  0.19845185]
 [ 0.99985184  0.99904822  0.26007736 -0.26501747  0.47996859  0.15752552]
 [ 0.99985184  0.9961947   0.25409535 -0.25335716  0.47381959  0.11718404]
 [ 0.99985184  0.99144486  0.34382556 -0.27518288  0.46767058  0.23794855]
 [ 0.99985184  0.98480775  0.23016729 -0.32840175  0.46275138  0.0502255 ]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.18380668 -0.18324578 -0.52877563  0.19845185]
 [ 0.99985184  0.99904822  0.26007736 -0.26501747  0.47996859  0.15752552]
 [ 0.99985184  0.9961947   0.25409535 -0.25335716  0.47381959  0.11718404]
 [ 0.99985184  0.99144486  0.34382556 -0.27518288  0.46767058  0.23794855]
 [ 0.99985184  0.98480775  0.23016729 -0.32840175  0.46275138  0.0502255 ]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.232722520828247
lalalalalal
260 [[ 1.         -0.42187227  0.03680529 -1.45081889 -0.40889279]
 [ 0.99904822 -0.44879133  0.17538365 -1.45204869 -0.41497521]
 [ 0.9961947  -0.34410608  0.05997643 -1.45758279 -0.32904161]
 [ 0.99144486 -0.17361868 -0.07665854 -1.45942749 -0.21420355]
 [ 0.98480775 -0.24540285 -0.17532274 -1.4661914  -0.21737473]]
hahahahahahah
265 [[-0.84754092  1.         -0.42187227  0.03680529 -1.45081889 -0.40889279]
 [-0.84754092  0.99904822 -0.44879133  0.17538365 -1.45204869 -0.41497521]
 [-0.84754092  0.9961947  -0.34410608  0.05997643 -1.45758279 -0.32904161]
 [-0.84754092  0.99144486 -0.17361868 -0.07665854 -1.45942749 -0.21420355]
 [-0.84754092  0.98480775 -0.24540285 -0.17532274 -1.4661914  -0.21737473]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.42187227  0.03680529 -1.45081889 -0.40889279]
 [-0.84754092  0.99904822 -0.44879133  0.17538365 -1.45204869 -0.41497521]
 [-0.84754092  0.9961947  -0.34410608  0.05997643 -1.45758279 -0.32904161]
 [-0.84754092  0.99144486 -0.17361868 -0.07665854 -1.45942749 -0.21420355]
 [-0.84754092  0.98480775 -0.24540285 -0.17532274 -1.4661914  -0.21737473]]

Epoch: 0, 
Train Loss: 0.9831065306393039, 
Validation Loss: 0.6606477629393339
Elapsed time for epoch-0: 3.7935872077941895
common line69: model saved with val loss 0.6606477629393339

Epoch: 1, 
Train Loss: 0.9434960091314396, 
Validation Loss: 0.6427021091803908
Elapsed time for epoch-1: 4.043084621429443
common line69: model saved with val loss 0.6427021091803908

Epoch: 2, 
Train Loss: 0.9366738158865135, 
Validation Loss: 0.6426636134274304
Elapsed time for epoch-2: 3.9563889503479004
common line69: model saved with val loss 0.6426636134274304

Epoch: 3, 
Train Loss: 0.9321854963523, 
Validation Loss: 0.6414216281846166
Elapsed time for epoch-3: 4.021245002746582
common line69: model saved with val loss 0.6414216281846166

Epoch: 4, 
Train Loss: 0.9294471842150728, 
Validation Loss: 0.6294211046770215
Elapsed time for epoch-4: 3.836946725845337
common line69: model saved with val loss 0.6294211046770215

Epoch: 5, 
Train Loss: 0.9274401847554856, 
Validation Loss: 0.6285208994522691
Elapsed time for epoch-5: 3.5895707607269287
common line69: model saved with val loss 0.6285208994522691

Epoch: 6, 
Train Loss: 0.9257489871077177, 
Validation Loss: 0.6300626937299967
Elapsed time for epoch-6: 3.499394416809082

Epoch: 7, 
Train Loss: 0.9243155967037217, 
Validation Loss: 0.6252360469661653
Elapsed time for epoch-7: 4.096707105636597
common line69: model saved with val loss 0.6252360469661653

Epoch: 8, 
Train Loss: 0.9231667786586184, 
Validation Loss: 0.6213610959239304
Elapsed time for epoch-8: 3.523242950439453
common line69: model saved with val loss 0.6213610959239304

Epoch: 9, 
Train Loss: 0.9222027834723977, 
Validation Loss: 0.6163293942809105
Elapsed time for epoch-9: 3.637655735015869
common line69: model saved with val loss 0.6163293942809105

Epoch: 10, 
Train Loss: 0.9212047837111128, 
Validation Loss: 0.6243642680346966
Elapsed time for epoch-10: 3.66571044921875

Epoch: 11, 
Train Loss: 0.9207621239313558, 
Validation Loss: 0.6192503748461604
Elapsed time for epoch-11: 3.8817782402038574

Epoch: 12, 
Train Loss: 0.9199517336713166, 
Validation Loss: 0.613057623617351
Elapsed time for epoch-12: 3.4415628910064697
common line69: model saved with val loss 0.613057623617351

Epoch: 13, 
Train Loss: 0.9194242291841186, 
Validation Loss: 0.6179031385108829
Elapsed time for epoch-13: 3.4351823329925537

Epoch: 14, 
Train Loss: 0.9186406054166185, 
Validation Loss: 0.6150209866464138
Elapsed time for epoch-14: 3.467097759246826

Epoch: 15, 
Train Loss: 0.9184894153550893, 
Validation Loss: 0.6157368887215853
Elapsed time for epoch-15: 3.444216012954712

Epoch: 16, 
Train Loss: 0.917947350054228, 
Validation Loss: 0.6111011086031795
Elapsed time for epoch-16: 3.5218615531921387
common line69: model saved with val loss 0.6111011086031795

Epoch: 17, 
Train Loss: 0.9174872857181966, 
Validation Loss: 0.6094564967788756
Elapsed time for epoch-17: 3.831164836883545
common line69: model saved with val loss 0.6094564967788756

Epoch: 18, 
Train Loss: 0.9170021463592514, 
Validation Loss: 0.6087459311820567
Elapsed time for epoch-18: 4.080630302429199
common line69: model saved with val loss 0.6087459311820567

Epoch: 19, 
Train Loss: 0.91682169630247, 
Validation Loss: 0.6053652176633477
Elapsed time for epoch-19: 3.9634037017822266
common line69: model saved with val loss 0.6053652176633477

Epoch: 20, 
Train Loss: 0.9163578305424762, 
Validation Loss: 0.6064369445666671
Elapsed time for epoch-20: 3.77095627784729

Epoch: 21, 
Train Loss: 0.9163041963797658, 
Validation Loss: 0.6080098417587578
Elapsed time for epoch-21: 3.7664167881011963

Epoch: 22, 
Train Loss: 0.9155774892879134, 
Validation Loss: 0.6093025370500982
Elapsed time for epoch-22: 4.288800477981567

Epoch: 23, 
Train Loss: 0.915653455908559, 
Validation Loss: 0.6034122440032661
Elapsed time for epoch-23: 3.4413933753967285
common line69: model saved with val loss 0.6034122440032661

Epoch: 24, 
Train Loss: 0.9152242293377885, 
Validation Loss: 0.602186291012913
Elapsed time for epoch-24: 3.8614957332611084
common line69: model saved with val loss 0.602186291012913

Epoch: 25, 
Train Loss: 0.9146999204609575, 
Validation Loss: 0.607946346513927
Elapsed time for epoch-25: 3.4624595642089844

Epoch: 26, 
Train Loss: 0.9146539416132855, 
Validation Loss: 0.6032039285637438
Elapsed time for epoch-26: 3.450960636138916

Epoch: 27, 
Train Loss: 0.9146466072367019, 
Validation Loss: 0.599869572557509
Elapsed time for epoch-27: 3.1864044666290283
common line69: model saved with val loss 0.599869572557509

Epoch: 28, 
Train Loss: 0.9142972220893667, 
Validation Loss: 0.5972416191361845
Elapsed time for epoch-28: 2.8995742797851562
common line69: model saved with val loss 0.5972416191361845

Epoch: 29, 
Train Loss: 0.9138870460896933, 
Validation Loss: 0.5972401825711131
Elapsed time for epoch-29: 2.8729236125946045
common line69: model saved with val loss 0.5972401825711131

Epoch: 30, 
Train Loss: 0.9135847069135233, 
Validation Loss: 0.5973724173381925
Elapsed time for epoch-30: 2.800527811050415

Epoch: 31, 
Train Loss: 0.9133758124183206, 
Validation Loss: 0.5966449901461601
Elapsed time for epoch-31: 3.026918411254883
common line69: model saved with val loss 0.5966449901461601

train line101: min loss for the epoch 31 is 0.5966449901461601

Training the 95-th turbine in 196.4233739376068 secs

>>>>>>>>> Training Turbine  96 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.7377946376800537
lalalalalal
260 [[ 1.          0.02690122 -0.0907504  -0.63724164  0.07775017]
 [ 0.99904822  0.10678168 -0.18252749  0.10495008  0.05092962]
 [ 0.9961947   0.11840065 -0.17909948  0.09499832  0.0392271 ]
 [ 0.99144486  0.19392399 -0.19156496  0.088713    0.11738906]
 [ 0.98480775  0.06030577 -0.26791601  0.08295146 -0.06116965]]
hahahahahahah
265 [[ 0.99985184  1.          0.02690122 -0.0907504  -0.63724164  0.07775017]
 [ 0.99985184  0.99904822  0.10678168 -0.18252749  0.10495008  0.05092962]
 [ 0.99985184  0.9961947   0.11840065 -0.17909948  0.09499832  0.0392271 ]
 [ 0.99985184  0.99144486  0.19392399 -0.19156496  0.088713    0.11738906]
 [ 0.99985184  0.98480775  0.06030577 -0.26791601  0.08295146 -0.06116965]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.02690122 -0.0907504  -0.63724164  0.07775017]
 [ 0.99985184  0.99904822  0.10678168 -0.18252749  0.10495008  0.05092962]
 [ 0.99985184  0.9961947   0.11840065 -0.17909948  0.09499832  0.0392271 ]
 [ 0.99985184  0.99144486  0.19392399 -0.19156496  0.088713    0.11738906]
 [ 0.99985184  0.98480775  0.06030577 -0.26791601  0.08295146 -0.06116965]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.044500112533569
lalalalalal
260 [[ 1.         -0.39283427 -0.07158473 -0.90541535 -0.43400383]
 [ 0.99904822 -0.39864375  0.08142903 -0.87660763 -0.41771555]
 [ 0.9961947  -0.34345362 -0.00302459 -0.88603561 -0.39602506]
 [ 0.99144486 -0.14012155 -0.16195945 -0.89389227 -0.26408593]
 [ 0.98480775 -0.08202667 -0.2838095  -0.8975587  -0.23077457]]
hahahahahahah
265 [[-0.84754092  1.         -0.39283427 -0.07158473 -0.90541535 -0.43400383]
 [-0.84754092  0.99904822 -0.39864375  0.08142903 -0.87660763 -0.41771555]
 [-0.84754092  0.9961947  -0.34345362 -0.00302459 -0.88603561 -0.39602506]
 [-0.84754092  0.99144486 -0.14012155 -0.16195945 -0.89389227 -0.26408593]
 [-0.84754092  0.98480775 -0.08202667 -0.2838095  -0.8975587  -0.23077457]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.39283427 -0.07158473 -0.90541535 -0.43400383]
 [-0.84754092  0.99904822 -0.39864375  0.08142903 -0.87660763 -0.41771555]
 [-0.84754092  0.9961947  -0.34345362 -0.00302459 -0.88603561 -0.39602506]
 [-0.84754092  0.99144486 -0.14012155 -0.16195945 -0.89389227 -0.26408593]
 [-0.84754092  0.98480775 -0.08202667 -0.2838095  -0.8975587  -0.23077457]]

Epoch: 0, 
Train Loss: 0.9997439468357744, 
Validation Loss: 0.6503608929924667
Elapsed time for epoch-0: 4.285146236419678
common line69: model saved with val loss 0.6503608929924667

Epoch: 1, 
Train Loss: 0.9574878259616739, 
Validation Loss: 0.6402276661247015
Elapsed time for epoch-1: 3.833585739135742
common line69: model saved with val loss 0.6402276661247015

Epoch: 2, 
Train Loss: 0.9494221303142419, 
Validation Loss: 0.6316587710753083
Elapsed time for epoch-2: 3.460062026977539
common line69: model saved with val loss 0.6316587710753083

Epoch: 3, 
Train Loss: 0.9450277102594616, 
Validation Loss: 0.6248214519582689
Elapsed time for epoch-3: 4.021447420120239
common line69: model saved with val loss 0.6248214519582689

Epoch: 4, 
Train Loss: 0.9419533392461408, 
Validation Loss: 0.617532073520124
Elapsed time for epoch-4: 3.698899984359741
common line69: model saved with val loss 0.617532073520124

Epoch: 5, 
Train Loss: 0.9397929359634384, 
Validation Loss: 0.6177458190359175
Elapsed time for epoch-5: 3.6900475025177

Epoch: 6, 
Train Loss: 0.93813856734949, 
Validation Loss: 0.6140968222171068
Elapsed time for epoch-6: 3.3866827487945557
common line69: model saved with val loss 0.6140968222171068

Epoch: 7, 
Train Loss: 0.93636867454072, 
Validation Loss: 0.6150331771932542
Elapsed time for epoch-7: 3.4228858947753906

Epoch: 8, 
Train Loss: 0.93542142137259, 
Validation Loss: 0.6182416817173362
Elapsed time for epoch-8: 3.721498489379883

Epoch: 9, 
Train Loss: 0.9342544428190264, 
Validation Loss: 0.6089607076719403
Elapsed time for epoch-9: 3.346778392791748
common line69: model saved with val loss 0.6089607076719403

Epoch: 10, 
Train Loss: 0.9333897459657252, 
Validation Loss: 0.6119132065214217
Elapsed time for epoch-10: 3.4306933879852295

Epoch: 11, 
Train Loss: 0.9327541066317999, 
Validation Loss: 0.6051960573531687
Elapsed time for epoch-11: 3.6243526935577393
common line69: model saved with val loss 0.6051960573531687

Epoch: 12, 
Train Loss: 0.931969148396444, 
Validation Loss: 0.6106315008364618
Elapsed time for epoch-12: 3.41947865486145

Epoch: 13, 
Train Loss: 0.931268255875892, 
Validation Loss: 0.6121661923825741
Elapsed time for epoch-13: 3.9357385635375977

Epoch: 14, 
Train Loss: 0.9306359406278915, 
Validation Loss: 0.6075582122430205
Elapsed time for epoch-14: 3.901428461074829

Epoch: 15, 
Train Loss: 0.9301701405969989, 
Validation Loss: 0.608079940546304
Elapsed time for epoch-15: 3.824636697769165

Epoch: 16, 
Train Loss: 0.9297465613158811, 
Validation Loss: 0.6032116138376296
Elapsed time for epoch-16: 3.3479301929473877
common line69: model saved with val loss 0.6032116138376296

Epoch: 17, 
Train Loss: 0.9290434972328299, 
Validation Loss: 0.6071652853861451
Elapsed time for epoch-17: 3.058082103729248

Epoch: 18, 
Train Loss: 0.9288087008880967, 
Validation Loss: 0.6069437088444829
Elapsed time for epoch-18: 3.3291990756988525

Epoch: 19, 
Train Loss: 0.9281692860507164, 
Validation Loss: 0.6071913102641702
Elapsed time for epoch-19: 3.040330648422241

Epoch: 20, 
Train Loss: 0.9278410385135843, 
Validation Loss: 0.6068359673954546
Elapsed time for epoch-20: 3.099360704421997

Epoch: 21, 
Train Loss: 0.9275992056902718, 
Validation Loss: 0.6102410992607474
Elapsed time for epoch-21: 2.9814698696136475

Epoch: 22, 
Train Loss: 0.9269390382937023, 
Validation Loss: 0.6066005695611238
Elapsed time for epoch-22: 2.966869354248047

Epoch: 23, 
Train Loss: 0.9265334589892075, 
Validation Loss: 0.6043612933717668
Elapsed time for epoch-23: 3.4223055839538574

Epoch: 24, 
Train Loss: 0.9266135697605229, 
Validation Loss: 0.605389938224107
Elapsed time for epoch-24: 3.0521538257598877

Epoch: 25, 
Train Loss: 0.9262230617909872, 
Validation Loss: 0.6049333750270307
Elapsed time for epoch-25: 3.161125421524048

Epoch: 26, 
Train Loss: 0.9262810260558328, 
Validation Loss: 0.6022616480477154
Elapsed time for epoch-26: 3.1047470569610596
common line69: model saved with val loss 0.6022616480477154

Epoch: 27, 
Train Loss: 0.9256034668754128, 
Validation Loss: 0.5979844881221652
Elapsed time for epoch-27: 2.8944530487060547
common line69: model saved with val loss 0.5979844881221652

Epoch: 28, 
Train Loss: 0.9257418156421485, 
Validation Loss: 0.6108458922244608
Elapsed time for epoch-28: 3.263871669769287

Epoch: 29, 
Train Loss: 0.9252592744697042, 
Validation Loss: 0.6075000241398811
Elapsed time for epoch-29: 2.957226037979126

Epoch: 30, 
Train Loss: 0.9246651877124771, 
Validation Loss: 0.6075320965610445
Elapsed time for epoch-30: 3.045397996902466

Epoch: 31, 
Train Loss: 0.9245929761844522, 
Validation Loss: 0.6049641165882349
Elapsed time for epoch-31: 3.426560401916504

train line101: min loss for the epoch 31 is 0.5979844881221652

Training the 96-th turbine in 191.32737016677856 secs

>>>>>>>>> Training Turbine  97 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.215263605117798
lalalalalal
260 [[ 1.          0.1502599  -0.1749333  -0.08943902 -0.03874951]
 [ 0.99904822  0.22492743 -0.34611597  0.44327997 -0.06873793]
 [ 0.9961947   0.20103382 -0.31206517  0.43947936 -0.0988168 ]
 [ 0.99144486  0.26972794 -0.34642552  0.43251158 -0.03005403]
 [ 0.98480775  0.12636629 -0.23374832  0.42807753 -0.14370254]]
hahahahahahah
265 [[ 0.99985184  1.          0.1502599  -0.1749333  -0.08943902 -0.03874951]
 [ 0.99985184  0.99904822  0.22492743 -0.34611597  0.44327997 -0.06873793]
 [ 0.99985184  0.9961947   0.20103382 -0.31206517  0.43947936 -0.0988168 ]
 [ 0.99985184  0.99144486  0.26972794 -0.34642552  0.43251158 -0.03005403]
 [ 0.99985184  0.98480775  0.12636629 -0.23374832  0.42807753 -0.14370254]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.1502599  -0.1749333  -0.08943902 -0.03874951]
 [ 0.99985184  0.99904822  0.22492743 -0.34611597  0.44327997 -0.06873793]
 [ 0.99985184  0.9961947   0.20103382 -0.31206517  0.43947936 -0.0988168 ]
 [ 0.99985184  0.99144486  0.26972794 -0.34642552  0.43251158 -0.03005403]
 [ 0.99985184  0.98480775  0.12636629 -0.23374832  0.42807753 -0.14370254]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.2621800899505615
lalalalalal
260 [[ 1.         -0.45454706  0.10784313 -1.55109071 -0.36298886]
 [ 0.99904822 -0.50382762  0.09066296 -1.55647491 -0.38756361]
 [ 0.9961947  -0.28579845 -0.03842054 -1.55710834 -0.24716971]
 [ 0.99144486 -0.24995804 -0.16131298 -1.56090895 -0.19928643]
 [ 0.98480775 -0.16931711  0.00646461 -1.56470956 -0.0455586 ]]
hahahahahahah
265 [[-0.84754092  1.         -0.45454706  0.10784313 -1.55109071 -0.36298886]
 [-0.84754092  0.99904822 -0.50382762  0.09066296 -1.55647491 -0.38756361]
 [-0.84754092  0.9961947  -0.28579845 -0.03842054 -1.55710834 -0.24716971]
 [-0.84754092  0.99144486 -0.24995804 -0.16131298 -1.56090895 -0.19928643]
 [-0.84754092  0.98480775 -0.16931711  0.00646461 -1.56470956 -0.0455586 ]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.45454706  0.10784313 -1.55109071 -0.36298886]
 [-0.84754092  0.99904822 -0.50382762  0.09066296 -1.55647491 -0.38756361]
 [-0.84754092  0.9961947  -0.28579845 -0.03842054 -1.55710834 -0.24716971]
 [-0.84754092  0.99144486 -0.24995804 -0.16131298 -1.56090895 -0.19928643]
 [-0.84754092  0.98480775 -0.16931711  0.00646461 -1.56470956 -0.0455586 ]]

Epoch: 0, 
Train Loss: 1.004737599932847, 
Validation Loss: 0.7902778163552284
Elapsed time for epoch-0: 3.5232532024383545
common line69: model saved with val loss 0.7902778163552284

Epoch: 1, 
Train Loss: 0.9569204998116533, 
Validation Loss: 0.7386103570461273
Elapsed time for epoch-1: 3.614875316619873
common line69: model saved with val loss 0.7386103570461273

Epoch: 2, 
Train Loss: 0.9395488315269727, 
Validation Loss: 0.7318106507882476
Elapsed time for epoch-2: 4.264520168304443
common line69: model saved with val loss 0.7318106507882476

Epoch: 3, 
Train Loss: 0.9322526161911107, 
Validation Loss: 0.7249670010060072
Elapsed time for epoch-3: 3.3526880741119385
common line69: model saved with val loss 0.7249670010060072

Epoch: 4, 
Train Loss: 0.9276572664996156, 
Validation Loss: 0.7263429146260023
Elapsed time for epoch-4: 3.8242151737213135

Epoch: 5, 
Train Loss: 0.924280586237667, 
Validation Loss: 0.7266500508412719
Elapsed time for epoch-5: 3.324331045150757

Epoch: 6, 
Train Loss: 0.9221209546848506, 
Validation Loss: 0.7257225746288896
Elapsed time for epoch-6: 3.4380345344543457

Epoch: 7, 
Train Loss: 0.9201851691268071, 
Validation Loss: 0.7302145780995488
Elapsed time for epoch-7: 3.3566133975982666

Epoch: 8, 
Train Loss: 0.9192060783129781, 
Validation Loss: 0.7246297486126423
Elapsed time for epoch-8: 3.4557418823242188
common line69: model saved with val loss 0.7246297486126423

Epoch: 9, 
Train Loss: 0.9180930022682462, 
Validation Loss: 0.7217754507437348
Elapsed time for epoch-9: 3.6626784801483154
common line69: model saved with val loss 0.7217754507437348

Epoch: 10, 
Train Loss: 0.9170822379719309, 
Validation Loss: 0.722858221270144
Elapsed time for epoch-10: 3.400780439376831

Epoch: 11, 
Train Loss: 0.9164024752979519, 
Validation Loss: 0.7285032104700804
Elapsed time for epoch-11: 3.74873685836792

Epoch: 12, 
Train Loss: 0.9156602858996191, 
Validation Loss: 0.7261593295261264
Elapsed time for epoch-12: 3.3612241744995117

Epoch: 13, 
Train Loss: 0.915055945265193, 
Validation Loss: 0.7228227891027927
Elapsed time for epoch-13: 3.5441951751708984

Epoch: 14, 
Train Loss: 0.9146963238966566, 
Validation Loss: 0.7259046519175172
Elapsed time for epoch-14: 3.4191527366638184

Epoch: 15, 
Train Loss: 0.9140000183041356, 
Validation Loss: 0.7228392958641052
Elapsed time for epoch-15: 3.527878999710083

Epoch: 16, 
Train Loss: 0.9132746141247389, 
Validation Loss: 0.7228869320824742
Elapsed time for epoch-16: 3.6642661094665527

Epoch: 17, 
Train Loss: 0.9129807274131214, 
Validation Loss: 0.7230699378997087
Elapsed time for epoch-17: 3.484790802001953

Epoch: 18, 
Train Loss: 0.9126972629993904, 
Validation Loss: 0.7214207882061601
Elapsed time for epoch-18: 3.236973762512207
common line69: model saved with val loss 0.7214207882061601

Epoch: 19, 
Train Loss: 0.912299360547747, 
Validation Loss: 0.724520854651928
Elapsed time for epoch-19: 3.2316508293151855

Epoch: 20, 
Train Loss: 0.9118653773760595, 
Validation Loss: 0.7197004007175565
Elapsed time for epoch-20: 3.2302353382110596
common line69: model saved with val loss 0.7197004007175565

Epoch: 21, 
Train Loss: 0.9117023586725989, 
Validation Loss: 0.7290643826127052
Elapsed time for epoch-21: 3.055837392807007

Epoch: 22, 
Train Loss: 0.9113730784474301, 
Validation Loss: 0.7241901606321335
Elapsed time for epoch-22: 3.090527296066284

Epoch: 23, 
Train Loss: 0.9110789987720361, 
Validation Loss: 0.7186798565089703
Elapsed time for epoch-23: 3.234955310821533
common line69: model saved with val loss 0.7186798565089703

Epoch: 24, 
Train Loss: 0.9108700215065179, 
Validation Loss: 0.7231836579740047
Elapsed time for epoch-24: 2.9767611026763916

Epoch: 25, 
Train Loss: 0.9109372894804016, 
Validation Loss: 0.7243122989311814
Elapsed time for epoch-25: 3.2221519947052

Epoch: 26, 
Train Loss: 0.9105777485030038, 
Validation Loss: 0.717620113864541
Elapsed time for epoch-26: 2.963761329650879
common line69: model saved with val loss 0.717620113864541

Epoch: 27, 
Train Loss: 0.9102283644826472, 
Validation Loss: 0.7241188585758209
Elapsed time for epoch-27: 2.9954729080200195

Epoch: 28, 
Train Loss: 0.9102137619707765, 
Validation Loss: 0.7263735756278038
Elapsed time for epoch-28: 3.1959197521209717

Epoch: 29, 
Train Loss: 0.9097238661361342, 
Validation Loss: 0.7179383095353842
Elapsed time for epoch-29: 3.0051209926605225

Epoch: 30, 
Train Loss: 0.9096752030759299, 
Validation Loss: 0.72779824398458
Elapsed time for epoch-30: 3.083704948425293

Epoch: 31, 
Train Loss: 0.9098578302048835, 
Validation Loss: 0.72515032812953
Elapsed time for epoch-31: 3.0811350345611572

train line101: min loss for the epoch 31 is 0.717620113864541

Training the 97-th turbine in 192.02272653579712 secs

>>>>>>>>> Training Turbine  98 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 4.202315330505371
lalalalalal
260 [[ 1.          0.09864848 -0.12862423 -0.42390704  0.19265295]
 [ 0.99904822  0.05628571 -0.07267366  0.72183582 -0.12387777]
 [ 0.9961947   0.00181929 -0.00261921  0.68589095 -0.18441712]
 [ 0.99144486  0.08351892  0.01070973  0.68420603 -0.13372521]
 [ 0.98480775 -0.02843983 -0.09251209  0.68027456 -0.22498184]]
hahahahahahah
265 [[ 0.99985184  1.          0.09864848 -0.12862423 -0.42390704  0.19265295]
 [ 0.99985184  0.99904822  0.05628571 -0.07267366  0.72183582 -0.12387777]
 [ 0.99985184  0.9961947   0.00181929 -0.00261921  0.68589095 -0.18441712]
 [ 0.99985184  0.99144486  0.08351892  0.01070973  0.68420603 -0.13372521]
 [ 0.99985184  0.98480775 -0.02843983 -0.09251209  0.68027456 -0.22498184]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.09864848 -0.12862423 -0.42390704  0.19265295]
 [ 0.99985184  0.99904822  0.05628571 -0.07267366  0.72183582 -0.12387777]
 [ 0.99985184  0.9961947   0.00181929 -0.00261921  0.68589095 -0.18441712]
 [ 0.99985184  0.99144486  0.08351892  0.01070973  0.68420603 -0.13372521]
 [ 0.99985184  0.98480775 -0.02843983 -0.09251209  0.68027456 -0.22498184]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 3.3845255374908447
lalalalalal
260 [[ 1.         -0.37944564  0.01148467 -1.20711214 -0.2681483 ]
 [ 0.99904822 -0.35523834 -0.00478904 -1.20570805 -0.25284561]
 [ 0.9961947  -0.26748689  0.08510384 -1.2152559  -0.17543693]
 [ 0.99144486 -0.20696865 -0.24532998 -1.22705032 -0.14564284]
 [ 0.98480775 -0.1222431  -0.01749803 -1.23772145  0.01429406]]
hahahahahahah
265 [[-0.84754092  1.         -0.37944564  0.01148467 -1.20711214 -0.2681483 ]
 [-0.84754092  0.99904822 -0.35523834 -0.00478904 -1.20570805 -0.25284561]
 [-0.84754092  0.9961947  -0.26748689  0.08510384 -1.2152559  -0.17543693]
 [-0.84754092  0.99144486 -0.20696865 -0.24532998 -1.22705032 -0.14564284]
 [-0.84754092  0.98480775 -0.1222431  -0.01749803 -1.23772145  0.01429406]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.37944564  0.01148467 -1.20711214 -0.2681483 ]
 [-0.84754092  0.99904822 -0.35523834 -0.00478904 -1.20570805 -0.25284561]
 [-0.84754092  0.9961947  -0.26748689  0.08510384 -1.2152559  -0.17543693]
 [-0.84754092  0.99144486 -0.20696865 -0.24532998 -1.22705032 -0.14564284]
 [-0.84754092  0.98480775 -0.1222431  -0.01749803 -1.23772145  0.01429406]]

Epoch: 0, 
Train Loss: 0.9621015882291714, 
Validation Loss: 0.7570430533960462
Elapsed time for epoch-0: 4.332026481628418
common line69: model saved with val loss 0.7570430533960462

Epoch: 1, 
Train Loss: 0.8912038255889877, 
Validation Loss: 0.753201394341886
Elapsed time for epoch-1: 3.7125113010406494
common line69: model saved with val loss 0.753201394341886

Epoch: 2, 
Train Loss: 0.8798269245053539, 
Validation Loss: 0.7587442770600319
Elapsed time for epoch-2: 3.5228724479675293

Epoch: 3, 
Train Loss: 0.8720641575691079, 
Validation Loss: 0.7711350470781326
Elapsed time for epoch-3: 3.7915055751800537

Epoch: 4, 
Train Loss: 0.8666769656814447, 
Validation Loss: 0.7674563219770789
Elapsed time for epoch-4: 4.206829309463501

Epoch: 5, 
Train Loss: 0.8634229644256479, 
Validation Loss: 0.7784641440957785
Elapsed time for epoch-5: 3.4020469188690186

Epoch: 6, 
Train Loss: 0.860781501070792, 
Validation Loss: 0.773383978754282
Elapsed time for epoch-6: 3.5638670921325684

Epoch: 7, 
Train Loss: 0.8584190206367428, 
Validation Loss: 0.7651165062561631
Elapsed time for epoch-7: 3.2859485149383545

Epoch: 8, 
Train Loss: 0.8569261956365168, 
Validation Loss: 0.7712279185652733
Elapsed time for epoch-8: 3.6983096599578857

Epoch: 9, 
Train Loss: 0.8551398223939062, 
Validation Loss: 0.7652678210288286
Elapsed time for epoch-9: 3.3244354724884033

Epoch: 10, 
Train Loss: 0.8540977937083284, 
Validation Loss: 0.767813847400248
Elapsed time for epoch-10: 3.4189517498016357

Epoch: 11, 
Train Loss: 0.8525591063148835, 
Validation Loss: 0.7776905773207545
Elapsed time for epoch-11: 3.303525686264038

Epoch: 12, 
Train Loss: 0.8515752114418174, 
Validation Loss: 0.7784670675173402
Elapsed time for epoch-12: 3.407285213470459

Epoch: 13, 
Train Loss: 0.8503988941176599, 
Validation Loss: 0.7765999594703317
Elapsed time for epoch-13: 4.149919033050537
Early stopped! 

train line101: min loss for the epoch 13 is 0.753201394341886

Training the 98-th turbine in 136.8142647743225 secs

>>>>>>>>> Training Turbine  99 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir  ...  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  ...   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  ...   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  ...   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  ...   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.775761604309082
lalalalalal
260 [[ 1.          0.16287051 -0.07355422 -0.47131537  0.10690442]
 [ 0.99904822  0.08953457 -0.13420572  0.45185445 -0.14273501]
 [ 0.9961947   0.01769527 -0.00171458  0.45006246 -0.16995988]
 [ 0.99144486  0.08953457  0.00623489  0.44110255 -0.09255637]
 [ 0.98480775 -0.02421098 -0.0732598   0.43393462 -0.20569942]]
hahahahahahah
265 [[ 0.99985184  1.          0.16287051 -0.07355422 -0.47131537  0.10690442]
 [ 0.99985184  0.99904822  0.08953457 -0.13420572  0.45185445 -0.14273501]
 [ 0.99985184  0.9961947   0.01769527 -0.00171458  0.45006246 -0.16995988]
 [ 0.99985184  0.99144486  0.08953457  0.00623489  0.44110255 -0.09255637]
 [ 0.99985184  0.98480775 -0.02421098 -0.0732598   0.43393462 -0.20569942]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.16287051 -0.07355422 -0.47131537  0.10690442]
 [ 0.99985184  0.99904822  0.08953457 -0.13420572  0.45185445 -0.14273501]
 [ 0.99985184  0.9961947   0.01769527 -0.00171458  0.45006246 -0.16995988]
 [ 0.99985184  0.99144486  0.08953457  0.00623489  0.44110255 -0.09255637]
 [ 0.99985184  0.98480775 -0.02421098 -0.0732598   0.43393462 -0.20569942]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0 -0.23  509.36
wind turbine line234: Elapsed time for processing time stamp 2.84917950630188
lalalalalal
260 [[ 1.         -0.30857486  0.06541427 -1.46676183 -0.23331007]
 [ 0.99904822 -0.2666686   0.1098724  -1.46915114 -0.16194122]
 [ 0.9961947  -0.29660164  0.06747524 -1.4769164  -0.24460784]
 [ 0.99144486 -0.21278913 -0.23195474 -1.47631907 -0.1912052 ]
 [ 0.98480775 -0.11999671 -0.24903138 -1.47930571 -0.1128648 ]]
hahahahahahah
265 [[-0.84754092  1.         -0.30857486  0.06541427 -1.46676183 -0.23331007]
 [-0.84754092  0.99904822 -0.2666686   0.1098724  -1.46915114 -0.16194122]
 [-0.84754092  0.9961947  -0.29660164  0.06747524 -1.4769164  -0.24460784]
 [-0.84754092  0.99144486 -0.21278913 -0.23195474 -1.47631907 -0.1912052 ]
 [-0.84754092  0.98480775 -0.11999671 -0.24903138 -1.47930571 -0.1128648 ]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.30857486  0.06541427 -1.46676183 -0.23331007]
 [-0.84754092  0.99904822 -0.2666686   0.1098724  -1.46915114 -0.16194122]
 [-0.84754092  0.9961947  -0.29660164  0.06747524 -1.4769164  -0.24460784]
 [-0.84754092  0.99144486 -0.21278913 -0.23195474 -1.47631907 -0.1912052 ]
 [-0.84754092  0.98480775 -0.11999671 -0.24903138 -1.47930571 -0.1128648 ]]

Epoch: 0, 
Train Loss: 1.0097709161644222, 
Validation Loss: 0.7978917276486754
Elapsed time for epoch-0: 3.0663602352142334
common line69: model saved with val loss 0.7978917276486754

Epoch: 1, 
Train Loss: 0.9687095745270994, 
Validation Loss: 0.7332262555137277
Elapsed time for epoch-1: 3.171699285507202
common line69: model saved with val loss 0.7332262555137277

Epoch: 2, 
Train Loss: 0.9395706518357542, 
Validation Loss: 0.7155989911407232
Elapsed time for epoch-2: 3.316699266433716
common line69: model saved with val loss 0.7155989911407232

Epoch: 3, 
Train Loss: 0.9322237333580226, 
Validation Loss: 0.712825077585876
Elapsed time for epoch-3: 3.00600528717041
common line69: model saved with val loss 0.712825077585876

Epoch: 4, 
Train Loss: 0.9280834911751146, 
Validation Loss: 0.7178571131080389
Elapsed time for epoch-4: 3.4799842834472656

Epoch: 5, 
Train Loss: 0.9248433006661279, 
Validation Loss: 0.7121356762945652
Elapsed time for epoch-5: 3.52995228767395
common line69: model saved with val loss 0.7121356762945652

Epoch: 6, 
Train Loss: 0.9223648213288363, 
Validation Loss: 0.7134600076824427
Elapsed time for epoch-6: 3.5603833198547363

Epoch: 7, 
Train Loss: 0.9208089923407851, 
Validation Loss: 0.7093595005571842
Elapsed time for epoch-7: 3.463408946990967
common line69: model saved with val loss 0.7093595005571842

Epoch: 8, 
Train Loss: 0.9193137682536069, 
Validation Loss: 0.7135361470282078
Elapsed time for epoch-8: 3.4115607738494873

Epoch: 9, 
Train Loss: 0.9182040642539994, 
Validation Loss: 0.7155165486037731
Elapsed time for epoch-9: 3.586050271987915

Epoch: 10, 
Train Loss: 0.917282928939627, 
Validation Loss: 0.7122226813808084
Elapsed time for epoch-10: 3.349813461303711

Epoch: 11, 
Train Loss: 0.9165147720765667, 
Validation Loss: 0.7095480551943183
Elapsed time for epoch-11: 3.546905279159546

Epoch: 12, 
Train Loss: 0.9157384402361237, 
Validation Loss: 0.7164139170199633
Elapsed time for epoch-12: 4.213993787765503

Epoch: 13, 
Train Loss: 0.9152528032535264, 
Validation Loss: 0.7142510339617729
Elapsed time for epoch-13: 3.5766119956970215

Epoch: 14, 
Train Loss: 0.9146280016969232, 
Validation Loss: 0.7075062822550535
Elapsed time for epoch-14: 3.4817004203796387
common line69: model saved with val loss 0.7075062822550535

Epoch: 15, 
Train Loss: 0.913986048778566, 
Validation Loss: 0.7049435926601291
Elapsed time for epoch-15: 3.4363908767700195
common line69: model saved with val loss 0.7049435926601291

Epoch: 16, 
Train Loss: 0.9135286637714931, 
Validation Loss: 0.7137217707931995
Elapsed time for epoch-16: 3.650360345840454

Epoch: 17, 
Train Loss: 0.9133275792378337, 
Validation Loss: 0.7105322359129786
Elapsed time for epoch-17: 3.854829788208008

Epoch: 18, 
Train Loss: 0.9128365824703409, 
Validation Loss: 0.7089401939883828
Elapsed time for epoch-18: 4.247347593307495

Epoch: 19, 
Train Loss: 0.912435747870878, 
Validation Loss: 0.7104643657803535
Elapsed time for epoch-19: 3.7060394287109375

Epoch: 20, 
Train Loss: 0.9123704330760891, 
Validation Loss: 0.7100373534485698
Elapsed time for epoch-20: 3.195892572402954

Epoch: 21, 
Train Loss: 0.9120588454128313, 
Validation Loss: 0.7123178243637085
Elapsed time for epoch-21: 3.5711286067962646

Epoch: 22, 
Train Loss: 0.9118633394231316, 
Validation Loss: 0.7130120676010847
Elapsed time for epoch-22: 3.5115108489990234

Epoch: 23, 
Train Loss: 0.9116485060012641, 
Validation Loss: 0.7123834118247032
Elapsed time for epoch-23: 3.445673942565918

Epoch: 24, 
Train Loss: 0.9112802134091113, 
Validation Loss: 0.7073786444962025
Elapsed time for epoch-24: 3.6812305450439453

Epoch: 25, 
Train Loss: 0.9110579186377405, 
Validation Loss: 0.7108996585011482
Elapsed time for epoch-25: 4.018417119979858

Epoch: 26, 
Train Loss: 0.910683999291989, 
Validation Loss: 0.7107603037729859
Elapsed time for epoch-26: 3.436168909072876

Epoch: 27, 
Train Loss: 0.910479088165179, 
Validation Loss: 0.7072803610935807
Elapsed time for epoch-27: 3.3714399337768555
Early stopped! 

train line101: min loss for the epoch 27 is 0.7049435926601291

Training the 99-th turbine in 176.1491756439209 secs

>>>>>>>>> Training Turbine 100 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp  ...   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN  ...    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  ...  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  ...  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  ...  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  ...  20.91   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.7663371562957764
lalalalalal
260 [[ 1.          0.01992908 -0.11270675 -1.38073228  0.11039536]
 [ 0.99904822  0.16398835 -0.10379259  0.11711122  0.148288  ]
 [ 0.9961947   0.13752848 -0.10346843  0.12189448  0.05512311]
 [ 0.99144486  0.19632819 -0.10152353  0.12189448  0.14894766]
 [ 0.98480775  0.10518865 -0.19617571  0.12189448 -0.07275027]]
hahahahahahah
265 [[ 0.99985184  1.          0.01992908 -0.11270675 -1.38073228  0.11039536]
 [ 0.99985184  0.99904822  0.16398835 -0.10379259  0.11711122  0.148288  ]
 [ 0.99985184  0.9961947   0.13752848 -0.10346843  0.12189448  0.05512311]
 [ 0.99985184  0.99144486  0.19632819 -0.10152353  0.12189448  0.14894766]
 [ 0.99985184  0.98480775  0.10518865 -0.19617571  0.12189448 -0.07275027]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.01992908 -0.11270675 -1.38073228  0.11039536]
 [ 0.99985184  0.99904822  0.16398835 -0.10379259  0.11711122  0.148288  ]
 [ 0.99985184  0.9961947   0.13752848 -0.10346843  0.12189448  0.05512311]
 [ 0.99985184  0.99144486  0.19632819 -0.10152353  0.12189448  0.14894766]
 [ 0.99985184  0.98480775  0.10518865 -0.19617571  0.12189448 -0.07275027]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp  ...   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN  ...    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  ...  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  ...  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  ...  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  ...  20.91   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.8830502033233643
lalalalalal
260 [[ 1.         -0.29317935  0.06039005 -0.59012784 -0.17357742]
 [ 0.99904822 -0.08591039  0.22295193 -0.5949111   0.06433304]
 [ 0.9961947  -0.10061032 -0.08726087 -0.5949111   0.01561937]
 [ 0.99144486 -0.20938977 -0.23961198 -0.5949111  -0.15439641]
 [ 0.98480775 -0.10649029 -0.25419879 -0.59627775 -0.05189473]]
hahahahahahah
265 [[-0.84754092  1.         -0.29317935  0.06039005 -0.59012784 -0.17357742]
 [-0.84754092  0.99904822 -0.08591039  0.22295193 -0.5949111   0.06433304]
 [-0.84754092  0.9961947  -0.10061032 -0.08726087 -0.5949111   0.01561937]
 [-0.84754092  0.99144486 -0.20938977 -0.23961198 -0.5949111  -0.15439641]
 [-0.84754092  0.98480775 -0.10649029 -0.25419879 -0.59627775 -0.05189473]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.29317935  0.06039005 -0.59012784 -0.17357742]
 [-0.84754092  0.99904822 -0.08591039  0.22295193 -0.5949111   0.06433304]
 [-0.84754092  0.9961947  -0.10061032 -0.08726087 -0.5949111   0.01561937]
 [-0.84754092  0.99144486 -0.20938977 -0.23961198 -0.5949111  -0.15439641]
 [-0.84754092  0.98480775 -0.10649029 -0.25419879 -0.59627775 -0.05189473]]

Epoch: 0, 
Train Loss: 1.008981746660561, 
Validation Loss: 0.8025433840230107
Elapsed time for epoch-0: 3.0686566829681396
common line69: model saved with val loss 0.8025433840230107

Epoch: 1, 
Train Loss: 0.9733850579051411, 
Validation Loss: 0.726142100058496
Elapsed time for epoch-1: 2.9899022579193115
common line69: model saved with val loss 0.726142100058496

Epoch: 2, 
Train Loss: 0.9435902886530932, 
Validation Loss: 0.720491805113852
Elapsed time for epoch-2: 3.0726757049560547
common line69: model saved with val loss 0.720491805113852

Epoch: 3, 
Train Loss: 0.9361816789923596, 
Validation Loss: 0.7126018069684505
Elapsed time for epoch-3: 2.8237082958221436
common line69: model saved with val loss 0.7126018069684505

Epoch: 4, 
Train Loss: 0.9315984319238102, 
Validation Loss: 0.7095004292204976
Elapsed time for epoch-4: 3.0467889308929443
common line69: model saved with val loss 0.7095004292204976

Epoch: 5, 
Train Loss: 0.9285666766036459, 
Validation Loss: 0.7115100082010031
Elapsed time for epoch-5: 3.026505470275879

Epoch: 6, 
Train Loss: 0.9263947947936899, 
Validation Loss: 0.7135503739118576
Elapsed time for epoch-6: 2.8007161617279053

Epoch: 7, 
Train Loss: 0.9247570128000083, 
Validation Loss: 0.7026629811152816
Elapsed time for epoch-7: 3.2625913619995117
common line69: model saved with val loss 0.7026629811152816

Epoch: 8, 
Train Loss: 0.9235488032343007, 
Validation Loss: 0.7053970582783222
Elapsed time for epoch-8: 3.0688934326171875

Epoch: 9, 
Train Loss: 0.9222878380482938, 
Validation Loss: 0.7082093795761466
Elapsed time for epoch-9: 2.9830052852630615

Epoch: 10, 
Train Loss: 0.9212982955099154, 
Validation Loss: 0.7036385526880622
Elapsed time for epoch-10: 3.9218573570251465

Epoch: 11, 
Train Loss: 0.9201286739411474, 
Validation Loss: 0.7033629771322012
Elapsed time for epoch-11: 3.2951602935791016

Epoch: 12, 
Train Loss: 0.919812288980524, 
Validation Loss: 0.7031161282211542
Elapsed time for epoch-12: 3.432835817337036

Epoch: 13, 
Train Loss: 0.9189763988266472, 
Validation Loss: 0.7084841579198837
Elapsed time for epoch-13: 3.323478937149048

Epoch: 14, 
Train Loss: 0.9185898495571954, 
Validation Loss: 0.6984993787482381
Elapsed time for epoch-14: 3.5145211219787598
common line69: model saved with val loss 0.6984993787482381

Epoch: 15, 
Train Loss: 0.9180302333180644, 
Validation Loss: 0.6983552416786551
Elapsed time for epoch-15: 3.4439632892608643
common line69: model saved with val loss 0.6983552416786551

Epoch: 16, 
Train Loss: 0.9174963588975057, 
Validation Loss: 0.7011937201023102
Elapsed time for epoch-16: 3.802304744720459

Epoch: 17, 
Train Loss: 0.9170696087995497, 
Validation Loss: 0.6991997268050909
Elapsed time for epoch-17: 3.607577085494995

Epoch: 18, 
Train Loss: 0.9166036402227498, 
Validation Loss: 0.6995199862867594
Elapsed time for epoch-18: 3.3432676792144775

Epoch: 19, 
Train Loss: 0.9162907395042291, 
Validation Loss: 0.7003117734566331
Elapsed time for epoch-19: 3.915403127670288

Epoch: 20, 
Train Loss: 0.915866711309978, 
Validation Loss: 0.6959960460662842
Elapsed time for epoch-20: 3.3522865772247314
common line69: model saved with val loss 0.6959960460662842

Epoch: 21, 
Train Loss: 0.9158095686125154, 
Validation Loss: 0.704396347515285
Elapsed time for epoch-21: 3.523751735687256

Epoch: 22, 
Train Loss: 0.9153435739899883, 
Validation Loss: 0.7018606141209602
Elapsed time for epoch-22: 3.8027503490448

Epoch: 23, 
Train Loss: 0.9152186278785978, 
Validation Loss: 0.6947838310152292
Elapsed time for epoch-23: 3.490072011947632
common line69: model saved with val loss 0.6947838310152292

Epoch: 24, 
Train Loss: 0.9146624588164962, 
Validation Loss: 0.7003125306218863
Elapsed time for epoch-24: 3.6690163612365723

Epoch: 25, 
Train Loss: 0.9144009009880179, 
Validation Loss: 0.6958287041634321
Elapsed time for epoch-25: 3.760540723800659

Epoch: 26, 
Train Loss: 0.9142638930753499, 
Validation Loss: 0.7001343164592981
Elapsed time for epoch-26: 3.646562099456787

Epoch: 27, 
Train Loss: 0.9142058750911921, 
Validation Loss: 0.6939532151445746
Elapsed time for epoch-27: 3.5694291591644287
common line69: model saved with val loss 0.6939532151445746

Epoch: 28, 
Train Loss: 0.9138292087977674, 
Validation Loss: 0.700242355465889
Elapsed time for epoch-28: 3.7299108505249023

Epoch: 29, 
Train Loss: 0.9136232702421541, 
Validation Loss: 0.6948746973648667
Elapsed time for epoch-29: 3.776099920272827

Epoch: 30, 
Train Loss: 0.9134110668126274, 
Validation Loss: 0.694982560351491
Elapsed time for epoch-30: 4.177505731582642

Epoch: 31, 
Train Loss: 0.9131716194273043, 
Validation Loss: 0.698626141063869
Elapsed time for epoch-31: 3.8412210941314697

train line101: min loss for the epoch 31 is 0.6939532151445746

Training the 100-th turbine in 191.6677975654602 secs

>>>>>>>>> Training Turbine 101 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp  ...   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN  ...    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  ...  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  ...  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  ...  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  ...  20.91   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.67537260055542
lalalalalal
260 [[ 1.          0.22250742 -0.18056974  0.58137498  0.16413451]
 [ 0.99904822  0.30520619 -0.28644691  0.45420877 -0.10112515]
 [ 0.9961947   0.20989236 -0.23059633  0.44819619 -0.13837473]
 [ 0.99144486  0.18466223  0.00146732  0.44037982 -0.06313344]
 [ 0.98480775  0.03608478 -0.09768986  0.43256346 -0.188767  ]]
hahahahahahah
265 [[ 0.99985184  1.          0.22250742 -0.18056974  0.58137498  0.16413451]
 [ 0.99985184  0.99904822  0.30520619 -0.28644691  0.45420877 -0.10112515]
 [ 0.99985184  0.9961947   0.20989236 -0.23059633  0.44819619 -0.13837473]
 [ 0.99985184  0.99144486  0.18466223  0.00146732  0.44037982 -0.06313344]
 [ 0.99985184  0.98480775  0.03608478 -0.09768986  0.43256346 -0.188767  ]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.22250742 -0.18056974  0.58137498  0.16413451]
 [ 0.99985184  0.99904822  0.30520619 -0.28644691  0.45420877 -0.10112515]
 [ 0.99985184  0.9961947   0.20989236 -0.23059633  0.44819619 -0.13837473]
 [ 0.99985184  0.99144486  0.18466223  0.00146732  0.44037982 -0.06313344]
 [ 0.99985184  0.98480775  0.03608478 -0.09768986  0.43256346 -0.188767  ]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp  ...   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN  ...    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  ...  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  ...  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  ...  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  ...  20.91   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.849954605102539
lalalalalal
260 [[ 1.         -0.34376888  0.03805393 -0.95724595 -0.35762301]
 [ 0.99904822 -0.28349689  0.18813371 -0.95454029 -0.32244417]
 [ 0.9961947  -0.28349689  0.06120057 -0.9587491  -0.31665086]
 [ 0.99144486 -0.28910359 -0.21148169 -0.99602714 -0.19630789]
 [ 0.98480775 -0.12090271 -0.15891644 -1.00745105 -0.08309884]]
hahahahahahah
265 [[-0.84754092  1.         -0.34376888  0.03805393 -0.95724595 -0.35762301]
 [-0.84754092  0.99904822 -0.28349689  0.18813371 -0.95454029 -0.32244417]
 [-0.84754092  0.9961947  -0.28349689  0.06120057 -0.9587491  -0.31665086]
 [-0.84754092  0.99144486 -0.28910359 -0.21148169 -0.99602714 -0.19630789]
 [-0.84754092  0.98480775 -0.12090271 -0.15891644 -1.00745105 -0.08309884]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.34376888  0.03805393 -0.95724595 -0.35762301]
 [-0.84754092  0.99904822 -0.28349689  0.18813371 -0.95454029 -0.32244417]
 [-0.84754092  0.9961947  -0.28349689  0.06120057 -0.9587491  -0.31665086]
 [-0.84754092  0.99144486 -0.28910359 -0.21148169 -0.99602714 -0.19630789]
 [-0.84754092  0.98480775 -0.12090271 -0.15891644 -1.00745105 -0.08309884]]

Epoch: 0, 
Train Loss: 0.9916366160917682, 
Validation Loss: 0.6927097635343671
Elapsed time for epoch-0: 3.020935297012329
common line69: model saved with val loss 0.6927097635343671

Epoch: 1, 
Train Loss: 0.9500380815828547, 
Validation Loss: 0.6633576778694987
Elapsed time for epoch-1: 3.16709303855896
common line69: model saved with val loss 0.6633576778694987

Epoch: 2, 
Train Loss: 0.9391968056183904, 
Validation Loss: 0.6582657238468528
Elapsed time for epoch-2: 3.128725290298462
common line69: model saved with val loss 0.6582657238468528

Epoch: 3, 
Train Loss: 0.9337783310593677, 
Validation Loss: 0.655814946629107
Elapsed time for epoch-3: 2.939216136932373
common line69: model saved with val loss 0.655814946629107

Epoch: 4, 
Train Loss: 0.9298471351381109, 
Validation Loss: 0.653182459063828
Elapsed time for epoch-4: 3.2218234539031982
common line69: model saved with val loss 0.653182459063828

Epoch: 5, 
Train Loss: 0.9271974601164585, 
Validation Loss: 0.6526471544057131
Elapsed time for epoch-5: 2.942315101623535
common line69: model saved with val loss 0.6526471544057131

Epoch: 6, 
Train Loss: 0.9249721904512213, 
Validation Loss: 0.6483365260064602
Elapsed time for epoch-6: 3.1627793312072754
common line69: model saved with val loss 0.6483365260064602

Epoch: 7, 
Train Loss: 0.923295639768368, 
Validation Loss: 0.6427701087668538
Elapsed time for epoch-7: 3.050929546356201
common line69: model saved with val loss 0.6427701087668538

Epoch: 8, 
Train Loss: 0.9220153865944437, 
Validation Loss: 0.6470574839040637
Elapsed time for epoch-8: 3.0224459171295166

Epoch: 9, 
Train Loss: 0.9209528670591467, 
Validation Loss: 0.641669100150466
Elapsed time for epoch-9: 3.1500699520111084
common line69: model saved with val loss 0.641669100150466

Epoch: 10, 
Train Loss: 0.9200741810207608, 
Validation Loss: 0.6437829826027155
Elapsed time for epoch-10: 2.9489409923553467

Epoch: 11, 
Train Loss: 0.9191775151661464, 
Validation Loss: 0.6396173993125558
Elapsed time for epoch-11: 3.299381971359253
common line69: model saved with val loss 0.6396173993125558

Epoch: 12, 
Train Loss: 0.9186191601412637, 
Validation Loss: 0.6383132408373058
Elapsed time for epoch-12: 3.6484498977661133
common line69: model saved with val loss 0.6383132408373058

Epoch: 13, 
Train Loss: 0.9177807086155194, 
Validation Loss: 0.641384806483984
Elapsed time for epoch-13: 3.429781436920166

Epoch: 14, 
Train Loss: 0.9174846924152695, 
Validation Loss: 0.6397945219650865
Elapsed time for epoch-14: 3.619467258453369

Epoch: 15, 
Train Loss: 0.9166799105015122, 
Validation Loss: 0.6382495062425733
Elapsed time for epoch-15: 3.369786262512207
common line69: model saved with val loss 0.6382495062425733

Epoch: 16, 
Train Loss: 0.9161200215335653, 
Validation Loss: 0.6377654150128365
Elapsed time for epoch-16: 3.685889720916748
common line69: model saved with val loss 0.6377654150128365

Epoch: 17, 
Train Loss: 0.9160658035959516, 
Validation Loss: 0.6414164351299405
Elapsed time for epoch-17: 3.580244302749634

Epoch: 18, 
Train Loss: 0.9156809226304543, 
Validation Loss: 0.637288112193346
Elapsed time for epoch-18: 3.9033970832824707
common line69: model saved with val loss 0.637288112193346

Epoch: 19, 
Train Loss: 0.9149148792278867, 
Validation Loss: 0.6393664181232452
Elapsed time for epoch-19: 3.683572769165039

Epoch: 20, 
Train Loss: 0.9150669669904629, 
Validation Loss: 0.6385570494458079
Elapsed time for epoch-20: 3.4607887268066406

Epoch: 21, 
Train Loss: 0.914619262103273, 
Validation Loss: 0.6412129923701286
Elapsed time for epoch-21: 3.4967188835144043

Epoch: 22, 
Train Loss: 0.9144729084077001, 
Validation Loss: 0.6374978851526976
Elapsed time for epoch-22: 3.641268730163574

Epoch: 23, 
Train Loss: 0.9138656594172245, 
Validation Loss: 0.6343592125922441
Elapsed time for epoch-23: 3.484344005584717
common line69: model saved with val loss 0.6343592125922441

Epoch: 24, 
Train Loss: 0.9137176822464005, 
Validation Loss: 0.634264700114727
Elapsed time for epoch-24: 3.86484694480896
common line69: model saved with val loss 0.634264700114727

Epoch: 25, 
Train Loss: 0.9132599416149765, 
Validation Loss: 0.6388389058411121
Elapsed time for epoch-25: 3.6779708862304688

Epoch: 26, 
Train Loss: 0.9132394879555502, 
Validation Loss: 0.6322092181071639
Elapsed time for epoch-26: 3.3433070182800293
common line69: model saved with val loss 0.6322092181071639

Epoch: 27, 
Train Loss: 0.9128382611675423, 
Validation Loss: 0.6355818412266672
Elapsed time for epoch-27: 3.5834527015686035

Epoch: 28, 
Train Loss: 0.9127530275272722, 
Validation Loss: 0.6362263914197683
Elapsed time for epoch-28: 3.4519174098968506

Epoch: 29, 
Train Loss: 0.9125694136659638, 
Validation Loss: 0.6357713993638754
Elapsed time for epoch-29: 3.6584415435791016

Epoch: 30, 
Train Loss: 0.9122589964325688, 
Validation Loss: 0.6361353201791644
Elapsed time for epoch-30: 3.9295132160186768

Epoch: 31, 
Train Loss: 0.9121398040476967, 
Validation Loss: 0.6341947000473738
Elapsed time for epoch-31: 4.170120000839233

train line101: min loss for the epoch 31 is 0.6322092181071639

Training the 101-th turbine in 193.88159584999084 secs

>>>>>>>>> Training Turbine 102 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp  ...   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN  ...    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  ...  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  ...  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  ...  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  ...  20.91   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.6779682636260986
lalalalalal
260 [[ 1.          0.26165146 -0.08090287 -0.51620587  0.27309779]
 [ 0.99904822  0.2220958   0.04396191  0.49776005  0.08028858]
 [ 0.9961947   0.12833423  0.01963944  0.4947778  -0.01947292]
 [ 0.99144486  0.18107511  0.04452755  0.48806773  0.02720848]
 [ 0.98480775  0.00527217 -0.12968922  0.47315646 -0.13455251]]
hahahahahahah
265 [[ 0.99985184  1.          0.26165146 -0.08090287 -0.51620587  0.27309779]
 [ 0.99985184  0.99904822  0.2220958   0.04396191  0.49776005  0.08028858]
 [ 0.99985184  0.9961947   0.12833423  0.01963944  0.4947778  -0.01947292]
 [ 0.99985184  0.99144486  0.18107511  0.04452755  0.48806773  0.02720848]
 [ 0.99985184  0.98480775  0.00527217 -0.12968922  0.47315646 -0.13455251]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.26165146 -0.08090287 -0.51620587  0.27309779]
 [ 0.99985184  0.99904822  0.2220958   0.04396191  0.49776005  0.08028858]
 [ 0.99985184  0.9961947   0.12833423  0.01963944  0.4947778  -0.01947292]
 [ 0.99985184  0.99144486  0.18107511  0.04452755  0.48806773  0.02720848]
 [ 0.99985184  0.98480775  0.00527217 -0.12968922  0.47315646 -0.13455251]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp  ...   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN  ...    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  ...  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  ...  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  ...  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  ...  20.91   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.603731155395508
lalalalalal
260 [[ 1.         -0.44302534  0.01440728 -1.58608902 -0.37389771]
 [ 0.99904822 -0.37856426  0.16783682 -1.56744994 -0.31989658]
 [ 0.9961947  -0.35805392  0.01115486 -1.62262161 -0.35542874]
 [ 0.99144486 -0.30531303 -0.2153835  -1.64275182 -0.24289408]
 [ 0.98480775 -0.17346082 -0.25299849 -1.62784055 -0.10684907]]
hahahahahahah
265 [[-0.84754092  1.         -0.44302534  0.01440728 -1.58608902 -0.37389771]
 [-0.84754092  0.99904822 -0.37856426  0.16783682 -1.56744994 -0.31989658]
 [-0.84754092  0.9961947  -0.35805392  0.01115486 -1.62262161 -0.35542874]
 [-0.84754092  0.99144486 -0.30531303 -0.2153835  -1.64275182 -0.24289408]
 [-0.84754092  0.98480775 -0.17346082 -0.25299849 -1.62784055 -0.10684907]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.44302534  0.01440728 -1.58608902 -0.37389771]
 [-0.84754092  0.99904822 -0.37856426  0.16783682 -1.56744994 -0.31989658]
 [-0.84754092  0.9961947  -0.35805392  0.01115486 -1.62262161 -0.35542874]
 [-0.84754092  0.99144486 -0.30531303 -0.2153835  -1.64275182 -0.24289408]
 [-0.84754092  0.98480775 -0.17346082 -0.25299849 -1.62784055 -0.10684907]]

Epoch: 0, 
Train Loss: 1.00354368383644, 
Validation Loss: 0.6204829812049866
Elapsed time for epoch-0: 3.194077253341675
common line69: model saved with val loss 0.6204829812049866

Epoch: 1, 
Train Loss: 0.9594013898813424, 
Validation Loss: 0.6160278953611851
Elapsed time for epoch-1: 3.443005323410034
common line69: model saved with val loss 0.6160278953611851

Epoch: 2, 
Train Loss: 0.9483748772064177, 
Validation Loss: 0.6129356771707535
Elapsed time for epoch-2: 3.539731502532959
common line69: model saved with val loss 0.6129356771707535

Epoch: 3, 
Train Loss: 0.9424897223210135, 
Validation Loss: 0.6117566195316613
Elapsed time for epoch-3: 3.622182607650757
common line69: model saved with val loss 0.6117566195316613

Epoch: 4, 
Train Loss: 0.9387615464565133, 
Validation Loss: 0.6043258514255285
Elapsed time for epoch-4: 3.359060525894165
common line69: model saved with val loss 0.6043258514255285

Epoch: 5, 
Train Loss: 0.9365461788007191, 
Validation Loss: 0.59958870196715
Elapsed time for epoch-5: 3.735581398010254
common line69: model saved with val loss 0.59958870196715

Epoch: 6, 
Train Loss: 0.9339899602306991, 
Validation Loss: 0.6019771853461862
Elapsed time for epoch-6: 3.371612071990967

Epoch: 7, 
Train Loss: 0.9323472458274424, 
Validation Loss: 0.6001257123425603
Elapsed time for epoch-7: 3.5379674434661865

Epoch: 8, 
Train Loss: 0.930979750486983, 
Validation Loss: 0.6019146516919136
Elapsed time for epoch-8: 3.4313647747039795

Epoch: 9, 
Train Loss: 0.9292682106254482, 
Validation Loss: 0.5993651328608394
Elapsed time for epoch-9: 3.48319149017334
common line69: model saved with val loss 0.5993651328608394

Epoch: 10, 
Train Loss: 0.9285841567927048, 
Validation Loss: 0.6034019598737359
Elapsed time for epoch-10: 3.643338680267334

Epoch: 11, 
Train Loss: 0.9276498573667863, 
Validation Loss: 0.5957331424579024
Elapsed time for epoch-11: 3.376082181930542
common line69: model saved with val loss 0.5957331424579024

Epoch: 12, 
Train Loss: 0.9265896724302227, 
Validation Loss: 0.5926405601203442
Elapsed time for epoch-12: 3.49155330657959
common line69: model saved with val loss 0.5926405601203442

Epoch: 13, 
Train Loss: 0.9259581090021534, 
Validation Loss: 0.5989235122688115
Elapsed time for epoch-13: 3.3366305828094482

Epoch: 14, 
Train Loss: 0.9254122516688179, 
Validation Loss: 0.5928491903468966
Elapsed time for epoch-14: 3.4456820487976074

Epoch: 15, 
Train Loss: 0.9248178647596295, 
Validation Loss: 0.5928196520544589
Elapsed time for epoch-15: 3.465705633163452

Epoch: 16, 
Train Loss: 0.9242735475051302, 
Validation Loss: 0.5956985396333039
Elapsed time for epoch-16: 3.841989755630493

Epoch: 17, 
Train Loss: 0.9236749311705598, 
Validation Loss: 0.5881640114821494
Elapsed time for epoch-17: 3.6097898483276367
common line69: model saved with val loss 0.5881640114821494

Epoch: 18, 
Train Loss: 0.9232884124547494, 
Validation Loss: 0.5935909114778042
Elapsed time for epoch-18: 3.5105996131896973

Epoch: 19, 
Train Loss: 0.9226615529100434, 
Validation Loss: 0.5862870304845273
Elapsed time for epoch-19: 4.0020012855529785
common line69: model saved with val loss 0.5862870304845273

Epoch: 20, 
Train Loss: 0.9225500441398942, 
Validation Loss: 0.585815841332078
Elapsed time for epoch-20: 3.6955409049987793
common line69: model saved with val loss 0.585815841332078

Epoch: 21, 
Train Loss: 0.9222724507836735, 
Validation Loss: 0.5850986526347697
Elapsed time for epoch-21: 3.412754774093628
common line69: model saved with val loss 0.5850986526347697

Epoch: 22, 
Train Loss: 0.9218543171882629, 
Validation Loss: 0.5846701553091407
Elapsed time for epoch-22: 3.309669017791748
common line69: model saved with val loss 0.5846701553091407

Epoch: 23, 
Train Loss: 0.9216028346734888, 
Validation Loss: 0.5814895001240075
Elapsed time for epoch-23: 3.5171587467193604
common line69: model saved with val loss 0.5814895001240075

Epoch: 24, 
Train Loss: 0.921327414883285, 
Validation Loss: 0.57903539435938
Elapsed time for epoch-24: 3.535162925720215
common line69: model saved with val loss 0.57903539435938

Epoch: 25, 
Train Loss: 0.9211135951160383, 
Validation Loss: 0.5799057651311159
Elapsed time for epoch-25: 3.886995792388916

Epoch: 26, 
Train Loss: 0.9208906647287497, 
Validation Loss: 0.5813015061430633
Elapsed time for epoch-26: 3.5788989067077637

Epoch: 27, 
Train Loss: 0.9207109966698814, 
Validation Loss: 0.5794879011809826
Elapsed time for epoch-27: 3.286222457885742

Epoch: 28, 
Train Loss: 0.9203408272827373, 
Validation Loss: 0.5794159602373838
Elapsed time for epoch-28: 3.587510347366333

Epoch: 29, 
Train Loss: 0.9201603291415367, 
Validation Loss: 0.5807759603485465
Elapsed time for epoch-29: 3.4713988304138184

Epoch: 30, 
Train Loss: 0.9200089711601994, 
Validation Loss: 0.5798444906249642
Elapsed time for epoch-30: 3.7546989917755127

Epoch: 31, 
Train Loss: 0.9198709604870371, 
Validation Loss: 0.5748598570935428
Elapsed time for epoch-31: 3.4133596420288086
common line69: model saved with val loss 0.5748598570935428

train line101: min loss for the epoch 31 is 0.5748598570935428

Training the 102-th turbine in 188.84962916374207 secs

>>>>>>>>> Training Turbine 103 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp  ...   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN  ...    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  ...  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  ...  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  ...  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  ...  20.91   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.7047834396362305
lalalalalal
260 [[ 1.          0.30767474 -0.16874455 -0.55302378  0.39853327]
 [ 0.99904822  0.24811634 -0.29843258  0.4973073   0.19177819]
 [ 0.9961947   0.12594525 -0.19617204  0.4973073   0.04145903]
 [ 0.99144486  0.10761959  0.2006801   0.49118491  0.02496294]
 [ 0.98480775 -0.0267686   0.01342819  0.48438224 -0.11721655]]
hahahahahahah
265 [[ 0.99985184  1.          0.30767474 -0.16874455 -0.55302378  0.39853327]
 [ 0.99985184  0.99904822  0.24811634 -0.29843258  0.4973073   0.19177819]
 [ 0.99985184  0.9961947   0.12594525 -0.19617204  0.4973073   0.04145903]
 [ 0.99985184  0.99144486  0.10761959  0.2006801   0.49118491  0.02496294]
 [ 0.99985184  0.98480775 -0.0267686   0.01342819  0.48438224 -0.11721655]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.30767474 -0.16874455 -0.55302378  0.39853327]
 [ 0.99985184  0.99904822  0.24811634 -0.29843258  0.4973073   0.19177819]
 [ 0.99985184  0.9961947   0.12594525 -0.19617204  0.4973073   0.04145903]
 [ 0.99985184  0.99144486  0.10761959  0.2006801   0.49118491  0.02496294]
 [ 0.99985184  0.98480775 -0.0267686   0.01342819  0.48438224 -0.11721655]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp  ...   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN  ...    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  ...  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  ...  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  ...  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  ...  20.91   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.7642087936401367
lalalalalal
260 [[ 1.         -0.50018154 -0.05293957 -1.63328659 -0.41154541]
 [ 0.99904822 -0.40244468 -0.01298347 -1.63804845 -0.35468807]
 [ 0.9961947  -0.34746769 -0.03973374 -1.63872872 -0.30197281]
 [ 0.99144486 -0.38106474 -0.31400869 -1.64893271 -0.29848094]
 [ 0.98480775 -0.24973082 -0.2530587  -1.65777617 -0.18630749]]
hahahahahahah
265 [[-0.84754092  1.         -0.50018154 -0.05293957 -1.63328659 -0.41154541]
 [-0.84754092  0.99904822 -0.40244468 -0.01298347 -1.63804845 -0.35468807]
 [-0.84754092  0.9961947  -0.34746769 -0.03973374 -1.63872872 -0.30197281]
 [-0.84754092  0.99144486 -0.38106474 -0.31400869 -1.64893271 -0.29848094]
 [-0.84754092  0.98480775 -0.24973082 -0.2530587  -1.65777617 -0.18630749]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.50018154 -0.05293957 -1.63328659 -0.41154541]
 [-0.84754092  0.99904822 -0.40244468 -0.01298347 -1.63804845 -0.35468807]
 [-0.84754092  0.9961947  -0.34746769 -0.03973374 -1.63872872 -0.30197281]
 [-0.84754092  0.99144486 -0.38106474 -0.31400869 -1.64893271 -0.29848094]
 [-0.84754092  0.98480775 -0.24973082 -0.2530587  -1.65777617 -0.18630749]]

Epoch: 0, 
Train Loss: 1.0024491515981049, 
Validation Loss: 0.6442154990509152
Elapsed time for epoch-0: 3.218040704727173
common line69: model saved with val loss 0.6442154990509152

Epoch: 1, 
Train Loss: 0.9599585440479407, 
Validation Loss: 0.6016522655263543
Elapsed time for epoch-1: 3.152512550354004
common line69: model saved with val loss 0.6016522655263543

Epoch: 2, 
Train Loss: 0.9475692829915455, 
Validation Loss: 0.599251882173121
Elapsed time for epoch-2: 3.3433432579040527
common line69: model saved with val loss 0.599251882173121

Epoch: 3, 
Train Loss: 0.9417464393778008, 
Validation Loss: 0.5935515500605106
Elapsed time for epoch-3: 3.554675340652466
common line69: model saved with val loss 0.5935515500605106

Epoch: 4, 
Train Loss: 0.936841951824036, 
Validation Loss: 0.5969820427708328
Elapsed time for epoch-4: 3.409409999847412

Epoch: 5, 
Train Loss: 0.9340508770541984, 
Validation Loss: 0.5993652897886932
Elapsed time for epoch-5: 3.421689510345459

Epoch: 6, 
Train Loss: 0.9315296293807631, 
Validation Loss: 0.5944158830679953
Elapsed time for epoch-6: 4.050271987915039

Epoch: 7, 
Train Loss: 0.9298323327753725, 
Validation Loss: 0.5951044983230531
Elapsed time for epoch-7: 3.832845687866211

Epoch: 8, 
Train Loss: 0.9288241836954566, 
Validation Loss: 0.5896739140152931
Elapsed time for epoch-8: 3.608673572540283
common line69: model saved with val loss 0.5896739140152931

Epoch: 9, 
Train Loss: 0.9274357807736436, 
Validation Loss: 0.6000660266727209
Elapsed time for epoch-9: 3.5217931270599365

Epoch: 10, 
Train Loss: 0.9264009752694298, 
Validation Loss: 0.5954988962039351
Elapsed time for epoch-10: 3.604278564453125

Epoch: 11, 
Train Loss: 0.925465973234978, 
Validation Loss: 0.5885051218792796
Elapsed time for epoch-11: 3.6683292388916016
common line69: model saved with val loss 0.5885051218792796

Epoch: 12, 
Train Loss: 0.924659059703851, 
Validation Loss: 0.5912667335942388
Elapsed time for epoch-12: 3.973079204559326

Epoch: 13, 
Train Loss: 0.9237987861162474, 
Validation Loss: 0.589405057951808
Elapsed time for epoch-13: 3.3816614151000977

Epoch: 14, 
Train Loss: 0.9234178676074293, 
Validation Loss: 0.5882496992126107
Elapsed time for epoch-14: 4.140110492706299
common line69: model saved with val loss 0.5882496992126107

Epoch: 15, 
Train Loss: 0.922494581642271, 
Validation Loss: 0.5835381466895342
Elapsed time for epoch-15: 3.642092704772949
common line69: model saved with val loss 0.5835381466895342

Epoch: 16, 
Train Loss: 0.9214671360594886, 
Validation Loss: 0.5806859373115003
Elapsed time for epoch-16: 3.4539618492126465
common line69: model saved with val loss 0.5806859373115003

Epoch: 17, 
Train Loss: 0.9212408679373124, 
Validation Loss: 0.5813206322491169
Elapsed time for epoch-17: 3.4202940464019775

Epoch: 18, 
Train Loss: 0.9206198661768136, 
Validation Loss: 0.5809903549961746
Elapsed time for epoch-18: 3.309581756591797

Epoch: 19, 
Train Loss: 0.9201771005862901, 
Validation Loss: 0.5840235040523112
Elapsed time for epoch-19: 3.5744307041168213

Epoch: 20, 
Train Loss: 0.9197509554253906, 
Validation Loss: 0.5738746398128569
Elapsed time for epoch-20: 3.6246237754821777
common line69: model saved with val loss 0.5738746398128569

Epoch: 21, 
Train Loss: 0.9193130357175314, 
Validation Loss: 0.5782585251145065
Elapsed time for epoch-21: 3.709135055541992

Epoch: 22, 
Train Loss: 0.9188939426876918, 
Validation Loss: 0.5752907325513661
Elapsed time for epoch-22: 3.433335542678833

Epoch: 23, 
Train Loss: 0.9188446190928211, 
Validation Loss: 0.5754316607490182
Elapsed time for epoch-23: 4.045333623886108

Epoch: 24, 
Train Loss: 0.9182730720323675, 
Validation Loss: 0.5808950602076948
Elapsed time for epoch-24: 3.36995530128479

Epoch: 25, 
Train Loss: 0.9175941648603487, 
Validation Loss: 0.5750812785699964
Elapsed time for epoch-25: 3.7520041465759277

Epoch: 26, 
Train Loss: 0.917476846891291, 
Validation Loss: 0.5778450756333768
Elapsed time for epoch-26: 3.4178261756896973

Epoch: 27, 
Train Loss: 0.9169948683315966, 
Validation Loss: 0.5765189779922366
Elapsed time for epoch-27: 3.0473549365997314

Epoch: 28, 
Train Loss: 0.9169144963516909, 
Validation Loss: 0.5709470808506012
Elapsed time for epoch-28: 3.5124588012695312
common line69: model saved with val loss 0.5709470808506012

Epoch: 29, 
Train Loss: 0.9165285357407161, 
Validation Loss: 0.5727425231598318
Elapsed time for epoch-29: 3.103254556655884

Epoch: 30, 
Train Loss: 0.9160392861656782, 
Validation Loss: 0.5743786878883839
Elapsed time for epoch-30: 3.1760356426239014

Epoch: 31, 
Train Loss: 0.9158494317231058, 
Validation Loss: 0.5787478531710804
Elapsed time for epoch-31: 3.1970107555389404

train line101: min loss for the epoch 31 is 0.5709470808506012

Training the 103-th turbine in 191.02458906173706 secs

>>>>>>>>> Training Turbine 104 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp  ...   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN  ...    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  ...  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  ...  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  ...  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  ...  20.91   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.9215073585510254
lalalalalal
260 [[ 1.          0.07413616 -0.00848211 -0.35196632  0.35506176]
 [ 0.99904822  0.14261916  0.03403262  0.36266329  0.06898094]
 [ 0.9961947   0.05227989  0.04617968  0.36049577 -0.01768566]
 [ 0.99144486  0.02896653  0.02842628  0.35529374 -0.02940002]
 [ 0.98480775 -0.04097356 -0.10269974  0.3500917  -0.15111145]]
hahahahahahah
265 [[ 0.99985184  1.          0.07413616 -0.00848211 -0.35196632  0.35506176]
 [ 0.99985184  0.99904822  0.14261916  0.03403262  0.36266329  0.06898094]
 [ 0.99985184  0.9961947   0.05227989  0.04617968  0.36049577 -0.01768566]
 [ 0.99985184  0.99144486  0.02896653  0.02842628  0.35529374 -0.02940002]
 [ 0.99985184  0.98480775 -0.04097356 -0.10269974  0.3500917  -0.15111145]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.07413616 -0.00848211 -0.35196632  0.35506176]
 [ 0.99985184  0.99904822  0.14261916  0.03403262  0.36266329  0.06898094]
 [ 0.99985184  0.9961947   0.05227989  0.04617968  0.36049577 -0.01768566]
 [ 0.99985184  0.99144486  0.02896653  0.02842628  0.35529374 -0.02940002]
 [ 0.99985184  0.98480775 -0.04097356 -0.10269974  0.3500917  -0.15111145]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp  ...   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN  ...    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  ...  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  ...  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  ...  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  ...  20.91   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 3.0999574661254883
lalalalalal
260 [[ 1.         -0.32656224 -0.10815035 -0.99290042 -0.32877921]
 [ 0.99904822 -0.27702135 -0.13041997 -0.99506794 -0.26184529]
 [ 0.9961947  -0.46061407 -0.07404513 -1.00070348 -0.37221074]
 [ 0.99144486 -0.25953633 -0.19271262 -1.00287099 -0.22166774]
 [ 0.98480775 -0.05554441 -0.16343507 -1.00287099 -0.07755904]]
hahahahahahah
265 [[-0.84754092  1.         -0.32656224 -0.10815035 -0.99290042 -0.32877921]
 [-0.84754092  0.99904822 -0.27702135 -0.13041997 -0.99506794 -0.26184529]
 [-0.84754092  0.9961947  -0.46061407 -0.07404513 -1.00070348 -0.37221074]
 [-0.84754092  0.99144486 -0.25953633 -0.19271262 -1.00287099 -0.22166774]
 [-0.84754092  0.98480775 -0.05554441 -0.16343507 -1.00287099 -0.07755904]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.32656224 -0.10815035 -0.99290042 -0.32877921]
 [-0.84754092  0.99904822 -0.27702135 -0.13041997 -0.99506794 -0.26184529]
 [-0.84754092  0.9961947  -0.46061407 -0.07404513 -1.00070348 -0.37221074]
 [-0.84754092  0.99144486 -0.25953633 -0.19271262 -1.00287099 -0.22166774]
 [-0.84754092  0.98480775 -0.05554441 -0.16343507 -1.00287099 -0.07755904]]

Epoch: 0, 
Train Loss: 0.987362330575951, 
Validation Loss: 0.6488734809681773
Elapsed time for epoch-0: 3.6725914478302
common line69: model saved with val loss 0.6488734809681773

Epoch: 1, 
Train Loss: 0.9456126519611904, 
Validation Loss: 0.6424412028864026
Elapsed time for epoch-1: 3.645881175994873
common line69: model saved with val loss 0.6424412028864026

Epoch: 2, 
Train Loss: 0.9374688074869268, 
Validation Loss: 0.6374834692105651
Elapsed time for epoch-2: 3.559809923171997
common line69: model saved with val loss 0.6374834692105651

Epoch: 3, 
Train Loss: 0.9321534147783488, 
Validation Loss: 0.6383264474570751
Elapsed time for epoch-3: 3.831022024154663

Epoch: 4, 
Train Loss: 0.9287935986238367, 
Validation Loss: 0.6335236867889762
Elapsed time for epoch-4: 3.9054806232452393
common line69: model saved with val loss 0.6335236867889762

Epoch: 5, 
Train Loss: 0.9258603015366722, 
Validation Loss: 0.6312365662306547
Elapsed time for epoch-5: 3.518481731414795
common line69: model saved with val loss 0.6312365662306547

Epoch: 6, 
Train Loss: 0.9233880324774429, 
Validation Loss: 0.6339841154403985
Elapsed time for epoch-6: 3.478036403656006

Epoch: 7, 
Train Loss: 0.9219612351485661, 
Validation Loss: 0.6245786785148084
Elapsed time for epoch-7: 3.470202684402466
common line69: model saved with val loss 0.6245786785148084

Epoch: 8, 
Train Loss: 0.9200509764066264, 
Validation Loss: 0.6314518563449383
Elapsed time for epoch-8: 3.5981733798980713

Epoch: 9, 
Train Loss: 0.918642596161666, 
Validation Loss: 0.6255280850455165
Elapsed time for epoch-9: 3.668886184692383

Epoch: 10, 
Train Loss: 0.9172810698006334, 
Validation Loss: 0.6228994741104543
Elapsed time for epoch-10: 3.5826823711395264
common line69: model saved with val loss 0.6228994741104543

Epoch: 11, 
Train Loss: 0.9160990408238243, 
Validation Loss: 0.6285257101990283
Elapsed time for epoch-11: 3.306314706802368

Epoch: 12, 
Train Loss: 0.9152373791742725, 
Validation Loss: 0.6257077557966113
Elapsed time for epoch-12: 3.9548604488372803

Epoch: 13, 
Train Loss: 0.914118758019279, 
Validation Loss: 0.6222051619552076
Elapsed time for epoch-13: 3.489915370941162
common line69: model saved with val loss 0.6222051619552076

Epoch: 14, 
Train Loss: 0.9132978028359533, 
Validation Loss: 0.6254307366907597
Elapsed time for epoch-14: 3.864123821258545

Epoch: 15, 
Train Loss: 0.9124293165797946, 
Validation Loss: 0.6246210457757115
Elapsed time for epoch-15: 3.411801815032959

Epoch: 16, 
Train Loss: 0.911764693986468, 
Validation Loss: 0.6232419302687049
Elapsed time for epoch-16: 3.5846142768859863

Epoch: 17, 
Train Loss: 0.9107830901356304, 
Validation Loss: 0.6265956927090883
Elapsed time for epoch-17: 3.767643451690674

Epoch: 18, 
Train Loss: 0.9103525796858203, 
Validation Loss: 0.6187970004975796
Elapsed time for epoch-18: 3.9172868728637695
common line69: model saved with val loss 0.6187970004975796

Epoch: 19, 
Train Loss: 0.90973509710376, 
Validation Loss: 0.6212357906624675
Elapsed time for epoch-19: 3.091473340988159

Epoch: 20, 
Train Loss: 0.9090653249696523, 
Validation Loss: 0.6216056859120727
Elapsed time for epoch-20: 3.1743979454040527

Epoch: 21, 
Train Loss: 0.9086781415869208, 
Validation Loss: 0.6177619588561356
Elapsed time for epoch-21: 3.051729440689087
common line69: model saved with val loss 0.6177619588561356

Epoch: 22, 
Train Loss: 0.9082489742451355, 
Validation Loss: 0.6224529147148132
Elapsed time for epoch-22: 3.349382162094116

Epoch: 23, 
Train Loss: 0.9079438536858359, 
Validation Loss: 0.6201952048577368
Elapsed time for epoch-23: 3.1187002658843994

Epoch: 24, 
Train Loss: 0.907652617753053, 
Validation Loss: 0.6189033621922135
Elapsed time for epoch-24: 2.9682159423828125

Epoch: 25, 
Train Loss: 0.9073227397283586, 
Validation Loss: 0.6176863792352378
Elapsed time for epoch-25: 3.1512231826782227
common line69: model saved with val loss 0.6176863792352378

Epoch: 26, 
Train Loss: 0.907021401058726, 
Validation Loss: 0.6142476233653724
Elapsed time for epoch-26: 3.0195367336273193
common line69: model saved with val loss 0.6142476233653724

Epoch: 27, 
Train Loss: 0.9064675433044674, 
Validation Loss: 0.6156854233704507
Elapsed time for epoch-27: 3.1983935832977295

Epoch: 28, 
Train Loss: 0.9063148836628729, 
Validation Loss: 0.6126472423784435
Elapsed time for epoch-28: 3.0533573627471924
common line69: model saved with val loss 0.6126472423784435

Epoch: 29, 
Train Loss: 0.9061496793722906, 
Validation Loss: 0.6133595872670412
Elapsed time for epoch-29: 2.9977006912231445

Epoch: 30, 
Train Loss: 0.9059357043324399, 
Validation Loss: 0.6104226382449269
Elapsed time for epoch-30: 3.1887762546539307
common line69: model saved with val loss 0.6104226382449269

Epoch: 31, 
Train Loss: 0.9056203861196502, 
Validation Loss: 0.6088762362487614
Elapsed time for epoch-31: 3.021742820739746
common line69: model saved with val loss 0.6088762362487614

train line101: min loss for the epoch 31 is 0.6088762362487614

Training the 104-th turbine in 188.8675537109375 secs

>>>>>>>>> Training Turbine 105 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp  ...   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN  ...    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  ...  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  ...  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  ...  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  ...  20.91   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 2.8826382160186768
lalalalalal
260 [[ 1.          0.36939994 -0.00245402 -0.70881842  0.37834927]
 [ 0.99904822  0.09423863  0.09734996  0.52756814  0.02449504]
 [ 0.9961947  -0.03054383  0.03850258  0.52610236 -0.10681638]
 [ 0.99144486  0.00465123  0.02282966  0.51730767 -0.0846001 ]
 [ 0.98480775 -0.12972988 -0.08481078  0.5070472  -0.2364113 ]]
hahahahahahah
265 [[ 0.99985184  1.          0.36939994 -0.00245402 -0.70881842  0.37834927]
 [ 0.99985184  0.99904822  0.09423863  0.09734996  0.52756814  0.02449504]
 [ 0.99985184  0.9961947  -0.03054383  0.03850258  0.52610236 -0.10681638]
 [ 0.99985184  0.99144486  0.00465123  0.02282966  0.51730767 -0.0846001 ]
 [ 0.99985184  0.98480775 -0.12972988 -0.08481078  0.5070472  -0.2364113 ]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.36939994 -0.00245402 -0.70881842  0.37834927]
 [ 0.99985184  0.99904822  0.09423863  0.09734996  0.52756814  0.02449504]
 [ 0.99985184  0.9961947  -0.03054383  0.03850258  0.52610236 -0.10681638]
 [ 0.99985184  0.99144486  0.00465123  0.02282966  0.51730767 -0.0846001 ]
 [ 0.99985184  0.98480775 -0.12972988 -0.08481078  0.5070472  -0.2364113 ]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp  ...   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN  ...    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  ...  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  ...  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  ...  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  ...  20.91   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 3.1529295444488525
lalalalalal
260 [[ 1.         -0.36649659 -0.13996172 -1.78836638 -0.32102196]
 [ 0.99904822 -0.37929479 -0.05109921 -1.79203084 -0.27829364]
 [ 0.9961947  -0.50087769 -0.04991635 -1.79642818 -0.50972541]
 [ 0.99144486 -0.28330828 -0.17382114 -1.80448998 -0.23469481]
 [ 0.98480775 -0.07853708 -0.18742405 -1.8103531  -0.09019095]]
hahahahahahah
265 [[-0.84754092  1.         -0.36649659 -0.13996172 -1.78836638 -0.32102196]
 [-0.84754092  0.99904822 -0.37929479 -0.05109921 -1.79203084 -0.27829364]
 [-0.84754092  0.9961947  -0.50087769 -0.04991635 -1.79642818 -0.50972541]
 [-0.84754092  0.99144486 -0.28330828 -0.17382114 -1.80448998 -0.23469481]
 [-0.84754092  0.98480775 -0.07853708 -0.18742405 -1.8103531  -0.09019095]]

 wind turbine line248 data after normalization: 
 [[-0.84754092  1.         -0.36649659 -0.13996172 -1.78836638 -0.32102196]
 [-0.84754092  0.99904822 -0.37929479 -0.05109921 -1.79203084 -0.27829364]
 [-0.84754092  0.9961947  -0.50087769 -0.04991635 -1.79642818 -0.50972541]
 [-0.84754092  0.99144486 -0.28330828 -0.17382114 -1.80448998 -0.23469481]
 [-0.84754092  0.98480775 -0.07853708 -0.18742405 -1.8103531  -0.09019095]]

Epoch: 0, 
Train Loss: 1.0052655364284997, 
Validation Loss: 0.6275212219916284
Elapsed time for epoch-0: 3.603339910507202
common line69: model saved with val loss 0.6275212219916284

Epoch: 1, 
Train Loss: 0.956579066875602, 
Validation Loss: 0.6142845433205366
Elapsed time for epoch-1: 3.6555709838867188
common line69: model saved with val loss 0.6142845433205366

Epoch: 2, 
Train Loss: 0.9458300759311483, 
Validation Loss: 0.6049144985154271
Elapsed time for epoch-2: 3.8240127563476562
common line69: model saved with val loss 0.6049144985154271

Epoch: 3, 
Train Loss: 0.9407759708266298, 
Validation Loss: 0.6068159276619554
Elapsed time for epoch-3: 3.5955705642700195

Epoch: 4, 
Train Loss: 0.9371403792575628, 
Validation Loss: 0.6089840908534825
Elapsed time for epoch-4: 3.5263116359710693

Epoch: 5, 
Train Loss: 0.9348996533315723, 
Validation Loss: 0.6054065283387899
Elapsed time for epoch-5: 3.660153865814209

Epoch: 6, 
Train Loss: 0.9329541646131948, 
Validation Loss: 0.5969570875167847
Elapsed time for epoch-6: 3.5323233604431152
common line69: model saved with val loss 0.5969570875167847

Epoch: 7, 
Train Loss: 0.9311248999433357, 
Validation Loss: 0.6104646194726229
Elapsed time for epoch-7: 3.504950523376465

Epoch: 8, 
Train Loss: 0.9297487433968472, 
Validation Loss: 0.5922962045297027
Elapsed time for epoch-8: 3.5807085037231445
common line69: model saved with val loss 0.5922962045297027

Epoch: 9, 
Train Loss: 0.928800610809767, 
Validation Loss: 0.5868325978517532
Elapsed time for epoch-9: 3.8016157150268555
common line69: model saved with val loss 0.5868325978517532

Epoch: 10, 
Train Loss: 0.9276196405667216, 
Validation Loss: 0.5917389360256493
Elapsed time for epoch-10: 3.6830313205718994

Epoch: 11, 
Train Loss: 0.9267691981141307, 
Validation Loss: 0.5933767673559487
Elapsed time for epoch-11: 3.9854729175567627

Epoch: 12, 
Train Loss: 0.9258299469947815, 
Validation Loss: 0.5886766593903303
Elapsed time for epoch-12: 3.399153709411621

Epoch: 13, 
Train Loss: 0.9247146459186778, 
Validation Loss: 0.586973890196532
Elapsed time for epoch-13: 3.3956146240234375

Epoch: 14, 
Train Loss: 0.9237800402050259, 
Validation Loss: 0.5764608085155487
Elapsed time for epoch-14: 3.5548179149627686
common line69: model saved with val loss 0.5764608085155487

Epoch: 15, 
Train Loss: 0.9231397877721226, 
Validation Loss: 0.5771328010596335
Elapsed time for epoch-15: 3.387688159942627

Epoch: 16, 
Train Loss: 0.9222377628839317, 
Validation Loss: 0.5807296042330563
Elapsed time for epoch-16: 3.30081844329834

Epoch: 17, 
Train Loss: 0.9216452120732861, 
Validation Loss: 0.584010670427233
Elapsed time for epoch-17: 3.051854133605957

Epoch: 18, 
Train Loss: 0.921270671136239, 
Validation Loss: 0.5847398652695119
Elapsed time for epoch-18: 3.2192182540893555

Epoch: 19, 
Train Loss: 0.9206901355450895, 
Validation Loss: 0.5734769483096898
Elapsed time for epoch-19: 3.0684220790863037
common line69: model saved with val loss 0.5734769483096898

Epoch: 20, 
Train Loss: 0.920080563976985, 
Validation Loss: 0.5784053420647979
Elapsed time for epoch-20: 2.929965019226074

Epoch: 21, 
Train Loss: 0.919758653690835, 
Validation Loss: 0.5774142970331013
Elapsed time for epoch-21: 3.0985031127929688

Epoch: 22, 
Train Loss: 0.9195855378854174, 
Validation Loss: 0.5728278462775052
Elapsed time for epoch-22: 3.0583953857421875
common line69: model saved with val loss 0.5728278462775052

Epoch: 23, 
Train Loss: 0.9190940706669783, 
Validation Loss: 0.5686799944378436
Elapsed time for epoch-23: 3.045989751815796
common line69: model saved with val loss 0.5686799944378436

Epoch: 24, 
Train Loss: 0.9185596287500959, 
Validation Loss: 0.5711979861371219
Elapsed time for epoch-24: 3.1253974437713623

Epoch: 25, 
Train Loss: 0.9184614215828791, 
Validation Loss: 0.5672871442511678
Elapsed time for epoch-25: 3.037712812423706
common line69: model saved with val loss 0.5672871442511678

Epoch: 26, 
Train Loss: 0.9183435248477119, 
Validation Loss: 0.5735159595496953
Elapsed time for epoch-26: 3.1685829162597656

Epoch: 27, 
Train Loss: 0.9179987331398395, 
Validation Loss: 0.5660632401704788
Elapsed time for epoch-27: 3.1895995140075684
common line69: model saved with val loss 0.5660632401704788

Epoch: 28, 
Train Loss: 0.917636774417733, 
Validation Loss: 0.5714291417971253
Elapsed time for epoch-28: 2.9094860553741455

Epoch: 29, 
Train Loss: 0.9173245055585348, 
Validation Loss: 0.5691136107780039
Elapsed time for epoch-29: 3.173464059829712

Epoch: 30, 
Train Loss: 0.9168217882138341, 
Validation Loss: 0.5715932617895305
Elapsed time for epoch-30: 3.043440103530884

Epoch: 31, 
Train Loss: 0.9170595943426886, 
Validation Loss: 0.5646231505088508
Elapsed time for epoch-31: 3.4344165325164795
common line69: model saved with val loss 0.5646231505088508

train line101: min loss for the epoch 31 is 0.5646231505088508

Training the 105-th turbine in 189.83283281326294 secs

>>>>>>>>> Training Turbine 106 >>>>>>>>>>>>>>>>>>>>>>>>>>

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp  ...   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN  ...    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  ...  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  ...  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  ...  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  ...  20.91   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]
wind turbine line234: Elapsed time for processing time stamp 3.0666983127593994
lalalalalal
260 [[ 1.          0.19516281 -0.05935911 -0.54852375  0.38305639]
 [ 0.99904822  0.20383107 -0.14503282  0.46766125  0.01458214]
 [ 0.9961947   0.05647076 -0.19846374  0.46356923 -0.14730626]
 [ 0.99144486  0.09981203 -0.20982549  0.45538519 -0.12721916]
 [ 0.98480775 -0.04465886 -0.2168882   0.44788315 -0.24800926]]
hahahahahahah
265 [[ 0.99985184  1.          0.19516281 -0.05935911 -0.54852375  0.38305639]
 [ 0.99985184  0.99904822  0.20383107 -0.14503282  0.46766125  0.01458214]
 [ 0.99985184  0.9961947   0.05647076 -0.19846374  0.46356923 -0.14730626]
 [ 0.99985184  0.99144486  0.09981203 -0.20982549  0.45538519 -0.12721916]
 [ 0.99985184  0.98480775 -0.04465886 -0.2168882   0.44788315 -0.24800926]]

 wind turbine line248 data after normalization: 
 [[ 0.99985184  1.          0.19516281 -0.05935911 -0.54852375  0.38305639]
 [ 0.99985184  0.99904822  0.20383107 -0.14503282  0.46766125  0.01458214]
 [ 0.99985184  0.9961947   0.05647076 -0.19846374  0.46356923 -0.14730626]
 [ 0.99985184  0.99144486  0.09981203 -0.20982549  0.45538519 -0.12721916]
 [ 0.99985184  0.98480775 -0.04465886 -0.2168882   0.44788315 -0.24800926]]

 train line60 ************** train loading finished**************** 

wind turbine 200: <<<<<<the original dataset is>>>>>
    TurbID  Day Tmstamp  Wspd  Wdir   Etmp  ...   Ndir  Pab1  Pab2  Pab3  Prtv    Patv
0       1    1   00:00   NaN   NaN    NaN  ...    NaN   NaN   NaN   NaN   NaN     NaN
1       1    1   00:10  6.17 -3.99  30.73  ...  25.92   1.0   1.0   1.0 -0.25  494.66
2       1    1   00:20  6.27 -2.18  30.60  ...  20.91   1.0   1.0   1.0 -0.24  509.76
3       1    1   00:30  6.42 -0.73  30.52  ...  20.91   1.0   1.0   1.0 -0.26  542.53
4       1    1   00:40  6.25  0.89  30.49  ...  20.91   1.0   1.0   1.0 -0.23  509.36

[5 rows x 13 columns]